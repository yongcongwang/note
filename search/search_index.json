{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-my-blog","title":"Welcome to my blog","text":"<p>I'm yongcong.wang, an algorithm engineer focusing on <code>PnC</code> of self-driving technique.</p> <p>This is the website I used to take notes while learning or working. And the source files of all the posts are in note.</p> <p>More about me:</p> <ul> <li>Email</li> <li>Github</li> <li>Leetcode</li> <li>Bilibili</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/","title":"Algorithm Pattern","text":""},{"location":"Coding/Algorithm/00_pattern/#basic-algorithm","title":"Basic Algorithm","text":""},{"location":"Coding/Algorithm/00_pattern/#sort","title":"Sort","text":""},{"location":"Coding/Algorithm/00_pattern/#quick-sort","title":"Quick Sort","text":"<pre><code>void quick_sort(int a[], int l , int r) {\n  if (l &gt;= r) return;\n\n  int i = l - 1, j = r + 1, p = a[l + r &gt;&gt; 1];\n  while (i &lt; j) {\n    while (a[++i] &lt; p);\n    while (a[--j] &gt; p);\n    if (i &lt; j) swap(a[i], a[j]);\n  }\n  quick_sort(a, l, j);\n  quick_sort(a, j + 1, r);\n}\n</code></pre>"},{"location":"Coding/Algorithm/00_pattern/#merge-sort","title":"Merge Sort","text":"<pre><code>int tmp[N];\nvoid merge_sort(int a[], int l, int r) {\n  if (l &gt;= r) return;\n\n  int mid = l + r &gt;&gt; 1;\n  merge_sort(a, l, mid);\n  merge_sort(a, mid + 1, r);\n\n  int i = l, j = mid + 1, k = l;\n  while (i &lt;= mid &amp;&amp; j &lt;= r) tmp[k++] = a[i] &lt; a[j] ? a[i++] : a[j++];\n  while (i &lt;= mid) tmp[k++] = a[i++];\n  while (j &lt;= r) tmp[k++] = a[j++];\n\n  for (int k = l; k &lt;= r; ++k) a[k] = tmp[k];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#serach","title":"Serach","text":""},{"location":"Coding/Algorithm/00_pattern/#binary-search","title":"Binary Search","text":"<pre><code>//           Left                             Right\n// |---------------------------| |------------------------------|\n//                   right end | | left end\n\n// Left end\n// Devide [l, r] to [l, mid] + [mid + 1, r], l locates at mid + 1\nint bs(int a[], int l, int r) {\n  while (l &lt; r) {\n    int mid = l + r &gt;&gt; 1;\n    if (resultl_is_in(mid)) {\n      r = mid;\n    } else {\n      l = mid + 1;\n    }\n  }\n  return l;\n}\n\n// Right end\n// Devide [l, r] to [l, mid - 1] + [mid, r], l locates at mid\nint bs(int a[], int l, int r) {\n  while (l &lt; r) {\n    // avoid the case [l, r] = [0, 1]\n    int mid = l + r + 1 &gt;&gt; 1;\n    if (is_result_in(mid)) {\n      l = mid;\n    } else {\n      r = mid - 1;\n    }\n  }\n  return l;\n}\n\n/// Float\nconstexpr double eps = 1e-6;\ndouble bs(double l, double r) {\n  while (r - l &gt; eps) {\n    double mid = (l + r) / 2;\n    if (Valid(mid)) {\n      r = mid;\n    } else {\n      l = mid;\n    }\n  }\n  return l;\n}\n</code></pre> <ul> <li>problem</li> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#prefix","title":"Prefix","text":""},{"location":"Coding/Algorithm/00_pattern/#prefix-sum","title":"Prefix Sum","text":"<pre><code>for (int i = 1; i &lt;= n; ++i) p[i] = p[i - 1] + a[i - 1];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#prefix-sum-2d","title":"Prefix Sum 2D","text":"<pre><code>for (int i = 1; i &lt;= n; ++i) for (int j = 1; j &lt;= m; ++j)\n    p[i][j] = a[i - 1][j - 1] + p[i][j - 1] + p[i - 1][j] - p[i - 1][j - 1];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#prefix-diff","title":"Prefix Diff","text":"<pre><code>void insert(int p[], int l, int r, int c) {\n  p[l] += c;\n  p[r + 1] -= c;\n}\n\n/// get each element\nfor (int i = 1; i &lt;= n; ++i) p[i] += p[i - 1];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#prefix-diff-2d","title":"Prefix Diff 2D","text":"<pre><code>void insert(int p[][N], int x1, int y1, int x2, int y2, int c) {\n  p[x1][y1] += c;\n  p[x2 + 1][y1] -= c;\n  p[x1][y2 + 1] -= c;\n  p[x2 + 1][y2 + 1] += c;\n}\n\n// Get each element\nfor (int i = 1; i &lt;= n; ++i) for (int j = 1; j &lt;= m; ++j)\n  b[i][j] += b[i - 1][j] + b[i][j - 1] - b[i - 1][j - 1];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#bit-operator","title":"Bit Operator","text":""},{"location":"Coding/Algorithm/00_pattern/#k-bit","title":"K bit","text":"<pre><code>int kbit(int x, int k) { return x &gt;&gt; k &amp; 1; }\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#lowbit","title":"Lowbit","text":"<pre><code>int lowbit(int x) { return x &amp; -x; }\n</code></pre>"},{"location":"Coding/Algorithm/00_pattern/#two-pointers","title":"Two Pointers","text":"<pre><code>/// 1 array\n/// nnnnnnnnnnnnnnnnnnnnnn\n///     ^          ^\n///     | j        | i    \n/// 2 array\n/// nnnnnnnnnnnnnnnnnnnnnn\n///     ^           \n///     | i               \n/// nnnnnnnnnnnnnnnnnnnnnn\n///                ^\n///                | j    \nfor (int i = 0, j = 0; i &lt; n; ++i) {\n  // add i here\n\n  while (j &lt; i &amp;&amp; check(i, j)) ++j;  // remove j\n\n  // record answer here\n}\n</code></pre> <ul> <li>problem</li> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#discrete","title":"Discrete","text":"<pre><code>vector&lt;int&gt; a{};  // to be discrete\nsort(a.begin(), a.end());\na.erase(unique(a.begin(), a.end()), a.end());\n\n// get index after discrete\nint find(int x) {\n  int l = 0, r = a.size() - 1;\n  while (l &lt; r) {\n    int mid = l + (r - l) / 2;\n    if (a[mid] &gt;= x) {\n      r = mid;\n    } else {\n      l = mid + 1;\n    }\n  }\n  return l;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#merge-range","title":"Merge Range","text":"<pre><code>using PII = pair&lt;int, int&gt;;\nvoid merge(vector&lt;PII&gt; &amp;segs) {\n  sort(segs.begin(), segs.end());\n\n  vector&lt;PII&gt; ans{};\n  for (auto [l, r] : segs) {\n    if (ans.emtpy() || ans.back().second &lt; l) {\n      ans.push_back({l, r});\n    } else {\n      ans.back().second = max(ans.back().second, r);\n    }\n  }\n\n  return ans;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#data-structure","title":"Data Structure","text":""},{"location":"Coding/Algorithm/00_pattern/#linked-list","title":"Linked List","text":"<pre><code>// head index , element, next element index, index to empty memory\nint head, e[N], ne[N], idx;\n\nvoid init() {\n  head = -1;\n  idx = 0;\n}\n\n// add a node with value of v to head\nvoid to_head(int v) {\n  e[idx] = v, ne[idx] = head, head = idx++;\n}\n\n// remove node after ith node\nvoid remove(int i) {\n  ne[i] = ne[ne[i]];\n}\n\n// insert a node with value of v after kth node\nvoid insert(int k, int v) {\n  e[idx] = v, ne[idx] = ne[k], ne[k] = idx++;\n}\n\n// traval the linked list\nfor (int i = head; i != -1; i = ne[i]) cout &lt;&lt; e[i];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#double-linked-list","title":"Double Linked List","text":"<pre><code>// 0 for head, 1 for tail, range: (0, 1)\nint e[N], l[N] = {0}, r[N] = {1}, idx = 2;\n\n// insert a node at i's right\nvoid insert(int i, int v) {\n  e[idx] = v, l[idx] = i, r[idx] = r[i];\n  l[r[idx]] = idx, r[l[idx]] = idx;\n  ++idx;\n}\n\n// remove i node\nvoid remove(int i) {\n  r[l[i]] = r[i];\n  l[r[i]] = l[i];\n}\n\n// travel\nfor (int i = r[0]; i != 1; i = r[i]) cout &lt;&lt; e[i];\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#stack","title":"Stack","text":"<pre><code>// index 0 for empty, range: (0, idx]\nint stk[N], idx = 0;\n\nvoid push(int x) { stk[++idx] = x; }\nvoid pop() { --idx; }\nint top() { return stk[idx]; }\nbool empty() { return idx == 0; }\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#queue","title":"Queue","text":"<pre><code>/// range: [h, t)\nint q[N], h = 0, t = 0;\n\nvoid push(int x) { q[t++ % N] = x; }\nvoid pop() { h = ++h % N; }\nvoid front() { return q[h]; }\nbool empty() { return h == t; }\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#monotonous-stack","title":"Monotonous stack","text":"<pre><code>/// range: (0, t]\nint stk[N], t = 0;\n\nfor (auto n : a) {\n  while (t &amp;&amp; stk[t] &gt;= n) --t;\n  stk[++t] = n;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#monotonous-queue","title":"Monotonous queue","text":"<pre><code>/// h for head of queue, t for tail, k for window size\n/// nnnnnnnnnnnnnnnnnnnnnn\n///     ^          ^\n///     | h        | t    \nint a[N], q[N];\n\nfor (int i = 0; i &lt; n; ++i) {\n  if (h &lt;= t &amp;&amp; i - q[h] + 1 &gt; k) ++h;\n  while (h &lt;=t &amp;&amp; a[q[t]] &gt;= a[i]) --t;\n  q[++t] = i;\n  /// Check min value of the window\n  printf(\"min value %d\", a[q[h]]);\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#kmp","title":"KMP","text":"<pre><code>char s[N], p[M], ne[N];\n\nfor (int i = 2, j = 0; i &lt;= m; ++i) {\n  while (j &amp;&amp; p[j + 1] != p[i]) j = ne[j];\n  if (p[j + 1] == p[i]) ++j;\n  ne[i] = j;\n}\n\nfor (int i = 1, j = 0; i &lt;= n; ++i) {\n  while (j &amp;&amp; p[j + 1] != s[i]) j = ne[j];\n  if (p[j + 1] == s[i]) ++j;\n  if (j == m) {\n    /// do something\n    j = ne[j];\n  }\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#trie","title":"Trie","text":"<pre><code>int son[N][26], cnt[N], idx;\n\nvoid insert(char str[]) {\n  int p = 0;\n  for (int i = 0; str[i]; ++i) {\n    int u = str[i] - 'a';\n    if (!son[p][u]) son[p][u] = ++idx;\n    p = son[p][u];\n  }\n  ++cnt[p];\n}\n\n/// return count of the str\nint query(char str[]) {\n  int p = 0;\n  for (int i = 0; str[i]; ++i) {\n    int u = str[i] - 'a';\n    if (!son[p][u]) return 0;\n    p = son[p][u];\n  }\n\n  return cnt[p];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#union","title":"Union","text":"<pre><code>/// origin Union, p for parent\nint p[N]\n\n// find parent\nint find(int x) {\n  if (p[x] != x) p[x] = find(p[x]);\n  return p[x];\n}\n\n// init\nfor (int i = 1; i &lt;= n; ++i) p[i] = i;\n\n// merge\np[find(a)] = find(b);\n\n/// Union with size\nint p[N], size[N];\n\n// find parent\nint find(int x) {\n  if (p[x] != x) p[x] = find(p[x]);\n  return p[x];\n}\n\n// init\nfor (int i = 1; i &lt;= n; ++i) p[i] = i;\nfor (int i = 1; i &lt;= n; ++i) size[i] = 1;\n\n// merge\nsize[find(a)] += size[find(b)];  // this must execute first\np[find(a)] = find(b);\n</code></pre> <ul> <li>problem</li> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#heap","title":"Heap","text":"<pre><code>/// Minimum root heap\nint h[N], size;\n\nvoid down(int x) {\n  int u = x;\n  if (auto left = x * 2; left &lt;= size &amp;&amp; h[left] &lt; h[u]) u = left; \n  if (auto right = x * 2 + 1; right &lt;= size &amp;&amp; h[right ] &lt; h[u]) u = right; \n  if (u != x) {\n    swap(h[u], h[x]);\n    down(u);\n  }\n}\n\nvoid up(int x) {\n  while (x / 2 &amp;&amp; h[x / 2] &gt; h[x]) {\n    swap(h[x / 2], h[x]);\n    x &gt;&gt;= 1;\n  }\n}\n\n/// O(N) build heap\nfor (int i = n / 2; i; --i) down(i);\n\n/// Insert a number\nh[++size] = x; up(size);\n\n/// Get minimum\nhead[1];\n\n/// Remove minimum(root)\nswap(h[1], head[size--]); down(1);\n\n/// Remove kth element\nhead[k] = head[size--]; down(k); up(k);\n\n/// Modify kth element\nhead[k] = x; down(k); up(k);\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#hash-table","title":"Hash table","text":"<pre><code>/// Integar Hash\n\n/// Seperate chaining\nconstexpr int N = 1e5 + 10;  // first prime number after length(1e5)\nint h[N], e[N], ne[N], idx;  // h[n] for chain head ptr, e[n] for element, ne[n] for next ptr, idx for ptr\n\n// init\nmemset(h, -1, sizeof(h));\n\nvoid insert(int x) {\n  int k = (x % N + N) % N;  // key, range in [0, N - 1]\n  e[idx] = x;\n  ne[idx] = h[k];\n  h[k] = idx++;\n}\n\nbool find(int x) {\n  int k = (x % N + N) % N;\n  for (int i = h[k]; i != -1; i = ne[i]) if (e[i] == x) return true;\n  return false;\n}\n\n/// Open addressing\nconstexpr int N = 2e5 + 3;  // 2 or 3 times of the number range, first prime\nconstexpr int null = 0x3f3f3f3f;  // a number bigger not in range to represent the nullptr\nint h[N];\n\nmemset(h, 0x3f, sizeof(h));\n\nint find(int x) {  // return the idx x locates or should be inserted\n  int t = (x % N + N) % N;\n  while (h[t] != null &amp;&amp; h[t] != x) t %= ++t;\n  return t;\n}\nh[find(x)] = x;  // insert\nh[find(x)] == x;  // query \n</code></pre> <ul> <li>problem</li> </ul> <pre><code>/// string hash, to check if two substring on string are the same\nusing ULL = unsigned long long;  // number range [0, 2^64), overflow for mod\nconstexpr int N = 1e5 + 10, P = 131;  // P-base numeral system\nULL h[N], p[N];\n\n// init\np[0] = 1;\nfor (int i = 1; i &lt;= n; ++i) {\n  h[i] = h[i - 1] * P + str[i];  // h for hash\n  p[i] = p[i - 1] * P;  // p for P^i\n}\n\nULL get(int l, int r) {\n  return h[r] - h[l - 1] * p[r - l + 1];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#graph","title":"Graph","text":""},{"location":"Coding/Algorithm/00_pattern/#storage-of-graph","title":"Storage of Graph","text":"<pre><code>/// adjecent matrix\ng[a][b];  // for the edge a -&gt; b\n\n/// adjecent list\nint h[N], e[N], ne[N], idx;\n\n// add edge a -&gt; b\nvoid add(int a, int b) {\n  e[idx] = b, ne[idx] = h[a], h[a] = idx++;\n}\n\n// init\nidx = 0;\nmemset(h, -1, sizeof(h));\n</code></pre>"},{"location":"Coding/Algorithm/00_pattern/#dfs-of-graph","title":"DFS of graph","text":"<pre><code>int dfs(int u) {\n  st[u] = true;\n  for (int i = h[u]; i != -1; i = ne[i]) {\n    int j = e[i];\n    if (!st[j]) dfs(j);\n  }\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#bfs-of-graph","title":"BFS of graph","text":"<pre><code>queue&lt;int&gt; q{};\nst[1] = true;\nq.push(1);\n\nwhile (!q.empty()) {\n  int t = q.front();\n  q.pop();\n\n  for (int i = h[t]; i != -1; i = ne[i]) if (int j = e[i]; !st[j]) {\n    st[j] = true;\n    q.push(j);\n  }\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#toposort","title":"Toposort","text":"<pre><code>bool topsort() {\n  int hh = 0, tt = -1;\n  for (int i = 1; i &lt;= n; ++i) if (!d[i]) q[++tt] = i;\n\n  while (hh &lt;= tt) {\n    int t = q[hh++];\n    for (int i = h[t]; i != -1; i = ne[i]) {\n      if (int j = e[i]; --d[j] == 0) q[++tt] = j;\n    }\n  }\n\n  return tt == n - 1;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#shortest-pathsp","title":"Shortest Path(SP)","text":""},{"location":"Coding/Algorithm/00_pattern/#original-dijkstra","title":"Original Dijkstra","text":"<pre><code>/// for dense graph, node from 1 to n\nint g[N][N], dist[N];\nbool st[N];  // Store the node whose sp is determined\n\nint dijkstra(int u) {\n  memset(dist, 0x3f, sizeof(dist));\n  dist[u] = 0;\n\n  for (int i = 0; i &lt; n - 1; ++i) {\n    // find the node who's not in st but has minimum distance to u\n    int t = -1;\n    for (int j = 1; j &lt;= n; ++j) if (!st[j] &amp;&amp; (t == -1 || dist[j] &lt; dist[t]))\n      t = j;\n\n    // use t to update all other nodes' distance\n    for (int j = 1; j &lt;= n; ++j) dis[j] = std::min(dist[j], dist[t] + g[t][j]);\n\n    // put t to st\n    st[t] = true;\n  }\n\n  return dist[n] == INF ? -1 : dist[n];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#heap-optimal-dijkstra","title":"Heap-optimal Dijkstra","text":"<pre><code>/// for sparse graph, node from 1 to n\nusing PII = piar&lt;int, int&gt;;\nint h[N], e[M], w[M], ne[M], idx;  // e for element, c for cost, ne for next\nmemset(h, -1, sizeof(h));\nvoid add(int x, int y, int z) {\n  e[idx] = y, w[idx] = z, ne[idx] = h[x], h[x] = idx++;\n}\n\nint dist[N];\nbool st[N];\n\nint dijkstra(int u) {\n  memset(dist, 0x3f, sizeof(dist));\n  dist[u] = 0;\n\n  priority_queue&lt;PII, vector&lt;int&gt;, greater&lt;PII&gt;&gt; pq{};\n  pq.push({0, u});\n\n  while (pq.size()) {\n    auto [dis, node] = pq.top();\n    pq.pop();\n\n    if (st[node]) continue;\n    st[node] = true;\n\n    for (int i = h[node]; i != -1; i = ne[i]) {\n      int next = e[i], cost = w[i];\n      if (dist[next] &gt; dist[node] + cost) {\n        dist[next] = dist[node] + cost;\n        pq.push({dist[next], next});\n      }\n    }\n  }\n\n  return dist[n] == INF ? -1 : dist[n];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#bellman-ford","title":"Bellman-Ford","text":"<pre><code>int dist[N], back[N];\nstruct Edge { int a, b, w; } es[M];\n\nint bellman_ford(int u) {\n  memset(dist, 0x3f, sizeof(dist));\n  dist[u] = 0;\n\n  // relax k times, all sps within k edges are found\n  for (int i = 0; i &lt; k; ++i) {\n    memcpy(back, dist, sizeof(dist));\n    for (int j = 0; j &lt; m; ++j) {\n      auto [a, b, w] = es[j];\n      dist[b] = std::min(dist[b], back[a] + w);\n    }\n  }\n\n  return dist[n];\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#spfa","title":"spfa","text":"<pre><code>/// Shortest Path\nint h[N], w[N], e[N], ne[N], idx;\nvoid add(int a, int b, int c) {\n  w[idx] = c, e[idx] = b, ne[idx] = h[a], h[a] = idx++;\n}\nint dist[N];\nbool st[N];\n\nint spfa() {\n  memset(dist, 0x3f, sizeof(diat));\n  dist[0] = 0;\n  st[0] = true;\n\n  queue&lt;int&gt; q{};\n  q.push(0);\n\n  while (q.size()) {\n    auto t = q.front();\n    q.pop();\n\n    st[t] = false;\n\n    for (int i = h[t]; i != -1; i = ne[i]) {\n      int j = e[i];\n      if (dist[j] &gt; dist[t] + w[i]) {\n        dist[j] = dist[t] + w[i];\n        if (!st[j]) {\n          q.push(j);\n          st[j] = true;\n        }\n      }\n    }\n  }\n\n  return dist[n] = 0x3f3f3f3f ? -1 : dist[n];\n}\n</code></pre> <ul> <li>problem</li> </ul> <pre><code>/// Check negtive cycle\nint h[N], e[N], w[N], ne[N], idx;\nvoid add(int a, int b, int c) {\n  e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;\n}\n\nint dist[N], cnt[N];\nbool st[N];\n\nbool spfa() {\n  queue&lt;int&gt; q{};\n  for (int i = 1; i &lt;= n; ++i) {\n    st[i] = true;\n    q.push(i);\n  }\n\n  while (q.size()) {\n    auto t = q.front();\n    q.pop();\n\n    st[t] = false;\n\n    for (int i = h[i]; i != -1; i = ne[i]) {\n      int j = e[i];\n      if (dist[j] &gt; dist[t] + w[i]) {\n        dist[j] = dist[t] + w[i];\n        cnt[j] += cnt[t] + 1;\n        if (cnt[j] &gt;= n) return false;\n\n        if (!st[j]) {\n          q.push(j);\n          st[j] = true;\n        }\n      }\n    }\n  }\n\n  return false;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#floyd","title":"Floyd","text":"<pre><code>/// init\nfor (int i = 1; i &lt;=n; ++i) {\n  for (int j = 1; j &lt;= n; ++j) {\n    dist[i][j] = i == j ? 0 : INF;\n  }\n}\n\n/// Floyd\nfor (int k = 1; k &lt;= n; ++k) {\n  for (int i = 1; i &lt;= n; ++i) {\n    for (int j = 1; j &lt;= n; ++j) {\n      dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]);\n    }\n  }\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#minimum-spanning-tree","title":"Minimum Spanning Tree","text":"<p><code>Prim</code> for dense graph, <code>Kruskal</code> for sparse graph.</p>"},{"location":"Coding/Algorithm/00_pattern/#prim","title":"Prim","text":"<pre><code>int g[N][N], dist[N];\nbool st[N];\n\nint prim() {\n  int ans = 0;\n  memset(dist, 0x3f, sizeof(dist));\n  for (int i = 0; i &lt; n; ++i) {\n    int t = -1;\n    for (int j = 1; j &lt;= n; ++j) if (!st[j] &amp;&amp; (t == -1 || dist[j] &lt; dist[t]))\n      t = j;\n\n    if (i &amp;&amp; dist[t] == INF) return INF;\n    if (i) ans += dist[t];\n\n    st[t] = true;\n    for (int j = 1; j &lt;= n; ++j) dist[j] = min(dist[j], g[t][j])\n  }\n\n  return ans;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#kruskal","title":"Kruskal","text":"<pre><code>int p[N];\nint find(int x) {\n  if (p[x] != x) p[x] = find(p[x]);\n  return p[x];\n}\n\nstruct Edge {\n  int a, b, w;\n  bool operator&lt;(const Edge&amp; rhs) const { return w &lt; rhs.w; }\n} edges[M];\n\nint kruskal() {\n  sort(edges, edges + m);\n\n  int ans = 0, cnt = 0;\n  for (int i = 0; i &lt; m; ++i) {\n    auto [a, b, w] = edges[i];\n    a = find(a), b = find(b);\n    if (a != b) {\n      p[a] = b;\n      and += w;\n      ++cnt;\n    }\n  }\n\n  return cnt &lt; n - 1 ? INF : ans;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#bipartite-graph","title":"Bipartite Graph","text":""},{"location":"Coding/Algorithm/00_pattern/#coloring-check-bipartite-graph","title":"Coloring (check bipartite graph)","text":"<pre><code>int color[N];  // -1 for uncolored, 0 for white, 1 for black\n\nbool dfs(int u, int c) {\n  color[u] = c;\n  for (int i = h[u]; i != -1; i = ne[i]) {\n    int j = e[i];\n    if (color[j] == -1 &amp;&amp; !dfs(j, !c)) return false;\n    if (color[j] == c) return false;\n  }\n\n  return true;\n}\n\nfor (int i = 1; i &lt;= n; ++i) if (!dfs(i, 0)) return false;\nreturn true;\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#maximum-bipartite-matchingmbm-hungarian","title":"Maximum Bipartite Matching(MBM), Hungarian","text":"<pre><code>int match[N];  // 0 for unmatched\nbool st[N];\n\nbool find(int x) {\n  for (int i = h[x]; i != -1; i = ne[i]) {\n    int j = e[i];\n    if (!st[j]) {\n      st[j] = true;\n      if (match[j] == 0 || find(match[j])) {\n        match[j] = x;\n        return true;\n      }\n    }\n  }\n\n  return false;\n}\n\nint ans = 0;\nfor (int i = 1; i &lt;= n1; ++i) {\n  memset(st, false, sizeof(st));\n  if (find(i)) ++ans;\n}\n</code></pre> <ul> <li>problem</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#strongly-connnected-component","title":"Strongly Connnected Component","text":""},{"location":"Coding/Algorithm/00_pattern/#tarjan","title":"Tarjan","text":"<pre><code>/// dfn: timestamp to hit a node in dfs travels\n/// low: lowest timestamp a node can connect\nvoid tarjan(int u) {\n  dfn[u] = low[u] = ++ts;\n  stk[++top] = u, in_stk[u] = true;\n\n  for (int i = h[u]; ~i; i = ne[i]) {\n    int j = e[i];\n    if (!dfn[j]) {\n      tarjan(j);\n      low[u] = min(low[u], low[j]);\n    } else if (in_stk[j]) {\n      low[u] = min(low[u], dfn[j]);\n    }\n  }\n\n  if (dfn[u] == low[u]) {\n    ++scc_cnt;\n    int y;\n    do {\n      y = stk[top--];\n      in_stk[y] = false;\n      id[y] = scc_cnt;\n      scc_size[scc_cnt]++;\n    } while (y != u);\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/00_pattern/#dynamic-programingdp","title":"Dynamic Programing(DP)","text":""},{"location":"Coding/Algorithm/00_pattern/#knapsack-problem","title":"Knapsack Problem","text":"<ul> <li>01 package</li> <li>unbounded package</li> <li>bounded package</li> <li>bounded package(optimal)</li> <li>group package</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#linear-dp","title":"Linear Dp","text":""},{"location":"Coding/Algorithm/00_pattern/#grid-problems","title":"Grid problems","text":"<ul> <li>1</li> <li>2</li> <li>3</li> <li> <p>4</p> </li> <li> <p>Triangle</p> </li> <li>Longest Increasing Subsequence(LIS)</li> <li>Longest Increasing Subsequence(optimal)</li> <li>Longest Common Subsequence(LCS)</li> <li>Edit Distance</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#range-dp","title":"Range Dp","text":"<ul> <li>Merge Stone</li> </ul>"},{"location":"Coding/Algorithm/00_pattern/#count-dp","title":"Count Dp","text":""},{"location":"Coding/Algorithm/00_pattern/#digital-statistic-dp","title":"Digital Statistic Dp","text":""},{"location":"Coding/Algorithm/00_pattern/#state-compress-dp","title":"State Compress Dp","text":""},{"location":"Coding/Algorithm/00_pattern/#tree-dp","title":"Tree Dp","text":""},{"location":"Coding/Algorithm/00_pattern/#memory-search","title":"Memory Search","text":""},{"location":"Coding/Algorithm/011_slding_window/","title":"Sliding Window","text":"<p>Sliding window can also be called <code>two pointers</code>, it use two pointers to define a sub-array of the origin array and keeps the <code>loop invariant</code> while steping on. The main idea behind the sliding window technique is to convert two nested loops into a single loop. And if the problem is to check something in a sub-array, sliding windwo may be applied.</p> <p>The process of sliding window is:</p> <ol> <li>define the range \\([left, right)\\) with <code>left</code> and <code>right</code> pointers;</li> <li>determine to iterate <code>left</code> or <code>right</code> boundary and extend the other boundary;</li> <li>keep the <code>invariant</code> in loop and collect the results.</li> </ol>"},{"location":"Coding/Algorithm/011_slding_window/#fixed-size-window","title":"Fixed Size Window","text":"<p>Sometimes we have to find the minimum/maximum/average of a fixed-size window, here comes the technique that move left and right pointer equally. The general code is:</p> <pre><code>int m = arr.size(), l = 0, r = 0, sum = 0;\nwhile (r &lt; m) {\n  while (r &lt; m &amp;&amp; r - l &lt; size) sum += arr[r++];\n  // collect answers\n  sum -= arr[l++];\n}\n</code></pre> <ul> <li>Maximum Average Subarray I</li> <li>Grumpy Bookstore Owner</li> <li>Maximum Points You Can Obtain From Cards</li> <li>Maximum Number of Vowels in a Substring of Given Length</li> </ul>"},{"location":"Coding/Algorithm/011_slding_window/#flexible-size-window","title":"Flexible Size Window","text":"<p>In some situations the window size is not fixed, for example, we want to find a window whose sum is less or equal a target, the number of elements is not fixed, that's where the flexible-size window works.</p> <p>The pattern is like:</p> <pre><code>int m = arr.size(), l = 0; r = 0;\nwhile (r &lt; m) {\n  window.add(arr[r++]);\n  while (is_invalid(window)) window.remove(arr[l++]);\n  // Collect the answers here\n}\n</code></pre> <ul> <li>Minimum Operations to Reduce X to Zero</li> <li>Minimum Window Substring</li> <li>Longest Repeating Character Replacement</li> <li>Minimum Number of K consecutive bit flips</li> <li>Minimum Window Subsequence</li> <li>Find K Length Substrings with No Repeated Characters</li> <li>Minimum Swaps to Group All 1s Together</li> <li>Diet Plan Performance</li> </ul>"},{"location":"Coding/Algorithm/011_slding_window/#count-prolems-in-window","title":"Count Prolems in Window","text":"<p>Some problems also need the times of number or charactor's appearance, we can use an array or hash to store them.</p> <p>And if we want to count the number of elements in a range <code>[low, high]</code>, we can convert the problem to find the required elements less or equal to a number, and then return <code>less_or_equal(high) - less_or_equal(low - 1)</code>.</p> <ul> <li>Longest Substring with at most Two Distinct Characters</li> <li>Number of Subarrays with Bounded Maximum</li> <li>Subarrays with k Different Integers</li> </ul>"},{"location":"Coding/Algorithm/011_slding_window/#other-properties-in-window","title":"Other Properties in Window","text":"<p>This class of problems needs not only sliding window, but also other data structures to get the required features effeciently.</p> <ul> <li>Sliding Window and Two Pointers</li> <li>Sliding Window Median</li> <li>Contains Duplicate III</li> <li>K Empty Slots</li> <li>Longest Continuous Subarray with Absolute Diff Less Than or Equal to Limit</li> </ul>"},{"location":"Coding/Algorithm/013_two_pointer/","title":"Two Pointers","text":"<p><code>Two pointers</code> method is really an easy and effective technique for searching in an array or list.</p> <p>There are two kinds of usage:</p> <ol> <li>two pointers runs in same direction, one slower-runner and the other faster-runner, an example is to remove duplicates from a sorted array;</li> <li>two pointers runs in different direction, one from the begining while the other starts from the end, the example can be to reverse the characters in a string.</li> </ol> <p>Problems:</p> <ul> <li>Linked List Cycle</li> <li>Remove Nth Node From End of List</li> <li>Reverse String</li> <li>3 Sum Closet</li> <li>3 Sum</li> <li>4 Sum</li> <li>Container with Most Water</li> </ul>"},{"location":"Coding/Algorithm/01_bs/","title":"Binary Search","text":"<p>In computer science, <code>binary search</code>, also known as <code>half-interval search</code>, <code>logarithmic search</code>, or <code>binary chop</code>, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, again taking the middle element to compare the target value, and repeating this until the target value is found. If the search ends with the remaining half being empty, the target is not in the array.</p> <p>Binary search can be used to solve a wider range of problems, such as finding the next-smallest or next-largest element in the array relative to the target even if it is absent from the array.</p>"},{"location":"Coding/Algorithm/01_bs/#problems","title":"Problems","text":"<p>The binary search algorithm solves two kinds of problems:</p> <ol> <li>to check if a target element is in an array;</li> <li>to find the element that is bigger(less) than or equal to a target.</li> </ol> <p>And if you think deeper, you can use the method for second problem to solve first one. That is, to find the element \\(\\ge\\) the target and check if the element found is the target.</p>"},{"location":"Coding/Algorithm/01_bs/#code","title":"Code","text":"<p>The main idea of binary search algorithm is to divide the search range into two parts:</p> <ol> <li>Target must not exit part, which will not be considered in next search process;</li> <li>Target may exit part, which will be considered in next search process.</li> </ol> <p>There are two templates for the code, one for left end and one for right:</p> <pre><code>// Left end\n// Devide range [l, r] to [l, mid] and [mid + 1, r], and l locates at (mid + 1)\nint bs(int a[], int l, int r) {\n  while (l &lt; r) {\n    int mid = l + r &gt;&gt; 1;\n    if (resultl_is_in(mid)) {\n      r = mid;\n    } else {\n      l = mid + 1;\n    }\n  }\n  return l;\n}\n\n// Right end\n// Devide range [l, r] to [l, mid - 1] and [mid, r], and l locates at (mid)\nint bs(int a[], int l, int r) {\n  while (l &lt; r) {\n    // avoid the case [l, r] = [0, 1]\n    int mid = l + r + 1 &gt;&gt; 1;\n    if (is_result_in(mid)) {\n      l = mid;\n    } else {\n      r = mid - 1;\n    }\n  }\n  return l;\n}\n</code></pre>"},{"location":"Coding/Algorithm/01_bs/#complexity","title":"Complexity","text":"<p>In binary search process, algorithm half the search range every time, so for an array of length \\(N\\), the worst time complexity is \\(O(log(N))\\).</p> <p>The iteration version implementation costs \\(O(1)\\) space complexity. But for the recursive version, the space complexity is \\(O(log(N))\\).</p>"},{"location":"Coding/Algorithm/01_bs/#practice","title":"Practice","text":"<p>There are many kinds of problems, but if the range of problem can be divided into two parts:</p> <ol> <li>Must not contain the target;</li> <li>May contain the target;</li> </ol> <p>it can be solved with binary search.</p>"},{"location":"Coding/Algorithm/01_bs/#binary-search-in-an-array","title":"Binary Search in an Array","text":"<ul> <li>704. Binary Search</li> <li>34. Find First and Last Position of Element in Sorted Array</li> <li>33. Search in Rotated Sorted Array</li> <li>81. Search in Rotated Sorted Array II</li> <li>153. Find Minimum in Rotated Sorted Array</li> <li>154. Find Minimum in Rotated Sorted Array II</li> <li>300. Longest Increasing Subsequence</li> <li>275. H-Index II</li> <li>852. Peak Index in a Mountain Array</li> <li>1095. Find in Mountain Array</li> <li>4. Median of Two Sorted Arrays</li> <li>658. Find K Closest Elements</li> </ul>"},{"location":"Coding/Algorithm/01_bs/#binary-search-in-a-range","title":"Binary Search in a Range","text":"<ul> <li>69. Sqrt(x)</li> <li>287. Find the Duplicate Number</li> <li>374. Guess Number Higher or Lower</li> <li>1300. Sum of Mutated Array Closest to Target</li> </ul>"},{"location":"Coding/Algorithm/01_bs/#binary-search-with-implicit-relations","title":"Binary Search with Implicit Relations","text":"<ul> <li>410. Split Array Largest Sum</li> <li>875. Koko Eating Bananas</li> <li>1482. Minimum Number of Days to Make m Bouquets</li> <li>1552. Magnetic Force Between Two Balls</li> </ul>"},{"location":"Coding/Algorithm/01_bs/#reference","title":"Reference","text":"<ul> <li>Wikipedia binary search algorithm</li> <li>OI-Wiki binary</li> <li>Leetcode binary search solution</li> <li>Leetbook</li> </ul>"},{"location":"Coding/Algorithm/02_sort/","title":"Sort","text":""},{"location":"Coding/Algorithm/02_sort/#assumption","title":"Assumption","text":"<p>To simplify matters, we will assume that the algorithms we describe will all be interchangeable:</p> <ol> <li>All array positions contain data to be sorted;</li> <li>The <code>N</code> is the number of elements passed to our sorting routines;</li> <li>the <code>&gt;</code> and <code>&lt;</code> operators exists, which can be used to place a consistant ordering on the input.</li> </ol> <p>Sorting under these conditions is known as comparision-based sorting.</p>"},{"location":"Coding/Algorithm/02_sort/#sort-with-on2-complexity","title":"Sort with O(n^2) Complexity","text":""},{"location":"Coding/Algorithm/02_sort/#bubble-sort","title":"Bubble Sort","text":"<p>Bubblesort is the simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in wrong order. The algorithm is a comparison sort, is named for the way smaller or larger elements \"bubble\" to the top of the list. Although the algorithm is simple, it is too slow and impractical for most problems even when compared to Insertionsort. Bubblesort can be practical if the input is in mostly sorted order with some out-of-order elements nearly in position.</p> <pre><code>template &lt;typename T&gt;\nvoid bubbleSort(vector&lt;T&gt;&amp; arr) {\n  int m = arr.size();\n  for (int i = 0; i &lt; m; ++i) {\n    for (int j = i + 1; j &lt; m; ++j) {\n      if (arr[j] &lt; arr[i]) swap(arr[j], arr[i]);\n    }\n  } \n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#selection-sort","title":"Selection Sort","text":"<p>The selection sort divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list and a sublist of the remaining unsorted items that occupy the rest of the list.</p> <pre><code>void SelectionSort(vector&lt;int&gt;&amp; arr) {\n  int m = arr.size();\n  for (int i = 0; i &lt; m; ++i) {\n    int min_idx = i;\n    for (int j = i + 1; j &lt; m; ++j) if (arr[j] &lt; arr[min_idx]) min_idx = j;\n    swap(arr[i], arr[min_idx]);\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#insertion-sort","title":"Insertion Sort","text":"<p>One of the simplest sorting algorithms is the insertion sort. Insertion sort consists of N - 1 passes. For pass p = 1 through N - 1, insertion sort ensures that the elements in position 0 through p are in sorted order. Insertion sort makes use of the fact that elements in position 0 through p - 1 are already known to be in sorted order.</p> <pre><code>void InsertSort(vector&lt;int&gt;&amp; arr) {\n  int m = arr.size();\n  for (int i = 1; i &lt; m; ++i) {\n    int j = i;\n    while (j &amp;&amp; arr[j] &lt; arr[j - 1]) swap(arr[j - 1], arr[j--]);\n  }\n}\n</code></pre> <p>Becuase of the nested loops, each of which can take N iterations, insertion sort is \\(O(N^2)\\). Furthermore, this bound is tight, because input in reverse order can achieve this bound.</p>"},{"location":"Coding/Algorithm/02_sort/#sort-with-onlogn-complexity","title":"Sort with O(nlogn) Complexity","text":""},{"location":"Coding/Algorithm/02_sort/#shell-sort","title":"Shell Sort","text":"<p>Shellsort, named after its inventor, Donald Shell, was one of the first algorithms to break the quadratic time barrier, althoungh it was not until several years after its initial discovery that a subquadratic time bound was proven. It works by comparing elements that are distant; the distance between comparisons decreases as the algorithm runs until the last phase, in which adjacent elements are compared. For this reason, Shellsort is sometimes referred to as diminishing increment sort. Shellsort uses a sequence, h1, h2,\u2026, ht, called increment sequence. Any increment sequence will do as long as h1 = 1, but some choices are better than others.</p> <p>A popular(but poor) choice for increment sequence is to use the sequence suggested by Shell:</p> \\[ h_t = [N / 2]$ and $h_k = [h_{k + 1} / 2] \\] <pre><code>void ShellSort(vector&lt;int&gt;&amp; arr) {\n  int m = arr.size();\n  for (int gap = m / 2; j; gap /= 2) {\n    for (int i = gap; i &lt; m; i += gap) {\n      int j = i;\n      while (j &gt;= gap &amp;&amp; nums[j] &lt; nums[j - gap]) {\n        swap(nums[j], nums[j - gap]);\n        j -= gap;\n      }\n    }\n  }\n}\n</code></pre> <p>The performance of Shellsort is quite acceptable in practice, even for N in the tens of thousands. The simplicity of the code makes it the algorithm of choice for sorting up to moderately large input.</p>"},{"location":"Coding/Algorithm/02_sort/#heap-sort","title":"Heap Sort","text":"<p>Priority queues can be used to sort in \\(O(NlogN)\\) time. The algorithm based on this idea is known as heapsort and gives the best Big-Oh running time we have seen so far. The basic strategy is to build a binary heap of N elements. This stage takes \\(O(N)\\) time. We then preform N deleteMin operations. The elements leave the heap smallest first, in sorted order. By recording these elements in a second array and then copying the array back, we sort N elements. Since each deleteMin takes \\(O(logN)\\) time, the total running time is \\(O(NlogN)\\).</p> <p>The main problem with this algorithm is that it uses an extra array. Thus, the memory requirement is doubled. This could be a problem in some instances. Notice that the extra time spent copying the second array back to the first is only \\(O(N)\\), so that this is not likely to affect the running time significantly. The problem is space.</p> <p>A clever way to avoid using a second array makes use of the fact that after each deleteMin, the heap shrinks by 1. Thus the cell that was last in the heap can be used to store the element that was just deleted.</p> <p>Using this strategy, after the last deleteMin the array will contain the elements in decreasing sorted order. If we want the elements in the more typical increasing sorted order, we can change the ordering property so that the parent has a larger elements than the child. Thus, we have a max-heap.</p> <pre><code>void percolateDown(vector&lt;int&gt; &amp;arr, int hole, int heap_size) {\n  int m = arr.size();\n  auto left_child = [](int x) { return x * 2 + 1; };\n  int tmp = arr[hole];\n  for (int child = getLeftChild(hole); child &lt; heap_size; child = getLeftChild(hole)) {\n    if (child != heap_size - 1 &amp;&amp; arr[child + 1] &gt; arr[child]) ++child;\n    if (tmp &gt;= arr[child]) break;\n    arr[hole] = arr[child];\n    hole = child;\n  }\n  arr[hole] = tmp;\n}\n\nvoid HeapSort(vector&lt;int&gt; &amp;arr) {\n  int m = arr.size();\n  // build heap\n  for (int i = m / 2; i &gt;= 0; --i) { percolateDown(arr, i, cnt); }\n  // delete max\n  for (int i = m - 1; i &gt;= 0; --i) {\n    swap(arr[0], arr[i]);\n    percolateDown(arr, 0, i);\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#merge-sort","title":"Merge Sort","text":"<p>Mergesort runs in \\(O(NlogN)\\) worse-case running time, and the number of comparisons used is nearly optimal. It is a fine example of a recursive algorithm.</p> <p>The fundamental operation in this algorithm is merging two sorted lists. Because the lists are sorted, this can be done in one pass through the input, if the output is put in a third list. The basic merging algorithm takes two input array A and B, an output array C, and three counters, Actr, Bctr, and Cctr, which are initially set to the beginning of their respective arrays. The smaller of A[Actr] and B[Bctr] is copied to the next entry in C, and the appropriate counters are advanced. When either input list is exhausted, the remainder of the other list is copied to C.</p> <pre><code>void MergeSort(vector&lt;int&gt;&amp; arr, vector&lt;int&gt;&amp; tmp, int left, int right) {\n  if (left &gt;= right) return;\n\n  int mid = left + (right - left) / 2;\n  MergeSort(arr, tmp, left, mid);\n  MergeSort(arr, tmp, mid + 1, right);\n\n  int l = left, r = mid + 1, i = left;\n  while (l &lt;= mid &amp;&amp; r &lt;= right) arr[i++] = arr[l] &lt; arr[r] ? tmp[l++] : tmp[r++];\n  while (l &lt;= mid) arr[i++] = tmp[l++];\n  while (r &lt;= right) arr[i++] = tmp[r++];\n  while (left &lt;= right) arr[left++] = tmp[left];\n}\n</code></pre> <p>Mergesort is a classic example of the techniques used to analyze recursive routines: We have to write a recurrence relation for the running time. We will assume that N is a power of 2 so that we always split into even halves. For N = 1, the time to mergesort is constant, which we will denote by 1. Otherwise, the time to mergesort N numbers is equal to the time to do two recursive mergesort of size N/2, plus the time to merge, which is linear:</p> \\[T(1) = 1\\] \\[T(N) = 2T(N/2) + N\\] <p>Although mergesort\u2019s running time is \\(O(NlogN)\\), it has the significant problem that merging two sorted lists uses linear extra memory. The additional work involved in copying to the temporary array and back, throughtout the algorithm, slows the sort considerably. This copying can be avoided by judiciously switching the roles of a and tmpArray at alternate levels of the recursion. The running time of mergesort, when compared with other \\(O(NlogN)\\) alternatives, depends heavily on the relative costs of comparing elements and moving elements in the array(and the temporary array). These costs are language dependent.</p>"},{"location":"Coding/Algorithm/02_sort/#quick-sort","title":"Quick Sort","text":"<p>As its name implies for C++, quicksort has historically been the fastest known generic sorting algorithm in practice. Its average running time is \\(O(NlogN)\\). It is very fast, mainly due to a very tight and highly optimized inner loop. It has \\(O(N^2)\\) worst-case performance, but this can be made exponentially unlikely with a little effort. By combining quicksort with heapsort, we can achieve quicksort\u2019s fast running time on almost all inputs, with heapsort\u2019s \\(O(NlogN)\\) worst-case running time. The quicksort algorithm is simple to understand and prove correct, although for many years it had the reputation of being an algorithm that could in theory be highly optimized but in practice was impossible to code correctly. Like mergesort, quicksort is a divide-and-conquer recursive algorithm.</p> <p>The classic quicksort algorithm to sort an array S consists of the following four easy steps:</p> <ol> <li>Pick any element v in S. This called the <code>pivot</code>;</li> <li>Partition S-{v}(the remaining elements in S) into two disjoint groups: \\(S_1 = {x \\in S - {v} | x \\le v}\\), and \\(S_x = {x \\in S - {v} | x \\ge v}\\);</li> <li>Return {quicksort(\\(S_1\\)) and quicksort(\\(S_2\\))}.</li> </ol> <pre><code>void QuickSort(vector&lt;int&gt;&amp; arr, int left, int right) {\n  if (left &gt;= right) return;\n  int l = left - 1, r = right + 1, p = arr[left + (right - left) / 2];\n  while (l &lt; r) {\n    while (arr[++l] &lt; p) {};\n    while (arr[--r] &gt; p) {};\n    if (l &lt; r) swap(arr[l], arr[r]);\n  }\n  QuickSort(arr, left, r);\n  QuickSort(arr, r + 1, right);\n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#sort-with-on-complexity","title":"Sort with O(N) Complexity","text":"<p>\\(O(N)\\) sorting algorithms were exsiting for a long time, but they can only be used in special scenes.</p>"},{"location":"Coding/Algorithm/02_sort/#counting-sort","title":"Counting Sort","text":"<p><code>Counting sort</code> uses an extra array <code>cnt</code>, the ith element of <code>cnt</code> is the couting number of the ith element in origin array, and at last we set the element of origin array to its proper position according to <code>cnt</code>.</p> <p>The process is:</p> <ol> <li>Couting how many times each number in origin array occurs;</li> <li>Calculating the pre-sum of each number;</li> <li>Get the index of each number according to its times from pre-sum list.</li> </ol> <p></p> <pre><code>void CountingSort(vector&lt;int&gt;&amp; a) {\n  int low = *min_element(a.begin(), a.end());\n  int high = *max_element(a.begin(), a.end());\n\n  vector cnt(high - low + 1, 0);\n  for (auto n : a) cnt[n - low]++;\n\n  // start to end\n  // int sum = 0;\n  // for (auto&amp; n : cnt) tie(sum, n) = pair{sum + n, sum};\n\n  // auto tmp = a;\n  // for (auto n : tmp) a[cnt[n - low]++] = n;\n\n  // end to start\n  for (int i = 1; i &lt; cnt.size(); ++i) cnt[i] += cnt[i - 1];\n\n  auto tmp = a;\n  for (int i = cnt.size() - 1; i &gt;= 0; --i) a[--cnt[tmp[i]- low]] = tmp[i];\n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#radix-sort","title":"Radix Sort","text":"<p><code>Radix sort</code> divides an element into k digit, and sort elements by its kth digit; after that, it does the same thing with \\((k-1), (k-2), /cdots, 0\\)th digit.</p> <p>The main process is:</p> <ol> <li>find the maximum element of the array;</li> <li>get the radix of each element;</li> <li>loop for <code>max_digit_length</code> times, and sort elements by their radix.</li> </ol> <p></p> <pre><code>void RadixSort(vector&lt;int&gt;&amp; a) {\n  // Get Max digital length\n  int mv = *max_element(a.begin(), a.end());\n  int ml = 0;\n  while (mv) {\n    ++ml;\n    mv /= 10;\n  }\n\n  int dev = 1;\n  auto tmp = a;\n  vector cnt(19, 0);\n  for (int i = 0; i &lt; ml; ++i) {\n    // digit count\n    for (auto n : a) {\n      int radix = n / dev % 10 + 9;\n      cnt[radix]++;\n    }\n\n    // counting sort\n    for (int j = 0; j &lt; 19; ++j) cnt[j] += cnt[j - 1];\n\n    // restore current digit result\n    for (int j = a.size() - 1; j &gt;= 0; --j) {\n      int radix = a[j] / dev % 10 + 9;\n      tmp[--cnt[radix]] = a[j];\n    }\n\n    a = tmp;\n    cnt = vector(19, 0);\n    dev *= 10;\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/02_sort/#bucket-sort","title":"Bucket Sort","text":"<p>The main process of <code>bucket sort</code> is:</p> <ol> <li>divide the array into <code>bucket_size</code> interval of range <code>bucket_len</code>, each interval is call a <code>bucket</code>;</li> <li>traversal the array, put all elements to buckets;</li> <li>sort every bucket;</li> <li>merge the numbers in all buckets in order.</li> </ol> <pre><code>void BucketSort(vector&lt;int&gt;&amp; a, int bucket_len) {\n  int low = *min_element(a.begin(), a.end());\n  int high = *max_element(a.begin(), a.end());\n  int bucket_cnt = (high - low) / bucket_len + 1;\n\n  vector buckets(bucket_cnt, vector&lt;int&gt;());\n  for (auto n : a) buckets[(n - a) / bucket_len] = n;\n  for (auto&amp; b : buckets) sort(b.begin(), b.end());\n\n  int i = 0;\n  for (auto&amp; b : buckets) for (auto n : b) a[i++] = n;\n}\n</code></pre> <ul> <li>Sort An Array</li> </ul>"},{"location":"Coding/Algorithm/031_bt/","title":"Backtracking","text":"<p>Backtracking is a general algorithm for finding solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate(\"backtracks\") as soon as it determines that the candidate cannot possibly be complated to a valid solution.</p> <p>It is generally a <code>DFS</code> with proper <code>prune</code>. If current solution is not suitable, then backtrack and try other solutions. Thus, recursion is used in this approach.</p> <p>The consider process maybe:</p> <ol> <li>Draw a state space tree, where each node represents a state and all its possible sellections are its children;</li> <li>Determine the terminal condition;</li> <li>Determine if a pruning is necessary here;</li> <li>Make selection;</li> <li>Get into next layer;</li> <li>Revoke the selection and restore the scene.</li> </ol> <p>A pseudocode can be:</p> <pre><code>void Backtrack(State&amp; curr) {\n  if (is_terminal(curr) || is_prune(curr)) return;\n  next = set_state(curr);\n  Backtrack(next);\n  curr = reverse_state(next);\n}\n</code></pre>"},{"location":"Coding/Algorithm/031_bt/#subsets-and-combinations","title":"Subsets and Combinations","text":"<p>Subset and combination problems are irrelevant with elements' order, so the problem can be described as: chosing at most <code>m</code> elements that meet the requirement from an array <code>arr</code>, where <code>m</code> is the length of <code>arr</code>. To prevent from choosing one element twice, only elements behind previous selection will be selected at each step.</p> <p>And for repeating elements, we sort them at the begining and then choose only one of them at each step.</p> <ul> <li>subsets</li> <li>subsets-ii</li> <li>combinations</li> <li>combination-sum</li> <li>combination-sum-ii</li> </ul>"},{"location":"Coding/Algorithm/031_bt/#permutations","title":"Permutations","text":"<p>When we talk about permutation, the order matters here. Each step we chose an element from all the rest, so we have to remember all the elements we have chosen and select from the other.</p> <ul> <li>permutations</li> <li>permutations-ii</li> <li>zi-fu-chuan-de-pai-lie-lcof</li> <li>letter-case-permutation</li> </ul>"},{"location":"Coding/Algorithm/031_bt/#searching","title":"Searching","text":"<ul> <li>sudoku-solver</li> <li>word-search</li> <li>eight-queens-lcci</li> <li>palindrome-partitioning</li> <li>binary-watch</li> </ul>"},{"location":"Coding/Algorithm/03_search/","title":"Searching","text":""},{"location":"Coding/Algorithm/03_search/#breadth-first-searchbfs","title":"Breadth-first Search(BFS)","text":"<p>BFS is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root(or some arbitrary node of a graph, sometimes referred as a <code>search key</code>), and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level.</p> <p></p> <pre><code>void bfs(Graph&amp; graph, int start) {\n  deque&lt;int&gt; d{start};\n  unordered_set&lt;int&gt; visited{start};\n  while (!d.empty()) {\n    int node = d.front();\n    d.pop_front();\n    for (auto next : graph[node]) {\n      if (visited.count(next)) continue;\n      visited.insert(next);\n      d.push_back(next);\n    }\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/03_search/#0-1-bfs","title":"0-1 BFS","text":"<p><code>0-1 BFS</code> is to solve the graph shortest path(SP) problem that the weight of <code>edge</code> can only be <code>0</code> or <code>1</code>.</p> <p>We can solve this problem with Dijkstra or A star, but the time complexity may reach \\(O(E + VlogV)\\), where <code>E</code> is the number of edges and <code>V</code> is the number of vertices.</p> <p><code>0-1 BFS</code> can reduce the time complexity ot \\(O(E + V)\\), since it travals all the vertices and edges once.</p> <p>Similar to Dijikstra, we only put a vertex in the queue if it has been relaxed by a previous vertex (distance is reduced by travelling on this edge) and we also keep the queue sorted by distance from source at every point of time.</p> <p>Now, when we are at <code>u</code>, we know one thing for sure:</p> <p>travelling an edge <code>(u, v)</code> would make sure that <code>v</code> is either in the same level as <code>u</code> or at the next successive level.</p> <p>This is because the edge weights are 0 and 1. An edge weight of 0 would mean that they lie on the same level, whereas an edge weight of 1 means they lie on level below. We also know that during BFS our queue holds vertices of two successive levels at max. So, when we are at vertex <code>u</code>, our queue contains elements of level \\(L[u]\\) or \\(L[u] + 1\\). And we also know that for an edge <code>(u, v)</code>, \\(L[v]\\) is either \\(L[u]\\) or \\(L[u] + 1\\). Thus, if the vertex <code>v</code> is relaxed and has the same level, we can push it to the front of our queue and if it has the very next level, we can push it to the end of the queue. This helps us keep the queue sorted by level for the BFS to work properly.</p> <p>But, using a normal queue data structure, we cannot insert and keep it sorted in \\(O(1)\\). Using priority queue cost us \\(O(logN)\\) to keep it sorted. The problem with the normal queue is the absence of methods which helps us to perform all of these functions:</p> <ol> <li>Remove Top Element (To get vertex for BFS)</li> <li>Insert At the beginning (To push a vertex with same level)</li> <li>Insert At the end (To push a vertex on next level)</li> </ol> <p>Fortunately, all of these operations are supported by a double ended queue:</p> <pre><code>int zero_one_bfs(Graph g, int src, int tar) {\n  vector dis(g.size(), INT_MAX);\n  dis[src] = 0;\n\n  deque&lt;int&gt; dq{};\n  dq.push_back(src);\n\n  while(!dq.empty()) {\n    auto node = dq.front(); dq.pop_front();\n\n    for (auto next : g[node]) {\n      int c = cost(node, next);\n      if (dis[node] + c &lt; dis[next]) {\n        dis[next] = dis[node] + c;\n        if (c == 1) {\n          dq.push_back(next);\n        } else {\n          dq.push_front(next);\n        }\n      }\n    }\n  }\n\n  return dis[tar];\n}\n</code></pre> <p>Problems:</p> <ul> <li>minimum-cost-to-make-at-least-one-valid-path-in-a-grid</li> </ul> <p>Reference:</p> <ul> <li>codeforces 0-1 BFS</li> </ul>"},{"location":"Coding/Algorithm/03_search/#depth-first-searchdfs","title":"Depth-first Search(DFS)","text":"<p>DFS is an algorithm for traversing or searching tree or graph data structure. The algorithm starts at the root node(selecting some arbitrary node as the root node in the case of a graph) and explores as far as possible along each branch before backtracking.</p> <p></p> <pre><code>void dfs(Graph&amp; graph, unordered_set&lt;int&gt;&amp; visited, int root) {\n  if (visited.count(root)) return;\n  for (auto next : graph[root]) {\n    dfs(graph, visited, next);\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/04_dp/","title":"Dynamic Programming","text":"<p>Dynamic programming is both a mathematical optimization method and a computer programming method. In both contexts it refers to simplifying a complicated problem by breaking it down into simpler sub-problem in a recursive manner. While some decision problems cannot be taken apart this way, decisions that span several points in time do often break apart recursively. Likewise, in computer science, if a problem can be solved optimally by breaking it into sub-problems and then recursively finding the optimal solutions to the sub-problem, then it is said to have <code>optimal substructure</code>.</p> <p>If sub-problems can be nested recursively inside larger problems, so that dynamic programming methods are applicable, then there is a relation between the value of the larger problem and the values of the sub-problems.</p> <p>In general, a problem can be solved with dynamic programming if it has:</p> <ul> <li><code>optimal substructure</code>, which means the problem can be solved with one or finite sub-problems;</li> <li><code>repeated sub-problems</code>, which means that the sub-problems will be solved multiple times.</li> </ul> <p>The <code>optimal substructure</code> defines the relationship between origin problem and its sub-problems, and <code>repeated sub-problems</code> defines the relationship between sub-problems. If <code>optimal substructure</code> is not satisfied, we can not apply the <code>dp</code> method; if <code>repeated sub-problems</code> is not satisfied, we can apply <code>dp</code>, but it has no advange over <code>recursive</code> method.</p> <p>The general process of applying <code>dp</code> is:</p> <ol> <li>Define the state variable, this is the most flexible step, different state variables has different transmission functions.</li> <li>Define the transmission function, in this step we iterate all possible <code>selections</code> and get the state with one or more sub-states.</li> <li>Define the base case, this is necessary when we need more than one sub-problem solutions at the begining but they are not solved.</li> <li>Solve the problem by calculating the state value needed.</li> </ol>"},{"location":"Coding/Algorithm/04_dp/#linear-dp","title":"Linear Dp","text":"<p>The main characteristic of <code>linear dp</code> is that the problem is related to its position. </p>"},{"location":"Coding/Algorithm/04_dp/#single-sequence","title":"Single Sequence","text":""},{"location":"Coding/Algorithm/04_dp/#longest-increasing-subsequencelis","title":"Longest Increasing Subsequence(LIS)","text":"<p>Given an integer array <code>nums</code>, return the length of the longest strictly increasing subsequence.</p> <p>The typical solution for <code>LIS</code> is <code>dp</code>, we define:</p> <ol> <li><code>state</code> dp[i]: the length of LIS which ends with <code>nums[i]</code>;</li> <li><code>transform</code>: dp[i] = max(dp[j]) + 1, where \\(0 \\le j &lt; i\\) and \\(nums[j] &lt; nums[i]\\);</li> <li><code>base case</code>: dp[0] = 1</li> </ol> <p>And we have the function:</p> <pre><code>int Lis(vector&lt;int&gt;&amp; a) {\n  int m = a.size();\n  vector dp(m, 1);\n\n  for (int i = 1; i &lt; m; ++i) {\n    for (int j = 0; j &lt; i; ++j) {\n      if (a[j] &gt;= a[i]) continue;\n      dp[i] = max(dp[i], dp[j] + 1);\n    }\n  }\n\n  return *max_element(dp.begin(), dp.end());\n}\n</code></pre> <p>Complexity:</p> <ul> <li>Time complexity: \\(O(N^2)\\)</li> <li>Space complexity: \\(O(N)\\)</li> </ul> <p>The general greedy strategy is that we let the subsequence increasing as slowly as posible. So we define an array <code>d</code> to store the minimum last number of the subsequence of each lenth, <code>d[len]</code> stores the minimum last number of the subsequence of the length i. If current number is greater than <code>d[len]</code>, we increase the <code>len</code> and update <code>d[len + 1]</code> to current number; otherwise we use binary search to update <code>d[j]</code> with current number, where <code>dp[j] &gt;= current number</code>.</p> <pre><code>int Lis(vector&lt;int&gt;&amp; a) {\n  auto bs = [](auto&amp; d, int tar, int l, int r) {\n    while (l &lt; r) {\n      int mid = l + (r - l) / 2;\n      if (d[mid] &lt; tar) {\n        l = mid + 1;\n      } else {\n        r = mid;\n      }\n    }\n\n    return l;\n  };\n  int m = a.size();\n  vector d(m + 1, a[0]);\n  int len = 1;\n\n  for (int i = 1; i &lt; m; ++i) {\n    if (a[i] &gt; d[len]) {\n      d[++len] = a[i];\n    } else {\n      int j = bs(d, a[i], 1, len);\n      d[j] = a[i];\n    }\n  }\n\n  return len;\n}\n</code></pre> <p>Complexity:</p> <ul> <li>Time complexity: \\(O(NlogN)\\)</li> <li>Space complexity: \\(O(N)\\)</li> </ul> <p>Other similar problems:</p> <ul> <li>Longest Increasing Subsequence</li> <li>Number of Longest Increasing Subsequence</li> <li>Russian Doll Evelopes</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#maximum-sub-array-problems","title":"Maximum Sub Array Problems","text":"<p>Given an integer array <code>nums</code>, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum.</p> <ul> <li>Maximum Subarray</li> <li>Maximum Product Subarray</li> <li>Maximum Sum Circular Subarray</li> <li>Max SubMatrix Lcci</li> <li>Max Sum of Rectangle No Larger Than K</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#single-sequence-that-not-continuouse-house-robber-problems","title":"Single Sequence that Not Continuouse -- House Robber Problems","text":"<p>When the sequence is not continuous, we need the information of more previous postions.</p> <ul> <li>House Robber</li> <li>House Robber II</li> <li>House Robber III</li> <li>Delete and Earn</li> <li>Pizza with 3n Slices</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#single-sequence-that-need-two-position","title":"Single Sequence that Need Two Position","text":"<p>Sometimes we need to consider two positions of subproblem, the state should be <code>dp[i][j]</code> to determine the two position <code>i j</code> of subproblems.</p> <ul> <li>Length of Longest Fibonacci Subsequence</li> <li>Longest Arithmetic Subsequence</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#single-sequence-with-another-dimenssion","title":"Single Sequence with Another Dimenssion","text":"<p>In addition to position, sometimes we need another variable, for example, the length/times/color. We generally write the state as <code>dp[i][k]</code>, where <code>i</code> for the position, <code>k</code> for the additional meanings.</p> <ul> <li>largest-sum-of-averages</li> <li>super-egg-drop</li> <li>paint-house</li> <li>paint-house-ii</li> <li>odd-even-jump</li> <li>frog-jump</li> <li>allocate-mailboxes</li> <li>toss-strange-coins</li> <li>split-array-largest-sum</li> <li>paint-house-iii</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#stock-series-problems","title":"Stock Series Problems","text":"<p>The general description for stock problems is:</p> <p>you're given an integer array of stock prices: <code>prices</code>, and you can complete at most <code>k</code> transactions.</p> <p>We define the state as: <code>dp[i][j][x]</code> means that <code>[0:i]</code> prices with <code>j</code> transactions and current state is <code>x</code>(0 or 1, 0 for empty, 1 for hold). And we define that a transaction including buying and selling.</p> <p>The code can be:</p> <pre><code>dp[0][0][1] = -ps[0];\nfor (int i = 1; i &lt; m; ++i) { dp[i][0][1] = max(dp[i - 1][0][1], -ps[i]); }\nfor (int i = 1; i &lt; m; ++i) {\n  for (int j = 1; j &lt;= k; ++j) {\n    dp[i][j][0] = max(dp[i - 1][j][0], dp[i - 1][j - 1][1] + ps[i]);\n    dp[i][j][1] = max(dp[i - 1][j][1], dp[i - 1][j][0] - ps[i]);\n  }\n}\n</code></pre> <ul> <li>best-time-to-buy-and-sell-stock</li> <li>best-time-to-buy-and-sell-stock-ii</li> <li>best-time-to-buy-and-sell-stock-iii</li> <li>best-time-to-buy-and-sell-stock-iv</li> <li>best-time-to-buy-and-sell-stock-with-cooldown</li> <li>best-time-to-buy-and-sell-stock-with-transaction-fee</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#package-series-problems","title":"Package Series Problems","text":"<p>Optimal Problems:</p> <ul> <li>coin-change</li> <li>ones-and-zeros</li> <li>last-stone-weight-ii</li> </ul> <p>Package Capacity Problems:</p> <ul> <li>partition-equal-subset-sum</li> </ul> <p>Combination Problems:</p> <ul> <li>combination-sum-iv</li> <li>target-sum</li> <li>coin-change-2</li> <li>profitable-schemes</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#other","title":"Other","text":"<ul> <li>Longest Valid Parentheses</li> <li>Arithmetic Slices</li> <li>Decode Ways</li> <li>Palindrome Partitioning ii</li> <li>Delete Operation for Two Strings</li> <li>Counting Bits</li> <li>Minimum Swaps to Make Sequences Increasing</li> <li>Minimum Number of Refueling Stops</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#double-sequences","title":"Double Sequences","text":"<p>In double sequence problems, we define <code>dp[i][j]</code> to represent the solution of <code>s1[0:i]</code> and <code>s2[0:j]</code>.</p>"},{"location":"Coding/Algorithm/04_dp/#longest-common-sequencelcs","title":"Longest Common Sequence(LCS)","text":"<p>Given two strings <code>text1</code> and <code>text2</code>, return the length of their longest common subsequence.</p> <ul> <li>longest-common-subsequence</li> <li>minimum-ascii-delete-sum-for-two-strings</li> <li>maximum-length-of-repeated-subarray</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#character-matching","title":"Character Matching","text":"<ul> <li>edit-distance</li> <li>wildcard-matching</li> <li>regular-expression-matching</li> <li>interleaving-string</li> <li>distinct-subsequences</li> <li>scramble-string</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#matrix","title":"Matrix","text":""},{"location":"Coding/Algorithm/04_dp/#matrix-related-to-its-position","title":"Matrix Related to Its Position","text":"<p>In matrix problems, we use <code>dp[i][j]</code> to determine the solution of position <code>matrix[i][j]</code>, and the subproblem may relate to <code>dp[i - 1][j]</code>, <code>dp[i][j - 1]</code> and <code>dp[i - 1][j - 1]</code>.</p> <ul> <li>triangle</li> <li>minimum-path-sum</li> <li>dungeon-game</li> <li>maximal-square</li> <li>minimum-falling-path-sum</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#matrix-with-another-dimenssion","title":"Matrix with Another Dimenssion","text":"<p>Sometimes we also need another variable of subproblems where comes the state <code>dp[i][j][k]</code>.</p> <ul> <li>maximal-rectangle</li> <li>max-sum-of-rectangle-no-larger-than-k</li> <li>max-submatrix-lcci</li> <li>number-of-ways-of-cutting-a-pizza</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#other_1","title":"Other","text":"<ul> <li>2-keys-keyboard</li> <li>ugly-number-ii</li> <li>perfect-squares</li> <li>integer-break</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#prefix-sum","title":"Prefix Sum","text":"<p>Prefix sums are trivial to compute in sequential models of computation, by using the formula \\(y_{i} = y_{i - 1} + x_{i}\\) to compute each output value in sequence order. However, despite their ease of computation, prefix sums are a useful primitive in certain algorithms such as counting sort, and they form the basis of the scan higher-order function in functional programming languages. Prefix sums have also been much studied in parallel algorithms, both as a test problem to be solved and as a useful primitive to be used as a subroutine in other parallel algorithms.</p> <p>Abstractly, a prefix sum requires only a binary associative operator \\(\\oplus\\), making it useful for many applications from calculating well-separated pair decompositions of points to string processing.</p> <p>Mathematically, the operation of taking prefix sums can be generalized from finite to infinite sequences; in that context, a prefix sum is known as a partial sum of a series. Prefix summation or partial summation form linear operators on the vector spaces of finite or infinite sequences; their inverses are finite difference operators.</p> <p>There are two types of prefix sum, 1d and 2d:</p> <ul> <li>range-sum-query-immutable</li> <li>range-sum-query-2d-immutable</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#sum-of-a-range-or-area","title":"Sum of a Range or Area","text":"<ul> <li>matrix-block-sum</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#the-range-or-area-that-less-or-equal-a-target","title":"The Range or Area that Less or Equal a Target","text":"<ul> <li>maximum-size-subarray-sum-equals-k</li> <li>contiguous-array</li> <li>find-the-longest-substring-containing-vowels-in-even-counts</li> <li>subarray-sum-equals-k</li> <li>count-number-of-nice-subarrays</li> <li>continuous-subarray-sum</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#range-dp","title":"Range Dp","text":"<p>In range dynamic programming, the defination and transmission of state are all related to a range.</p> <p>The typical patterns of this problem is:</p> <pre><code>for (int len = 1; len &lt;= m; ++len) {\n  for (int i = 0; i + len - 1 &lt; m; ++i) {\n    int j = i + len - 1;\n\n    // dp[i][j] = ...\n  }\n}\n</code></pre>"},{"location":"Coding/Algorithm/04_dp/#palindrome-problems","title":"Palindrome Problems","text":"<ul> <li>longest-palindromic-substring</li> <li>palindromic-substrings</li> <li>longest-palindromic-subsequence</li> <li>longest-chunked-palindrome-decomposition</li> <li>count-different-palindromic-subsequences</li> <li>minimum-insertion-steps-to-make-a-string-palindrome</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#reverse-order-problems","title":"Reverse Order Problems","text":"<ul> <li>burst-balloons</li> <li>remove-boxes</li> <li>minimum-score-triangulation-of-polygon</li> <li>strange-printer</li> <li>minimum-cost-to-merge-stones</li> <li>predict-the-winner</li> <li>encode-string-with-shortest-length</li> </ul>"},{"location":"Coding/Algorithm/04_dp/#other_2","title":"Other","text":""},{"location":"Coding/Algorithm/055_bit/","title":"Bitwise","text":""},{"location":"Coding/Algorithm/055_bit/#position-notation","title":"Position Notation","text":"<p><code>Position notation</code> usually denotes the extension to any base of the Huindu-Arabic number system (or decimal system). More generally, a positional system is a numeral system in which the contribution of a digit to the value of a number is the value of the digit muktiplied by a factor determined by the position of the digit.</p> <p></p> <p>For a x position notation number, the value is determined by the position of position of the digit and the radix. The 10 position number system(decimal) number 123.45 can be written as:</p> \\[ 123.45 = 1 \\times 10^2 + 2 \\times 10^1 + 3 \\times 10^0 + 4 \\times 10^{-1} + 5 \\times 10^{-2} \\] <p>8 position number system(Octal) number 720.5 can be written:</p> \\[ 720.5_{(8)} = 7 * 8^2 + 2 * 8^1 + 0 * 8^0 + 5 * 8^{-1} \\]"},{"location":"Coding/Algorithm/055_bit/#other-position-system-number-to-decimal-system-number","title":"Other Position System Number to Decimal System Number","text":"<p>Add all position digit weigted with the radix. For example:</p> \\[ 720.5_{(8)} = 7 * 8^2 + 2 * 8^1 + 0 * 8^0 + 5 * 8^{-1} = 464.625 \\]"},{"location":"Coding/Algorithm/055_bit/#decimal-to-other-position-system","title":"Decimal to Other Position System","text":"<ol> <li>The remainder is stored in a variable when it is divided by 2;</li> <li>Divide the number by 2;</li> <li>Repeat these steps till the number is greater than zero;</li> <li>Combine all reminders in reversing order.</li> </ol>"},{"location":"Coding/Algorithm/055_bit/#bit-and-operators","title":"Bit and Operators","text":"<p>Computer stores all numbers with binary system, and all calculations are implemented by bitwise operatons.</p>"},{"location":"Coding/Algorithm/055_bit/#and","title":"AND","text":"<p><code>AND</code>(\\(\\&amp;\\)) takes two equal-length binary representations and performs the logical AND operation on each pair of the corresponding bits. If both bits in the compared position are 1, the bit in the resulting binary representation is \\(1\\), other wise the result is \\(0\\).</p> x y result 0 0 0 0 1 0 1 0 0 1 1 1"},{"location":"Coding/Algorithm/055_bit/#or","title":"OR","text":"<p>A bitwise <code>OR</code> (\\(|\\)) is a binary operation that takes two bit patterns of equal length and performs the logical inclusive OR operation on each pair of corresponding bits. The result in each position is 0 if both bits are 0, while otherwise the result is 1.</p> x y result 0 0 0 0 1 1 1 0 1 1 1 1"},{"location":"Coding/Algorithm/055_bit/#xor","title":"XOR","text":"<p>A bitwise <code>XOR</code> (\\(\\oplus\\))is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if only one of the bits is 1, but will be 0 if both are 0 or both are 1. In this we perform the comparison of two bits, being 1 if the two bits are different, and 0 if they are the same. </p> x y result 0 0 0 0 1 1 1 0 1 1 1 0"},{"location":"Coding/Algorithm/055_bit/#not","title":"NOT","text":"<p>The bitwise <code>NOT</code>(\\(\\sim\\)), or complement, is a unary operation that performs logical negation on each bit, forming the ones' complement of the given binary value. Bits that are 0 become 1, and those that are 1 become 0.</p> x result 0 1 0 0"},{"location":"Coding/Algorithm/055_bit/#left-shift","title":"Left Shift","text":"<p>When shifting left(\\(&lt;&lt;\\)), the most-significant bit is lost, and a 0 bit is inserted on the other end.</p> \\[ 0010 &lt;&lt; 1 \\to 0100 \\] \\[ 0010 &lt;&lt; 2 \\to 1000 \\]"},{"location":"Coding/Algorithm/055_bit/#right-shift","title":"Right shift","text":"<p>When shifting right(\\(&gt;&gt;\\)), the most-significant bit is lost, and a 0 bit is inserted on the other end.</p> \\[ 0010 &gt;&gt; 1 \\to 0001 \\] \\[ 0010 &gt;&gt; 2 \\to 0000 \\]"},{"location":"Coding/Algorithm/055_bit/#bitwise-operation-properties","title":"Bitwise Operation Properties","text":"<ul> <li>Idempotent Law: \\(a \\&amp; a = a, a | a = a\\)</li> <li>Exchange Law: \\(a \\&amp; b = b \\&amp;a, a | b = b | a, a \\oplus b = b \\oplus a\\)</li> <li>Union Law: \\((a \\&amp; b) \\&amp; c = a \\&amp; (b \\&amp; c), (a | b) | c = a | (b | c), (a \\oplus b) \\oplus c = a \\oplus (b \\oplus c)\\)</li> <li>Distribution Law: \\((a \\&amp; b) | c = (a | c) \\&amp; (b | c), (a | b) \\&amp; c = (a \\&amp; c) | (b \\&amp; c), (a \\oplus b) \\&amp; c = (a \\&amp; c) \\oplus (b \\&amp; c)\\)</li> <li>De Morgan Law: \\(\\sim(a \\&amp; b) = (\\sim a) | (\\sim b), \\sim(a | b) = (\\sim a) \\&amp; (\\sim b)\\)</li> <li>Not Operation Property: \\(-1 = \\sim 0, -a = \\sim(a - 1)\\)</li> <li>And Operation Property: \\(a \\&amp; 0 = 0, a \\&amp; (-1) = a, a \\&amp; (\\sim a) = 0\\)</li> <li>Or Operation Property: \\(a | 0 = a, a | (\\sim a) = -1\\)</li> <li>Xor Operation Property: \\(a \\oplus 0 = a, a \\oplus a = 0\\)</li> </ul> <p>Other useful properties:</p> <ul> <li>Set the last \\(1\\) of the binary representation of \\(n\\) to \\(0\\): \\(n \\&amp; (n - 1)\\)</li> <li>Keep the last \\(1\\) of the binary representation of \\(n\\), and the rest of the \\(1\\)s become \\(0\\): \\(n \\&amp; (\\sim n)\\)</li> </ul>"},{"location":"Coding/Algorithm/05_greedy/","title":"Greedy","text":""},{"location":"Coding/Algorithm/06_math/","title":"Math","text":""},{"location":"Coding/Algorithm/06_math/#greatest-common-divisorgcd","title":"Greatest Common Divisor(GCD)","text":"<p>Greatest common divisor(GCD) of two positive integers is the largest positive integer that divides both numbers without remainder. It is useful for reducing fractions to be in its lowest terms.</p> <pre><code>int gcd(int x, inty) { return y ? gcd(y, x % y) : x; } ``` ## Least Common Multiple(LCM)\n\nLeast common multiple(LCM) of two integer is the smallest integer that is a multiple of both numbers.\n\n```C++\nint lcm(int x, int y) { return x / gcd(x, y) * y; }\n</code></pre>"},{"location":"Coding/Algorithm/06_math/#josephus-problem","title":"Josephus Problem","text":"<p>People are standing in a circle wating to be executed. Counting begins at a special point in the circle and proceeds around the circle in a specified direction. After a specified number of people are skipped, the next person is executed. The procedure is repeated with the remaining people, starting with the next person, going in the same direction and skipping the same number of people, until only one person remains, and is freed.</p> <p>We define that:</p> <ul> <li><code>f(n, m)</code> returns the remaining people indexed from <code>0</code> in <code>n</code> people and skips each <code>m</code> people.</li> <li>if we know <code>f(n - 1, m) = x</code>, then at the <code>n</code> trip we start from index <code>x + 1</code> and skip <code>m</code> people and then return the answer: <code>f(n - 1, m) + m</code>. Now that people are in a circle, we can avoid overflow by <code>f(n, m) = (f(n - 1, m) + m) % n</code>.</li> <li>As for the base, if <code>n == 1</code>, result is <code>0</code>.</li> </ul> <pre><code>int josephus(int n, int m) {\n  return n == 1 ? 0 : (f(n - 1, m) + m) % n;\n}\n</code></pre>"},{"location":"Coding/Algorithm/06_math/#probability","title":"Probability","text":""},{"location":"Coding/Algorithm/06_math/#conditional-probability","title":"Conditional Probability","text":"<p>The conditional probability of an event \\(A\\), given an event \\(B\\) with \\(P(B) &gt; 0\\), is defined by:</p> \\[ P(A|B) = \\frac{P(A \\cap B)} {P(B)} \\] \\[ P(A \\cap B) = P(B) * P(A|B) \\]"},{"location":"Coding/Algorithm/06_math/#multiplication-rule","title":"Multiplication Rule","text":"<p>Assuming that all of the conditioning events have positive probability, we have:</p> \\[ P(\\cap^{n}_{i = 1} A_{i}) = P(A_1) P(A_2 | A_1) P(A_3 | A_1 \\cap A_2) \\cdots P(A_n | \\cap^{n - 1}_{i = 1} A_{i}) \\]"},{"location":"Coding/Algorithm/06_math/#total-probability-theorem","title":"Total Probability Theorem","text":"<p>Let \\(A_1, \\cdots, A_n\\) be disjoint events that form a partition of the sample space (each possible outcome is included in one and only one of the events \\(A_1, \\cdots, A_n\\)) and assume that \\(P(A_i) &gt; 0\\), for all \\(i = 1, \\cdots, n\\). Then, for any event B, we have:</p> \\[ \\begin{align} P(B) &amp;= P(A_1 \\cap B) + \\cdots + P(A_n \\cap B) \\\\      &amp;= P(A_1)P(B|A_1) + \\cdots + P(A_n)P(B|A_n) \\\\ \\end{align} \\]"},{"location":"Coding/Algorithm/06_math/#bayes-rule","title":"Bayes' Rule","text":"<p>Let \\(A_1, A_2, \\cdots, A_n\\) be disjoint events that form a partition of the sample space, and assume that \\(P(A_i) &gt; 0\\), for all \\(i\\). Then, for any event B such that \\(P(B) &gt; 0\\), we have:</p> \\[ \\begin{align} P(A_i | B) &amp;= \\frac{P(A_i) P(B | A_i)} {P(B)} \\\\            &amp;= \\frac{P(A_i) P(B | A_i)} {P(A_1)P(B|A_1) + \\cdots + P(A_n)P(B|A_n)} \\end{align} \\]"},{"location":"Coding/Algorithm/06_math/#counting","title":"Counting","text":"<p>The <code>permutation</code> of n objects is:</p> \\[ n! \\]"},{"location":"Coding/Algorithm/06_math/#k-permutations","title":"K-Permutations","text":"<p>If we want to count the number of different ways that we can pick k out of n objects and arrange them in a sequence, the number of posibble sequences is called <code>k-permutations</code>:</p> \\[ \\begin{align} n(n - 1) \\cdots (n - k + 1) &amp;= \\frac{n(n - 1)\\cdots(n - k + 1)(n - k)\\cdots 2 \\times 1} {(n - k) \\cdots 2 \\times 1} \\\\                             &amp;= \\frac{n!}{(n - k)!} \\\\ \\end{align} \\]"},{"location":"Coding/Algorithm/06_math/#k-combinations","title":"K-Combinations","text":"<p>A combination is a choice of k elements out of an n-element set without regard to order. Combination has no ordering of the selected elements.</p> \\[ \\binom{n}{k} = \\frac{n!} {k! (n - k)!} \\]"},{"location":"Coding/Algorithm/06_math/#partition","title":"Partition","text":"<p>We have n distinct objects and we are given nonnegative integers \\(n_1, n_2, \\cdots, n_r\\), whose sum is equal to n. The n items are to be divided into r disjoint groups, with the ith group containing exactly \\(n_i\\) items. Partitions of n objects into r groups with ith group having \\(n_i\\) objects is called <code>multinomial coefficient</code>:</p> \\[ \\begin{align} \\binom{n}{n_1, n_2, \\cdots, n_r} &amp;= \\binom{n}{n_1} \\binom{n - n_1}{n_2} \\binom{n - n_1 - n_2}{n_3} \\cdots \\binom{n - n_1 - \\cdots - n_{r - 1}}{n_r} \\\\ &amp;= \\frac{n!}{n_1!(n - n_1)!} \\frac{(n - n_1)!}{n_2!(n - n_1 - n_2)!} \\cdots \\frac{(n - n_1 - \\cdots - n_{r - 1})!}{(n - n_1 - \\cdots - n_{r - 1} - n_r)!n_r!} \\\\ &amp;= \\frac{n!}{n_1!n_2!\\cdots n_r!} \\\\ \\end{align} \\]"},{"location":"Coding/Algorithm/06_math/#expression","title":"Expression","text":""},{"location":"Coding/Algorithm/06_math/#addition","title":"Addition","text":"<pre><code>/// digits of A, B and C are in reverse order\nvector&lt;int&gt; add(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B) {\n  if (A.size() &lt; B.size()) return add(B, A);\n\n  vector&lt;int&gt; C{};\n  int t{0};\n  for (int i = 0; i &lt; A.size(); ++i) {\n    t += A[i];\n    if (i &lt; B.size()) t += B[i];\n    C.push_back(t % 10);\n    t /= 10;\n  }\n  if (t) C.push_back(t);\n\n  return C;\n}\n</code></pre>"},{"location":"Coding/Algorithm/06_math/#subtraction","title":"Subtraction","text":"<pre><code>/// digits of A, B and C are in reverse order\n/// and A is bigger than B\nvector&lt;int&gt; add(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B) {\n  vector&lt;int&gt; C{};\n  for (int i = 0, t = 0; i &lt; A.size(); ++i) {\n    t = A[i] - t;\n    if (i &lt; B.size()) t -=B[i];\n    C.push_back((t + 10) % 10);\n    t = t &lt; 0 ? -1 : 0;\n  }\n  while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();\n  return C;\n}\n</code></pre>"},{"location":"Coding/Algorithm/06_math/#multiplication","title":"Multiplication","text":"<pre><code>/// digits of A and C are in reverse order\nvector&lt;int&gt; mul(vector&lt;int&gt;&amp; A, int b) {\n  vector&lt;int&gt; C{};\n  for (int i = 0, t = 0; i &lt; A.size() || t; ++i) {\n    if (i &lt; A.size()) t += A[i] * b;\n    C.push_back(t % 10);\n    t /= 10;\n  }\n  while (C.size() &gt; 1 &amp;&amp; C.back() == 0) c.pop_back();\n  return C;\n}\n</code></pre>"},{"location":"Coding/Algorithm/06_math/#division","title":"Division","text":"<pre><code>/// digits of A and C are in reverse order\npair&lt;vector&lt;int&gt;, int&gt; div(vector&lt;int&gt;&amp; A, int b) {\n  vector&lt;int&gt; C{};\n  int r{0};\n  for (int i = A.size() - 1; i &gt;= 0; --i) {\n    r = r * 10 + A[i];\n    C.push_back(r / b);\n    r %= 10;\n  }\n  reverse(C.begin(), C.end());\n  while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();\n  return {C, r};\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/","title":"Geometry(2D)","text":"<p>To solve geometry problems in 2D with computers, we need some basic knowledge about geometry relationships and equations.</p>"},{"location":"Coding/Algorithm/07_geometry/#notion","title":"Notion","text":""},{"location":"Coding/Algorithm/07_geometry/#point","title":"Point","text":"<p>In Cartesian Coordinate System, we use coordinates \\((x, y)\\) to represent a point, for example, \\((2, 3)\\), \\((-7, 0)\\).</p> <pre><code>struct Point {\n  double x{0.};\n  double y{0.};\n};\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#vector","title":"Vector","text":"<p>The representation of vector is like point, we use \\((x, y)\\) to represent a vector.</p> <pre><code>using Vector = Point;\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#line","title":"Line","text":"<p>There are many variant ways to write the equation of a line:</p> <ul> <li>Normal form: \\(ax + by + c = 0\\);</li> <li>Slope-intercept form: \\(y = kx + b\\);</li> <li>Intercept form: \\(\\frac{x}{a} + \\frac{y}{b} = 1\\);</li> </ul> <p>Consider that we just want to know where the line locates and how the line slopes, we can use the form of:</p> <ul> <li>a point on line and the unit vector of the line.</li> </ul> <pre><code>struct Line {\n  Point point{0., 0.};\n  Vector unit{0., 1.};\n};\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#line-segment","title":"Line Segment","text":"<p>We use two end points \\((x_1, y_1), (x_2, y_2)\\) of the line segment to represent it.</p> <pre><code>struct LineSegment {\n  Point start{0., 0.};\n  Point end{0., 0.};\n};\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#polygon","title":"Polygon","text":"<p>We record all vertices of the polygon to represent it.</p> <pre><code>struct Polygon {\n  vector&lt;Vector&gt; points{};\n};\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#curve","title":"Curve","text":"<p>Some special curves like Bezier curve and Bell curve, we use its analytical expressions to represent them. For simple curve like circle, we can use the central point and radius of the circle to represent it.</p> <pre><code>struct Circle {\n  Point center{0., 0.};\n  double radius{0.};\n};\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#basic-equations","title":"Basic Equations","text":""},{"location":"Coding/Algorithm/07_geometry/#triangle","title":"Triangle","text":""},{"location":"Coding/Algorithm/07_geometry/#law-of-sines","title":"Law of sines","text":"\\[ \\frac{a}{\\sin{A}} = \\frac{b}{\\sin{B}} = \\frac{c}{\\sin{C}} = 2R \\] <p>where:</p> <ul> <li>\\(a, b, c\\) are the lengths of the sides of a triangle;</li> <li>\\(A, B, C\\) are the opposite angle of \\(a, b, c\\);</li> <li>\\(R\\) is the radius of the triangle's circumcircle.</li> </ul>"},{"location":"Coding/Algorithm/07_geometry/#law-of-cosines","title":"Law of cosines","text":"\\[ a^2 = b^2 + c^2 - 2bc\\cos{A} \\] \\[ b^2 = a^2 + c^2 - 2ac\\cos{B} \\] \\[ c^2 = a^2 + b^2 - 2ab\\cos{C} \\]"},{"location":"Coding/Algorithm/07_geometry/#vector_1","title":"Vector","text":""},{"location":"Coding/Algorithm/07_geometry/#addition-and-subtraction","title":"Addition and Subtraction","text":"<p>The sum of two vectors is a third vector, represented as the diagonal of the parallelogram constructed with the two original vectors as sides. As for subtraction, set the second vector coordinates with its opposite number and use the same equation.</p> <p></p> \\[ A(x_1, y_1) + B(x_2, y_2) = C(x_1 + x_2, y_1 + y_2) \\] <pre><code>Vector operator+(const Vector&amp; A, const Vector&amp; B) {\n  return Vector{A.x + B.x, A.y + B.y};\n}\n\nVector operator-(const Vector&amp; A, const Vector&amp; B) {\n  return Vector{A.x - B.x, A.y - B.y};\n}\n\nVector operator*(const Vector&amp; A, const double k) {\n  return Vector{A.x * k, A.y * k};\n}\n\nVector operator/(const Vector&amp; A, const double k) {\n  return Vector{A.x / k, A.y / k};\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#dot-production","title":"Dot Production","text":"<p>The dot product, also called the scalar product, is a scalar real number equal to the product of the lengths of vector \\(|\\vec{a}|\\) and \\(|\\vec{b}|\\) and the cosine of the angle \\(\\theta\\) between them:</p> \\[ \\vec{a} \\cdot \\vec{b} = |\\vec{a}||\\vec{b}|\\cos{\\theta}  \\] <p>We use dot product to:</p> <ul> <li>check if the two vectors are perpendicular: </li> </ul> \\[a \\cdot b = 0\\] <ul> <li>calculate the angle between two vectors:</li> </ul> \\[\\cos{\\theta} = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}||\\vec{b}|}\\] <p>The result of dot product is calculated as:</p> <pre><code>double operator*(const Vector&amp; A, const Vector&amp; B) {\n  return A.x * B.x + A.y * B.y;\n}\n\ndouble Length(const Vector&amp; A) {\n  return sqrt(A * A);\n}\n\ndouble Angle(const Vector&amp; A, const Vector&amp; B) {\n  return acos(A * B / Length(A) / Length(B));\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#cross-production","title":"Cross Production","text":"<p>The cross product, also called the vector product, is a third vector \\(\\vec{c}\\), perpendicular to the plane of the original vectors. The magnitude of \\(\\vec{c}\\) is equal to the product of the lengths of vectorss \\(\\vec{a}\\) and \\(\\vec{b}\\) and the sine of the angle \\(\\theta\\) between them:</p> \\[ |\\vec{c}| = |\\vec{a}||\\vec{b}|\\sin{\\theta} \\] <p>We can find the direction of cross product with right-hand rule: </p> <p>The cross product \\(\\vec{c} = \\vec{a} \\times \\vec{b}\\) (vertical, in purple) changes as the angle between the vector \\(\\vec{a}\\)(blue) and \\(\\vec{b}\\)(red) changes.  The cross product is:</p> <ul> <li>always orthogonal to both vectors;</li> <li>has magnitude \\(0\\) when the vectors are parallel;</li> <li>has maximum magnitude \\(|\\vec{a}||\\vec{b}|\\) when they are orthogonal.</li> </ul> <p></p> <p>The result of dot product is calculated as: <pre><code>double Cross(const Vector&amp; A, const Vector&amp; B) {\n  return A.x * B.y - A.y * B.x;\n}\n</code></pre></p>"},{"location":"Coding/Algorithm/07_geometry/#rotation-of-vector","title":"Rotation of Vector","text":"<p>Let's say that we have a point \\((x_1, y_1)\\), which also defines the vector \\(\\vec{a_1}\\). The angle of \\(\\vec{a_1}\\) is \\(\\beta\\). The vector \\(\\vec{a_1}\\) has length \\(L\\). We rotate this vector anticlockwise around the origin by \\(\\alpha\\) degrees, the new vector \\(\\vec{a_2}\\) has coordinates \\((x_2, y_x)\\). The length \\(L\\) is not changed, so we have:</p> \\[ x_1 = L \\cos{\\beta} \\] <p>$$ y_1 = L \\sin{\\beta} $$ As we rotate \\((x_1, y_1)\\) by angle \\(\\beta\\) to get \\((x_2, y_2)\\), the new vector \\(\\vec{a_2}\\) has:</p> \\[ x_2 = L \\cos{(\\alpha + \\beta)} \\] \\[ y_2 = L \\sin{(\\alpha + \\beta)} \\] <p>Combine all these equations above we have:</p> \\[ \\begin{align} x_2  &amp; = L cos(\\alpha + \\beta) \\\\\\\\ &amp; = L (\\cos{\\alpha}\\cos{\\beta} - \\sin{\\alpha}\\sin{\\beta}) \\\\\\\\ &amp; = L \\cos{\\beta}\\cos{\\alpha} - L \\sin{\\beta}\\sin{\\alpha} \\\\\\\\ &amp; = x_1 \\cos{\\alpha} - y_1 \\sin{\\alpha} \\\\\\\\ \\end{align} \\] \\[ \\begin{align} y_2  &amp; = L sin(\\alpha + \\beta) \\\\\\\\ &amp; = L (\\sin{\\alpha}\\cos{\\beta} + \\cos{\\alpha}\\sin{\\beta}) \\\\\\\\ &amp; = L \\cos{\\beta}\\sin{\\alpha} + L \\sin{\\beta}\\cos{\\alpha} \\\\\\\\ &amp; = x_1 \\sin{\\alpha} + y_1 \\cos{\\alpha} \\\\\\\\ \\end{align} \\] <p>So the result of rotation of vector is: <pre><code>Vector Rotate(Vector A, double alpha) {\n  return Vector{A.x * cos(alpha) - A.y * sin(alpha),\n                A.x * sin(alpha) + A.y * cos(alpha)};\n}\n</code></pre></p>"},{"location":"Coding/Algorithm/07_geometry/#basic-problems","title":"Basic Problems","text":""},{"location":"Coding/Algorithm/07_geometry/#area-of-triangle","title":"Area of Triangle","text":"<p>When we know the base and height, the area of triangle is:`</p> \\[ S = \\frac{1}{2} |AB| \\cdot h \\] <p>as we have:</p> \\[ |\\vec{AB} \\times \\vec{AC}| = |\\vec{AB}||\\vec{AC}|sin\\theta \\] <p>and</p> \\[ h = |\\vec{AC}|sin\\theta \\] <p>The area of triangle can be calculated:</p> \\[ S = \\frac{1}{2} |\\vec{AB} \\times \\vec{AC}|  \\] <pre><code>double TriangleArea(const Point&amp; A, const Point&amp; B, const Point&amp; C) {\n  return Cross(B - A, C - A) / 2;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#area-of-polygon","title":"Area of Polygon","text":"<p>We can divide a polygon to multiple triagnles and calculate the sum of their areas.</p> <pre><code>double PolygonArea(const Polygon&amp; poly) {\n  double res{0};\n  int m = poly.points.size();\n  for (int i = 1; i &lt; m - 1; ++i) {\n    res += Cross(poly.points[i] - poly.points[0], \n                 poly.points[i + 1], poly.points[0]);\n  }\n  return res / 2.;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#point-on-line-side","title":"Point on Line Side","text":"<p>We can use the cross product to check a point on wihch side of the line: if the cross product is </p> <ul> <li>\\(&gt; 0\\), point is on line left;</li> <li>\\(&lt; 0\\), point is on line right.</li> </ul> <pre><code>bool IsPointOnLineLeft(const Line&amp; L, const Point&amp; P) {\n  return Cross((P - L.point), L.unit) &gt; 0.;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#point-and-line-distance","title":"Point and Line Distance","text":"<p>The result of cross product is the area of parallelogram, we divide this by parallelogram's base to get height, which is the distance from point to line.</p> <pre><code>double DistanceFromPointToLine(const Point&amp; P, const Line&amp; L) {\n  Vector v1{L.unit - L.point};\n  Vector v2{P - L.point};\n  return fabs(Cross(v1, v2) / Length(v1));\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#point-and-line-segment-distance","title":"Point and Line Segment Distance","text":"<p>If the point is not in the rectangle of line segment, we should calculate the distance from point to nearest line segment point; otherwise we can use the line distance to get the result.</p> <pre><code>double DistanceFromPointToLineSegment(const Point&amp; P, const LineSegment&amp; L) {\n  Vector v1{L.end - L.start};\n  Vector v2{P - L.start};\n  Vector v3{P - L.end};\n  if (sign(v1 * v2) &lt; 0) return Length(v2);\n  if (sign(v1 * v3) &gt; 0) return Length(v3);\n  return fabs(Cross(v1, v2) / Length(v1));\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#point-on-line-segment","title":"Point on Line Segment","text":"<p>If a point is on line segment, it should meet:</p> <ul> <li>the point is on the line;</li> <li>the point is between two end points of line segment.</li> </ul> <pre><code>int Sign(double x) {\n  return x &lt; -1e-4 ? -1 : x &gt; 1e-4 ? 1 : 0;\n}\n\nbool IsPointOnSegment(const LineSegment&amp; L, const Point A) {\n  return Sign(Cross(L.start - A, L.end - A)) == 0 &amp;&amp;\n         Sign((L.start - A) * (L.end - A)) &lt;= 0;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#point-in-polygonpip","title":"Point in Polygon(PIP)","text":"<p>In computational geometry, the <code>point in polygon</code> problem asks whether a given point in the plane lies inside of a polygon. There are two methods to check if the point is in polygon:</p> <ul> <li>Ray casting</li> <li>Winding number</li> </ul>"},{"location":"Coding/Algorithm/07_geometry/#ray-casting-algorithm","title":"Ray casting algorithm","text":"<p>One simple way of finding whether the point is inside a simple polygon is to test how many times a ray, starting from the point in any fixed direction, intersects the edges of the polygon. If the ray intersects the polygon's edge:</p> <ul> <li><code>even number</code> times, the point is outside the polygon;</li> <li><code>odd number</code> times, the point is inside the polygon.</li> </ul> <p>There are some special cases we need to deal with:</p> <ol> <li>ray intersects the conves vertex(case 1), which should count once;</li> <li>ray intersects the concave vertex(case 2), which should not be counted;</li> <li>ray intersects the edge of polygon, which should not be counted.</li> </ol> <p>To simplify the logic, we think that a point is in a polygon if:</p> <ol> <li>the point is on the edge;</li> <li>the ray from point to long long right has intersetion with the edge.</li> </ol> <p>While calculating the intersection with the edge, we check:</p> <ol> <li>the point is between the edge in y direction: <code>p0.y - p.y != p1.y - p.y</code></li> <li>the intersection size: <code>p0.y &lt; p1.y ? cross_product &gt; 0 : cross_product &lt; 0</code></li> </ol> <pre><code>// Ray casting\nbool IsPointInPolygon(const Point&amp; p, cosnt Polygon&amp; poly) {\n  bool f{false};\n  auto p0 = poly.points.back();\n  for (auto p1 : poly.points) {\n    if (IsPointOnSegment(p, {p0, p1})) return true;\n    if ((p0.y &gt; p.y) != (p1.y &gt; p.y)) {\n      auto side = (p1 - p0).Cross(p - p0);\n      f ^= p0.y &lt; p1.y ? side &gt; 0 : side &lt; 0;\n    }\n    p0 = p1;\n  }\n  return f;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#winding-number-algorithm","title":"Winding Number Algorithm","text":"<p>Winding number algorithm links the point to all points of the polygon and calculate the sum of all the angles, if the angle is: </p> <ul> <li>\\(\\ne 0\\), the point is not in polygon;</li> <li>\\(= 0\\), the point is in polygon.</li> </ul> <pre><code>// Winding number\nbool IsPointInPolygon(const Point&amp; p, const Polygon&amp; poly) {\n  double accumulate_angle{0};\n  int m = poly.points.size();\n  for (int i = 0; i &lt; m; ++i) {\n    auto&amp; p1 = poly.points[i];\n    auto&amp; p2 = poly.points[(i + 1) % m];\n    if (IsPointOnSegment(p, {p1, p2})) return true;\n    accumulate_angle += acos((p1 - P) * (p2 - P) / Length(p1 - p) / Length(p2 - p));\n  }\n  return sign(accumulate_angle) == 0;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#line-segment-intersection","title":"Line Segment Intersection","text":"<p>There are three relationships between two line segments:</p> <ul> <li>no intersection;</li> <li>intersection;</li> <li>overlaps.</li> </ul> <p>And as for the intersection case, we can use following methods to calculate its intersection point:</p> <p></p> <p>We assume that the intersection point is \\(O\\), the area of the \\(\\triangle ABC\\) and \\(\\triangle ABD\\) can be calculated by:</p> \\[ S_{ABC} = \\frac{\\vec{AB} \\times \\vec{AC}} {2} \\] \\[ S_{ABD} = \\frac{\\vec{AB} \\times \\vec{AD}} {2} \\] <p>As we have known that \\(\\triangle ABC\\) and \\(\\triangle ABD\\) have the same base \\(AB\\):</p> \\[ \\frac{S_{ABC}} {S_{ABD}} = \\frac{\\frac{|AB| * |CN|}{2}}{\\frac{|AB| * |DM|}{2}} =  \\frac{|CN|} {|DM|} \\] <p>And according to triangle rules:</p> \\[ \\frac{|DM|}{|CN|} = \\frac{|DO|}{|CO|} \\] <p>Finally:</p> \\[ \\frac{|DO|}{|CO|} = \\frac{S_{ABD}}{S_{ABC}} \\] \\[ \\frac{|DO|}{|DC|} = \\frac{S_{ABD}}{S_{ABC} + S_{ABD}} = k \\] \\[ \\vec{DO} = k * \\vec{DC} \\] <pre><code>bool IsLineSegmentIntersection(const LineSegment&amp; L1, const LineSegment&amp; L2) {\n  return sign(Cross(L1.end - L1.start, L2.start - L1.start)) *\n             sign(Cross(L1.end - L1.start, L2.end - L1.start)) &lt; 0 &amp;&amp;\n         sign(Cross(L2.end - L2.start, L1.start - L2.start)) *\n             sign(Cross(L2.end - L2.start, L1.end - L2.start)) &lt; 0;\n}\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#convex-hull","title":"Convex Hull","text":"<p>The convex hull of a set of points is defined as the smallest convex polygon, that encloses all of the points in the set. Convex means that the polygon has no coner that is bent inwards.</p> <p>A usefull way to think about the convex hull is the rubber band analogy. Suppose the points in the set were nails, sticking out of a flat surface. Imaging now, what would happen if you took a rubber band and stretched it around the nails. Trying to contract back to its origin length, the rubber band would enclose the nails, touching the ones that stick out the furthest from the centre.</p>"},{"location":"Coding/Algorithm/07_geometry/#andrews-monotone-chain-convex-hull-algorithm","title":"Andrew's monotone chain convex hull algorithm","text":"<p>Andrew's algorithm constructs the convex hull of a set of 2D points in \\(O(NlogN)\\) time.</p> <p>It does so by first sorting the points lexicographically (first by x-coordinate, and in case of a tie, by y-coordinate), and then constructing upper and lower hulls of the points in \\(O(n)\\) time.</p> <p></p> <p>The process is mainly:</p> <ol> <li>Sort the points by its x-coordinate, if the x-coordinate is equal, by y-coordinate;</li> <li>Start from the leftmost point, if the new point is higher(use <code>cross product</code>) than last point in stack, we pop the last; if not, we push the new point to stack. After this, we can get the upper hull.</li> <li>We remove all points used in upper hull, and do the same thing as step 2 in reverse order to get the lower hull.</li> <li>Return all points in upper and lower hull.</li> </ol> <pre><code>vector&lt;vector&lt;int&gt;&gt; andrew(const vector&lt;vector&lt;int&gt;&gt;&amp; pts) {\n    sort(pts.begin(), pts.end(), [](auto&amp; a , auto&amp; b) {\n      return a[0] == b[0] ? a[1] &lt; b[1] : a[0] &lt; b[0];\n    });\n    auto cross = [](auto&amp; p1, auto&amp; p2, auto&amp; p0) -&gt; int {\n      return (p1[0] - p0[0]) * (p2[1] - p0[1]) -\n             (p1[1] - p0[1]) * (p2[0] - p0[0]);\n    };\n\n    int m = pts.size();\n    vector&lt;int&gt; hull{};\n    vector&lt;bool&gt; v(m, true);\n    for (int i = 0; i &lt; m; ++i) {\n      while (hull.size() &gt;= 2 &amp;&amp; cross(pts[*hull.rbegin()], pts[i],\n                                       pts[*(hull.rbegin() + 1)]) &gt; 0) {\n        v[hull.back()] = false;\n        hull.pop_back();\n      }\n      hull.push_back(i);\n    }\n\n    int n = hull.size();\n    v[0] = false;\n    for (int i = m - 1; i &gt;= 0; --i) {\n      if (v[i]) continue;\n      while (hull.size() &gt;= 2 &amp;&amp; cross(pts[*hull.rbegin()], pts[i],\n                                       pts[*(hull.rbegin() + 1)]) &gt; 0) {\n        hull.pop_back();\n      }\n      hull.push_back(i);\n    }\n    hull.pop_back();\n\n    vector&lt;vector&lt;int&gt;&gt; ans{};\n    for (auto i : hull) ans.push_back(std::move(pts[i]));\n    return ans;\n  }\n</code></pre>"},{"location":"Coding/Algorithm/07_geometry/#reference","title":"Reference","text":"<ul> <li>Geometry</li> <li>Computer Geometry Tutorial</li> </ul>"},{"location":"Coding/Algorithm/08_graph/","title":"Graph","text":"<p>A <code>Graph</code> consists of:</p> <ul> <li><code>node</code>s(vertices) and</li> <li><code>edge</code>s which connecting these <code>node</code>s.</li> </ul> <p>Graphs are mathematical structures uesed to model pairwise relations between objects. </p> <p></p> <p>A distinction is made between:</p> <ul> <li><code>undirected graph</code>: where edges link two nodes symmetrically;</li> <li><code>directed graph</code>: where edges link two nodes asymmetrically.</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#topological-sorting","title":"Topological Sorting","text":"<p>A <code>topological sort</code> of a <code>directed graph</code> is a linear ordering of its vertices such that for every directed edge <code>uv</code> from vertex <code>u</code> to vertex <code>v</code>, <code>u</code> comes before <code>v</code> in the ordering.</p>"},{"location":"Coding/Algorithm/08_graph/#kahns-algorithm","title":"Kahn's Algorithm","text":"<p>The process is:</p> <ol> <li>we find a list of <code>start nodes</code> which have no incoming edges and insert them into a queue;</li> <li>we remove a node from queue and for each of next nodes, we decrease its indegrees, if next node's indegree is zero, we push it to the queue;</li> <li>loop step 1 and 2 until the queue is empty.</li> </ol> <pre><code>vector&lt;int&gt; TopoSort(const vector&lt;pair&lt;int, int&gt;&gt;&amp; edges, int n) {\n  unordered_map&lt;int, vector&lt;int&gt;&gt; graph{};\n  vector indeg(n, 0);\n  for (auto [f, t] : edges) { \n    graph[f].push_back(t);\n    indeg[t]++;\n  }\n\n  queue&lt;int&gt; q{};\n  for (int i = 0; i &lt; n; ++i) if (!indeg[i]) q.push(i);\n\n  vector&lt;int&gt; ans{};\n  while (!q.empty()) {\n    auto node = q.front(); q.pop();\n    ans.push_back(nodee);\n    for (auto next : graph[node]) if (!--indeg[next]) q.push(next);\n  }\n\n  return ans;\n}\n</code></pre>"},{"location":"Coding/Algorithm/08_graph/#shortest-pathsp","title":"Shortest Path(SP)","text":"<p>In graph theory, the <code>shortest path problem</code> is the problem of finding a path between two nodes in a graph such that the sum of the weights of its constituent edges is minimized. The mainly used algorihtms are:</p> <ul> <li>Floyd</li> <li>Bellman-Ford</li> <li>Dijkstra</li> </ul> Floyd Bellman-Ford Dijkstra Multiple-source Shortest Path Singole-source Shortest Path Single-source Shortest Path Not negtive cycle graph any graph Not negtive edge graph \\(O(N^3)\\) \\(O(NM)\\) \\(O(MlogM)\\)"},{"location":"Coding/Algorithm/08_graph/#floyd","title":"Floyd","text":"<p>Floyd algorithm compares all possible paths through the graph between each pair of vertices. <pre><code>vector&lt;vector&lt;int&gt;&gt; floyd(Graph&amp; graph, int node) {\n  auto m = graph.size();\n  vector distance(m + 1, vector&lt;int&gt;(m + 1, INT_MAX));\n  for (int i = 1; i &lt;= n; ++i) distance[i][i] = 0;\n  for (int k = 1; k &lt;= n; ++k) {\n    for (int i = 1; i &lt;= n; ++i) {\n      for (int j = 1; j &lt;= n; ++j) {\n        distance[i][j] = min(distance[i][j], distance[i][k] + graph[k][j]);\n      }\n    }\n  }\n\n  return distance;  // RVO\n}\n</code></pre></p> <ul> <li>network-delay-time</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#bellman-ford","title":"Bellman-Ford","text":"<p>Bellman-Ford is an algorithm that computes shortest paths from a single source node to all of the other nodes in a weighted digraph. It is capable of handling graphs in which some of the edge weights are negtive numbers. <pre><code>int bellman_ford(Graph&amp; graph, int src, int tar) {\n  queue&lt;int&gt; q{src};\n  vector distance(graph.size() + 1, INT_MAX);\n  distance[src] = 0;\n\n  auto relax = [&amp;](auto src, auto tar) -&gt; bool {\n    if (distance[src] + graph[src][tar] &gt; distance[tar]) return false;\n    distance[tar] = distance[src] + graph[src][tar];\n    return true;\n  };\n\n  while (!q.empty()) {\n    int node = q.top(); q.pop();\n    for (auto next : graph[node]) { if (relax(node, next)) q.push(next); }\n  }\n\n  return distance[tar];\n}\n</code></pre></p> <ul> <li>network-delay-time</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#dijkstra","title":"Dijkstra","text":"<p>Dijkstra is an algorithm that computes shortest paths from a single source node to all of the other nodes in a weighted digraph. It is not able to handle graphs in which some of the edge weights are negtive numbers.</p> <p></p> <pre><code>int dijkstra(Graph&amp; graph, int src, int tar) {\n  vector distance(graph.size() + 1, INT_MAX);\n  distance[src] = 0;\n\n  auto gt = [](auto&amp; a, auto&amp; b) { return a.second &gt; b.second; };\n  usint PII = pair&lt;int, int&gt;;\n  priority_queue&lt;PII, vector&lt;PII&gt;, decltype(gt)&gt; q(gt);\n\n  auto relax = [&amp;](auto src, auto tar) -&gt; bool {\n    if (distance[src] + graph[src][tar] &gt; distance[tar]) return false;\n    distance[tar] = distance[src] + graph[src][tar];\n    return true;\n  };\n\n  while (!q.empty()) {\n    auto [node, val] = q.top();\n    q.pop();\n\n    for (auto next : graph[node]) {\n      if (relax(node, next)) q.emplace_back(next, distance[next]);\n    }\n  }\n\n  return distance[tar];\n}\n</code></pre> <ul> <li>network-delay-time</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#k-shortest-pathksp","title":"K Shortest Path(KSP)","text":"<p>The <code>KSP</code> problem is a generalization of the <code>SP</code> problem in a given network. It asks not only about a shortest path but also about next \\(k - 1\\) shortest path (which may be longer than the shortest path). A variant of the problem is the loopless k shortest paths.</p>"},{"location":"Coding/Algorithm/08_graph/#a","title":"A*","text":"<pre><code>double a_star(Graph&lt;int&gt; graph, vector&lt;double&gt;&amp; h, int src,\n                           int tar, int k) {\n  int m = graph.GetVertexSize();\n  vector&lt;double&gt; g(m, 1e7);\n  g[src] = 0;\n\n  auto gt = [](auto&amp; a, auto&amp; b) -&gt; bool { return a.second &gt; b.second; };\n  using PID = pair&lt;int, double&gt;;\n  priority_queue&lt;PID, vector&lt;PID&gt;, decltype(gt)&gt; q(gt);\n  q.emplace(src, h[src]);\n\n  unordered_map&lt;int, int&gt; parent{};\n  int cnt{0};\n\n  while (!q.empty()) {\n    auto [node, f] = q.top();\n    q.pop();\n\n    if (node == tar) cnt++;\n    if (cnt == k) return g[node];\n\n    for (auto&amp; [from, to, cost]: graph.GetEdges(node)) {\n      g[to-&gt;id] = g[node] + cost;\n      q.emplace(to, g[to-&gt;id] + h[to-&gt;id]);\n    }\n  }\n\n  return -1;\n}\n</code></pre>"},{"location":"Coding/Algorithm/08_graph/#topological-sorting_1","title":"Topological Sorting","text":"<p>A topological sort of a directed graph is a linear ordering of its nodes such that for every directed edge \\((u, v)\\), \\(u\\) comes before \\(v\\) in the ordering.</p>"},{"location":"Coding/Algorithm/08_graph/#bfs","title":"BFS","text":"<pre><code>vector&lt;int&gt; res{};\nbool topo_sort(Graph&amp; graph, vector&lt;int&gt;&amp; in_degree) {\n  queue&lt;int&gt; q{};\n  for (int i = 0; i &lt; in_degree.size(); ++i) {\n    if (in_degree[i] == 0) q.push(i);\n  }\n\n  while (!q.empty()) {\n    int node = q.top();\n    q.pop();\n    res.push(node);\n    for (auto next : graph[node]) {\n      in_degree[next]--;\n      if (in_degree[next] == 0) q.push(next);\n    }\n  }\n\n  return res.size() == in_degree.size();\n}\n</code></pre>"},{"location":"Coding/Algorithm/08_graph/#dfs","title":"DFS","text":"<pre><code>vector&lt;int&gt; color{};  // 0: white; 1: gray; 2: black\nvector&lt;int&gt; topo{};\n\nbool dfs(Graph&amp; graph, int node) {\n  color[node] = 1;\n  for (auto next : graph[node]) {\n    if (color[next] == 1) return false;\n    if (color[next] == 0 &amp;&amp; !dfs(graph, next)) return false;\n  }\n  color[node] = 2;\n  topo.push_back(node);\n  return true;\n}\n\nbool topo_sort(Graph&amp; graph) {\n  color.resize(graph.size(), 0);\n  topo.clear();\n\n  for (int i = 0; i &lt; graph.size(); ++i) {\n    if (color[i] == 0 &amp;&amp; !dfs(graph, i)) return false;\n  }\n  reverse(topo.begin(), topo.end());\n  return true;\n}\n</code></pre>"},{"location":"Coding/Algorithm/08_graph/#minimum-spanning-treemst","title":"Minimum Spanning Tree(MST)","text":"<p>A minimum spanning tree(MST) is a subset of the edges of a connected, edge-weighted undirected graph that connects all the nodes together, without any cycles and with the minimum possible total edge weight. That is, it is a spanning tree whose sum of the edge weights is as small as possible. More generallly, any edge-weighted undirected graph(not neccessarily connected) has a minimum spanning forest, which is a union of the minimum spanning trees for its connected components.</p> <p></p>"},{"location":"Coding/Algorithm/08_graph/#kruskal","title":"Kruskal","text":"<p>Kruscal's algorithm finds a minimum spanning forest of an undirected edge-weighted graph. If the graph is connected, it finds a minimum spanning tree. For a disconnected graph, a minimum spanning forest is composed of a minimum spanning tree for each connected component. It is a greedy algorithm in graph theory as in each step it adds the next lowest-weight edge that will not form a cycle to the minimum spanning forest.</p> <p></p> <pre><code>class UnionFind {\n public:\n  Union(int n) : size(n - 1, 1), cnt{n} {\n    for (int i = 0; i &lt; n; ++i) parent.push_back(i);\n  }\n\n public:\n  int find(int x) {\n    if (parent[x] != x) parent[x] = find(parent[x]);\n    return parent[x];\n  }\n\n  bool unite(int x, int y) {\n    int xx = find(x);\n    int yy = find(y);\n    if (xx == yy) return false;\n    if (size[xx] &gt; size[yy]) swap(xx, yy);\n    parent[xx] = yy;\n    size[yy] += size[xx];\n    cnt--;\n    return true;\n  }\n\n  int count() const {\n    return cnt;\n  }\n\n private:\n  vector&lt;int&gt; parent{};\n  vector&lt;int&gt; size{};\n  int cnt{0};\n};\n\nstruct Edge{\n  int from{0};\n  int to{0};\n  int cost{0};\n};\n\n// n: node_num\nint kruskal(vector&lt;Edge&gt;&amp; edges, int n) {\n  UnionFind uf{n};\n  sort(edges.begin(), edges.end(), [](auto&amp; a, auto&amp; b) {\n    return a.cost &lt; b.cost;\n  });\n\n  int res{0};\n  for (auto [from, to, cost] : edges) {\n    if (uf.unite(from, to)) res += cost;\n  }\n\n  return uf.count() == 1 ? res : -1;\n}\n</code></pre> <ul> <li>min-cost-to-connect-all-points</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#prim","title":"Prim","text":"<p>Prim algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. This means it finds a subset of the edges that forms a tree that includes every nodes, where the total weight of all the edges in the tree is minimized. The algorithm operates by building this tree one node at a time, from an arbitrary starting node, at each step adding the cheapest possible connection from the tree to another node.</p> <p></p> <ul> <li>min-cost-to-connect-all-points</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#strongly-connected-componentsscc","title":"Strongly Connected Components(SCC)","text":""},{"location":"Coding/Algorithm/08_graph/#tarjan","title":"Tarjan","text":""},{"location":"Coding/Algorithm/08_graph/#kosaraju","title":"Kosaraju","text":""},{"location":"Coding/Algorithm/08_graph/#euler-graph","title":"Euler Graph","text":"<p>An <code>Eulerian trail</code> or <code>Euler walk</code> in an undirected graph is a path that uses each edge exactly once. If such a path exists, the graph is called <code>traversable</code> or <code>semi-eulerian</code>.</p> <p>An <code>Eulerian cycle</code>, <code>Eulerian circuit</code> or <code>Euler tour</code> in an undirected graph is a cycle that uses each edge exactly once. </p> <p>A graph that has an Eulerian trail but not an Eulerian circuit is called <code>semi-Eulerian</code>.</p>"},{"location":"Coding/Algorithm/08_graph/#properties","title":"Properties","text":"<ul> <li>An undirected graph has Eulerian cycle if and only if every vertex has even degree, and all of its vertices with nonzero degree belong to a single connected component.</li> <li>An undirected graph can be decomposed into edge-disjoint cycles if and only if all of its vertices have even degree. </li> <li>An undirected graph has an Eulerian cycle if and only if exactly zero or two vertices have odd degree.</li> <li>A directed graph has an Eulerian cycle if and only if every vertex has equal in degree and out degree, and all of its vertices with nonzero degree belong to a single strongly connected component.</li> <li>A directed graph has an Eulerian trail if and only if at most one vertex has (out-degree) \u2212 (in-degree) = 1, at most one vertex has (in-degree) \u2212 (out-degree) = 1, every other vertex has equal in-degree and out-degree, and all of its vertices with nonzero degree belong to a single connected component of the underlying undirected graph.</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#fleury","title":"Fleury","text":"<p>Fleury's algorithm is an elegant but inefficient algorithm, we don't use it in general.</p>"},{"location":"Coding/Algorithm/08_graph/#hierholzer","title":"Hierholzer","text":"<p>Hierholzer's algorithm provides a different method for finding Euler cycles that is more efficient than Fleury's algorithm:</p> <ul> <li>Choose any starting vertex v, and follow a trail of edges from that vertex until returning to v. It is not possible to get stuck at any vertex other than v, because the even degree of all vertices ensures that, when the trail enters another vertex w there must be an unused edge leaving w. The tour formed in this way is a closed tour, but may not cover all the vertices and edges of the initial graph.</li> <li>As long as there exists a vertex u that belongs to the current tour but that has adjacent edges not part of the tour, start another trail from u, following unused edges until returning to u, and join the tour formed in this way to the previous tour.</li> <li>Since we assume the original graph is connected, repeating the previous step will exhaust all edges of the graph.</li> </ul> <pre><code>void Hierholzer(Graph&amp; graph, Node node) {\n  while (!graph[node].empty()) {\n    auto next = graph[node].back();\n    graph[node].pop_back();\n    Hierholzer(graph, next);\n  }\n}\n</code></pre> <p>Problems:</p> <ul> <li>Reconstruct Itinerary</li> <li>Cracking the Safe</li> <li>Valid Arrangement of Pairs</li> </ul>"},{"location":"Coding/Algorithm/08_graph/#reference","title":"Reference","text":"<ul> <li>10 Graph Algorithms Visually Explained</li> <li>OI WIKI/Graph</li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/","title":"C++11 New Features and Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_11/#new-features","title":"New Features","text":""},{"location":"Coding/C%2B%2B/cpp_11/#move-segmentics","title":"Move Segmentics","text":"<p>Moving an object means to transfer ownership of some resource it manage to another object.</p> <p>Benefits:</p> <ul> <li>Performance optimization: while copying a temporary object(for example, a <code>vector</code>) to a list, without <code>std::move</code> you have to copy every element in vector and store them in new place. <code>Moving</code> a vector is just copying some pointer and internal state over to the new one.</li> <li>Make it possible to have only one instance at a time: for example, <code>std::unique_ptr</code> is non-copyable, but you can use <code>move</code> to transfer an instance between scopes at the language level.</li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/#rvalue-references","title":"Rvalue References","text":"<p><code>Rvalue reference</code> is a new reference. It's a non-template type(such as <code>int</code>) and can be created with the syntax <code>T &amp;&amp;</code>. It can be binded only to rvalues.</p>"},{"location":"Coding/C%2B%2B/cpp_11/#forwarding-references","title":"Forwarding References","text":"<p><code>Forwarding reference</code> is also known as <code>universal references</code>.</p> <ul> <li>It can be created by <code>T&amp;&amp;</code> when <code>T</code> is a template type or <code>auto&amp;&amp;</code>.</li> <li>This enables <code>perfect forwarding</code>: the ability to pass arguments while maintaining their value category(e.g. lvalue stay as lvalue, temporaries are forwarded as rvalue).</li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/#variadic-templates","title":"Variadic Templates","text":"<p>The <code>...</code> syntax creates a <code>parameter pack</code> or expands one. A template <code>parameter pack</code> is a template parameter that accepts zero or more template arguments. A template with at least one parameter pack is called a <code>variadic template</code>. An exmple is as following: <pre><code>template &lt;typename... T&gt;\nstruct arity {\n  constexpr static int value = sizeof...(T);\n};\nstatic_assert(arity&lt;&gt;::value == 0);\nstatic_assert(arity&lt;char, short, int&gt;::value == 3);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#initializer-lists","title":"Initializer Lists","text":"<p>A lightweight array-like container of elements created using a \"braced list\" syntax. For example, <code>1, 2, 3</code> creates a sequences of integars, that has type <code>std::initializer_list&lt;int&gt;</code>. Useful as a replacement to passing a vector of objects to a function. <pre><code>int sum(const std::initializer_list&lt;int&gt; &amp;list) {\n  int sum = 0;\n  for (auto &amp;e : list) {\n    sum += e;\n  }\n  return sum;\n}\n\nauto list = {1, 2, 3};\nsum(list);\nsum({1, 2, 3});\nsum({});\n</code></pre> It can also be used to initialize a vector, for example: <pre><code>const std::vector&lt;int&gt; test({1, 2, 3, 4});\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#static-assertions","title":"Static Assertions","text":"<p>Assertions that are evaluated at compile-time. Usage: <code>static_assert(condition, string)</code>. For example: <pre><code>constexpr int x = 0;\nconstexpr int y = 1;\nstatic_assert(x == y, \"x != y\");\n</code></pre> If <code>x == y</code> is true, compiler will do nothing, else the compiler will report an error, the error message is <code>x != y</code>.</p>"},{"location":"Coding/C%2B%2B/cpp_11/#auto","title":"<code>auto</code>","text":"<p><code>auto</code> typed variables are deduced by the compiler according to the type of their initializer. However, if the compiler cannot determine the type of variable, it will report an error. <pre><code>auto pi = 3.14;  // double\nauto b = 1;  // int\nauto l = 1, m = true, n = 1.6;  // error, 1 is int, m is bool\nauto o;  // error\n</code></pre></p> <p>Functions can also deduce the return type using <code>auto</code>. <pre><code>template &lt;typename X, typename Y&gt;\nauto add(X x, Y y) -&gt; decltype(x + y) {\n  return x + y;\n}\nadd(1, 2);  // int\nadd(1.0, 2);  // double\nadd(1.0, 2.0);  // double\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#lambda-expressions","title":"Lambda Expressions","text":"<p>A <code>lambda</code> is an unnamed function object capable of capturing variable in scope. It features:</p> <ul> <li>a capture list</li> <li>an optional set of parameters with an optional trailing return type</li> <li>a body</li> </ul> <p>An example of <code>capture list</code>:</p> <ul> <li><code>[]</code>: capture nothing</li> <li><code>[=]</code>: capture local objects(local variables, parameters) in scope by value</li> <li><code>[&amp;]</code>: cpature local objects(local variables, parameters) in scope by reference</li> <li><code>[this]</code>: capture <code>this</code> pointer by value</li> <li><code>[a, &amp;b]</code>: capture object <code>a</code> by value and <code>b</code> by reference</li> </ul> <pre><code>int x = 1;\n\nauto getX = [=] { return x; };\ngetX(); // == 1\n\nauto addX = [=](int y) { return x + y; };\naddX(1); // == 2\n\nauto getXRef = [&amp;]() -&gt; int&amp; { return x; };\ngetXRef(); // int&amp; to `x`\n</code></pre> <p>By default, value-captures cannot be modified inside the lambda because the complier-generated method is marked as <code>const</code>. The <code>mutable</code> keyword allows modifying captured variables. The keyword is placed after the parameter-list(which must be present even if it is empty). <pre><code>int x = 1;\n\nauto f1 = [&amp;x] { x = 2; }; // OK: x is a reference and modifies the original\n\nauto f2 = [x] { x = 2; }; // ERROR: the lambda can only perform const-operations on the captured value\n// vs.\nauto f3 = [x]() mutable { x = 2; }; // OK: the lambda can perform any operations on the captured value\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#decltype","title":"<code>decltype</code>","text":"<p><code>decltype</code> is an operator which returns the declared type of an expression passed to it. <pre><code>int a = 1; // `a` is declared as type `int`\ndecltype(a) b = a; // `decltype(a)` is `int`\nconst int&amp; c = a; // `c` is declared as type `const int&amp;`\ndecltype(c) d = a; // `decltype(c)` is `const int&amp;`\ndecltype(123) e = 123; // `decltype(123)` is `int`\nint&amp;&amp; f = 1; // `f` is declared as type `int&amp;&amp;`\ndecltype(f) g = 1; // `decltype(f) is `int&amp;&amp;`\ndecltype((a)) h = g; // `decltype((a))` is int&amp;\n\ntemplate &lt;typename X, typename Y&gt;\nauto add(X x, Y y) -&gt; decltype(x + y) {\n  return x + y;\n}\nadd(1, 2.0); // `decltype(x + y)` =&gt; `decltype(3.0)` =&gt; `double`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#type-aliases","title":"Type Aliases","text":"<p>Semantically similar to using a <code>typedef</code> but <code>using</code> of type aliases is easier to read and are compatible with templates. <pre><code>int x = 1;\n\nauto getX = [=] { return x; };\ngetX(); // == 1\n\nauto addX = [=](int y) { return x + y; };\naddX(1); // == 2\n\nauto getXRef = [&amp;]() -&gt; int&amp; { return x; };\ngetXRef(); // int&amp; to `x`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#nullptr","title":"<code>nullptr</code>","text":"<p>C++11 introduces a new null pointer to replace C's <code>NULL</code> macro. <code>nullptr</code> is of type <code>std::nullptr_t</code> and can be implicitly converted into pointer types, and unlike <code>NULL</code>, not convertible to integral types except <code>bool</code>. <pre><code>void foo(int);\nvoid foo(char*);\nfoo(NULL); // error -- ambiguous\nfoo(nullptr); // calls foo(char*)\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#strongly-typed-enums","title":"Strongly-typed Enums","text":"<p>Type-safe enums that solve a variable of problems with C-style enums:</p> <ul> <li>implicit conversions</li> <li>inability to specify the underlying type</li> <li>scope pollutions</li> </ul> <pre><code>// Specifying underlying type as `unsigned int`\nenum class Color : unsigned int { Red = 0xff0000, Green = 0xff00, Blue = 0xff };\n// `Red`/`Green` in `Alert` don't conflict with `Color`\nenum class Alert : bool { Red, Green };\nColor c = Color::Red;\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_11/#attributes","title":"Attributes","text":"<p>Attributes provide a universal syntax over <code>__attribute__(...)</code>, <code>__declspec</code>, etc <pre><code>// `noreturn` attribute indicates `f` doesn't return.\n[[ noreturn ]] void f() {\n  throw \"error\";\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#constexpr","title":"<code>constexpr</code>","text":"<p><code>constexp</code> is the expression that evaluated by the compiler at compile-time. It must be a const expression that compiler can evaluate at compile-time and can be used to indicate the variables, functions, etc. <pre><code>const int x = 123;\nconstexpr const int&amp; y = x; // error -- constexpr variable `y` must be initialized by a constant expression\n</code></pre></p> <p>The difference to <code>const</code>:</p> <ul> <li><code>const</code> variables can be initialized at run-time, but <code>constexp</code> variables must be initialized at compile-time</li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/#delegating-constructors","title":"Delegating Constructors","text":"<p>Constructors can now call other constructors in the same class using an initializer list. <pre><code>struct Foo {\n  int foo;\n  Foo(int foo) : foo{foo} {}\n  Foo() : Foo(0) {}\n};\n\nFoo foo;\nfoo.foo; // == 0\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#user-defined-literals","title":"User-defined Literals","text":"<p>User-defined literals allow you to extend the language and add your own syntax. To create a literal, define: <pre><code>T operator \"\"X(...) {}\n</code></pre> which returns a type <code>T</code> with a name <code>X</code>.</p> <p>Note that the name of this function defines the name of the literal. Any literal names not starting with an underscore are reserved an won't be invoked.</p> <p>String to integar conversion: <pre><code>// `const char*` and `std::size_t` required as parameters.\nint operator \"\" _int(const char* str, std::size_t) {\n  return std::stoi(str);\n}\n\n\"123\"_int; // == 123, with type `int`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#explicit-virtual-overrides","title":"Explicit Virtual Overrides","text":"<p>Specifies that a virtual function overrides another virtual function. If the virtual function does not override a parent's virtual function, throw a compiler error. <pre><code>struct A {\n  virtual void foo();\n  void bar();\n};\n\nstruct B : A {\n  void foo() override; // correct -- B::foo overrides A::foo\n  void bar() override; // error -- A::bar is not virtual\n  void baz() override; // error -- B::baz does not override A::baz\n};\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#final-specifier","title":"Final Specifier","text":"<p>Specifies that a virtual function cannot be overridden in a derived class or that a class cannot be inherited from. <pre><code>struct A {\n  virtual void foo();\n};\n\nstruct B : A {\n  virtual void foo() final;\n};\n\nstruct C : B {\n  virtual void foo(); // error -- declaration of 'foo' overrides a 'final' function\n};\n\nstruct A final {};\nstruct B : A {}; // error -- base 'A' is marked 'final'\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#default-functions","title":"Default Functions","text":"<p>A more elegant, efficient way to provide a default implementation of a funtion, such as a constructor. <pre><code>struct A {\n  A() = default;\n  A(int x) : x{x} {}\n  int x {1};\n};\nA a; // a.x == 1\nA a2 {123}; // a.x == 123\n\nstruct B {\n  B() : x{1} {}\n  int x;\n};\n\nstruct C : B {\n  // Calls B::B\n  C() = default;\n};\n\nC c; // c.x == 1\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#deleted-functions","title":"Deleted Functions","text":"<p>A more elegant, efficient way to provide a deleted implementation of a function. Useful for preventing copied on objects. <pre><code>class A {\n  int x;\n\npublic:\n  A(int x) : x{x} {};\n  A(const A&amp;) = delete;\n  A&amp; operator=(const A&amp;) = delete;\n};\n\nA x {123};\nA y = x; // error -- call to deleted copy constructor\ny = x; // error -- operator= deleted\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#range-based-for-loops","title":"Range-based For Loops","text":"<p>Syntactic sugar for iterating over a container's elements. <pre><code>std::array&lt;int, 5&gt; a {1, 2, 3, 4, 5};\nfor (int&amp; x : a) x *= 2;\n// a == { 2, 4, 6, 8, 10 }\nfor (int x : a) x *= 2;\n// a == { 1, 2, 3, 4, 5 }\n</code></pre> If you want to change element's value, don't forget to use reference.</p>"},{"location":"Coding/C%2B%2B/cpp_11/#special-member-function-for-move-sementics","title":"Special Member Function for Move Sementics","text":"<p>The copy constructor and copy assignment operator are called when copies are made, and with C++11's introduction of move semantics, there is now a move constructor and move assignment operator for moves. <pre><code>struct A {\n  std::string s;\n  A() : s{\"test\"} {}\n  A(const A&amp; o) : s{o.s} {}\n  A(A&amp;&amp; o) : s{std::move(o.s)} {}\n  A&amp; operator=(A&amp;&amp; o) {\n   s = std::move(o.s);\n   return *this;\n  }\n};\n\nA f(A a) {\n  return a;\n}\n\nA a1 = f(A{}); // move-constructed from rvalue temporary\nA a2 = std::move(a1); // move-constructed using std::move\nA a3 = A{};\na2 = std::move(a3); // move-assignment using std::move\na1 = f(A{}); // move-assignment from rvalue temporary\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#converting-constructors","title":"Converting Constructors","text":"<p>Converting constructors will convert values of braced list syntax into constructor arguments. <pre><code>struct A {\n  A(int) {}\n  A(int, int) {}\n  A(int, int, int) {}\n};\n\nA a {0, 0}; // calls A::A(int, int)\nA b(0, 0); // calls A::A(int, int)\nA c = {0, 0}; // calls A::A(int, int)\nA d {0, 0, 0}; // calls A::A(int, int, int)\n</code></pre></p> <p>Note that the braced list syntax does not allow narrowing: <pre><code>struct A {\n  A(int) {}\n};\n\nA a(1.1); // OK\nA b {1.1}; // Error narrowing conversion from double to int\n</code></pre></p> <p>Note that if a constructor accepts a <code>std::initializer_list</code>, it will be called instead: <pre><code>struct A {\n  A(int) {}\n  A(int, int) {}\n  A(int, int, int) {}\n  A(std::initializer_list&lt;int&gt;) {}\n};\n\nA a {0, 0}; // calls A::A(std::initializer_list&lt;int&gt;)\nA b(0, 0); // calls A::A(int, int)\nA c = {0, 0}; // calls A::A(std::initializer_list&lt;int&gt;)\nA d {0, 0, 0}; // calls A::A(std::initializer_list&lt;int&gt;)\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#explicit-convertion-functions","title":"Explicit Convertion Functions","text":"<p>Conversion functions can now be made explicit using the <code>explicit</code> specifier. <pre><code>struct A {\n  operator bool() const { return true; }\n};\n\nstruct B {\n  explicit operator bool() const { return true; }\n};\n\nA a;\nif (a); // OK calls A::operator bool()\nbool ba = a; // OK copy-initialization selects A::operator bool()\n\nB b;\nif (b); // OK calls B::operator bool()\nbool bb = b; // error copy-initialization does not consider B::operator bool()\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#inline-namespaces","title":"Inline Namespaces","text":"<p>All members of an inline namespace are treated as if they were part of its parent namespace, allowing specialization of functions and easing the process of versioning. This is a transitive property, if A contains B, which in turn contains C and both B and C are inline namespace, C's member can be used as if they were on A. <pre><code>namespace Program {\n  namespace Version1 {\n    int getVersion() { return 1; }\n    bool isFirstVersion() { return true; }\n  }\n  inline namespace Version2 {\n    int getVersion() { return 2; }\n  }\n}\n\nint version {Program::getVersion()};              // Uses getVersion() from Version2\nint oldVersion {Program::Version1::getVersion()}; // Uses getVersion() from Version1\nbool firstVersion {Program::isFirstVersion()};    // Does not compile when Version2 is added\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#non-static-data-member-initializers","title":"Non-static Data Member Initializers","text":"<p>Allows non-static members to be initialized where they are declared, potentially cleaning up constructors of default initializations. <pre><code>// Default initialization prior to C++11\nclass Human {\n    Human() : age{0} {}\n  private:\n    unsigned age;\n};\n// Default initialization on C++11\nclass Human {\n  private:\n    unsigned age {0};\n};\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#right-angle-brackets","title":"Right Angle Brackets","text":"<p>C++11 is now able to infer when a series of right angle brackets is used as an operator or as a closing statement of typedef, without having to add whitespaces. <pre><code>typedef std::map&lt;int, std::map &lt;int, std::map &lt;int, int&gt; &gt; &gt; cpp98LongTypedef;\ntypedef std::map&lt;int, std::map &lt;int, std::map &lt;int, int&gt;&gt;&gt;   cpp11LongTypedef;\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#ref-qualified-member-functions","title":"Ref-qualified Member Functions","text":"<p>Member functions can now be qualified depending on whether <code>*this</code> is an lvalue or rvalue reference. <pre><code>struct Bar {\n  // ...\n};\n\nstruct Foo {\n  Bar getBar() &amp; { return bar; }\n  Bar getBar() const&amp; { return bar; }\n  Bar getBar() &amp;&amp; { return std::move(bar); }\n  Bar getBar() const&amp;&amp; { return std::move(bar); }\nprivate:\n  Bar bar;\n};\n\nFoo foo{};\nBar bar = foo.getBar(); // calls `Bar getBar() &amp;`\n\nconst Foo foo2{};\nBar bar2 = foo2.getBar(); // calls `Bar Foo::getBar() const&amp;`\n\nFoo{}.getBar(); // calls `Bar Foo::getBar() &amp;&amp;`\nstd::move(foo).getBar(); // calls `Bar Foo::getBar() &amp;&amp;`\n\nstd::move(foo2).getBar(); // calls `Bar Foo::getBar() const&amp;&amp;`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#trailing-return-types","title":"Trailing Return Types","text":"<p>C++11 allows functions and lambdas an alternative syntax for specifying their return types. <pre><code>int f() {\n  return 123;\n}\n// vs.\nauto f() -&gt; int {\n  return 123;\n}\n\nauto g = []() -&gt; int {\n  return 123;\n};\n</code></pre></p> <p>This feature is especially useful when certain return types cannot be resolved: <pre><code>// NOTE: This does not compile!\ntemplate &lt;typename T, typename U&gt;\ndecltype(a + b) add(T a, U b) {\n    return a + b;\n}\n\n// Trailing return types allows this:\ntemplate &lt;typename T, typename U&gt;\nauto add(T a, U b) -&gt; decltype(a + b) {\n    return a + b;\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#noexcept-specifier","title":"Noexcept Specifier","text":"<p>The <code>noexcept</code> specifier specifies whether a function could throw exceptions. It is an improved version of <code>throw()</code>. <pre><code>void func1() noexcept;        // does not throw\nvoid func2() noexcept(true);  // does not throw\nvoid func3() throw();         // does not throw\n\nvoid func4() noexcept(false); // may throw\n</code></pre> Non-throwing functions are permitted to call potentially-throwing functions. Whenever an exception is thrown and the search for a handler encounters the outermost block of a non-throwing function, the function std::terminate is called. <pre><code>extern void f();  // potentially-throwing\nvoid g() noexcept {\n    f();          // valid, even if f throws\n    throw 42;     // valid, effectively a call to std::terminate\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#new-libraries","title":"New Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_11/#stdmove","title":"<code>std::move</code>","text":"<p><code>std::move</code> indicates that the object passed to it may have its resources transferred. Using objects that have been moved from should be used with care, as they can be left in an unspecified state. <pre><code>std::unique_ptr&lt;int&gt; p1 {new int{0}}; // in practice, use std::make_unique\nstd::unique_ptr&lt;int&gt; p2 = p1; // error -- cannot copy unique pointers\nstd::unique_ptr&lt;int&gt; p3 = std::move(p1); // move `p1` into `p3`\n                                         // now unsafe to dereference object held by `p1`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdforward","title":"<code>std::forward</code>","text":"<p>Return the arguments passed to it while maintaining their value category and cv-qualifiers. Useful for generic code and factories. Used in conjunction with <code>forward reference</code> <pre><code>struct A {\n  A() = default;\n  A(const A&amp; o) { std::cout &lt;&lt; \"copied\" &lt;&lt; std::endl; }\n  A(A&amp;&amp; o) { std::cout &lt;&lt; \"moved\" &lt;&lt; std::endl; }\n};\n\ntemplate &lt;typename T&gt;\nA wrapper(T&amp;&amp; arg) {\n  return A{std::forward&lt;T&gt;(arg)};\n}\n\nwrapper(A{}); // moved\nA a;\nwrapper(a); // copied\nwrapper(std::move(a)); // moved\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdthread","title":"<code>std::thread</code>","text":"<p>The <code>std::thread</code> library provides a standard way to control threads, such as spawning and killing them. In the example below, multiple threads are spawned to do different calculations and then the program waits for all of them to finish. <pre><code>void foo(bool clause) { /* do something... */ }\n\nstd::vector&lt;std::thread&gt; threadsVector;\nthreadsVector.emplace_back([]() {\n  // Lambda function that will be invoked\n});\nthreadsVector.emplace_back(foo, true);  // thread will run foo(true)\nfor (auto&amp; thread : threadsVector) {\n  thread.join(); // Wait for threads to finish\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdto_string","title":"std::to_string","text":"<p>Converts a numeric argument to a <code>std::string</code> <pre><code>std::to_string(1.2);  // == \"1.2\"\nstd::to_string(123);  // == \"123\"\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#type-traits","title":"Type Traits","text":"<p>Type trait defines a compile-time template-based interfaces to query or modify the properties of types. <pre><code>static_assert(std::is_integral&lt;int&gt;::value);\nstatic_assert(std::is_same&lt;int, int&gt;::value);\nstatic_assert(std::is_same&lt;std::conditional&lt;true, int, double&gt;::type, int&gt;::value);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#smart-pointers","title":"Smart Pointers","text":"<p>C++11 introduces new smart pointers: </p> <ul> <li><code>std::unique_ptr</code></li> <li><code>std::shared_ptr</code></li> <li><code>std::weak_ptr</code></li> </ul> <p><code>std::auto_ptr</code> now becomes deprecated and then eventually removed in C++17</p> <p><code>std::unique_ptr</code> is a non-copyable, movable pointer that manages its own heap-allocated memory.  Note: Prefer using the <code>std::make_X</code> helper functions as opposed to using constructors. <pre><code>std::unique_ptr&lt;Foo&gt; p1 {new Foo{}};  // `p1` owns `Foo`\nif (p1) {\n  p1-&gt;bar();\n}\n\n{\n  std::unique_ptr&lt;Foo&gt; p2 {std::move(p1)};  // Now `p2` owns `Foo`\n  f(*p2);\n\n  p1 = std::move(p2);  // Ownership returns to `p1` -- `p2` gets destroyed\n}\n\nif (p1) {\n  p1-&gt;bar();\n}\n// `Foo` instance is destroyed when `p1` goes out of scope\n</code></pre> A <code>std::shared_ptr</code> is a smart pointer that manages a resource that is shared across multiple owners. A shared pointer holds a control block which has a few components such as the managed object and a reference counter. All control block is thread-safe, however, manipulating the managed object itself is not thread-safe. <pre><code>void foo(std::shared_ptr&lt;T&gt; t) {\n  // Do something with `t`...\n}\n\nvoid bar(std::shared_ptr&lt;T&gt; t) {\n  // Do something with `t`...\n}\n\nvoid baz(std::shared_ptr&lt;T&gt; t) {\n  // Do something with `t`...\n}\n\nstd::shared_ptr&lt;T&gt; p1 {new T{}};\n// Perhaps these take place in another threads?\nfoo(p1);\nbar(p1);\nbaz(p1);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdchrono","title":"<code>std::chrono</code>","text":"<p>The chrono library contains a set of utility functions and types that deal with durations, clocks, and time points. One use case of this library is benchmarking code: <pre><code>std::chrono::time_point&lt;std::chrono::steady_clock&gt; start, end;\nstart = std::chrono::steady_clock::now();\n// Some computations...\nend = std::chrono::steady_clock::now();\n\nstd::chrono::duration&lt;double&gt; elapsed_seconds = end - start;\ndouble t = elapsed_seconds.count(); // t number of seconds, represented as a `double`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#tuples","title":"Tuples","text":"<p>Tuples are a fixed-size collection of heterogeneous values. Access the elements of a <code>std::tuple</code> by unpacking using <code>std::tie</code> or <code>std::get</code>. <pre><code>// `playerProfile` has type `std::tuple&lt;int, const char*, const char*&gt;`.\nauto playerProfile = std::make_tuple(51, \"Frans Nielsen\", \"NYI\");\nstd::get&lt;0&gt;(playerProfile); // 51\nstd::get&lt;1&gt;(playerProfile); // \"Frans Nielsen\"\nstd::get&lt;2&gt;(playerProfile); // \"NYI\"\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdtie","title":"<code>std::tie</code>","text":"<p>Creates a tuple of lvalue references. Useful for unpacking <code>std::pair</code> and <code>std::tuple</code> objects. Use <code>std::ignore</code> as a placeholder for ignored values. In C++17, structured bindings shouhld be used instead. <pre><code>// With tuples...\nstd::string playerName;\nstd::tie(std::ignore, playerName, std::ignore) = std::make_tuple(91, \"John Tavares\", \"NYI\");\n\n// With pairs...\nstd::string yes, no;\nstd::tie(yes, no) = std::make_pair(\"yes\", \"no\");\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdarray","title":"<code>std::array</code>","text":"<p><code>std::array</code> is a container built on top of a C-style array. Supports common container   operations such as sorting. <pre><code>std::array&lt;int, 3&gt; a = {2, 1, 3};\nstd::sort(a.begin(), a.end()); // a == { 1, 2, 3 }\nfor (int&amp; x : a) x *= 2; // a == { 2, 4, 6 }\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#unordered-container","title":"Unordered Container","text":"<p>These containers maintain average constant-time complexity for search, insert, and remove operations. In order to achieve constant-time complexity, sacrifices order for speed by hashing elements into buckets. There are four unordered containers:</p> <ul> <li><code>unordered_set</code></li> <li><code>unordered_multiset</code></li> <li><code>unordered_map</code></li> <li><code>unordered_multimap</code></li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/#stdmake_shared","title":"<code>std::make_shared</code>","text":"<p><code>std::make_shared</code> is the recommanded way to create instance of <code>std::shared_ptr</code> due to the following reasons:</p> <ul> <li>Avoid having to use the new operator.</li> <li>Prevents code repetition when specifying the underlying type the pointer shall hold.</li> <li>It provides exception-safety. Suppose we were calling a function <code>foo</code> like:</li> </ul> <p><pre><code>foo(std::shared_ptr&lt;T&gt;{new T{}}, function_that_throws(), std::shared_ptr&lt;T&gt;{new T{}});\n</code></pre> The compiler is free to call <code>new T{}</code>, then <code>function_that_throw()</code>, and so on. Since we have allocated data on the heap in the first construction of a <code>T</code> we have introduced a leak here. With <code>std::make_shared</code>, we are given exception-safety: <pre><code>foo(std::make_shared&lt;T&gt;(), function_that_throws(), std::make_shared&lt;T&gt;());\n</code></pre></p> <ul> <li>Prevents having to do two allocations. When calling <code>std::shared_ptr{new T{}}</code>, we have to allocate memory for <code>T</code>, then in the shared pointer we have to allocate memory for the control block within the pointer.</li> </ul>"},{"location":"Coding/C%2B%2B/cpp_11/#stdref","title":"<code>std::ref</code>","text":"<p><code>std::ref(val)</code> is used to create object of type <code>std::reference_wrapper</code> that holds reference of val. Used in cases when usual reference passing using <code>&amp;</code> does not compile or <code>&amp;</code> is dropped due to type deduction. <code>std::cref</code> is similar but created reference wrapper holds a const reference to val. <pre><code>// create a container to store reference of objects.\nauto val = 99;\nauto _ref = std::ref(val);\n_ref++;\nauto _cref = std::cref(val);\n//_cref++; does not compile\nstd::vector&lt;std::reference_wrapper&lt;int&gt;&gt;vec; // vector&lt;int&amp;&gt;vec does not compile\nvec.push_back(_ref); // vec.push_back(&amp;i) does not compile\ncout &lt;&lt; val &lt;&lt; endl; // prints 100\ncout &lt;&lt; vec[0] &lt;&lt; endl; // prints 100\ncout &lt;&lt; _cref; // prints 100\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_11/#memory-model","title":"Memory Model","text":"<p>C++11 introduces a memory model for C++, which means library support for threading and atomic operations. Some of these operations include (but aren't limited to) atomic loads/stores, compare-and-swap, atomic flags, promises, futures, locks, and condition variables.</p>"},{"location":"Coding/C%2B%2B/cpp_11/#stdasync","title":"<code>std::async</code>","text":"<p><code>std::async</code> runs the given function either asynchronously or lazily-evaluated, then returns a <code>std::future</code> which holds the result of that function call.</p> <p>The first parameter is the policy which can be:</p> <ol> <li><code>std::launch::async</code> | <code>std::launch::deferred</code> It is up to the implementation whether to perform asynchronous execution or lazy evaluation.</li> <li><code>std::launch::async</code> Run the callable object on a new thread.</li> <li><code>std::launch::deferred</code> Perform lazy evaluation on the current thread.</li> </ol> <pre><code>int foo() {\n  /* Do something here, then return the result. */\n  return 1000;\n}\n\nauto handle = std::async(std::launch::async, foo);  // create an async task\nauto result = handle.get();  // wait for the result\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_11/#stdbeginend","title":"<code>std::begin/end</code>","text":"<p><code>std::begin</code> and <code>std::end</code> free functions were added to return begin and end iterators of a container generically. These functions also work with raw arrays which do not have begin and end member functions. <pre><code>template &lt;typename T&gt;\nint CountTwos(const T&amp; container) {\n  return std::count_if(std::begin(container), std::end(container), [](int item) {\n    return item == 2;\n  });\n}\n\nstd::vector&lt;int&gt; vec = {2, 2, 43, 435, 4543, 534};\nint arr[8] = {2, 43, 45, 435, 32, 32, 32, 32};\nauto a = CountTwos(vec); // 2\nauto b = CountTwos(arr);  // 1\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/","title":"C++14 New Features and Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_14/#new-features","title":"New Features","text":""},{"location":"Coding/C%2B%2B/cpp_14/#binary-literals","title":"Binary Literals","text":"<p>Binary literals provide a convenient way to represent a number in binary. It is possible to separate digits with <code>'</code>. <pre><code>0b110  // == 6\n0b1111'1111 // == 255\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#generic-lambda-expressions","title":"Generic Lambda Expressions","text":"<p>C++14 now allows the <code>auto</code> type-specifier in the param list, enabling polymorphic lambdas. <pre><code>auto identity = [](auto x) { return x; };\nint three = identity(3);  // == 3\nstd::string foo = identity(\"foo\");  // == \"foo\"\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#lambda-capture-initializers","title":"Lambda Capture Initializers","text":"<p>This allows creating lambda captures initialized whith arbitrary expressions. The name given to the captured value does not need to be related to any variables in the enclosing scopes and introduces a new name inside the lambda body. The initializing expression is evaluated when the lambda is created(not invoked). <pre><code>int factory(int i) { return i * 10; }\nauto f = [x = factory(2)] { return x; }; // returns 20\n\nauto generator = [x = 0] () mutable {\n  // this would not compile without 'mutable' as we are modifying x on each call\n  return x++;\n};\nauto a = generator(); // == 0\nauto b = generator(); // == 1\nauto c = generator(); // == 2\n</code></pre></p> <p>Because it is now possible to move(or forward) values into a lambda that could previously be only captured by copy or reference we can now capture move-only types in a lambda by value. Note that in the below example the <code>p</code> in the capture-list of <code>task2</code> on the left-hand-side of <code>=</code> is a new variable private to the lambda body and does not refer to the original <code>p</code>. <pre><code>auto p = std::make_unique&lt;int&gt;(1);\n\nauto task1 = [=] { *p = 5; }; // ERROR: std::unique_ptr cannot be copied\n// vs.\nauto task2 = [p = std::move(p)] { *p = 5; }; // OK: p is move-constructed into the closure object\n// the original p is empty after task2 is created\n</code></pre></p> <p>Using this reference-captures can have different names than the referenced variable. <pre><code>auto x = 1;\nauto f = [&amp;r = x, x = x * 10] {\n  ++r;\n  return r + x;\n};\nf(); // sets x to 2 and returns 12\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#return-type-deduction","title":"Return Type Deduction","text":"<p>Using an <code>auto</code> return type in C++14, the compiler will attempt to deduce the type for you. With lambdas, you can now deduce its return type using <code>auto</code>, which makes returning a deduced reference or rvalue reference possible. <pre><code>// Deduce return type as `int`.\nauto f(int i) {\n return i;\n}\ntemplate &lt;typename T&gt;\nauto&amp; f(T&amp; t) {\n  return t;\n}\n\n// Returns a reference to a deduced type.\nauto g = [](auto&amp; x) -&gt; auto&amp; { return f(x); };\nint y = 123;\nint&amp; z = g(y); // reference to `y`\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#decltypeauto","title":"<code>decltype(auto)</code>","text":"<p>The <code>decltype(auto)</code> type-specifier also deduces a type like <code>auto</code> does. The difference is:</p> <ul> <li><code>decltype(auto)</code> keeps the reference and cv-qulifiers while <code>auto</code> not.</li> </ul> <pre><code>const int x = 0;\nauto x1 = x; // int\ndecltype(auto) x2 = x; // const int\nint y = 0;\nint&amp; y1 = y;\nauto y2 = y1; // int\ndecltype(auto) y3 = y1; // int&amp;\nint&amp;&amp; z = 0;\nauto z1 = std::move(z); // int\ndecltype(auto) z2 = std::move(z); // int&amp;&amp;\n// Note: Especially useful for generic code!\n\n// Return type is `int`.\nauto f(const int&amp; i) {\n return i;\n}\n\n// Return type is `const int&amp;`.\ndecltype(auto) g(const int&amp; i) {\n return i;\n}\n\nint x = 123;\nstatic_assert(std::is_same&lt;const int&amp;, decltype(f(x))&gt;::value == 0);\nstatic_assert(std::is_same&lt;int, decltype(f(x))&gt;::value == 1);\nstatic_assert(std::is_same&lt;const int&amp;, decltype(g(x))&gt;::value == 1);\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_14/#relaxing-constraints-on-constexpr-functions","title":"Relaxing Constraints on Constexpr Functions","text":"<p>In C++11 <code>constexpr</code> function bodies can only contain a very limited set of syntaxes, including(but not limited to):</p> <ul> <li><code>typedef</code></li> <li><code>using</code></li> <li><code>return</code></li> </ul> <p>In C++14, the set of allowable syntaxes expands greatly to include the most common syntaxes such as <code>if</code> statements, multiple <code>return</code>s, loops, etc.</p> <pre><code>constexpr int factorial(int n) {\n  if (n &lt;= 1) {\n    return 1;\n  } else {\n    return n * factorial(n - 1);\n  }\n}\nfactorial(5); // == 120\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_14/#variable-templates","title":"Variable Templates","text":"<p>C++14 allows variables to be templated: <pre><code>template&lt;class T&gt;\nconstexpr T pi = T(3.1415926535897932385);\ntemplate&lt;class T&gt;\nconstexpr T e  = T(2.7182818284590452353);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#deprecated-attribute","title":"<code>[[deprecated]]</code> Attribute","text":"<p>C++14 introduces the <code>[[deprecated]]</code> attribute to indicate that a unit (function, clss, etc) is discouraged and likely yield conpilation warnings. If a reason is provided, it will be included in the warning. <pre><code>[[deprecated]]\nvoid old_method();\n[[deprecated(\"Use new_method instead\")]]\nvoid legacy_method();\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#new-libraries","title":"New Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_14/#user-defined-literals-for-standard-library-types","title":"User-defined Literals for Standard Library Types","text":"<p>New user-defineqd literals for standard library types, include new built-in literals for <code>chrono</code> and <code>basic_string</code>. These can be <code>constexpr</code> meaning that they can be used at compile-time. Some uses for these literals include compile-time integar parsing, binary literals, and imaginary number literals. <pre><code>using namespace std::chrono_literals;\nauto day = 24h;\nday.count(); // == 24\nstd::chrono::duration_cast&lt;std::chrono::minutes&gt;(day).count(); // == 1440\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_14/#compile-time-integar-sequence","title":"Compile-time Integar Sequence","text":"<p>The class template <code>std::integar_sequence</code> represents a compile-time sequence of integar. There are a few helpers built on top:</p> <ul> <li><code>std::make_integar_sequence&lt;T, N&gt;</code>: creates a sequence of <code>0, ..., N - 1</code> with type <code>T</code>.</li> <li><code>std::index_sequence_for&lt;T...&gt;</code>: converts a template parameter pack into an integar sequence.</li> </ul> <pre><code>template&lt;typename Array, std::size_t... I&gt;\ndecltype(auto) a2t_impl(const Array&amp; a, std::integer_sequence&lt;std::size_t, I...&gt;) {\n  return std::make_tuple(a[I]...);\n}\n\ntemplate&lt;typename T, std::size_t N, typename Indices = std::make_index_sequence&lt;N&gt;&gt;\ndecltype(auto) a2t(const std::array&lt;T, N&gt;&amp; a) {\n  return a2t_impl(a, Indices());\n}\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_14/#stdmake_unique","title":"<code>std::make_unique</code>","text":"<p><code>std::make_unique</code> is the recommanded way to create instances of <code>std::unique_ptr</code>s due to the following reasons:</p> <ul> <li>Avoid having to use the <code>new</code> operator.</li> <li>Prevents code repetition when specifying the underlying type the pointer shall hold.</li> <li>Most importantly, it provides exception-safety. Suppose we were calling a function <code>foo</code> like:</li> </ul> <p><pre><code>foo(std::unique_ptr&lt;T&gt;{new T{}}, function_that_throws(), std::unique_ptr&lt;T&gt;{new T{}});\n</code></pre> The compiler is free to call <code>new T{}</code>, then <code>function_that_throws()</code>, and so on... Since we have allocated data on the heap in the first construction of a <code>T</code>, we have introduced a leak here. With <code>std::make_unique</code>, we are given exception-safety: <pre><code>foo(std::make_unique&lt;T&gt;(), function_that_throws(), std::make_unique&lt;T&gt;());\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/","title":"C++17 New Features and Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_17/#new-features","title":"New Features","text":""},{"location":"Coding/C%2B%2B/cpp_17/#template-argument-deduction-for-class-templates","title":"Template Argument Deduction for Class Templates","text":"<p>Automatic template argument deduction much like how it's done for functions, but now including class constructors. <pre><code>template &lt;typename T = float&gt;\nstruct MyContainer {\n  T val;\n  MyContainer() : val{} {}\n  MyContainer(T val) : val{val} {}\n  // ...\n};\nMyContainer c1 {1}; // OK MyContainer&lt;int&gt;\nMyContainer c2; // OK MyContainer&lt;float&gt;\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#declaring-non-type-template-parameters-with-auto","title":"Declaring Non-type Template Parameters with <code>auto</code>","text":"<p>Following the deduction rules of <code>auto</code>, while respecting the non-type template parameter list of allowable types[*], template arguments can be deduced from the type ot its arguments: <pre><code>template &lt;auto... seq&gt;\nstruct my_integer_sequence {\n  // Implementation here ...\n};\n\n// Explicitly pass type `int` as template argument.\nauto seq = std::integer_sequence&lt;int, 0, 1, 2&gt;();\n// Type is deduced to be `int`.\nauto seq2 = my_integer_sequence&lt;0, 1, 2&gt;();\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#folding-expressions","title":"Folding Expressions","text":"<p>A fold expression performs a fold of a template parameter pack over a binary operator.</p> <ul> <li>An expression of the form <code>(... op e)</code> or <code>(e op ...)</code>, where <code>op</code> is a fold-operator and <code>e</code> is an unexpanded parameter pack, are called unary folds.</li> <li>An expression of the form <code>(e1 op ... op e2)</code>, where <code>op</code> are fold-operators, is called a binary fold. Either <code>e1</code> or <code>e2</code> is an unexpanded parameter pack, but not both.</li> </ul> <pre><code>template &lt;typename... Args&gt;\nbool logicalAnd(Args... args) {\n    // Binary folding.\n    return (true &amp;&amp; ... &amp;&amp; args);\n}\nbool b = true;\nbool&amp; b2 = b;\nlogicalAnd(b, b2, true); // == true\n\ntemplate &lt;typename... Args&gt;\nauto sum(Args... args) {\n    // Unary folding.\n    return (... + args);\n}\nsum(1.0, 2.0f, 3); // == 6.0\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_17/#new-rules-for-auto-deduction-from-braced-init-list","title":"New Rules for <code>auto</code> Deduction from Braced-init-list","text":"<p>Changes to <code>auto</code> deduction when used with the uniform initialization syntax. Previously, <code>auto x {3}</code> deduced a <code>std::initializer_list&lt;int&gt;</code>, which now deduces to <code>int</code>. <pre><code>auto x1 {1, 2, 3};  // error: not a single element.\nauto x2 = {1, 2, 3};  // x2 is std::initializer_list&lt;int&gt;\nauto x3 {3};  // x3 is int\nauto x4 {3.0};  // x4 is double\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#constexpr-lambda","title":"<code>constexpr</code> Lambda","text":"<p>Compile-time lambda using <code>constexpr</code>. <pre><code>auto identity = [](int n) constexpr { return n; };\nstatic_assert(identity(123) == 123);\nconstexpr auto add = [](int x, int y) {\n  auto L = [=] { return x; };\n  auto R = [=] { return y; };\n  return [=] { return L() + R(); };\n};\n\nstatic_assert(add(1, 2)() == 3);\nconstexpr int addOne(int n) {\n  return [n] { return n + 1; }();\n}\n\nstatic_assert(addOne(1) == 2);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#lambda-capture-this-by-value","title":"Lambda Capture <code>this</code> by Value","text":"<p>Capturing <code>this</code> in a lambda's environment was previously reference-only. An example of where <code>this</code> is problematic is asynchronous code using callbacks that require an object to be available, potentially past its lifetime. <code>*this</code> (C++17) will now make a copy of the current object, while <code>this</code> (C++11) continues to capture by reference. <pre><code>struct MyObj {\n  int value {123};\n  auto getValueCopy() {\n    return [*this] { return value; };\n  }\n  auto getValueRef() {\n    return [this] { return value; };\n  }\n};\nMyObj mo;\nauto valueCopy = mo.getValueCopy();\nauto valueRef = mo.getValueRef();\nmo.value = 321;\nvalueCopy(); // 123\nvalueRef(); // 321\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#inline-variables","title":"Inline Variables","text":"<p>The inline specifier can be applied to variables as well as to functions. A variable declared inline has the same semantics as a function declared inline. <pre><code>// Disassembly example using compiler explorer.\nstruct S { int x; };\ninline S x1 = S{321}; // mov esi, dword ptr [x1]\n                      // x1: .long 321\n\nS x2 = S{123};        // mov eax, dword ptr [.L_ZZ4mainE2x2]\n                      // mov dword ptr [rbp - 8], eax\n                      // .L_ZZ4mainE2x2: .long 123\n</code></pre> It can also be used to declare and define a static member variable, such that it does not need to be initialized in the source file. <pre><code>struct S {\n  S() : id{count++} {}\n  ~S() { count--; }\n  int id;\n  static inline int count{0}; // declare and initialize count to 0 within the class\n};\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#nested-namespaces","title":"Nested Namespaces","text":"<p>Using the namespace resolution operator to create nested namespace definitions. <pre><code>namespace A {\n  namespace B {\n    namespace C {\n      int i;\n    }\n  }\n}\n// vs.\nnamespace A::B::C {\n  int i;\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#structured-bindings","title":"Structured Bindings","text":"<p>A proposal for de-structuring initialization, that would allow writting <code>auto [ x, y, z] = expr;</code> where the type of <code>expr</code> was a tuple-like object, whose elements would be bound to the variables <code>x</code>, <code>y</code> and <code>z</code>(which is construc declares). tuple-like objects include <code>std::tuple</code>, <code>std::pair</code>, <code>std::array</code>, and aggregate structures. <pre><code>using Coordinate = std::pair&lt;int, int&gt;;\nCoordinate origin() {\n  return Coordinate{0, 0};\n}\n\nconst auto [ x, y ] = origin();\nx; // == 0\ny; // == 0\nstd::unordered_map&lt;std::string, int&gt; mapping {\n  {\"a\", 1},\n  {\"b\", 2},\n  {\"c\", 3}\n};\n\n// Destructure by reference.\nfor (const auto&amp; [key, value] : mapping) {\n  // Do something with key and value\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#selection-statements-with-initializer","title":"Selection Statements with Initializer","text":"<p>New version of <code>if</code> and <code>switch</code> statements which simplify code patterns and help users keep scopes tight. <pre><code>{\n  std::lock_guard&lt;std::mutex&gt; lk(mx);\n  if (v.empty()) v.push_back(val);\n}\n// vs.\nif (std::lock_guard&lt;std::mutex&gt; lk(mx); v.empty()) {\n  v.push_back(val);\n}\n\nFoo gadget(args);\nswitch (auto s = gadget.status()) {\n  case OK: gadget.zip(); break;\n  case Bad: throw BadFoo(s.message());\n}\n// vs.\nswitch (Foo gadget(args); auto s = gadget.status()) {\n  case OK: gadget.zip(); break;\n  case Bad: throw BadFoo(s.message());\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#constexpr-if","title":"<code>constexpr if</code>","text":"<p>Write code that is instantiated depending on a compile=time condition. <pre><code>template &lt;typename T&gt;\nconstexpr bool isIntegral() {\n  if constexpr (std::is_integral&lt;T&gt;::value) {\n    return true;\n  } else {\n    return false;\n  }\n}\nstatic_assert(isIntegral&lt;int&gt;() == true);\nstatic_assert(isIntegral&lt;char&gt;() == true);\nstatic_assert(isIntegral&lt;double&gt;() == false);\nstruct S {};\nstatic_assert(isIntegral&lt;S&gt;() == false);\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#utf-8-character-literals","title":"UTF-8 Character Literals","text":"<p>A character literal that begins with <code>u8</code> is a character literal of type <code>char</code>. The value of a UTF-8 character literal is equal to its ISO 10646 code point value. <pre><code>char x = u8'x';\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#direct-list-initialization-of-enums","title":"Direct List Initialization of Enums","text":"<p>Enums can now be initialized using braced syntax. <pre><code>enum byte : unsigned char {};\nbyte b {0}; // OK\nbyte c {-1}; // ERROR\nbyte d = byte{1}; // OK\nbyte e = byte{256}; // ERROR\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#fallthrough-nodiscard-maybe_unused-attributes","title":"<code>fallthrough</code>, <code>nodiscard</code>, <code>maybe_unused</code> attributes","text":"<p>C++17 introduces threee new attributes:</p> <ul> <li> <p><code>[[fallthrough]]</code>: indicates to the compiler that falling through in a switch statement is intended behavior. <pre><code>switch (n) {\n  case 1: [[fallthrough]]\n    // ...\n  case 2:\n    // ...\n    break;\n}\n</code></pre></p> </li> <li> <p><code>[[nodiscard]]</code>: issues a warning when either a function or class has this attribute and its return value is discarded. <pre><code>[[nodiscard]] bool do_something() {\n  return is_success; // true for success, false for failure\n}\n\ndo_something(); // warning: ignoring return value of 'bool do_something()',\n                // declared with attribute 'nodiscard'\n\n// Only issues a warning when `error_info` is returned by value.\nstruct [[nodiscard]] error_info {\n  // ...\n};\n\nerror_info do_something() {\n  error_info ei;\n  // ...\n  return ei;\n}\n\ndo_something(); // warning: ignoring returned value of type 'error_info',\n                // declared with attribute 'nodiscard'\n</code></pre></p> </li> <li> <p><code>[[maybe_unused]]</code>: indicates to be compiler that a variable or parameter might be unused an is intended. <pre><code>void my_callback(std::string msg, [[maybe_unused]] bool error) {\n  // Don't care if `msg` is an error message, just log it.\n  log(msg);\n}\n</code></pre></p> </li> </ul>"},{"location":"Coding/C%2B%2B/cpp_17/#new-libraries","title":"New Libraries","text":""},{"location":"Coding/C%2B%2B/cpp_17/#stdvariant","title":"<code>std::variant</code>","text":"<p>The class template <code>std::variant</code> represents a type-safe <code>union</code>. An instance of <code>std::variant</code> at any given time holds a value of one of its alternativqe types(it's possible for it to be valueless). <pre><code>std::variant&lt;int, double&gt; v{ 12 };\nstd::get&lt;int&gt;(v); // == 12\nstd::get&lt;0&gt;(v); // == 12\nv = 12.0;\nstd::get&lt;double&gt;(v); // == 12.0\nstd::get&lt;1&gt;(v); // == 12.0\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdoptional","title":"<code>std::optional</code>","text":"<pre><code>std::optional&lt;std::string&gt; create(bool b) {\n  if (b) {\n    return \"Godzilla\";\n  } else {\n    return {};\n  }\n}\n\ncreate(false).value_or(\"empty\"); // == \"empty\"\ncreate(true).value(); // == \"Godzilla\"\n// optional-returning factory functions are usable as conditions of while and if\nif (auto str = create(true)) {\n  // ...\n}\n</code></pre>"},{"location":"Coding/C%2B%2B/cpp_17/#stdany","title":"<code>std::any</code>","text":"<p>A type-safe container for single values of any type. <pre><code>std::any x {5};\nx.has_value() // == true\nstd::any_cast&lt;int&gt;(x) // == 5\nstd::any_cast&lt;int&amp;&gt;(x) = 10;\nstd::any_cast&lt;int&gt;(x) // == 10\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdstring_view","title":"std::string_view","text":"<p>A non-owning reference to a string. Useful for providing an abstraction on top of strings (e.g. for parsing). <pre><code>// Regular strings.\nstd::string_view cppstr {\"foo\"};\n// Wide strings.\nstd::wstring_view wcstr_v {L\"baz\"};\n// Character arrays.\nchar array[3] = {'b', 'a', 'r'};\nstd::string_view array_v(array, std::size(array));\n\nstd::string str {\"   trim me\"};\nstd::string_view v {str};\nv.remove_prefix(std::min(v.find_first_not_of(\" \"), v.size()));\nstr; //  == \"   trim me\"\nv; // == \"trim me\"\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdinvoke","title":"<code>std::invoke</code>","text":"<p>Invoke a <code>Callable</code> object with parameters. Examples of <code>Callable</code> objects are <code>std::function</code> or <code>std::bind</code> where an object can be called similarly to a regular function. <pre><code>template &lt;typename Callable&gt;\nclass Proxy {\n  Callable c;\npublic:\n  Proxy(Callable c): c(c) {}\n  template &lt;class... Args&gt;\n  decltype(auto) operator()(Args&amp;&amp;... args) {\n    // ...\n    return std::invoke(c, std::forward&lt;Args&gt;(args)...);\n  }\n};\nauto add = [](int x, int y) {\n  return x + y;\n};\nProxy&lt;decltype(add)&gt; p {add};\np(1, 2); // == 3\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdapply","title":"<code>std::apply</code>","text":"<p>Invoke a <code>Callable</code> object with a tuple of arguments <pre><code>auto add = [](int x, int y) {\n  return x + y;\n};\nstd::apply(add, std::make_tuple(1, 2)); // == 3\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdfilesystem","title":"<code>std::filesystem</code>","text":"<p>The new <code>std::filesystem</code> library provides a standard way to manipulate files, directories, and paths in a filesystem. <pre><code>const auto bigFilePath {\"bigFileToCopy\"};\nif (std::filesystem::exists(bigFilePath)) {\n  const auto bigFileSize {std::filesystem::file_size(bigFilePath)};\n  std::filesystem::path tmpPath {\"/tmp\"};\n  if (std::filesystem::space(tmpPath).available &gt; bigFileSize) {\n    std::filesystem::create_directory(tmpPath.append(\"example\"));\n    std::filesystem::copy_file(bigFilePath, tmpPath.append(\"newFile\"));\n  }\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#stdbyte","title":"std::byte","text":"<p>The new <code>std::byte</code> type provides a standard way of representing data as byte. Benefits of using <code>std::byte</code> over <code>char</code> or <code>unsigned char</code> is that it is not a character type, and is also not an arithmetic type; while the only operator overloads available are bitwise operator. <pre><code>std::byte a {0};\nstd::byte b {0xFF};\nint i = std::to_integer&lt;int&gt;(b); // 0xFF\nstd::byte c = a &amp; b;\nint j = std::to_integer&lt;int&gt;(c); // 0\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#splicing-for-maps-and-sets","title":"Splicing for Maps and Sets","text":"<p>Moving nodes and merging containers whithout the overhead of expensive copies, moves, or heap allocations/deallocations. Moving elements from one map to another: <pre><code>std::map&lt;int, string&gt; src {{1, \"one\"}, {2, \"two\"}, {3, \"buckle my shoe\"}};\nstd::map&lt;int, string&gt; dst {{3, \"three\"}};\ndst.insert(src.extract(src.find(1))); // Cheap remove and insert of { 1, \"one\" } from `src` to `dst`.\ndst.insert(src.extract(2)); // Cheap remove and insert of { 2, \"two\" } from `src` to `dst`.\n// dst == { { 1, \"one\" }, { 2, \"two\" }, { 3, \"three\" } };\n</code></pre> Inserting elements which outlive the container: <pre><code>auto elementFactory() {\n  std::set&lt;...&gt; s;\n  s.emplace(...);\n  return s.extract(s.begin());\n}\ns2.insert(elementFactory());\n</code></pre> Changing the key of a map element: <pre><code>std::map&lt;int, string&gt; m {{1, \"one\"}, {2, \"two\"}, {3, \"three\"}};\nauto e = m.extract(2);\ne.key() = 4;\nm.insert(std::move(e));\n// m == { { 1, \"one\" }, { 3, \"three\" }, { 4, \"two\" } }\n</code></pre></p>"},{"location":"Coding/C%2B%2B/cpp_17/#parallel-algorithms","title":"Parallel Algorithms","text":"<p>Many of the STL algorithms, such as the <code>copy</code>, <code>find</code> and <code>sort</code> methods, started to support the parallel execution policies: <code>seq</code>, <code>par</code> and <code>par_unseq</code> which translate to \"sequentially\", \"parallel\" and \"parallel unsequenced\". <pre><code>std::vector&lt;int&gt; longVector;\n// Find element using parallel execution policy\nauto result1 = std::find(std::execution::par, std::begin(longVector), std::end(longVector), 2);\n// Sort elements using sequential execution policy\nauto result2 = std::sort(std::execution::seq, std::begin(longVector), std::end(longVector));\n</code></pre></p>"},{"location":"Coding/C%2B%2B/effective_cpp/","title":"Effective C++","text":"<p>This is a summary of the book \"Effective C++\" which gives 55 specific ways to imporve your programs and designs by Scott Meyers.</p>"},{"location":"Coding/C%2B%2B/effective_cpp/#1-view-c-as-a-federation-of-languages","title":"1. View C++ as a federation of languages.","text":"<ul> <li>Rules for effective C++ programming vary, depending on the part of C++ you are using.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#2-prefer-consts-enums-and-inlines-to-defines","title":"2. Prefer consts, enums, and inlines to #defines.","text":"<ul> <li>For simple constants, prefer const objects or enums to <code>#define</code>s.</li> <li>For function-like macros, prefer inline functions to <code>#define</code>s.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#3-use-const-whenever-possible","title":"3. Use <code>const</code> whenever possible.","text":"<ul> <li>Declaring something const help compilers detect usage errors. const can be applied to objects at any scope, to function parameters and return types, and to member functions as a whole.</li> <li>Compilers enforce bitwise constness, but you should program using logical constness.</li> <li>When const and non-const member functions have essentially identical implementations, code duplication can be avoided by having the non-const version call the const version.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#4-make-sure-that-the-objects-are-initialized-before-theyre-used","title":"4. Make sure that the objects are initialized before they're used.","text":"<ul> <li>Manually initialize objects of built-in type, because C++ only sometimes initializes them itself.</li> <li>In a constructor, prefer use of the member initialization list to assignment inside the body of the constructor. List data members in the initialization list in the same order they're declared in the class.</li> <li>Avoid initialization order problems across translation units by replacing non-local static objects with local static objects.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#5-know-what-functions-c-silently-writes-and-calls","title":"5. Know what functions C++ silently writes and calls.","text":"<ul> <li>Compilers may implicityly generate a class's default constructor, copy constructor, copy assignment operator, and destructor.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#6-explicityly-disallow-the-use-of-compiler-generated-function-you-do-not-want","title":"6. Explicityly disallow the use of compiler-generated function you do not want.","text":"<ul> <li>To disallow functionality automatically provided by compilerssss, declare the corresponding member functions <code>private</code> or <code>= delete</code> and give no implementations. Using a base class like Uncopyable is one way to do this.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#7-declare-destructors-virtual-in-polymorphic-basic-classes","title":"7. Declare destructors virtual in polymorphic basic classes.","text":"<ul> <li>Polymorphic base classes should declare virtual destructors. If a class has dany virtual functions, it should have a virtual destructor.</li> <li>Classes not designed to be base class or not designed to be used polymorhpically should not declare virtual destructors.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#8-prevent-exceptions-from-leaving-destructors","title":"8. Prevent exceptions from leaving destructors.","text":"<ul> <li>Destructors should never emit exceptions. If functions called in a destructor may throw, the destructor should catch any exceptions, then swallow them or terminate the program.</li> <li>If class clientss need to be able to react exceptions thron during an opreration, the class should provide a regular (i.e., non-destructor)function that performs the operation.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#9-never-call-virtual-function-during-construction-or-destruction","title":"9. Never call virtual function during construction or destruction.","text":"<ul> <li>Don't call virtual functions during construction or destruction, because such calls will never go to a more derived class than that of the currently executing constructor or destructor.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#10-have-assignment-operators-return-a-reference-to-this","title":"10. Have assignment operators return a reference to <code>*this</code>.","text":"<ul> <li>To meet the chain of assignments like <code>x = y = z = 15;</code>.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#11-handle-assignment-to-self-in-operator","title":"11. Handle assignment to self in <code>operator=</code>.","text":"<ul> <li>Make sure <code>operator=</code> is well-behaved when an object is assigned to itself. Techniques include comparing addresses of source and target objects, careful statement ordering, and copy-and-swap.</li> <li>Make sure that any function operating on more than one object behaves correctly if two or more of the objects are the same.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#12-copy-all-parts-of-an-object","title":"12. Copy all parts of an object.","text":"<ul> <li>Copy functions should be sure to copy all of an object's data members and all of its base class parts.</li> <li>Don't try to implement one of the copying functions in terms of the other. Instead, put common functionality in a third function that both call.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#13-use-objects-to-manage-resources","title":"13. Use objects to manage resources.","text":"<ul> <li>To prevent resource leaks, use <code>RAII</code>(Resource Acquisition Is Initialization) objects that acquire resources in their constructors and release them in their destructors.</li> <li>Two commonly useful <code>RAII</code> classes are <code>std::shared_ptr</code> and <code>std::unique_ptr</code>. <code>std::shared_ptr</code> is usually the better choice, because its behavior when copied is intuitive.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#14-think-carefully-about-copying-behavior-in-resource-managing-classes","title":"14. Think carefully about copying behavior in resource-managing classes.","text":"<ul> <li>Copying an <code>RAII</code> object entails copying the resource it manages, so the copying behavior of the resource determines the copying behavior of the <code>RAII</code> object.</li> <li>Common <code>RAII</code> class copying behaviors are disallowing copying and performing reference counting, but other behaviorss are possible.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#15-provide-access-to-raw-resource-in-resource-managing-classes","title":"15. Provide access to raw resource in resource-managing classes.","text":"<ul> <li><code>API</code>s often require access to raw resources, so each <code>RAII</code> class should offer a way to get at the resource it manages.</li> <li>Access may be via explicit conversion or implicit conversion. In general, explicit conversion is safer, but implicit conversion is more convenient for clients.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#16-use-the-same-form-in-correspongding-uses-of-new-and-delete","title":"16. Use the same form in correspongding uses of <code>new</code> and <code>delete</code>.","text":"<ul> <li>If you use <code>[]</code> in a new expression, you must use <code>[]</code> in the corresponding delete expression. If you don't use <code>[]</code> in a new expression, you mustn't use <code>[]</code> in the corresponding delete expression.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#17-store-newed-objects-in-smart-pointers-in-standalone-statements","title":"17. Store <code>new</code>ed objects in smart pointers in standalone statements.","text":"<ul> <li>Store <code>new</code>ed objects in smart pointer in standlone statements. Failure to do this can lead to subtle resource leaks when exceptions are thrown.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#18-make-interfaces-easy-to-use-correctly-and-hard-to-use-incorrectly","title":"18. Make interfaces easy to use correctly and hard to use incorrectly.","text":"<ul> <li>Good interfaces are easy to use correctly and hard to use incorrectly. You should strive for these characteristics in all your interfaces.</li> <li>Ways to facilitate correct use include consistency in interfaces and behavioral compatibility with built-in types.</li> <li>Ways to prevent errors include creating new typess, restricting operations on types, constraining object values, and eliminating client resource management respoinsibilities.</li> <li><code>std::shared_ptr</code> supports custom deleters. This preventss the cross-DLL problems, can be used to automatically unlock mutexes.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#19-treak-class-design-as-type-design","title":"19. Treak class design as type design.","text":"<p>Before defining a new type, be sure to consider all these issues:</p> <ul> <li>How should objects of your new type be created and destroyed?</li> <li>How should object initialization differ from object assignment?</li> <li>What does it mean for objects of your new type to be passed by value?</li> <li>What are the restrictions on legal value for your new type?</li> <li>Does your new type fit into an inheritance graph?</li> <li>What kind of type conversions are allowed for your new type?</li> <li>What operators and functions make sense for the new type?</li> <li>What standard functions should be disallowed?</li> <li>Who should have access to the members of your new type?</li> <li>What is the \"undeclared interface\" of your new type?</li> <li>How general is your new type?</li> <li>Is a new type really what you need?</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#20-prefer-pass-by-reference-to-const-to-pass-by-value","title":"20. Prefer pass-by-reference-to-const to pass-by-value.","text":"<ul> <li>Prefer pass-by-reference-to-const over pass-by-value. It's typically more efficient and it avoids the slicing problem.</li> <li>The rule doesn't apply to built-in types and <code>STL</code> iterator and function object types. For them, pass-by-value is usually appropriate.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#21-dont-try-to-return-a-reference-when-you-must-return-an-object","title":"21. Don't try to return a reference when you must return an object.","text":"<ul> <li>Never return a pointer or reference to a local stack object, a reference to a heap-allocated object or a pointer or reference to a local static object i there is a chance that more than one such object will be needed.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#22-declare-data-members-private","title":"22. Declare data members <code>private</code>.","text":"<ul> <li>Declare data members <code>private</code>, it gives clients syntactically uniform access to data, affords fine-grained access control, allows invariants to be enforced, and offers class authors implementation flexibility.</li> <li>Protected is no more encapsulated than <code>public</code>.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#23-prefer-non-member-non-friend-functions-to-member-functions","title":"23. Prefer non-member non-friend functions to member functions.","text":"<ul> <li>Doing so increases encapsulation, packaging flexibility, and functional extensibility.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#24-declare-non-member-functions-when-type-conversions-should-apply-to-all-parameters","title":"24. Declare non-member functions when type conversions should apply to all parameters.","text":"<ul> <li>If you need type conversions on all parameters to a function (including the one that would otherwise be pointed to by the <code>this</code> pointer), the function must be a non-member.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#25-consider-support-for-a-non-throwing-swap","title":"25. Consider support for a non-throwing <code>swap</code>.","text":"<ul> <li>Provide a <code>swap</code> member function when <code>std::swap</code> would be inefficient for your type. Make sure your swap doesn't throw exceptions.</li> <li>If you offer a member swap, also offer a non-member swap that calls the member. For classes(not templates), specialize <code>std::swap</code>, too.</li> <li>When calling swap, employ a using declaration for <code>std::swap</code>, then call swap without namespace qualification.</li> <li>It's fine to totally specialize <code>std</code> templates for user-defined bypes, but never try to add something completely new to std.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#26-postpone-variable-definitions-as-long-as-possible","title":"26. Postpone variable definitions as long as possible.","text":"<ul> <li>It increase problem clarity and improves program efficiency.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#27-minimize-casting","title":"27. Minimize casting.","text":"<p>C++ offers four new cast froms:</p> <ul> <li><code>const_cast&lt;T&gt;(expression)</code>: used to cast away constness of objects.</li> <li><code>dynamic_cast&lt;T&gt;(expression)</code>: used to perform \"safe downcasting\", i.e., to determine whether an object is of a particular type in an inheritance hierarchy.</li> <li><code>reinterpret_cast&lt;T&gt;(expression)</code>: used for low-level casts that yield implementation-dependent results, e.g., casting a pointer to an int.</li> <li> <p><code>static_cast&lt;T&gt;(expression)</code>: used to force implicit conversions, e.g. non-const object to const object, int to double, etc.</p> </li> <li> <p>Avoid casts whenever practical, especially <code>dynamic_cast</code> in performance-sensitive code. If a design requires casting, try to develop a cast-free alternative.</p> </li> <li>When casting is neccessary, try to hide it inside a function. Clients can then call the function instead of putting casts in their own code.</li> <li>Prefer C++-style casts to old-style casts. They are easier to see, and they are more specific aboud what they do.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#28-avoid-returning-handle-to-object-internals","title":"28. Avoid returning \"handle\" to object internals","text":"<ul> <li>Avoid returning handles (references, pointers, or iterators) to object internals. Not returning handles increases encapsulation, helps const member functions act cosnt and minimizes the creation of dangling handles.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#29-strive-for-exception-safe-code","title":"29. Strive for exception-safe code.","text":"<ul> <li>Exception-safe functions leak no resource and allow no data structure to become corrupted, even when exceptions are thrown. Such functions offer the basic, strong, or nothrow guarantees.</li> <li>The strong guarantee can often be implemented via copy-and-swap, but the strong guarantee is not practical for all functions.</li> <li>A function can usually offer a guarantee no stronger than the weakest guarantee of the functions it calls.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#30-understand-the-ins-and-outs-of-inlining","title":"30. Understand the ins and outs of inlining.","text":"<ul> <li>Limit most inlining to small, frequently called functions. This facilitates debugging and binary upgradability, minimizes potential code bloat, and maximizes the chances of greater program speed.</li> <li>Don't declare fucntion template inline just because they appear in header files.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#31-minimize-compilation-dependencies-between-files","title":"31. Minimize compilation dependencies between files.","text":"<ul> <li>The general idea behind minimizing compilation dependencies is to depend on declarations instead of definitions. Two approaches based on this idea are Handle classes and Interface classes.</li> <li>Library header files should exist in full and declaration-only forms. This applies regardless of whether templates are involved.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#32-make-sure-public-inheritance-models-is-a","title":"32. Make sure public inheritance models \"is-a\".","text":"<ul> <li>Public inheritance means \"is-a\". Everything that applies to base classes must also apply to derived classes, because every derived class object <code>is a</code> base class object.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#33-avoid-hiding-inherited-names","title":"33. Avoid hiding inherited names.","text":"<ul> <li>Names in derived classes hide names in base classes. Under public inheritance, this is never desirable.</li> <li>To make hidden names visible again, employ <code>using</code> declarations or forwarding functions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#34-differentiate-between-inheritance-of-interface-and-inheritance-of-implementation","title":"34. Differentiate between inheritance of interface and inheritance of implementation.","text":"<ul> <li>Inheritance of interface is different from inheritance of implementation. Under public inheritance, derived classes always inherit base class interfaces.</li> <li>Pure vitual functions specify inheritance of interface only.</li> <li>Simple (impure) virtual functions specify inheritance of interface plus inheritance of a default implementation.</li> <li>Non-virtual functions specify inheritance of interface plus inheritance of a mandatory implementation.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#35-consider-alternatives-to-virtual-functions","title":"35. Consider alternatives to virtual functions.","text":"<p>Here are some alternatives of virtual function:</p> <ul> <li>Use the non-virtual interface idiom(NVI idiom), a form of the Template Method design pattern that wraps public non-virtual member functions around less accessible virtual functions.</li> <li>Replace virtual functions with <code>function pointer data member</code>, a stripped-down manifestation of the <code>Strategy</code> design pattern.</li> <li>Replace virtual functions with <code>std::function</code> data member, thus allowing use of any callable entity with a signature compatible with what you ned. This, too is a form of the <code>Strategy</code> design pattern.</li> <li> <p>Replace virtual functions in one hierarchy with <code>virtual functions in another hierarychy</code>. This is the conventional implementation of the <code>Strategy</code> design pattern.</p> </li> <li> <p>Alternatives to virtual functions include the <code>NVI</code> idiom and various forms of the Strategy design pattern. The NVI idiom is itself an example of the Template Method design pattern.</p> </li> <li>A disadvantage of moving functionality from a member function to a function outside the class is that the non-member function lacks access to the class's non-public members.</li> <li><code>std::function</code> objects act like generalized function pointers. Such objects support all callable entities compatible with a given target signature.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#36-never-redefine-an-inherited-non-virtual-function","title":"36. Never redefine an inherited non-virtual function.","text":"<ul> <li>The implementation of derived class will hide the one of base class, which may lead to different results when called by pointer of derived class and pointer of base class.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#37-never-redefine-a-functions-inherited-default-parameter-value","title":"37. Never redefine a function's inherited default parameter value.","text":"<ul> <li>Because default parameter values are statically bound, while virtual functions(the only functions you should be redefining) are dynamically bound.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#38-model-has-a-or-is-implemented-in-terms-of-through-composition","title":"38. Model \"has-a\" or \"is-implemented-in-terms-of\" through composition.","text":"<ul> <li>Composition has meanings completely different from that of public inheritance.</li> <li>In the application domain, composition means \"has-a\". In the implementation domain, it means is-implemented-in-terms-of.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#39-use-private-inheritance-judiciously","title":"39. Use private inheritance judiciously.","text":"<ul> <li>Private inheritance means is-implementation-in-terms of. It's usually inferior to composition, but it makes sense when a derived class needs access to protected base class members or needs to redefine inherited virtual functions.</li> <li>Unlike composition, private inheritance can enable the empty base optimization. This can be important for library developers who strive to minimize object sizes.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#40-use-multiple-inheritance-judiciously","title":"40. Use multiple inheritance judiciously.","text":"<ul> <li>Multiple inheritance is more complex than single inheritance. It can lead to new ambiguity issues and to the need for virtual inheritance.</li> <li>Virtual inheritance imposes costs in size, speed, and complexity of initialization and assignment. It's most practical when virtual base classes have no idea.</li> <li>Multiple inheritance does have legitimate uses. On scenario involves combining public inheritance from an Interface class with private inheritance from a class that helps with implementation.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#41-understand-implicit-interfaces-and-compile-time-polymorphism","title":"41. Understand implicit interfaces and compile-time polymorphism.","text":"<ul> <li>Both classes and templates support interfaces and polymorphism.</li> <li>For classes, interfaces are centered on function signatures. Polymorphism occurs at runtime through virtual functions.</li> <li>For template parameters, interfaces are implicit and base on valid expression. Polymorphism occurs during compilation through template instantiation and function overloading resolution.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#42-understand-the-two-meaning-of-typename","title":"42. Understand the two meaning of typename.","text":"<ul> <li>When declaring template parameters, <code>class</code> and <code>template</code> are interchangeable.</li> <li>Use <code>typename</code> to identify nested dependent type names, except in base class lists or as a base class identifier in a member initialization list.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#43-know-how-to-access-names-in-templatized-base-classes","title":"43. Know how to access names in templatized base classes.","text":"<ul> <li>In derived class templates, refer to names in base class templates via:<ul> <li><code>this-&gt;</code> prefix;</li> <li><code>using</code> declaration;</li> <li>explicit base class qualification.</li> </ul> </li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#44-factor-parameter-independent-code-out-of-templates","title":"44. Factor parameter-independent code out of templates.","text":"<ul> <li>Templates generate multiple classes and multiple functions, so any template code not dependent on a template parameter causes bloat.</li> <li>Bloat due to non-type template parameters can often be eliminated by replacing template parameters with function parameters or class data members.</li> <li>Bloat due to type parameters can be reduced by sharing implementations for instantiation types with identical binary representations.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#45-use-member-function-templates-to-accept-all-compatible-types","title":"45. Use member function templates to accept \"all compatible types\".","text":"<ul> <li>Use member function templates to generate functions that accept all compatible types.</li> <li>If you declare member templates for generalized copy construction or generalized assignment, you'll still need to declare the normal copy constructor and copy assignment operator, too.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#46-define-non-member-functions-inside-templates-when-type-conversions-are-disired","title":"46. Define non-member functions inside templates when type conversions are disired.","text":"<ul> <li>When writting a class template that offers functions related to the template that support implicit type conversions on all parameters, define those functions as friends inside the class template.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#47-use-traits-classes-for-information-about-types","title":"47. Use traits classes for information about types.","text":"<ul> <li>Traits classes make information about types available during compilation. They're implemented using templates specializations.</li> <li>In conjunction with overloading, traits classes make it possible to perform compile-time <code>if else</code> tests on types.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#48-beware-of-template-metaprogramming","title":"48. Beware of template metaprogramming.","text":"<ul> <li>Template metaprogramming can shift work from runtime to compile-time, thus enabling earlier error detection and higher runtime performance.</li> <li>TMP can be used to generate custom code based on combinations of policy choices, and it can also be used to avoid generating code inappropriate for particular types.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#49-understand-the-behavior-of-the-new-handler","title":"49. Understand the behavior of the new-handler.","text":"<ul> <li><code>set_new_handler</code> allows you to specify a function to be called when memory allocation requests cannot be satisfied.</li> <li>Nothrow new is of limited utility, because it applies only to memory allocation; associated constructor calls may still throw exceptions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#50-understand-when-it-makes-sense-to-replace-new-and-delete","title":"50. Understand when it makes sense to replace <code>new</code> and <code>delete</code>.","text":"<p>There are many valid reasons for writting custom versions of <code>new</code> and <code>delete</code>:</p> <ul> <li>To detect usage errors.</li> <li>To collect statistics about the use of dynamically allocated memory.</li> <li>To increase the speed of allocation and deallocation.</li> <li>To reduce the space overhead of default memory management.</li> <li>To compensate for suboptimal alignment in the default allocator.</li> <li>To cluster related objects near one another.</li> <li>To obtain unconventional behavior.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#51-adhere-to-convention-when-writing-new-and-delete","title":"51. Adhere to convention when writing <code>new</code> and <code>delete</code>.","text":"<ul> <li>operator <code>new</code> should <ul> <li>contain an infinite loop trying to allocate memory,</li> <li>call the new-handler if it can't satisfy a memory request, </li> <li>handle requests from zero bytes,</li> <li>class-specific versions should requests for larger blocks than expected.</li> </ul> </li> <li>operator <code>delete</code> should do nothing if passed a pointer that is null. Class-specific versions should handle blocks that are larger than expected.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#52-write-placement-delete-if-you-write-placement-new","title":"52. Write placement <code>delete</code> if you write placement <code>new</code>.","text":"<ul> <li>When you write a placement version of operator new, be sure to write the corresponding placement version of operator delete. If you don't, your program may experience subtle, intermittent memory leaks.</li> <li>When you declare placement version of new and delete, be sure not to unintentionally hide the normal versions of those functions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#53-pay-attention-to-compiler-warnings","title":"53. Pay attention to compiler warnings.","text":"<ul> <li>Take compiler warnings seriously, and strive to compile warning-free at the maximum warning level supported by your compilers.</li> <li>Don't become dependent on compiler warnings, because different compilers warn about different things. Porting to a new compiler may eliminate warning messages you've come to rely on.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#54-familiarize-yourself-with-the-standard-library","title":"54. Familiarize yourself with the standard library.","text":"<ul> <li>The primary standard C++ library functionality consists of:<ul> <li>STL,</li> <li>iostreams,</li> <li>locales,</li> <li>C89 standard library.</li> </ul> </li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#55-familiarize-yourself-with-boost","title":"55. Familiarize yourself with Boost.","text":"<ul> <li>Boost is a community and website for the development of free, open source, peer-reviewed C++ libraries. Boost plays an influential role in C++ standardization.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_cpp/#reference","title":"Reference","text":"<ul> <li>Effective C++ </li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/","title":"Effective Modern C++","text":"<p>This is a summary of the book \"Effective Modern C++\" which gives 42 specific ways to imporve your programs and designs by Scott Meyers.</p>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#1-understand-template-type-deduction","title":"1. Understand template type deduction.","text":"<ul> <li>During template type deduction, arguments that are references are treated as non-reference, i.e., their reference-ness is ignored.</li> <li>When deducing types for universal reference parameters, lvalue arguments get special treatment.</li> <li>when deducing types for by-value parameters, <code>const</code> and/or <code>volatile</code> arguments are treated as non-const and non-volatile.</li> <li>During template type deduction, arguments that are array or function names decay to pointers, unless they're used to initialize references.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#2-understand-auto-type-deduction","title":"2. Understand auto type deduction.","text":"<ul> <li><code>auto</code> type deduction is usually the same as template type deduction, buy <code>auto</code> type deduction assumes that a braced initializer represents a <code>std::initializer_list</code>, and template type deduction doesn't.</li> <li><code>auto</code> in a function return type or a lambda parameter implies template type deduction, not auto type deduction.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#3-understand-decltype","title":"3. Understand <code>decltype</code>.","text":"<ul> <li><code>decltype</code> almost always yields the type of a variable or expression without any modifications.</li> <li>For lvalue expressions of type T other than names, decltype always reports a type of <code>T&amp;</code>.</li> <li>C++14 supports <code>decltype(auto)</code>, which, like auto, deduces a type from its initializer, but it performs the type deduction using the <code>decltype</code> rules.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#4-know-how-to-view-deduced-types","title":"4. Know how to view deduced types.","text":"<ul> <li>Deduced types can often be seen using:<ul> <li>IDE editors,</li> <li>compiler error messages,</li> <li>Boost TypeIndex library.</li> </ul> </li> <li>The results of some tools may be neither helpful nor accurate, so an understanding of C++'s type deduction rules remains essential.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#5-prefer-auto-to-explicit-type-declarations","title":"5. Prefer <code>auto</code> to explicit type declarations.","text":"<ul> <li>The advances are:<ul> <li><code>auto</code> variables must be initialized,</li> <li>immune to type mismatches that can lead to portability or efficiency problems,</li> <li>can ease the process of refactoring,</li> <li>require less typing than variables with explicitly specified types.</li> </ul> </li> <li><code>auto</code>-typed variables are subject to the pitfalls described in iterm 2 and 6.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#6-use-the-explicitly-typed-initializer-idiom-when-auto-deduces-undesired-types","title":"6. Use the explicitly typed initializer idiom when auto deduces undesired types.","text":"<ul> <li>\"Invisible\" proxy types can cause auto to deduce the \"wrong\" type for an initializing expression.</li> <li>The explicitly typed initializer idiom forces auto to deduce the type you want it to have.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#7-distinguish-between-and-when-creating-objects","title":"7. Distinguish between <code>()</code> and <code>{}</code> when creating objects.","text":"<ul> <li>Braced initialization is the most widely usable initialization syntax, it prevents narrowing conversions, and it's immune to C++'s most vexing parse.</li> <li>During constructor overload resolution, braced initializers are matched to <code>std::initializer_list</code> parameters if at all possible, even if other constructors offer seemingly better matches.</li> <li>An example of where the choice between parentheses and braces can make a significant difference is creating a <code>std::vector&lt;numeric type&gt;</code> with two arguments.</li> <li>Choosing between parentheses and braces for object creation inside templates can be challenging.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#8-prefer-nullptr-to-0-and-null","title":"8. Prefer <code>nullptr</code> to <code>0</code> and <code>NULL</code>.","text":"<ul> <li>Avoid overloading on integral and pointer types.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#9-prefer-alias-declarations-to-typedefs","title":"9. Prefer alias declarations to typedefs.","text":"<ul> <li><code>typedef</code>s don't support templatization, but alias declarations do.</li> <li>Alias templates avoid the <code>::type</code> suffix and, in templates, the \"typename\" prefix often required to refer to  typedefs.</li> <li>C++14 offers alias templates for all the C++11 type traits transformations.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#10-prefer-scoped-enums-to-unscoped-enums","title":"10. Prefer <code>scoped enums</code> to <code>unscoped enums</code>.","text":"<ul> <li>C++98-style <code>enum</code>s are now known as unscoped enums.</li> <li>Enumerators of scoped enums are visible only within the enum. They convert to other types only with a cast.</li> <li>Both scoped and unscoped enums support specification of the underlying type. The default underlying type for scoped enums is int. Unscoped enums have no default underlying type.</li> <li>Scoped enums may always be forward-declared. Unscoped enums may be forward-declared only if their declaraation specifies an underlying type.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#11-prefer-deleted-functions-to-private-underfined-ones","title":"11. Prefer deleted functions to private underfined ones.","text":"<ul> <li>Any function may be deleted, including non-member functions and template instantiations.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#12-declare-overriding-functions-override","title":"12. Declare overriding functions <code>override</code>.","text":"<ul> <li>Declare overriding functions <code>override</code>.</li> <li>Member function reference qualifiers make it possible to treat lvalue and rvalue objects(<code>*this</code>) diffrently.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#13-prefer-const_iterators-to-iterators","title":"13. Prefer <code>const_iterator</code>s to <code>iterator</code>s.","text":"<ul> <li>In maximally generic code, prefer non-member versions of begin, end, rbegin, etc, over their member function counterparts.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#14-declare-functions-noexcept-if-they-wont-emit-exceptions","title":"14. Declare functions <code>noexcept</code> if they won't emit exceptions.","text":"<ul> <li><code>noexcept</code> is part of a function's interface, and that means that callers may depend on it.</li> <li><code>noexcept</code> functions are more optimizable than non-noexcept functions.</li> <li><code>noexcept</code> is particularly valuable for the move operations, swap, memory deallocation functions and destructions.</li> <li>Most functions are exception-neutral rather than <code>noexcept</code>.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#15-use-constexpr-whenever-possible","title":"15. Use <code>constexpr</code> whenever possible.","text":"<ul> <li><code>constexpr</code> objects are <code>const</code> and are initialized with values known during compilation.</li> <li><code>constexpr</code> functions can produce compile-time results when called with arguments whose values are known during compilation.</li> <li><code>constexpr</code> objects and functions may be used in a wider range of contexts than non-constexpr objects and functions.</li> <li><code>constexpr</code> is part of an object's or function's interface.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#16-make-const-member-functions-thread-safe","title":"16. Make <code>const</code> member functions thread safe.","text":"<ul> <li>Make <code>const</code> member functionsthreadsafe unless you're certain they'll never be used in a concurrent context.</li> <li>Use of <code>std::atomic</code> variables may offer better performance than a mutex, but they're suited for manipulation of only a single variable or memory location.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#17-understand-special-member-function-generation","title":"17. Understand special member function generation.","text":"<ul> <li>The special member functions are those compilers may generate on their own:<ul> <li>default constructor,</li> <li>destructor,</li> <li>copy constructor,</li> <li>copy operator,</li> <li>move constructor,</li> <li>move operator</li> </ul> </li> <li>Move operations are generated only for classes lacking explicitly declared move operations, copy operations and a destructor.</li> <li>The copy operations are generated only for classes lacking an explicitly declared copy operations, and it's deleted if a move operation is declared.</li> <li>Member function templates never suppress generation of special member functions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#18-use-stdunique_ptr-for-exclusive-ownership-resource-management","title":"18. Use <code>std::unique_ptr</code> for exclusive-ownership resource management.","text":"<ul> <li><code>std::unique_ptr</code> is a small, fast, move-only smart pointer for managing resources with exclusive-ownership semantics.</li> <li>By default, resource destruction takes place via <code>delete</code>, but custom deleters can be specified. Stateful deleters and function pointers as deleters increase the size of <code>std::unique_ptr</code> objects.</li> <li>Converting a <code>std::unique_ptr</code> to a <code>std::shared_ptr</code> is easy.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#19-use-stdshared_ptr-for-shared-ownership-resource-management","title":"19. use <code>std::shared_ptr</code> for shared-ownership resource management.","text":"<ul> <li><code>std::shared_ptr</code>s offer convenience approaching that of garbage collection for the shared lifetime management of arbitrary resources.</li> <li>Compared to <code>std::unique_ptr</code>, <code>std::shared_ptr</code> objects are typically twice as big, incur overhead for control blocks, and require atomic reference count manipulations.</li> <li>Default resource destruction is via <code>delete</code>, but custom deleters are supported. The type of the deleter has no effect on the type of the <code>std::shared_ptr</code>.</li> <li>Avoid creating <code>std::shared_ptr</code>s from viariable of raw pointer type.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#20-use-stdweak_ptr-for-stdshared_ptr-like-pointers-that-can-dangle","title":"20. Use <code>std::weak_ptr</code> for <code>std::shared_ptr</code>-like pointers that can dangle.","text":"<ul> <li>Use <code>std::weak_ptr</code> for <code>std::shared_ptr</code>-like pointers that can dangle.</li> <li>Potential use cases for <code>std::weak_ptr</code> includes caching, observer lists, and the prevention of <code>std::shared_ptr</code> cycles.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#21-prefer-stdmake_unique-and-stdmake_shared-to-direct-use-of-new","title":"21. Prefer <code>std::make_unique</code> and <code>std::make_shared</code> to direct use of <code>new</code>.","text":"<ul> <li>Compared to direct use of <code>new</code>, <code>make</code> functions eliminate source code duplication, improve exception safety, and, for <code>std::make_shared</code> and <code>std::allocate_shared</code>, generate code that's smaller and faster.</li> <li>Situations where use of <code>make</code> functions is inappropriate include the need to specify custom deleters and a desire to pass braced initializers.</li> <li>For <code>std::shared_ptr</code>s, additional situations where <code>make</code> functions may be ill-advised include:<ul> <li>classes with custom memory management,</li> <li>systems with memory concerns, very large objects, and <code>std::weak_ptr</code>s that outlive the corresponding <code>std::shared_ptr</code>s.</li> </ul> </li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#22-when-using-the-pimplpointer-to-implementation-idiom-define-special-member-functions-in-the-implementation-file","title":"22. When using the Pimpl(Pointer to implementation) Idiom, define special member functions in the implementation file.","text":"<ul> <li>The Pimpl Idiom decreases build times by reducing compilation dependencies between class clients and class implementations.</li> <li>For <code>std::unique_ptr pImpl</code> pointers, declare special member functions in the class header, but implement them in the implementation file. Do this even if the default function implementations are acceptable.</li> <li>The above advice applies to <code>std::unique_ptr</code>, but no to <code>std::shared_ptr</code>.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#23-understand-stdmove-and-stdforward","title":"23. Understand <code>std::move</code> and <code>std::forward</code>.","text":"<ul> <li><code>std::move</code> performs an uncoditional cast to an rvalue. In and of itself, it doesn't move anything.</li> <li><code>std::forward</code> casts its argument to an rvalue only if that argument is bound to an rvalue. <code>Neither</code>std::move<code>nor</code>std::forward` do anything at runtime.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#24-distinguish-universal-references-from-rvalue-references","title":"24. Distinguish universal references from rvalue references.","text":"<ul> <li>If a function template parameter has type <code>T&amp;&amp;</code> for a deduced type <code>T</code>, or if an object is declared using <code>auto&amp;&amp;</code>, the parameter or object is a universal reference.</li> <li>If the form of the type declaration isn't precisely <code>type&amp;&amp;</code>, or if type deduction does not occur, <code>type&amp;&amp;</code> denotes an rvalue reference.</li> <li>Universal references correspond to rvalue references if they're initialized with rvalues. The correspond to lvalue references if they're initialized with lvalues.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#25-use-stdmove-on-rvalue-references-stdforward-on-universal-references","title":"25. Use <code>std::move</code> on rvalue references, <code>std::forward</code> on universal references.","text":"<ul> <li>Apply <code>std::move</code> to rvalue references and <code>std::forward</code> to universal references the last time each is used.</li> <li>Do the same thing for rvalue references and universal references being returned from functions that return by value.</li> <li>Never apply <code>std::move</code> or <code>std::forward</code> to local objects if they would otherwise be eligible for the return value optimization.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#26-avoid-overloading-on-universal-references","title":"26. Avoid overloading on universal references.","text":"<ul> <li>Overloading on universal references almost always leads to the universal reference overload being called more frequently than expected.</li> <li>Perfect-forwarding constructors are especially problematic, because they're typically better matches than copy constructors for non-cost lvalues, and they can hijack derived class calls to base class copy and move constructors.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#27-familiarize-yourselff-with-alternatives-to-overloading-on-universal-references","title":"27. Familiarize yourselff with alternatives to overloading on universal references.","text":"<ul> <li>Alternatives to the combination of universal references and overloading include:<ul> <li>the use of distinct function names,</li> <li>passing parameters by lvalue-reference-to-cost,</li> <li>passing parameters by value,</li> <li>using tag dispatch.</li> </ul> </li> <li>Constraining template via <code>std::enable_if</code> permits the use of universal references and  overloading together, but it controls the conditions under which compilers may use the universal reference overloads.</li> <li>Universal reference parameters often have efficiency advantages, but they typically have usability diadvantages.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#28-understand-reference-collapsing","title":"28. Understand reference collapsing.","text":"<ul> <li>Reference collapsing occurs in four contexts:<ul> <li>template instantiation,</li> <li><code>auto</code> type generation,</li> <li>creation and use of <code>typedef</code>s and alias declarations,</li> <li><code>decltype</code></li> </ul> </li> <li>When compilers generate a reference to a reference in a reference collapsing context, the result becomes a single reference. If either of the original references is an lvalue reference, the result is an lvalue reference. Otherwise it's an rvalue reference.</li> <li>Universaal references are rvalue references in contexts where type deduction distinguishes lvalues from rvalues and where reference collapsing occurs.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#29-assume-that-move-operations-are-not-present-not-cheap-and-not-used","title":"29. Assume that move operations are not present, not cheap, and not used.","text":"<ul> <li>Assume that move operations are not present, not cheap, and not used.</li> <li>In code with known types or support for move semantics, there is no need for assumptions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#30-familiarize-yourself-with-perfect-forwarding-failure-cases","title":"30. Familiarize yourself with perfect forwarding failure cases.","text":"<ul> <li>Perfect forwarding fails when template type deduction fails or when it deduces the wrong type.</li> <li>The kinds of arguments that lead to perfect forwarding failure are:<ul> <li>braced initializers,</li> <li>null pointers expressed as <code>0</code> or <code>NULL</code>,</li> <li>declaration-only integral <code>const static</code> data members,</li> <li>template and overloaded function names,</li> <li>bitfields.</li> </ul> </li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#31-avoid-default-capture-modes","title":"31. Avoid default capture modes.","text":"<ul> <li>Default by-reference capture can lead to dangling references.</li> <li>Default by-value capture is susceptible to dangling pointers(especially <code>this</code>), and it misleadingly suggests that lambdas are self-contained.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#32-use-init-capture-to-move-objects-into-closures","title":"32. Use init capture to move objects into closures.","text":"<ul> <li>Use C++14's init capture to move objects into closures.</li> <li>In C++11, emulate init capture via:<ul> <li>hand-written classes,</li> <li><code>std::bind</code></li> </ul> </li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#33-use-decltype-on-auto-parameters-to-stdforward-them","title":"33. Use <code>decltype</code> on <code>auto&amp;&amp;</code> parameters to <code>std::forward</code> them.","text":"<ul> <li>Use <code>decltype</code> on <code>auto&amp;&amp;</code> parameters to <code>std::forward</code> them.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#34-prefer-lambda-to-stdbind","title":"34. Prefer lambda to <code>std::bind</code>.","text":"<ul> <li>Lambdas are more readable, more expressive, and may be more efficient than using <code>std::bind</code>.</li> <li>In C++11 only, <code>std::bind</code> may be useful for implementing move capture or for binding objects with templatized function call operators.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#35-prefer-task-based-programming-to-thread-based","title":"35. Prefer task-based programming to thread-based.","text":"<ul> <li>The <code>std::thread</code> API offers no direct way to get return values from asynchronouly run functions, and if those functions throw, the program is terminated.</li> <li>Threadd-base programming calls for manual management of thread exhaustion, oversubscription, load balancing, and adaptation to new platform.</li> <li>Task-based programming via <code>std::async</code> with the default launch policy handles most of these issues for you.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#36-specify-stdlaunchasync-if-asynchronicity-is-essential","title":"36. Specify <code>std::launch::async</code> if asynchronicity is essential.","text":"<ul> <li>The default launch policy for <code>std::async</code> permits both asynchronous and synchronous task execution.</li> <li>This flexibility leads to uncertainty when accessing <code>thread_local</code>s, implies that the task may never execute, and affects program logic for timeout-based wait calls.</li> <li>Specify <code>std::launch::async</code> if asynchronous task execution is essential.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#37-make-stdthreads-unjoinable-on-all-paths","title":"37. Make <code>std::threads</code> unjoinable on all paths.","text":"<ul> <li>Make <code>std::thread</code>s unjoinable on all paths.</li> <li>join-on-destruction can lead to difficult-to-debug performance anomalies.</li> <li>detach-on-destruction can lead to difficult-to-debug undefined behavior.</li> <li>Declare <code>std::thread</code> objects last in lists of data members.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#38-be-aware-of-varying-thread-handle-destructor-behavior","title":"38. Be aware of varying thread handle destructor behavior.","text":"<ul> <li>Future destructors normally just destroy the future's data members.</li> <li>The final future referring to a shared state for a non-deferred task launched via <code>std::async</code> blocks until the task completes.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#39-consider-void-function-for-one-shot-event-communication","title":"39. Consider <code>void</code> function for one-shot event communication.","text":"<ul> <li>For simple event communication, condvar-based designs require a superfluous mutex, impose constraints on the relative progress of detecting and reacting tasks, and require reacting tasks to verify that the event has taken place.</li> <li>Design employing a flag avoid those problems, but are based on polling, not blocking.</li> <li>Using <code>std::promise</code>s and futures dodges these issues, but the approach uses heap memory for shared states, and it's limited to one-shot communication.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#40-use-stdatomic-for-concurrency-volatile-for-special-memory","title":"40. Use <code>std::atomic</code> for concurrency, <code>volatile</code> for special memory.","text":"<ul> <li><code>std::atomic</code> is for data accessed from multiple threads without using mutexes, It's a tool for writing concurrent software.</li> <li><code>volatile</code> is for memory where reads and writes should not be optimized away. It's a tool for working with special memory.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#41-consider-pass-by-value-for-copyable-parameters-that-are-cheap-to-move-and-always-copied","title":"41. Consider pass by value for copyable parameters that are cheap to move and always copied.","text":"<ul> <li>For copyable, cheap-to-move parameters that are always copied, pass by value may be nearly as efficient as pass by reference, it's easier to implement, and it can generate less object code.</li> <li>Copying parameters via construction may be significantly more expensive than copying them via assignment.</li> <li>Pass by value is suject to the slicing problem, so it's typically inappropriate for base class parameter types.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#42-consider-emplacement-instead-of-insertion","title":"42. Consider emplacement instead of insertion.","text":"<ul> <li>In principle, emplacement functions should sometimes be more efficient than their insertion counterparts, and they should never be less efficient.</li> <li>In practice, they're most likely to be faster when:<ul> <li>the value being added is constructed into the container, not assigned;</li> <li>the argment types passed differ from the type held by the container;</li> <li>the container won't reject the value being added due to it being a duplicate.</li> </ul> </li> <li>Emplacement functions may perfrom type conversions that would be rejected by insertion functions.</li> </ul>"},{"location":"Coding/C%2B%2B/effective_modern_cpp/#reference","title":"Reference","text":"<ul> <li>Effective Modern C++</li> </ul>"},{"location":"Coding/Concurrency/01_concurrency_in_cpp/","title":"C++ Concurrency in Action","text":"<p>TODO</p>"},{"location":"Coding/Concurrency/02_cuda_coding/","title":"Cuda Coding","text":"<p>TODO</p>"},{"location":"Coding/Data-Structure/01_stack/","title":"Stack","text":"<p>Stacks and queues are dynamic sets in which the element removed from the set by <code>Delete</code> operation is prespecified.</p> <p>In a <code>stack</code>, the element deleted from the set is the most recently inserted: the stack implements a <code>last-in, first-out</code> or <code>LIFO</code>, policy.</p> <p></p> <p>The <code>Insert</code> operation on a stack is often called <code>Push</code>, and the <code>Delete</code> operation, which does not take an element, is often called <code>Pop</code>. These names are allusions to physical stacks, such as the spring-loaded stacks of plates used in cafeteriass. The order in which plates are popped from the stack is the reverse of the order in which they were pushed onto the stack, since only the top plate is accessible.</p>"},{"location":"Coding/Data-Structure/01_stack/#problems","title":"Problems","text":""},{"location":"Coding/Data-Structure/01_stack/#implementation","title":"Implementation","text":"<p>This kind of problems mainly contains use other data structures of:</p> <ul> <li>array</li> <li>linked list</li> <li>queue</li> </ul> <p>to implement a <code>stack</code> class.</p> <ul> <li>155. Min Stack</li> <li>225. Implement Stack using Queues</li> </ul>"},{"location":"Coding/Data-Structure/01_stack/#syntax-parsing","title":"Syntax Parsing","text":"<p>This kind of problems are mainly about the few elements at the end of lists, for example:</p> <ul> <li>Paretheses matching, which delete the parentheses matched;</li> <li>Path finding, which delete the elements at the back if <code>..</code> occurs.</li> </ul> <p>problems:</p> <ul> <li>20. Valid Parentheses</li> <li>71. Simplify Path</li> </ul>"},{"location":"Coding/Data-Structure/01_stack/#expression-evaluation","title":"Expression Evaluation","text":"<p>The tytical problem of this is the calculator. We usually solve this with two stacks:</p> <ul> <li><code>number</code> stack, which records all numbers to be calculated\uff1b</li> <li><code>operator</code> stack, which stores operators(<code>(, ), +, -, *, /</code>) in increasing grade, <code>(, )</code> is 0, <code>+, -</code> is 1, <code>*, /</code> is 2.</li> </ul> <p>The general frame is: <pre><code>stack&lt;string&gt; ops;\nstack&lt;int&gt; nums;\nint i = 0;\nwhile (i &lt; str.size()) {\n  if (is_left_parenth) {\n    // push to ops\n    ++i;\n  } else if (is_right_parenth) {\n    // calculate numbers and operators util ops.top() is left parenth\n    // ops.pop()\n    ++i\n  } else if (is_number) {\n    // get the whole number\n    // push the number to number stack\n    ++i\n  } else if (is_operator) {\n    // if curr_op &lt;= ops.top()\n    // calculate the operators\n    // push curr_op to operator stack\n    ++i\n  }\n}\n</code></pre></p> <ul> <li>150. Evaluate Reverse Polish Notation</li> <li>224. Basic Calculator</li> <li>227. Basic Calculator II</li> <li>772. Basic Calculator III</li> </ul>"},{"location":"Coding/Data-Structure/01_stack/#monotonous-stack","title":"Monotonous Stack","text":"<p>Monotonous stack make sure that all elements from bottom to top are in increasing or decreasing order. To do so, use the loop:</p> <pre><code>stack&lt;int&gt; ss{};\nfor (auto n : nums) {\n  while (!ss.empty() &amp;&amp; n &lt;= ss.top()) ss.pop();\n  ss.push(n);\n}\n</code></pre> <p>Sometimes we want to choose <code>n</code> number form a list, the relative order of the digits from the list should be preserved and make the new number with the length of <code>n</code> maximum.</p> <p>This could also be created with monotonous stack:</p> <pre><code>int drop = arr.size() - n;\nstack&lt;int&gt; ss{};\nfor (auto n : nums) {\n  while (drop &amp;&amp; !ss.empty() &amp;&amp; ss.top() &lt;= n) { ss.pop(); --drop; }\n  ss.push(n);\n}\nwhile (ss.size() &gt; n) ss.pop();\n</code></pre> <ul> <li>42. Trapping Rain Water</li> <li>84. Largest Rectangle in Histogram</li> <li>321. Create Maximum Number</li> </ul>"},{"location":"Coding/Data-Structure/02_queue/","title":"Queue","text":"<p>In computer science, a queue is a collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the other end of the sequence. By convention, the end of the sequence at which elements are added is called the back, tail, or rear of the queue, and the end at which elements are removed is called the head or front of the queue, anologously to the words used when people line up to wait for goods or services.</p> <p></p> <p>The operations of a queue make it a <code>first-in-first-out(FIFO)</code> data structure. Common implementations of queue are:</p> <ul> <li>circular buffers</li> <li>linked lists</li> </ul>"},{"location":"Coding/Data-Structure/02_queue/#problems","title":"Problems","text":""},{"location":"Coding/Data-Structure/02_queue/#implementation","title":"Implementation","text":"<ul> <li>232. Implement Queue Using Stack</li> <li>346. Moving Average from Data Stream</li> <li>622. Design Circular Queue</li> </ul>"},{"location":"Coding/Data-Structure/02_queue/#breadth-first-search","title":"Breadth First Search","text":"<p>A common use of BFS is to find the shortest path, in other words, the minimum steps from start state to the target state. If the problem is about states transforming and we can traverse all states step by step, we can use DFS to find the answer.</p> <p>The general pattern for BFS is:</p> <pre><code>queue&lt;Node&gt; q{};\nq.push(start_node);\nwhile (!q.empty()) {\n  auto node = q.front();\n  q.pop();\n\n  for (auto n : node.next_nodes()) {\n    q.push_back(n);\n  }\n}\n</code></pre> <p>And if we want to count how many times (steps) the state transformation happens, we should use deque and add the counter:</p> <pre><code>deque&lt;Node&gt; q{};\nq.push_back(start_node);\nint step = 0;\nwhile (!q.empty()) {\n  auto size = q.size();\n  while (size--) {\n    auto node = q.front();\n    q.pop_front();\n\n    for (auto n : node.next_nodes()) {\n      q.push_back(n);\n    }\n  }\n  ++step;\n}\n</code></pre> <p>And more often, we do not want to visit a state twice(because the state is viisted and there is no need to do it again), we can choose which node can enqueue:</p> <pre><code>deque&lt;Node&gt; q{};\nq.push_back(start_node);\nunordered_set&lt;Node&gt; visited{};\nvisited.insert(start_node);\nint step = 0;\nwhile (!q.empty()) {\n  auto size = q.size();\n  while (size--) {\n    auto node = q.front();\n    q.pop_front();\n\n    for (auto n : node.next_nodes()) {\n      if (visited.count(n)) continue;\n      visited.insert(n);\n      q.push_back(n);\n    }\n  }\n  ++step;\n}\n</code></pre> <ul> <li>Walls and Gates</li> <li>Number of Islands</li> <li>Open the Lock</li> <li>Sliding Window Maximum</li> </ul>"},{"location":"Coding/Data-Structure/02_queue/#reference","title":"Reference","text":"<ul> <li>LeetBook Queue and Stack</li> </ul>"},{"location":"Coding/Data-Structure/03_linked_list/","title":"Linked List","text":"<p>A <code>linked list</code> is a data structure in which the objects are arranged in a linear order. Unlike an array, however, in which the linear order is determined by the array indeces, the order in a linked list is determined by a pointer in each object. Linked lists provide a simple, flexible representation for dynamic sets, supporting (though not necessaryily efficiently) all the operations.</p> <p>Each record of a linked list is often called an <code>node</code>.</p> <p>The field of each node that contains the address of the next node is usually called the <code>next link</code> or <code>next pointer</code>. The remaining fields are known as the <code>data</code>.</p>"},{"location":"Coding/Data-Structure/03_linked_list/#types","title":"Types","text":"<p>Generally, there are two kinds of linked list:</p> <ul> <li>singly linked list</li> <li>Doubly linked list</li> </ul> <p>The operation complexities are:</p> Insert/Delete Check/Modify O(1) O(n)"},{"location":"Coding/Data-Structure/03_linked_list/#singly-linked-list","title":"Singly Linked List","text":"<p>Singly linked lists contain nodes which have a data field as well as <code>next</code>, which points to the next node in line of nodes.</p> <pre><code>struct Node {\n  int val{0};\n  Node* next{nullptr};\n};\n</code></pre>"},{"location":"Coding/Data-Structure/03_linked_list/#doubly-linked-list","title":"Doubly Linked List","text":"<p>In a doubly linked list, each node contains, besides the next-node link, as second link field pointing to the <code>previous</code> node in the sequence.</p> <pre><code>struct Node {\n  int val{0};\n  Node* prev{nullptr};\n  Node* next{nullptr};\n};\n</code></pre>"},{"location":"Coding/Data-Structure/03_linked_list/#problems","title":"Problems","text":"<p>The problems about linked list are generally easy, but it may take much attention to care about:</p> <ul> <li>check the if pointer of linked list is valid</li> <li>check if the node is correct while traveling the linked list</li> <li>sometimes it will simplify the code if we add a dump node at the head or tail of linked list.</li> </ul>"},{"location":"Coding/Data-Structure/03_linked_list/#implementation","title":"Implementation","text":"<p>Implementation involves operations of delete and add:</p> <ul> <li>for singly linked list</li> </ul> <pre><code>// Add after node\nauto next = new Node{val, node-&gt;next};\nnode-&gt;next = next;\n\n// Delete the node behind\nnode-&gt;next = node-&gt;next-&gt;next;\n</code></pre> <ul> <li>for doubly linked list</li> </ul> <pre><code>// Add after node\nauto next = new Node{val, node, node-&gt;next};\nnext-&gt;prev-&gt;next = next;\nnext-&gt;next-&gt;prev = next;\n\n// Delete the node behind\nnode-&gt;next-&gt;next-&gt;prev = node;\nnode-&gt;next = node-&gt;next-&gt;next;\n</code></pre> <ul> <li>Design Linked List</li> </ul>"},{"location":"Coding/Data-Structure/03_linked_list/#reverse-linked-list","title":"Reverse Linked List","text":"<p>This problem often works as the intermediate step in other more complex problems.</p> <p>The main idea is to put the node to the head while traversing all the nodes.</p> <pre><code>auto node = head-&gt;next;\n    head-&gt;next = nullptr;\n    while (node) {\n      auto tmp = node-&gt;next;\n      node-&gt;next = head;\n      head = node;\n      node = tmp;\n    }\n</code></pre> <ul> <li>Reverse Linked List</li> </ul>"},{"location":"Coding/Data-Structure/03_linked_list/#double-pointer","title":"Double Pointer","text":"<p>The typical usage of double pointers is to check if the linked list is circular and the entry of loop. In this skill we have two pointers:</p> <ul> <li>slow pointer, which goes one step once;</li> <li>faster pointer, which goes two steps once.</li> </ul> <pre><code>auto slow = head;\nauto fast = head-&gt;next;\nwhile (fast &amp;&amp; fast-&gt;next) {\n  slow = slow-&gt;next;\n  fast = fast-&gt;next-&gt;next;\n}\n</code></pre> <p>If two pointers meet at the same node, the linked list is circular.</p> <p>In other situations, double pointers of slow and fast can divide the linked into two equal parts, because fast pointer goes twice of the slow, and when fast stops at the tail, the slow stops at the middle.</p> <ul> <li>Linked List Cycle</li> <li>Linked List Cycle II</li> <li>Intersection of Two Linked List</li> <li>Remove Nth Node from End of List</li> </ul>"},{"location":"Coding/Data-Structure/03_linked_list/#other","title":"Other","text":"<ul> <li>Flateen a Multilevel Doubly Linked List</li> <li>Copy List with Random Pointer</li> </ul>"},{"location":"Coding/Data-Structure/045_kd_tree/","title":"K-d Tree","text":"<p>A k-d tree(short for k-dimension tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches). k-d trees are a special case of binary space partitioning trees.</p> <p>k-d trees are not suitable, however, for efficiently finding the nearest neighbor in high dimensional spaces. As a general rule, if the dimensionality is <code>k</code>, the number of point in the data is <code>N</code>, should be:</p> \\[ N \\gg 2^k \\] <p>Otherwise, when k-d trees are used with high-dimensional data, most of the points in the tree will be evaluated and the efficiency is no better than exhaustive search, and other methods such as approximate nearest-neighbor are used instead.</p> <pre><code>#include &lt;algorithm&gt;\n#include &lt;array&gt;\n#include &lt;vector&gt;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\n#include &lt;functional&gt;\n\n/// @class the KdTree Implementation\ntemplate&lt;typename T, size_t D&gt;\nclass KdTree {\n public:\n  using Point = std::array&lt;T, D&gt;;\n\n private:\n  /// @struct Kdtree node defination\n  struct Node {\n    Point point{};\n    Node* left{nullptr};\n    Node* right{nullptr};\n  };\n\n  /// @struct Less compare operator for two points \n  struct NodeComp {\n    size_t index{0};\n\n    bool operator()(const Point&amp; a, const Point&amp; b) {\n      return a[index] &lt; b[index];\n    }\n  };\n\n  /// Build the tree with a list of points recursively\n  /// @return root of the tree\n  Node* build_tree(\n      std::vector&lt;Point&gt;&amp; pts, size_t begin, size_t end, size_t dim) {\n    if (begin &gt;= end) return nullptr;\n\n    size_t mid = begin + (end - begin) / 2;\n    auto it = pts.begin();\n    std::nth_element(it + begin, it + mid, it + end, NodeComp{.index = dim});\n    dim = ++dim % D;\n\n    return new Node{pts[mid], build_tree(pts, begin, mid, dim),\n                              build_tree(pts, mid + 1, end, dim)};\n  }\n\n  /// Calculate the square distance of two points\n  /// @return squre distance\n  double sqr_dis(const Point&amp; p1, const Point&amp; p2) {\n    double ans{0};\n    for (size_t i = 0; i &lt; D; ++i) ans += (p1[i] - p2[i]) * (p1[i] - p2[i]);\n    return ans;\n  }\n\n  /// Get the nearest point and distance by the given point\n  void nearest(const Node* root, const Point&amp; tar, size_t dim, Point&amp; best,\n               double&amp; min_dis) {\n    if (!root) return;\n\n    const double d = sqr_dis(root-&gt;point, tar);\n    if (d &lt; min_dis) {\n      min_dis = d;\n      best = root-&gt;point;\n    }\n\n    const double dx = root-&gt;point[dim] - tar[dim];\n    dim = ++dim % D;\n\n    nearest(dx &gt; 0 ? root-&gt;left : root-&gt;right, tar, dim, best, min_dis);\n    if (dx * dx &gt; min_dis) return;\n    nearest(dx &gt; 0 ? root-&gt;right : root-&gt;left, tar, dim, best, min_dis);\n  }\n\n public:\n  /// Copy control\n  KdTree(const KdTree&amp;) = delete;\n  KdTree&amp; operator=(const KdTree&amp;) = delete;\n  KdTree(KdTree&amp;&amp;) = delete;\n  KdTree&amp; operator=(KdTree&amp;&amp;) = delete;\n\n  ~KdTree() {\n    std::function&lt;void(Node*)&gt; f = [&amp;f](Node* root) {\n      if (!root) return;\n      f(root-&gt;left);\n      f(root-&gt;right);\n      delete root;\n      root = nullptr;\n      return;\n    };\n\n    f(root);\n  }\n\n  /// Constructor with a list of points\n  KdTree(std::vector&lt;Point&gt; pts) {\n    root = build_tree(pts, 0, pts.size(), 0);\n  }\n\n  /// Get the nearest point and distance with given point\n  /// @return point and distance of the nearest\n  std::pair&lt;Point, double&gt; Nearest(const Point&amp; tar) {\n    if (!root) return {};\n\n    double min_dis{std::numeric_limits&lt;double&gt;::max()};\n    Point ans{};\n    nearest(root, tar, 0, ans, min_dis);\n\n    return {ans, std::sqrt(min_dis)};\n  }\n\n private:\n  Node* root{nullptr};\n};\n\n/// Test code\nint main() {\n  std::vector&lt;std::array&lt;double, 2&gt;&gt; pts{\n      {2, 3}, {5, 4}, {9, 6}, {4, 7}, {8, 1}, {7, 2}};\n  KdTree&lt;double, 2&gt; kdt{pts};\n\n  auto [pt, dis] = kdt.Nearest({9, 2});\n  std::cout &lt;&lt; \"nearest: (\" &lt;&lt; pt[0] &lt;&lt; \", \" &lt;&lt; pt[1] &lt;&lt; \") in \" &lt;&lt; dis\n            &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"Coding/Data-Structure/045_kd_tree/#reference","title":"Reference","text":"<ul> <li>K-d Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/","title":"Tree","text":"<p>A <code>tree</code> is a widely used abstract data type that simulate a hierarchical tree structure, with a root value and subtrees of children with a paarent node, represented as a set of linked nodes. Some nodes are:</p> <p></p> <ul> <li><code>node</code>: a structure wich may contain a value or condition, or represent a separate data structure.</li> <li><code>child node</code>: each node in a tree has zero or more child node, which are below it in the tree.</li> <li><code>parent node</code>: a node has a child is called the child's parent node(or <code>superior</code>).</li> <li><code>acestor node</code>: a node's parent's parent, a node has at most one parent but possibly many ancestor nodes.</li> <li><code>sibling nodes</code>: child nodes with the same paarent are  sibling nodes.</li> <li><code>root node</code>: the tomost node in a tree.</li> <li><code>branch nodes</code>: any node of a tree that has child nodes.</li> <li><code>leaf nodes</code>: any node that does not have child nodes.</li> <li><code>height</code> of a node: the length of the longest downward path to a leaf from that node.</li> <li><code>depth</code> of a node: the length of the path to root.</li> </ul> <p>The general solutions for tree often involves with recursion, a function which calls itself. We can use the following steps to define the recursive function:</p> <ol> <li>Consider the return value;</li> <li>Consider the parameter list;</li> <li>Consider the terminal condition;</li> <li>Consider the level logic.</li> </ol>"},{"location":"Coding/Data-Structure/04_tree/#binary-tree","title":"Binary Tree","text":"<p><code>Binary Tree</code> is a kind of <code>tree</code> that each node has at most two children, which are refered to as the <code>left child</code> and <code>right child</code>.</p> <p></p>"},{"location":"Coding/Data-Structure/04_tree/#traversal","title":"Traversal","text":"<p>There are mainly two methods to traversal a binary tree:</p> <ol> <li>Depth First Search(BFS), and according to the order we visited the parent node, BFS can be divided into:<ol> <li><code>pre-order traversal</code>: first visiting parent node, and then left and right child;</li> <li><code>in-order traversal</code>: first visiting left child, and then parent node, and then right child;</li> <li><code>post-order traversal</code>: first visiting left and right child, and then parent node.</li> </ol> </li> <li>Bread First Search(BFS), which visits the tree layer by layer.</li> </ol> <p>The general code for DFS is:</p> <pre><code>void dfs(TreeNode* root) {\n  if (!root) return;\n\n  // visit root-&gt;val here, pre-order\n  dfs(root-&gt;left);\n  // visit root-&gt;val here, in-order\n  dfs(root-&gt;right);\n  // visit root-&gt;val here, post-order\n}\n</code></pre> <ul> <li>Binary Tree Preorder Traversal</li> <li>Binary Tree Inorder Traversal</li> <li>Binary Tree Postorder Traversal</li> </ul> <p>And for BFS:</p> <pre><code>void bfs(TreeNode* root) {\n  if (!root) return;\n\n  deque&lt;TreeNode*&gt; q{};\n  q.push_back(root);\n\n  while (!q.empty()) {\n    auto size = q.size();\n    while (size--) {  // visit each layer\n      auto node = q.front();\n      q.pop_front();\n\n      if (node-&gt;left) q.push_back(node-&gt;left);\n      if (node-&gt;right) q.push_back(node-&gt;right);\n    }\n  }\n}\n</code></pre> <ul> <li>Binary Tree Level Order Traversal</li> </ul> <p>There are other types of traversal, but all can be solved with above methods.</p>"},{"location":"Coding/Data-Structure/04_tree/#priorities","title":"Priorities","text":"<p>Sometimes we want to get the priority of a tree, like:</p> <ul> <li>Symmetric/Same</li> <li>Maximum/Minimum depth</li> <li>Balance</li> <li>Number of nodes</li> <li>Sum of the path from root to leaf node</li> <li>Common ancestor</li> </ul> <p>Problems:</p> <ul> <li>Symmetric Tree</li> <li>Maximum Depth of Binary Tree</li> <li>Minimum Depth of Binary Tree</li> <li>Count Complete Tree Nodes</li> <li>Balanced Binary Tree</li> <li>Binary Tree Paths</li> <li>Lowest Common Ancestor of a Binary Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#modify-and-construct","title":"Modify and Construct","text":"<ul> <li>Invert Binary Tree</li> <li>Constract Binary Tree from Inorder and Postorder Traversal</li> <li>Serialize and Deserialize Binary Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#binary-search-tree","title":"Binary Search Tree","text":"<p>Binary Search Tree(BST) is a binary tree has the priority:</p> <p>Each branch node stores a key greater than all the keys in left subtree and less than those in its right substree.</p> <p>The order of nodes in a BST means that each comparison skips about half of the remaining tree, so the whole lookup takes \\(log(N)\\) time.</p> <p>For BST problems, you can convert a BST to a sorted array by inorder traversal. Or, you can also use an extral pointer pointing to node visited last time in inorder traversal to get the left node in an sorted array.</p>"},{"location":"Coding/Data-Structure/04_tree/#priority","title":"Priority","text":""},{"location":"Coding/Data-Structure/04_tree/#search","title":"Search","text":"<ul> <li>Search in a Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#check","title":"Check","text":"<ul> <li>Validate Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#application","title":"Application","text":"<ul> <li>Minimum Absolute difference in BST</li> <li>Find Mode in Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#construct-and-modify","title":"Construct and Modify","text":""},{"location":"Coding/Data-Structure/04_tree/#construct","title":"Construct","text":"<ul> <li>Convert Sorted Array to Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#insert","title":"Insert","text":"<ul> <li>Insert into a Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#delete","title":"Delete","text":"<ul> <li>Delete Node in a BST</li> </ul>"},{"location":"Coding/Data-Structure/04_tree/#trim","title":"Trim","text":"<ul> <li>Trim a Binary Search Tree</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/","title":"Hash Table","text":"<p>A <code>hash table</code> is a data structure that implements an associative array abstract data type, a structure that can map <code>keys</code> to <code>values</code>.</p> <p></p> <p>A <code>hash table</code> use a <code>hash function</code> to compute an index of <code>buckets</code> with <code>keys</code> to store desired <code>values</code>.</p> <p>Ideally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause <code>hash collisions</code> where the hash function generate the same index for more than one key. The resolution of collision may contain:</p> <ul> <li><code>seperate chaining</code>, if collision occers, we store both elements in the same bucket;</li> </ul> <p></p> <ul> <li><code>linear probing</code>, when collision occers, we look for a new empty bucket to store the element.</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/#problems","title":"Problems","text":""},{"location":"Coding/Data-Structure/05_hash/#implementation","title":"Implementation","text":"<p>For the implementation of hash table, we can simply use a vector of linked list with the size of prime number. When addition, we just attach a new element at the end of linked list(bucket); and for deletion, we can swap the position of element to be deleted with the last element and then delete the last element.</p> <ul> <li>Design Hashset</li> <li>Design Hashmap</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/#duplication-detectionhash-set","title":"Duplication Detection(Hash Set)","text":"<p>We can use the hashset to check if an element have been visited while traversaling.</p> <ul> <li>Contains Duplicate</li> <li>Single Number</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/#associating-keys-with-more-informationhash-map","title":"Associating Keys with more Information(Hash Map)","text":"<p>We can use hashmap to create connections between keys and information about keys. For example, connecting the value and its index in an array.</p> <ul> <li>Two Sum</li> <li>Minimum Index Sum of Two Lists</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/#grouping-elements-with-keyshash-map","title":"Grouping Elements with Keys(Hash Map)","text":"<p>We can also group all elements with the same identity.</p> <ul> <li>First Unique Charactor in a String</li> <li>Intersection of Two arrays II</li> </ul>"},{"location":"Coding/Data-Structure/05_hash/#designing-key-to-use-hash","title":"Designing Key to Use Hash","text":"<p>Sometimes we want to use the hash table to deal with problems, but the key of elements is not as simple as int, string, etc.</p> <p>The general variants are:</p> <ol> <li>Sorted string, if the order of charactors is not important;</li> <li>Offset of each element;</li> <li>Serialized string, if the element is a tree;</li> <li>Row or Coloumn index, if you are dealing with matrix.</li> </ol> <p>Problems:</p> <ul> <li>Group Anagrams</li> <li>Group Shifted Strings</li> <li>Valid Sudoku</li> <li>Find Duplicate Subtrees</li> </ul>"},{"location":"Coding/Data-Structure/06_array/","title":"Array","text":"<p>In computer science, an <code>array data structure</code>, or simply an <code>array</code>, is a data structure consisting of a cllection of elements(values or variables), each identified by at least one <code>array index</code> or <code>key</code>. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is linear array, also called one-dimensional array. We can also use an array to store another array, which is called the 2-dimensional array.</p> <p>Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage device, the memory is one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.</p>"},{"location":"Coding/Data-Structure/06_array/#operations","title":"Operations","text":"<p>The operations ant their time complexities of array are:</p> <ul> <li>Read an element by its index, \\(O(1)\\);</li> <li>Look up an element, \\(O(N)\\);</li> <li>Insert an element, \\(O(1)\\) for back, \\(O(N)\\) for random;</li> <li>Delete an element, \\(O(1)\\) for back, \\(O(N)\\) for random.</li> </ul>"},{"location":"Coding/Data-Structure/06_array/#problems","title":"Problems","text":"<p>Generally speaking, the problems about array are simple, but it may need more complex methods like:</p> <ul> <li>doubly pointer;</li> <li>dynamic programming;</li> <li>greedy;</li> <li>dfs;</li> <li>bfs;</li> </ul>"},{"location":"Coding/Data-Structure/075_lru/","title":"LRU(Latest Recently Used) Cache","text":"<p>Least Recently Used(LRU) is a common caching strategy. It defines the policy to evict elements from the cache to make room for new elements when the cache is full, meaning it discards the least recently used items first.</p> <pre><code>class LRUCache {\n  struct Node {\n    int key{0};\n    int val{0};\n    Node* prev{nullptr};\n    Node* next{nullptr};\n  };\n\n  Node* head{new Node{}};\n  Node* tail{new Node{.prev = head}};\n  int cap{0};\n  unordered_map&lt;int, Node*&gt; k_n{};\n\n  void to_head(Node* node) {\n    if (node-&gt;prev) node-&gt;prev-&gt;next = node-&gt;next;\n    if (node-&gt;next) node-&gt;next-&gt;prev = node-&gt;prev;\n    node-&gt;prev = head;\n    node-&gt;next = head-&gt;next;\n    node-&gt;prev-&gt;next = node;\n    node-&gt;next-&gt;prev = node;\n  }\n\n  void trim_tail() {\n    k_n.erase(tail-&gt;prev-&gt;key);\n    auto died = tail-&gt;prev;\n    tail-&gt;prev-&gt;prev-&gt;next = tail;\n    tail-&gt;prev = tail-&gt;prev-&gt;prev;\n    delete died;\n  }\n\n public:\n  LRUCache(int capacity) : cap{capacity} {\n    head-&gt;next = tail;\n  } \n  ~LRUCache() { delete head; delete tail; }\n\n  int get(int key) {\n    if (!k_n.count(key)) return -1;\n    to_head(k_n[key]);\n    return k_n[key]-&gt;val;\n  }\n\n  void put(int key, int value) {\n    if (!k_n.count(key)) k_n[key] = new Node{key, value};\n    to_head(k_n[key]);\n    k_n[key]-&gt;val = value;\n    if (k_n.size() &gt; cap) trim_tail();\n  }\n};\n</code></pre>"},{"location":"Coding/Data-Structure/076_lfu/","title":"LFU","text":""},{"location":"Coding/Data-Structure/07_string/","title":"String","text":"<p>A <code>string</code> is traditionally a sequence of charactors, either as a literal constant or as some kind of variable. The storage of string can be:</p> <ul> <li>an array of <code>char</code> with the end of <code>\\0</code>, which is the <code>C</code>-style string;</li> <li>the stl <code>string</code> container, whose length is changable;</li> <li>literal constant(some charactors enclosed by <code>\"\"</code>).</li> </ul> <p>Some definiations:</p> <ul> <li>Prefix: a string <code>s</code> is said to be a prefix of <code>t</code> if there exists a string <code>u</code> such that <code>t = su</code>;</li> <li>Proper prefix: if <code>u</code> is nonempty, <code>s</code> is said to be a <code>proper prefix</code> of <code>t</code>;</li> <li>Suffix: a string <code>s</code> is said to be a prefix of <code>t</code> if there exists a string <code>u</code> such that <code>t = us</code>;</li> <li>Proper suffix: if <code>u</code> is nonempty, <code>s</code> is said to be a <code>proper prefix</code> of <code>t</code>;</li> </ul>"},{"location":"Coding/Data-Structure/07_string/#pattern-matching","title":"Pattern Matching","text":"<p>This probelm is defined as:</p> <p>Given strings <code>s</code> and <code>t</code>, find the position that <code>t</code> appears in <code>s</code> for the first time. <code>t</code> is called the <code>pattern</code>.</p>"},{"location":"Coding/Data-Structure/07_string/#brute-force","title":"Brute Force","text":"<p>The basic method is to enumerate the start position of substring in pattern, and check if it's true;</p> <pre><code>for (int i = 0; i &lt; m; ++i) {\n  bool is_sub{true};\n  for (int j = 0; j &lt; n; ++j) {\n    if (pattern[i + j] == substr[j]) continue;\n    is_sum = false;\n    break;\n  }\n  if (is_sub) return i;\n}\n\nreturn -1;\n</code></pre> <p>The time complexity is \\(O(mn)\\), which costs a lot;</p>"},{"location":"Coding/Data-Structure/07_string/#knuth-morris-prattkmp","title":"Knuth-Morris-Pratt(KMP)","text":"<p>The disadvantage of BF is that every time comparing the <code>s</code> and <code>t</code> we have to return to the start of substring if failed, which wastes much time.</p> <p>If the repeated string appears in substring, we can jump over the same prefix of the string and check the first different charactor when mismatching occurs. Where comes the <code>next</code> array:</p>"},{"location":"Coding/Data-Structure/07_string/#next-array","title":"<code>next</code> Array","text":"<p>Generally speaking, <code>next</code> is an array that <code>next[i]</code> represents the length of the longest common proper prefix of two string:</p> <ol> <li>prefix of string <code>s[0:i - 1]</code>;</li> <li>suffix of string <code>s[0:i - 1]</code>;</li> </ol> <p>where <code>s</code> is the given substring.</p> <p></p> <p>We let <code>next[0] = -1</code> because <code>s[0:-1]</code> has no proper prefix. And at the position <code>i</code> we fill the result of <code>next[i + 1]</code>, so the terminate condition is <code>i &lt; n - 1</code>.</p> <pre><code>int i = 0;  // for main loop\nint j = next[0] = -1;  // for common part of prefix and suffix\nwhile (i &lt; n - 1) {  // n is the length of s, i &lt; n - 1 to ensure index safety\n  if (j &lt; 0 || s[i] == s[j]) {  // matching\n    next[++i] = ++j;\n  } else {\n    j = next[j];  // not matching, go to first different position\n  }\n}\n</code></pre>"},{"location":"Coding/Data-Structure/07_string/#main-process","title":"Main Process","text":"<p>The main process is the same with how we get the <code>next</code> array:</p> <pre><code>int i = 0, j = 0;\nwhile (i &lt; m) {\n  if (j &lt; 0 || t[i] == s[j]) {\n    ++i; ++j;\n  } else {\n    j = next[j];\n  }\n  if (j == n) return i - n;\n}\n\nreturn -1;\n</code></pre> <p>The time complexity of KMP is \\(O(m + n)\\).</p> <p>Problems:</p> <ul> <li>implement-strstr</li> <li>longest-happy-prefix</li> </ul>"},{"location":"Coding/Data-Structure/07_string/#substring","title":"Substring","text":""},{"location":"Coding/Data-Structure/07_string/#prefixes-and-suffixes","title":"Prefixes and Suffixes","text":""},{"location":"Coding/Data-Structure/08_trie/","title":"Trie","text":"<p>In computer science, a <code>trie</code>, also called <code>digital tree</code> or <code>prefix tree</code>, is a type of <code>k-ary search tree</code>, a tree data structure used for locating specific keys from within as set. These keys are most often strings, with links between nodes defined not by the entire key, but by individual characters.  Unlike a binary search tree, nodes in the trie do not store their associated key, Instead, a node's position in the trie defines the key with which it is associated.</p> <p></p>"},{"location":"Coding/Data-Structure/08_trie/#implementation","title":"Implementation","text":"<p>An implementation of trie can be:</p> <pre><code>class Trie {\n  struct Node {\n    bool is_word{false};\n    vector&lt;Node*&gt; child{};\n    Node() : child(26, nullptr) {};\n  };\n  Node* root{new Node{}};\n public:\n  void insert(const string&amp; word) {\n    auto node = root;\n    for (auto c : word) {\n      if (!node-&gt;child[c - 'a']) node-&gt;child[c - 'a'] = new Node{};\n      node = node-&gt;child[c - 'a'];\n    }\n    node-&gt;is_word = true;\n  }\n\n  bool search(const string&amp; word) {\n    auto node = root;\n    for (auto c : word) {\n      if (!node-&gt;child[c - 'a']) return false;\n      node = node-&gt;child[c - 'a'];\n    }\n    return node-&gt;is_word;\n  }\n\n  bool startsWith(const string&amp; prefix) {\n    auto node = root;\n    for (auto c : prefix) {\n      if (!node-&gt;child[c - 'a']) return false;\n      node = node-&gt;child[c - 'a'];\n    }\n    return true;\n  }\n};\n</code></pre> <ul> <li>Implement Trie Prefix Tree</li> <li>Map Sum Pairs</li> <li>Replace Words</li> <li>Design Search Autocomplete System</li> <li>Design Add and Search Words Data Structure</li> <li>Maximum Xor of Two Numbers in an Array</li> <li>Word Search II</li> <li>Word Squares</li> <li>Palindrome Pairs</li> </ul>"},{"location":"Coding/Data-Structure/09_union_find/","title":"Union-Find","text":"<p>A <code>union-find</code>, is a data structure that stores a collection of disjoint(non-overlapping) setting. Equivalently, it stores a partition of a set into disjoint subsets. It provides operations for adding new sets, merging sets and finding a representative member of a set.</p> <pre><code>class UnionFind {\n public:\n  Union(int n) : size(n - 1, 1), cnt{n} {\n    for (int i = 0; i &lt; n; ++i) parent.push_back(i);\n  }\n\n public:\n  int Find(int x) {\n    if (parent[x] != x) parent[x] = find(parent[x]);\n    return parent[x];\n  }\n\n  bool Union(int x, int y) {\n    int xx = find(x);\n    int yy = find(y);\n    if (xx == yy) return false;\n    if (size[xx] &gt; size[yy]) swap(xx, yy);\n    parent[xx] = yy;\n    size[yy] += size[xx];\n    cnt--;\n    return true;\n  }\n\n  int Count() { return cnt; }\n\n  bool Connect(int x, int y) { return find(x) == find(y); }\n\n private:\n  vector&lt;int&gt; parent{};\n  vector&lt;int&gt; size{};\n  int cnt{0};\n};\n</code></pre> <p>Problems:</p> <ul> <li>satisfiability-of-equality-equations</li> <li>number-of-provinces</li> <li>redundant-connection</li> <li>number-of-operations-to-make-network-connected</li> <li>number-of-provinces</li> <li>evaluate-division</li> <li>regions-cut-by-slashes</li> <li>swim-in-rising-water</li> <li>smallest-string-with-swaps</li> <li>most-stones-removed-with-same-row-or-column</li> <li>bricks-falling-when-hit</li> </ul>"},{"location":"Coding/Data-Structure/10_bit/","title":"Fenwick Tree","text":"<p>A <code>Fenwick tree</code> or <code>binary indexed tree</code> is a data structure that can efficiently update elements and calculate prefix sums in a table of numbers.</p> <p>When compared with a flat array of numbers, the Fenwick tree achieves a much better balance between two operations:</p> <ul> <li>element udpate;</li> <li>prefix sum calculattion.</li> </ul> <p>A flat array of <code>n</code> numbers can either store the elements or the prefix sums. Fenwick trees allow both operations above to be performed in \\(O(logn)\\) time. This is achieved by representing the numbers as a tree, where the value of each node is the sum of the numbers in that subtree.</p> Algorithm Time Complexity Space \\(O(n)\\) Search \\(O(logn)\\) Insert \\(O(logn)\\) Delete \\(O(logn)\\) <p>A Fenwick tree is most easily understood by considering a one-based array. Each element whose index <code>i</code> is a power of 2 contains the sum of the first <code>i</code> elements. Elements whose indices are the sum of two (distinct) powers of 2 contains the sum of the elements since the preceding power of 2. In general, each element contains the sum of the values since its parent in the tree, and that parent is found by clearing the least significant bit in the index.</p> <pre><code>class FenwickTree {\n public:\n  NumArray(vector&lt;int&gt;&amp; nums) : tree(nums.size() + 1, 0), arr{nums} {\n    for (int i = 0; i &lt; arr.size(); ++i) add(i + 1, arr[i]);\n  }\n\n  void update(int x, int val) {\n    add(x + 1, val - arr[x]);\n    arr[x] = val;\n  }\n\n  int sumRange(int l, int r) {\n    return query(r + 1) - query(l);\n  }\n\n private:\n  int query(int x) {\n    int ans = 0;\n    for (; x; x -= x &amp; -x) ans += tree[x];\n    return ans;\n  }\n\n  void add(int x, int v) {\n    for (; x &lt; tree.size(); x += x &amp; -x) tree[x] += v;\n  }\n\n  vector&lt;int&gt; tree{};\n  vector&lt;int&gt; arr{};\n};\n</code></pre> <ul> <li>range-sum-query-mutable</li> </ul>"},{"location":"Coding/Data-Structure/11_segment_tree/","title":"Segment Tree","text":"<p>A <code>segment tree</code> is a data structure that allows answering range querying over an array effectively, while still being flexible enough to allow modifying the array. This includes finding the sum of consecutive array elements <code>a[l : r]</code>, or finding the minimum element in a such a range in \\(O(log n)\\) time. Between answering such queries, the Segment Tree allows modifying the array by replacing one element, or even changing the elements of a whole subsegment (e.g. assigning all elements <code>a[l : r]</code> to any value, or adding a value to all element in the sub segment).</p> <p>The root node of the segment tree is <code>1</code>, and for an array <code>a = {10, 11, 12, 13, 14}</code>, the segment tree will be like:</p> <p></p> <pre><code>/// Segment tree for range sum\nclass SegmentTree {\n public:\n  /// Reset data and change list to the size of 4n, where n is the size of array\n  SegmentTree(const vector&lt;int&gt;&amp; a) : d(4 * a.size(), 0), b(4 * a.size(), 0) {\n    build(0, a.size() - 1, 1, a);\n  }\n\n  /// Recursively build the tree\n  void build(int s, int e, int p, const vector&lt;int&gt;&amp; a) {\n    if (s == e) { d[p] = a[s]; return; }\n\n    int m = s + (e - s) / 2;  // mid of the range\n    build(s, m, p * 2, a)t\n    build(m + 1, e, p * 2 + 1, a);\n    d[p] = d[p * 2] + d[p * 2 + 1];\n  }\n\n  /// Pushdown the bias\n  void pushdown(int s, int e, int m, int p) {\n    if (!b[p]) return;\n    // update current node's left and right child's data and bias\n    // range [l, r] add a bias\n    d[p * 2] += (m - s + 1) * b[p], d[p * 2 + 1] += (e - m) * b[p];\n    b[p * 2] += b[p], b[p * 2 + 1] += b[p];\n    b[p] = 0;  // clear current node's bias\n  }\n\n  /// Update the range [l, r] to c in the tree d[p], which is the range [s, e]\n  void update(int l, int r, int c, int s, int e, int p) {\n    if (l &lt;= s &amp;&amp; e &lt;= r) {  // l &lt;= s &lt;= e &lt;= r\n      d[p] += (e - s + 1) * c;\n      b[p] = c;\n      return;\n    }\n\n    // range half to update\n    int m = s + (e - s) / 2;\n    pushdown(s, e, m, p);\n\n    if (l &lt;= m) update(l, r, c, s, m, p * 2);\n    if (r &gt; m) update(l, r, c, m + 1, e, p * 2 + 1);\n    d[p] = d[p * 2] + d[p * 2 + 1];\n  }\n\n  /// Query sum of range [l, r] in the tree d[p], which is the range [s, e]\n  int query(int l, int r, int s, int e, int p) {\n    if (l &lt;= s &amp;&amp; e &lt;= r) return d[p];\n\n    int m = s + (e - s) / 2, sum = 0;\n    pushdown(s, e, m, p);\n\n    if (l &lt;= m) sum += query(l, r, s, m, p * 2);\n    if (r &gt; m) sum += query(l, r, m + 1, e, p * 2 + 1);\n    return sum;\n  }\n\n private:\n  vector&lt;int&gt; d{};  // tree node data array\n  vector&lt;int&gt; b{};  // tree node bias array\n};\n\n/// Usage:\nVector&lt;int&gt; arr{11, 12, 13, 14, 15};\nSegmentTree st{arr};\nst.query(0, 2, 0, 4, 1);  // get sum of arr in range [0, 2], node 1 has range [0, 4]\nst.update(0, 3, 5, 0, 4, 1);  // add(update) 5 to array in range[0, 2]\n</code></pre> <ul> <li>range-sum-query-mutable</li> </ul>"},{"location":"Coding/System-Design/algorithm-analysis/","title":"Algorithm Analysis","text":"<p>An <code>algorithm</code> is a clearly specified set of simple instructions to be followed to solve a problem. The important step of algorithm analysis is to determine how much in the way of resource, such as time or spaces, the algorithm requires.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#general-rules","title":"General Rules","text":"<p>Since we are giving the running time in terms of <code>Big-Oh</code>, there are lots of shortcuts that can be taken without affecting the final answer.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#for-loops","title":"For Loops","text":"<p>The running time of a <code>for</code> loop is at most the running time of the statements inside the <code>for</code> loop times the number of iterations.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#nested-loops","title":"Nested Loops","text":"<p>The total running time of a statement inside a group of nested loops is the running time of the statement multiplied by the product of the sizes of all the loops.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#consecutive-statements","title":"Consecutive Statements","text":"<p>Just add them all. The maximum is the one that counts.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#ifelse","title":"If/else","text":"<p>The running of an <code>if/else</code> statement is never more than the running time of the larger of the running time of two statements.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#stratagy-of-analyzing-recursion","title":"Stratagy of Analyzing Recursion","text":"<p>If the recursion is really just a thinly veiled <code>for</code> loop, the analysis is usually trivial.</p> <p>If the recursion is properly used, it is difficult to convert the recursion into a simple loop structure. In this case, the analysis will involve a recurrence relation that needs to be solved.</p> <p>We firstly let \\(T(N)\\) be the running time for current function, and then running time involved with recursion is represented, for example: $$ T(N) = T(N - 1) + T(N - 2) $$ And then we can solve the equation and analysis the approximate running time.</p>"},{"location":"Coding/System-Design/algorithm-analysis/#logarithms-in-the-running-time","title":"Logarithms in the Running Time","text":"<p>An algorithm is \\(O(N)\\) if it take constant time to cut the problem size by a fraction (which is usually \\(\\frac{1}{2}\\)). Otherwise, if constant time is required to merely reduce the problem by a constant amount(such as 1), the algorithm is \\(O(N)\\).</p>"},{"location":"Coding/System-Design/algorithm-analysis/#general-input-size-and-maximum-time-complexity","title":"General Input Size and Maximum Time Complexity","text":"Input Size(N) Worst Accepted Algorithm Algorithm Type \\(&lt; 10\\) \\(O(N!)\\) Permutation \\(&lt; 15\\) \\(O(2^N)\\) Combination \\(&lt; 50\\) \\(O(N^4)\\) DP \\(&lt; 200\\) \\(O(N^3)\\) DP \\(&lt; 1000\\) \\(O(N^2)\\) DP \\(&lt; 10^6\\) \\(O(N)\\) or \\(O(N\\log(N))\\) DP, Greedy, Heap, Divide&amp;Conquer \\(&lt; 10^8\\) \\(O(log(N))\\) or \\(O(1)\\) Binary Search, Math"},{"location":"Coding/System-Design/design_patterns/","title":"Design Patterns","text":"<p>Design patterns are typical solutions to commonly occurring problems in software design. They are likely pre-made blueprints that you can customize to solve a recurring design problem in your code.</p> <p>You can't just find a pattern and copy it into your problem, as the way you can with off-the-shelf functions or libraries. The pattern is not a specific piece of code, but a general concept for solving a particular problem. You can follow the pattern details and implement a solution that suits the realities of your own problem.</p>"},{"location":"Coding/System-Design/design_patterns/#benefits","title":"Benefits","text":"<p>Why should we spend time learning design patterns?</p> <ul> <li>Design patterns are a toolkit of <code>tried and tested solutions</code> to common problems in software design. Even if you never encounter those problems, knowing patterns is still useful because it teaches you how to solve all sorts of problems using principles of object-oriented design.</li> <li>Design patterns define a common language that you and your teammates can use to communicate more efficiently. You can say \"just use a Singleton for that\", and everyone will understand the idea behind your suggestion. No need to explain what a singleton is if you know the pattern and its name.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#classification-of-patterns","title":"Classification of Patterns","text":"<p>Design patterns differ by their complexity, level of detail and scale of applicability to the entire system being designed. </p> <p>The most basic and low-level patterns are often called <code>idioms</code>. They usually apply only to a single programming language.</p> <p>The most universal and high-level patterns are architectural patterns. Developers can implement these patterns in virtually any language. Unlike other patterns, they can be used to design the architecture of an entire application.</p> <p>In addition, all patterns can be categorized by their <code>intent</code>, we cover three main groups of patterns:</p> <ul> <li><code>Creational patterns</code>, provide object creation mechanisms that increase flexibility and reuse of existing code.</li> <li><code>Structural patterns</code>, explain how to assemble objects and classes into large structures, while keeping the structures flexible and efficient.</li> <li><code>Behavioral patterns</code>, take care of effective communication and the assignment of responsibilities between objects.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#creational-pattern","title":"Creational Pattern","text":"<p>Creational patterns provide various object creation mechanisms, which increase flexibility and reuse of existing code.</p>"},{"location":"Coding/System-Design/design_patterns/#factory-method","title":"Factory Method","text":"<p><code>Factory Method</code> is a creational design pattern that provides an interface for creating objects in a superclass, but allows subclass to alter the type of objects that will be created.</p>"},{"location":"Coding/System-Design/design_patterns/#structure","title":"Structure","text":"<ul> <li>The <code>Product</code> declares the interface, which is common to all objects that can be produced by the creator and its subclasses.</li> <li><code>Concrete Products</code> are different implementations of the product interface.</li> <li>The <code>Creator</code> class declares the factory method that returns new product objects. It\u2019s important that the return type of this method matches the product interface. You can declare the factory method as abstract to force all subclasses to implement their own versions of the method. As an alternative, the base factory method can return some default product type. Note, despite its name, product creation is not the primary responsibility of the creator. Usually, the creator class already has some core business logic related to products. The factory method helps to decouple this logic from the concrete product classes. Here is an analogy: a large software development company can have a training department for programmers. However, the primary function of the company as a whole is still writing code, not producing programmers.</li> <li><code>Concrete Creators</code> override the base factory method so it returns a different type of product. Note that the factory method doesn\u2019t have to create new instances all the time. It can also return existing objects from a cache, an object pool, or another source.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage","title":"Advantage","text":"<ul> <li>You avoid tight coupling between the creator and the concrete products.</li> <li><code>Single Responsiblity Principle</code>. You can move the product creation code into one place in the program, making the code easier to support.</li> <li><code>Open/Close Principle</code>. You can introduce new types of products into the program without breaking existing client code.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage","title":"Disadvantage","text":"<ul> <li>The code may become more complicated since you need to introduce a lot of new subclasses to implement the pattern. The best case scenario is when you're introducing the pattern into an existing hierarchy of creator classes.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#abstract-factory","title":"Abstract Factory","text":"<p>Abstract Factory is a creational design pattern that lets you produce families of related objects without specifying their concrete classes.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_1","title":"Structure","text":"<ul> <li><code>Abstract Products</code> declare interfaces for a set of distinct but related products which make up a product family.</li> <li><code>Concrete Products</code> are various implementations of abstract products, grouped by variants. Each abstract product (chair/sofa) must be implemented in all given variants (Victorian/Modern).</li> <li>The <code>Abstract Factory</code> interface declares a set of methods for creating each of the abstract products.</li> <li><code>Concrete Factories</code> implement creation methods of the abstract factory. Each concrete factory corresponds to a specific variant of products and creates only those product variants.</li> <li>Although concrete factories instantiate concrete products, signatures of their creation methods must return corresponding abstract products. This way the client code that uses a factory doesn\u2019t get coupled to the specific variant of the product it gets from a factory. The Client can work with any concrete factory/product variant, as long as it communicates with their objects via abstract interfaces.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_1","title":"Advantage","text":"<ul> <li>You can be sure that the products you're getting from a factory are compatible with each other.</li> <li>You avoid tight coupling between the creator and the concrete products.</li> <li><code>Single Responsiblity Principle</code>. You can move the product creation code into one place in the program, making the code easier to support.</li> <li><code>Open/Close Principle</code>. You can introduce new types of products into the program without breaking existing client code.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_1","title":"Disadvantage","text":"<ul> <li>The code may become more complicated since you need to introduce a lot of new subclasses to implement the pattern. The best case scenario is when you're introducing the pattern into an existing hierarchy of creator classes.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#builder","title":"Builder","text":"<p>Builder is a creational design pattern that lets you construct complex objects step by step. The pattern allows you to produce different types and representations of an object using the same construction.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_2","title":"Structure","text":"<ul> <li>The <code>Builder</code> interface declares product construction steps that are common to all types of builders.</li> <li><code>Concrete Builders</code> provide different implementations of the construction steps. Concrete builders may produce products that don\u2019t follow the common interface.</li> <li><code>Products</code> are resulting objects. Products constructed by different builders don\u2019t have to belong to the same class hierarchy or interface.</li> <li>The <code>Director</code> class defines the order in which to call construction steps, so you can create and reuse specific configurations of products.</li> <li>The <code>Client</code> must associate one of the builder objects with the director. Usually, it\u2019s done just once, via parameters of the director\u2019s constructor. Then the director uses that builder object for all further construction. However, there\u2019s an alternative approach for when the client passes the builder object to the production method of the director. In this case, you can use a different builder each time you produce something with the director.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_2","title":"Advantage","text":"<ul> <li>You can construct objects step-by-step, defer construction steps or run steps recursively.</li> <li>You can reuse the same construction code when building various representations of products.</li> <li><code>Single Responsibility Principle</code>. You can isolate complex construction code from the business logic of the product.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_2","title":"Disadvantage","text":"<ul> <li>The overall complexity of the code increases since the pattern requires creating multiple new classes.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#prototype","title":"Prototype","text":"<p>Prototype is a creational design pattern that lets you copy existing objects without making your code dependent on their classes.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_3","title":"Structure","text":"<ul> <li>The <code>Prototype</code> interface declares the cloning methods. In most cases, it\u2019s a single <code>clone</code> method.</li> <li>The <code>Concrete Prototype</code> class implements the cloning method. In addition to copying the original object\u2019s data to the clone, this method may also handle some edge cases of the cloning process related to cloning linked objects, untangling recursive dependencies, etc.</li> <li>The <code>Client</code> can produce a copy of any object that follows the prototype interface.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_3","title":"Advantage","text":"<ul> <li>You can clone objects without coupling to their concrete classes.</li> <li>You can get rid of repeated initialization code in favor of cloning pre-built prototypes.</li> <li>You can produce complex objects more conveniently.</li> <li>You get an alternative to inheritance when dealing with configuration presets for complex objects.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_3","title":"Disadvantage","text":"<ul> <li>Cloning complex objects that have circular references might be very tricky.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#singleton","title":"Singleton","text":"<p>Signleton is a creational design pattern that lets you ensure a class has only one instance, while providing a global access point to this instance.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_4","title":"Structure","text":"<ul> <li>The <code>Singleton</code> class declares the static method <code>getInstance</code> that returns the same instance of its own class. The Singleton's constructor should be hidden from the client code. Calling the <code>getInstance</code> method should be the only way of getting the Singleton object.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_4","title":"Advantage","text":"<ul> <li>You can be sure that a class has only a single instance.</li> <li>You gain a global access point to that instance.</li> <li>The singleton object is initialized only when it's requested for the first time.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_4","title":"Disadvantage","text":"<ul> <li>Violates the <code>Single Responsibility Principle</code>. The pattern solves two problems at the time.</li> <li>The Singleton pattern can mask bad design, for instance, when components of the program know too much about each other.</li> <li>The pattern requires special treatment in a multithreaded environment so that multiple threads won't create a singleton object several times.</li> <li>It may be difficult to unit test the client code of the Singleton because many test frameworks rely on inheritance when producing mock objects. Since the constructor of the singleton class is private and override static methods is impossible in most languages, you will need to think of a creative way to mock the singleton. Or just don't write the tests. Or don't use the Singleton pattern.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#structural-pattern","title":"Structural Pattern","text":"<p>Structural patterns explain how to assemble objects and classes into larger structures while keeping these structures flexible and efficient.</p>"},{"location":"Coding/System-Design/design_patterns/#adapter","title":"Adapter","text":"<p>Adapter allows objects with incompatible interfaces to collaborate.</p>"},{"location":"Coding/System-Design/design_patterns/#strucure","title":"Strucure","text":"<ul> <li>The <code>Client</code> is a class that contains the existing business logic of the program.</li> <li>The <code>Client Interface</code> describes a protocol that other classes must follow to be able to collaborate with the client code.</li> <li>The <code>Service</code> is some useful class (usually 3<sup>rd</sup>-party or legacy). The client can\u2019t use this class directly because it has an incompatible interface.</li> <li>The <code>Adapter</code> is a class that's able to work with both the client and the service: it implements the client interface, while wrapping the service object. The adapter receives calls from the client via the adapter interface and translates them into calls to the wrapped service object in a format it can understand.</li> <li>The client code doesn\u2019t get coupled to the concrete adapter class as long as it works with the adapter via the client interface. Thanks to this, you can introduce new types of adapters into the program without breaking the existing client code. This can be useful when the interface of the service class gets changed or replaced: you can just create a new adapter class without changing the client code.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_5","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_5","title":"Disadvantage","text":"<ul> <li>The overall complexity of the code increases becuase you need to introduce a set of new interfaces and classes. Sometimes it's simpler just to change the service class so that it matches the rest of your code.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#bridge","title":"Bridge","text":"<p>Bridge lets you split a large class or a set of closely related classes into two separate hierarchies: abstraction and implementation, which can be developed independently of each other.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_5","title":"Structure","text":"<ul> <li>The <code>Abstraction</code> provides high-level control logic. It relies on the implementation object to do the actual low-level work.</li> <li>The <code>Implementation</code> declares the interface that\u2019s common for all concrete implementations. An abstraction can only communicate with an implementation object via methods that are declared here. The abstraction may list the same methods as the implementation, but usually the abstraction declares some complex behaviors that rely on a wide variety of primitive operations declared by the implementation.</li> <li><code>Concrete Implementations</code> contain platform-specific code.</li> <li><code>Refined Abstractions</code> provide variants of control logic. Like their parent, they work with different implementations via the general implementation interface.</li> <li>Usually, the <code>Client</code> is only interested in working with the abstraction. However, it\u2019s the client\u2019s job to link the abstraction object with one of the implementation objects.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_6","title":"Advantage","text":"<ul> <li>You can create platform-independent classes and apps.</li> <li>The client code works with high-level abstractions. It isn't exposed to the platform details.</li> <li><code>Open/Close Principle</code>.</li> <li><code>Single Responsibility Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_6","title":"Disadvantage","text":"<ul> <li>You might make the code more complicated by applying the pattern to a highly cohesive class.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#composite","title":"Composite","text":"<p>Composite lets you compose objects into tree structures and then work with these structures as if they were individual objects.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_6","title":"Structure","text":"<ul> <li>The <code>Component</code> interface describes operations that are common to both simple and complex elements of the tree.</li> <li>The <code>Leaf</code> is a basic element of a tree that doesn\u2019t have sub-elements. Usually, leaf components end up doing most of the real work, since they don\u2019t have anyone to delegate the work to.</li> <li>The <code>Container</code> (aka composite) is an element that has sub-elements: leaves or other containers. A container doesn\u2019t know the concrete classes of its children. It works with all sub-elements only via the component interface. Upon receiving a request, a container delegates the work to its sub-elements, processes intermediate results and then returns the final result to the client.</li> <li>The <code>Client</code> works with all elements through the component interface. As a result, the client can work in the same way with both simple or complex elements of the tree.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_7","title":"Advantage","text":"<ul> <li>You can work with complex tree structures more conveniently: use polymorphism and recursion to your advantage.</li> <li><code>Open/Close Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_7","title":"Disadvantage","text":"<ul> <li>It might be difficult to provide a common interface for classes whose functionality differs too much. In certain scenarios, you'd need to overgeneralize the component interface, making it harder to comprehend.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#decratorwrapper","title":"Decrator(Wrapper)","text":"<p>Decorator lets you attach new behaviors to objects by placing these objects inside special wrapper objects that contain the behavior.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_7","title":"Structure","text":"<ul> <li>The <code>Component</code> declares the common interface for both wrappers and wrapped objects.</li> <li><code>Concrete Component</code> is a class of objects being wrapped. It defines the basic behavior, which can be altered by decorators.</li> <li>The <code>Base Decorator</code> class has a field for referencing a wrapped object. The field\u2019s type should be declared as the component interface so it can contain both concrete components and decorators. The base decorator delegates all operations to the wrapped object.</li> <li><code>Concrete Decorators</code> define extra behaviors that can be added to components dynamically. Concrete decorators override methods of the base decorator and execute their behavior either before or after calling the parent method.</li> <li>The <code>Client</code> can wrap components in multiple layers of decorators, as long as it works with all objects via the component interface.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_8","title":"Advantage","text":"<ul> <li>You can extand an object's behavior without making a new subclass.</li> <li>You can add or remove resonsibilities from an object at runtime.</li> <li>You can combine several behaviors by wrapping an object into multiple decorates.</li> <li><code>Single Responsibility Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_8","title":"Disadvantage","text":"<ul> <li>It's hard to remove a specific wrapper from the wrapper stack.</li> <li>It's hard to implement a decorator in such a way that its behavior doesn't depend on the order in the decorators stack.</li> <li>The initial configuration code of layers might look pretty ugly.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#facade","title":"Facade","text":"<p>Facade provides a simplified interface to a library, a framework, or any other complex set of classes.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_8","title":"Structure","text":"<ul> <li>The <code>Facade</code> provides convenient access to a particular part of the subsystem\u2019s functionality. It knows where to direct the client\u2019s request and how to operate all the moving parts. </li> <li>An <code>Additional Facade</code> class can be created to prevent polluting a single facade with unrelated features that might make it yet another complex structure. Additional facades can be used by both clients and other facades.</li> <li>The <code>Complex Subsystem</code> consists of dozens of various objects. To make them all do something meaningful, you have to dive deep into the subsystem\u2019s implementation details, such as initializing objects in the correct order and supplying them with data in the proper format. Subsystem classes aren\u2019t aware of the facade\u2019s existence. They operate within the system and work with each other directly.</li> <li>The <code>Client</code> uses the facade instead of calling the subsystem objects directly.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_9","title":"Advantage","text":"<ul> <li>You can isolate your code from the complexity of a subsystem.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_9","title":"Disadvantage","text":"<ul> <li>A facade can become a god object coupled to all classes of an app.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#flyweight","title":"Flyweight","text":"<p>Flyweight lets you fit more objects into the available amount of RAM by sharing common parts of state between multiple objects instead of keeping all of the data in each objects.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_9","title":"Structure","text":"<ul> <li>The Flyweight pattern is merely an optimization. Before applying it, make sure your program does have the RAM consumption problem related to having a massive number of similar objects in memory at the same time. Make sure that this problem can\u2019t be solved in any other meaningful way.</li> <li>The <code>Flyweight</code> class contains the portion of the original object\u2019s state that can be shared between multiple objects. The same flyweight object can be used in many different contexts. The state stored inside a flyweight is called intrinsic. The state passed to the flyweight\u2019s methods is called extrinsic.</li> <li>The <code>Context class</code> contains the extrinsic state, unique across all original objects. When a context is paired with one of the flyweight objects, it represents the full state of the original object.</li> <li>Usually, the behavior of the original object remains in the flyweight class. In this case, whoever calls a flyweight\u2019s method must also pass appropriate bits of the extrinsic state into the method\u2019s parameters. On the other hand, the behavior can be moved to the context class, which would use the linked flyweight merely as a data object.</li> <li>The <code>Client</code> calculates or stores the extrinsic state of flyweights. From the client\u2019s perspective, a flyweight is a template object which can be configured at runtime by passing some contextual data into parameters of its methods.</li> <li>The <code>Flyweight Factory</code> manages a pool of existing flyweights. With the factory, clients don\u2019t create flyweights directly. Instead, they call the factory, passing it bits of the intrinsic state of the desired flyweight. The factory looks over previously created flyweights and either returns an existing one that matches search criteria or creates a new one if nothing is found.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_10","title":"Advantage","text":"<ul> <li>You can save lots of RAM, assuming your program has tons of similar objects.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_10","title":"Disadvantage","text":"<ul> <li>You might be trading RAM over CPU cycles when some of the context data needs to be recalculated each time somebody calls a flyweight method.</li> <li>The code becomes more complicated. New team members will always be wondering why the state of an entity was separated in such a way.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#proxy","title":"Proxy","text":"<p>Proxy lets you provide a substitute or placeholder for another object. A proxy controls access to the original object, allowing you to perform something either before or after the request gets through to the original object.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_10","title":"Structure","text":"<ul> <li>The <code>Service Interface</code> declares the interface of the Service. The proxy must follow this interface to be able to disguise itself as a service object.</li> <li>The <code>Service</code> is a class that provides some useful business logic.</li> <li>The <code>Proxy</code> class has a reference field that points to a service object. After the proxy finishes its processing (e.g., lazy initialization, logging, access control, caching, etc.), it passes the request to the service object. Usually, proxies manage the full lifecycle of their service objects.</li> <li>The <code>Client</code> should work with both services and proxies via the same interface. This way you can pass a proxy into any code that expects a service object.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_11","title":"Advantage","text":"<ul> <li>You can control the service object without clients knowing about it.</li> <li>You can manage the lifecycle of the service object when clients don't care about it.</li> <li>The proxy works even if the service object isn't ready or is not available.</li> <li><code>Open/Close Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_11","title":"Disadvantage","text":"<ul> <li>The code may become more complicated since you need to introduce a lot of new classes.</li> <li>The response from the service might get delayed.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#behavioral-pattern","title":"Behavioral Pattern","text":""},{"location":"Coding/System-Design/design_patterns/#chain-of-responsibility","title":"Chain of Responsibility","text":"<p>Chain of Responsibility is a behavioral design pattern that lets you pass requests along a chain of handlers. Upon receiving a request, each handler decides either to process the request or to pass it to the next handler in the chain.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_11","title":"Structure","text":"<ul> <li>The <code>Handler</code> declares the interface, common for all concrete handlers. It usually contains just a single method for handling requests, but sometimes it may also have another method for setting the next handler on the chain.</li> <li>The <code>Base Handler</code> is an optional class where you can put the boilerplate code that\u2019s common to all handler classes. Usually, this class defines a field for storing a reference to the next handler. The clients can build a chain by passing a handler to the constructor or setter of the previous handler. The class may also implement the default handling behavior: it can pass execution to the next handler after checking for its existence.</li> <li><code>Concrete Handlers</code> contain the actual code for processing requests. Upon receiving a request, each handler must decide whether to process it and, additionally, whether to pass it along the chain. Handlers are usually self-contained and immutable, accepting all necessary data just once via the constructor.</li> <li>The <code>Client</code> may compose chains just once or compose them dynamically, depending on the application\u2019s logic. Note that a request can be sent to any handler in the chain\u2014it doesn\u2019t have to be the first one.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_12","title":"Advantage","text":"<ul> <li>You can control the order of request handling.</li> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_12","title":"Disadvantage","text":"<ul> <li>Some requets may end up unhandled.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#command","title":"Command","text":"<p>Command turns a request into a stand-alone object that contains all information about the request. This transformation lets you parameterize methods with different requests. This transformation lets you parameterize methods with different requests, delay or queue a request's execution, and support undoable operation.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_12","title":"Structure","text":"<ul> <li>The <code>Sender</code> class (aka invoker) is responsible for initiating requests. This class must have a field for storing a reference to a command object. The sender triggers that command instead of sending the request directly to the receiver. Note that the sender isn\u2019t responsible for creating the command object. Usually, it gets a pre-created command from the client via the constructor.</li> <li>The <code>Command</code> interface usually declares just a single method for executing the command.</li> <li><code>Concrete Commands</code> implement various kinds of requests. A concrete command isn\u2019t supposed to perform the work on its own, but rather to pass the call to one of the business logic objects. However, for the sake of simplifying the code, these classes can be merged. Parameters required to execute a method on a receiving object can be declared as fields in the concrete command. You can make command objects immutable by only allowing the initialization of these fields via the constructor.</li> <li>The <code>Receiver</code> class contains some business logic. Almost any object may act as a receiver. Most commands only handle the details of how a request is passed to the receiver, while the receiver itself does the actual work.</li> <li>The <code>Client</code> creates and configures concrete command objects. The client must pass all of the request parameters, including a receiver instance, into the command\u2019s constructor. After that, the resulting command may be associated with one or multiple senders.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_13","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> <li>You can implement undo/redo.</li> <li>You can implement deferred execution of operation.</li> <li>You can assemble a set of simple commands into a complex one.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_13","title":"Disadvantage","text":"<ul> <li>The code may become more complicated since you're introducing a whole new layer between senders and receivers.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#iterator","title":"Iterator","text":"<p>Iterator lets you traverse elements of a collection without exposing its underlying representation(list, stack, tree, etc.).</p>"},{"location":"Coding/System-Design/design_patterns/#structure_13","title":"Structure","text":"<ul> <li>The <code>Iterator</code> interface declares the operations required for traversing a collection: fetching the next element, retrieving the current position, restarting iteration, etc.</li> <li><code>Concrete Iterators</code> implement specific algorithms for traversing a collection. The iterator object should track the traversal progress on its own. This allows several iterators to traverse the same collection independently of each other.</li> <li>The <code>Collection</code> interface declares one or multiple methods for getting iterators compatible with the collection. Note that the return type of the methods must be declared as the iterator interface so that the concrete collections can return various kinds of iterators.</li> <li><code>Concrete Collections</code> return new instances of a particular concrete iterator class each time the client requests one. You might be wondering, where\u2019s the rest of the collection\u2019s code? Don\u2019t worry, it should be in the same class. It\u2019s just that these details aren\u2019t crucial to the actual pattern, so we\u2019re omitting them.</li> <li>The <code>Client</code> works with both collections and iterators via their interfaces. This way the client isn\u2019t coupled to concrete classes, allowing you to use various collections and iterators with the same client code. Typically, clients don\u2019t create iterators on their own, but instead get them from collections. Yet, in certain cases, the client can create one directly; for example, when the client defines its own special iterator.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_14","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> <li>You can iterate over the same collection in parallel because each iterator object contains its own iteration state.</li> <li>For the same reason, you can delay an iteration and continue it when needed.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_14","title":"Disadvantage","text":"<ul> <li>Applying the pattern can be overkill if your app only works with simple collections.</li> <li>Using an iterator may be less efficient than going through elements of some specialized collections directly.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#mediator","title":"Mediator","text":"<p>Mediator lets you reduce chaotic dependencies between objects. The pattern restricts direct communications between the objects and forces them to collaborate only via a mediator object.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_14","title":"Structure","text":"<ul> <li><code>Components</code> are various classes that contain some business logic. Each component has a reference to a mediator, declared with the type of the mediator interface. The component isn\u2019t aware of the actual class of the mediator, so you can reuse the component in other programs by linking it to a different mediator.</li> <li>The <code>Mediator</code> interface declares methods of communication with components, which usually include just a single notification method. Components may pass any context as arguments of this method, including their own objects, but only in such a way that no coupling occurs between a receiving component and the sender\u2019s class.</li> <li><code>Concrete Mediators</code> encapsulate relations between various components. Concrete mediators often keep references to all components they manage and sometimes even manage their lifecycle.</li> <li><code>Components</code> must not be aware of other components. If something important happens within or to a component, it must only notify the mediator. When the mediator receives the notification, it can easily identify the sender, which might be just enough to decide what component should be triggered in return. From a component\u2019s perspective, it all looks like a total black box. The sender doesn\u2019t know who\u2019ll end up handling its request, and the receiver doesn\u2019t know who sent the request in the first place.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_15","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> <li>You can reduce coupling between various components of a program.</li> <li>You can reuse individual components more easily.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_15","title":"Disadvantage","text":"<ul> <li>Over time a mediator can evolve into a <code>God Object</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#memento","title":"Memento","text":"<p>Memento lets you save and restore the previous state of an object without revealing the detail of its implementation.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_15","title":"Structure","text":"<ul> <li>The <code>Originator</code> class can produce snapshots of its own state, as well as restore its state from snapshots when needed.</li> <li>The <code>Memento</code> is a value object that acts as a snapshot of the originator\u2019s state. It\u2019s a common practice to make the memento immutable and pass it the data only once, via the constructor.</li> <li>The <code>Caretaker</code> knows not only \u201cwhen\u201d and \u201cwhy\u201d to capture the originator\u2019s state, but also when the state should be restored. A caretaker can keep track of the originator\u2019s history by storing a stack of mementos. When the originator has to travel back in history, the caretaker fetches the topmost memento from the stack and passes it to the originator\u2019s restoration method.</li> <li>In this implementation, the memento class is nested inside the originator. This lets the originator access the fields and methods of the memento, even though they\u2019re declared private. On the other hand, the caretaker has very limited access to the memento\u2019s fields and methods, which lets it store mementos in a stack but not tamper with their state.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_16","title":"Advantage","text":"<ul> <li>You can reduce snapshots of the object's state without violating its encapsulation.</li> <li>You can simplify the originator's code by letting the caretaker maintain the history of the originator's state.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_16","title":"Disadvantage","text":"<ul> <li>The app might consume lots of RAM if clients create mementos too often.</li> <li>Catetaker's should track the originator's lifecycle to be able to destroy obsolete mementos.</li> <li>Most dynamic programming languages, such as PHP, Python, and JavaScript, can't guarantee that the state within the memento stays untouched.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#observer","title":"Observer","text":"<p>Observer lets you define a subscription mechanism to notify multiple objects about any events that happen to the object they're observing. </p>"},{"location":"Coding/System-Design/design_patterns/#structure_16","title":"Structure","text":"<ul> <li>The <code>Publisher</code> issues events of interest to other objects. These events occur when the publisher changes its state or executes some behaviors. Publishers contain a subscription infrastructure that lets new subscribers join and current subscribers leave the list.</li> <li>When a new event happens, the publisher goes over the subscription list and calls the notification method declared in the subscriber interface on each subscriber object.</li> <li>The <code>Subscriber</code> interface declares the notification interface. In most cases, it consists of a single <code>update</code> method. The method may have several parameters that let the publisher pass some event details along with the update.</li> <li><code>Concrete Subscribers</code> perform some actions in response to notifications issued by the publisher. All of these classes must implement the same interface so the publisher isn\u2019t coupled to concrete classes.</li> <li>Usually, subscribers need some contextual information to handle the update correctly. For this reason, publishers often pass some context data as arguments of the notification method. The publisher can pass itself as an argument, letting subscriber fetch any required data directly.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_17","title":"Advantage","text":"<ul> <li><code>Open/Close Principle</code>.</li> <li>You can establish relations between objects at run time.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_17","title":"Disadvantage","text":"<ul> <li>Subscribers are notified in random order.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#state","title":"State","text":"<p>State lets an object alter its behavior when its internal state changes. It appears as if the object changed its class.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_17","title":"Structure","text":"<ul> <li><code>Context</code> stores a reference to one of the concrete state objects and delegates to it all state-specific work. The context communicates with the state object via the state interface. The context exposes a setter for passing it a new state object.</li> <li>The <code>State</code> interface declares the state-specific methods. These methods should make sense for all concrete states because you don\u2019t want some of your states to have useless methods that will never be called.</li> <li><code>Concrete States</code> provide their own implementations for the state-specific methods. To avoid duplication of similar code across multiple states, you may provide intermediate abstract classes that encapsulate some common behavior. State objects may store a backreference to the context object. Through this reference, the state can fetch any required info from the context object, as well as initiate state transitions.</li> <li>Both context and concrete states can set the next state of the context and perform the actual state transition by replacing the state object linked to the context.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_18","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> <li>Simplify the code of the context by eliminating the code of the context by eliminating bulky state machine conditionals.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_18","title":"Disadvantage","text":"<ul> <li>Applying the pattern can be overkill if a state mechine has only a few states or rarely changes.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#strategy","title":"Strategy","text":"<p>Strategy lets you define a family of algorithms, put each of them into a separate class, and make their objects interchangeable.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_18","title":"Structure","text":"<ul> <li>The <code>Context</code> maintains a reference to one of the concrete strategies and communicates with this object only via the strategy interface.</li> <li>The <code>Strategy</code> interface is common to all concrete strategies. It declares a method the context uses to execute a strategy.</li> <li><code>Concrete Strategies</code> implement different variations of an algorithm the context uses.</li> <li>The context calls the execution method on the linked strategy object each time it needs to run the algorithm. The context doesn\u2019t know what type of strategy it works with or how the algorithm is executed.</li> <li>The <code>Client</code> creates a specific strategy object and passes it to the context. The context exposes a setter which lets clients replace the strategy associated with the context at runtime.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_19","title":"Advantage","text":"<ul> <li>You can swap algorithms used inside an object at runtime.</li> <li>You can isolate the implementation details of an algorithm from the code that uses it.</li> <li>You can replace inheritance with composition.</li> <li><code>Open/Close Principle</code>.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_19","title":"Disadvantage","text":"<ul> <li>If you only have a couple of algorithms and they rarely change, there's no real reason to overcomplicate the program with new classes and interfaces that come along with the pattern.</li> <li>Clients must be aware of the differences between strategies to be able to select a proper one.</li> <li>A lot of modern programming languages have functional type support that lets you implement different versions of an algorithm inside a set of anonymous functions. Then you could use these functions exactly as you'd have used the strategy objects, but without bloating your code with extra classes and interfaces.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#template-method","title":"Template Method","text":"<p>Template Method defines the skeleton of an algorithm in the superclass but lets subclasses override specific steps of the algorithm without changing its structure.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_19","title":"Structure","text":"<ul> <li>The <code>Abstract Class</code> declares methods that act as steps of an algorithm, as well as the actual template method which calls these methods in a specific order. The steps may either be declared <code>abstract</code> or have some default implementation.</li> <li><code>Concrete Classes</code> can override all of the steps, but not the template method itself.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_20","title":"Advantage","text":"<ul> <li>You can let clients override only certain parts of a large algorithm, making them less affected by changes that happen to other parts of the algorithm.</li> <li>You can pull the duplicate code into a superclass.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_20","title":"Disadvantage","text":"<ul> <li>Some clients may be limited by the provided skeleton of an algorithm.</li> <li>You might violate the <code>Liskov Substitution Principle</code> by supperessing a default step implementation via a super calss.</li> <li>Template methods tend to be harder to maintain the more steps they have.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#visitor","title":"Visitor","text":"<p>Visitor lets you separate algorithms from the objects on which they operate.</p>"},{"location":"Coding/System-Design/design_patterns/#structure_20","title":"Structure","text":"<ul> <li>The <code>Visitor</code> interface declares a set of visiting methods that can take concrete elements of an object structure as arguments. These methods may have the same names if the program is written in a language that supports overloading, but the type of their parameters must be different.</li> <li>Each <code>Concrete Visitor</code> implements several versions of the same behaviors, tailored for different concrete element classes.</li> <li>The <code>Element</code> interface declares a method for \u201caccepting\u201d visitors. This method should have one parameter declared with the type of the visitor interface.</li> <li>Each <code>Concrete Element</code> must implement the acceptance method. The purpose of this method is to redirect the call to the proper visitor\u2019s method corresponding to the current element class. Be aware that even if a base element class implements this method, all subclasses must still override this method in their own classes and call the appropriate method on the visitor object.</li> <li>The <code>Client</code> usually represents a collection or some other complex object (for example, a Composite tree). Usually, clients aren\u2019t aware of all the concrete element classes because they work with objects from that collection via some abstract interface.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#advantage_21","title":"Advantage","text":"<ul> <li><code>Single Responsibility Principle</code>.</li> <li><code>Open/Close Principle</code>.</li> <li>A visitor object can accumulate some useful information while working with various objects. This might be hady when you want to traverse some complex object structure, such as an object tree, and apply the visitor to each object of this structure.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#disadvantage_21","title":"Disadvantage","text":"<ul> <li>You need to update all visitors each time a class gets added or removed from the element hierarchy.</li> <li>Visitors might lack the necessary access to the private fields and methods of the elements that they're supposed to work with.</li> </ul>"},{"location":"Coding/System-Design/design_patterns/#reference","title":"Reference","text":"<ul> <li>Design Patterns</li> </ul>"},{"location":"Coding/System-Design/oop10/","title":"The 10 Object-Oriented-Principles(OOP)","text":"<p>The Object-Oriented Design Principles are the core of OOP programming, and we programmer should pay more attention to them. It's important to learn the basics of Object-Oriented Programming like <code>Abstraction</code>, <code>Encapsulation</code>, <code>Polymorphism</code> and <code>Inheritance</code>, and meanwhile, it's equally important to know object-oriented design principles.</p>"},{"location":"Coding/System-Design/oop10/#1-dont-repeat-yourselfdry","title":"1. Don't Repeat Yourself(DRY)","text":"<p>This means don't write duplicated code, you can use <code>abstraction</code> to abstract common things in one place. If you have a block of code in more than two places, make it a separate method; if you use a hard-coded value more than one time, make them <code>public constant</code>. The benefit of this principle is in maintenance.</p> <p>It's important not to abuse it, duplication is not for code, but for functionality.</p> <p>Just don't combine any code that looks alike but not related.</p>"},{"location":"Coding/System-Design/oop10/#2-encapsulate-what-changes","title":"2. Encapsulate What Changes","text":"<p>There is only one thing which is constant in software field and that is \"Change\". So encapsulate the code you expect or suspect to be changed in the future.</p> <p>The benefit of this principle is that it's easy to test and maintain proper encapsulated code.</p> <p>The <code>Factory Design Pattern</code> is one example of this principle which encapsulates object creation code and provides flexibility to introduce a new product later with no impact on existing code.</p>"},{"location":"Coding/System-Design/oop10/#3-open-close-principleocp","title":"3. Open Close Principle(OCP)","text":"<p>Classes, methods or functions should be <code>open</code> for extension(new functionality) and <code>close</code> for modification. This prevents someone from changing already tried and tested code.</p> <p>The benefit of this principle is that tested code will not be touched so that they won't break.</p> <p>If you just add a new function, your code should be tested and not affect the existing code, that's the goal of this principle.</p>"},{"location":"Coding/System-Design/oop10/#4-single-responsibilty-principlesrp","title":"4. Single Responsibilty Principle(SRP)","text":"<p>As for this pinciple, there should not be more than one reason for a class to change, or a class should always handle single functionality.</p> <p>The benefit is that it reduces coupling between the individual component of the software and code.</p> <p>For example, if you put more than one functionality in one class, this will introduce coupling between two functionality. And enven if you change one functionality there is a chance you broke coupled functionality, which requires another round of testing to avoid any surprise on the production environment.</p>"},{"location":"Coding/System-Design/oop10/#5-dependency-injection-or-inversion-principle","title":"5. Dependency Injection or Inversion Principle","text":"<p>The beauty of this design principle is that any class which is injected by framework is easy to test with the mock object ans easier to maintain because object creation code is centralized in the framework and client code is not littered with that.</p>"},{"location":"Coding/System-Design/oop10/#6-favor-composition-over-inheritance","title":"6. Favor Composition over Inheritance","text":"<p>There are two general ways to reuse the code you have already written: <code>inheritance</code> and <code>composition</code>, both have their own advantage and disadvantage. But, in general, you should always favor composition over inheritance, if possible.</p> <p>Composition is the lot more flexible than inheritance.</p> <p>Composition alllows changing the behavior of a class at run-time by setting property during run-time and by using <code>interface</code> to compose a class we use <code>polymorphism</code> which provides flexibility to replace with better implementation any time.</p>"},{"location":"Coding/System-Design/oop10/#7-liskov-substitution-principlelsp","title":"7. Liskov Substitution Principle(LSP)","text":"<p>Subtypes must be substitutable for supertype, so that methods or functions which use superclass can work with the object of subclass without any issue.</p> <p>If a class has more functionality than subcalss, subclass might not support some of the functionality, this does violate LSP.</p> <p>In order to follow LSP, derived class or subclass must enhance functionality, but not reduce them.</p>"},{"location":"Coding/System-Design/oop10/#8-interface-segregation-principleisp","title":"8. Interface Segregation Principle(ISP)","text":"<p>A client should not implement an interface if it doesn't use that. This happens mostly when one interface contains more than one functionality, and the client only need one functionality.</p> <p>The benefit is, single functionality means less method to implement</p>"},{"location":"Coding/System-Design/oop10/#9-programming-for-interface-not-implementation","title":"9. Programming for Interface not Implementation","text":"<p>A programmer should always program for the <code>interface</code> and not for <code>implementation</code>, this will lead to flexible code which can work with any new implementation of the interface.</p>"},{"location":"Coding/System-Design/oop10/#10-delegation-principle","title":"10. Delegation Principle","text":"<p>Don't do all stuff by yourself, delegate it to the respective class.</p> <p>The key benefit of this principle is no duplication of code and pretty easy to modify behavior.</p>"},{"location":"Deep-Learning/00_mechine_learning/","title":"Mechine Learning","text":""},{"location":"Deep-Learning/00_mechine_learning/#instruction","title":"Instruction","text":""},{"location":"Deep-Learning/00_mechine_learning/#defination","title":"Defination","text":"<p>A Computer program is said to learn from experience <code>E</code> with respect to some task <code>T</code> and some performance measure <code>P</code>, if its performance on <code>T</code>, as measured by <code>P</code>, improves with experience <code>E</code>.</p> <p>There are two common types of Machine Learning: Supervised Learning and Unsupervised Learning.</p>"},{"location":"Deep-Learning/00_mechine_learning/#supervised-learning","title":"Supervised Learning","text":"<p>The term Supervised Learning refers to the fact that we gave the algorithm a data set which we call \"right answer\", and the task of the algorithm was to produce more of these right answers.</p> <p>The problem is called a</p> <ul> <li>regression problem, if the algorithm should predict a continuous valued output;</li> <li>classification problem, if the algirhtm should predict a discrete valued output.</li> </ul> <p>For example, you have a large inventory of identical items and want to predict how many of these items will sell over the next 3 months, this is a regression problem. </p> <p>If you would like to examine individual customer accounts, and for each account decide if it has been hacked/compromised, this is a classification problem.</p>"},{"location":"Deep-Learning/00_mechine_learning/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>Unsupervised Learning allows us to approach problems whith little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.</p> <p>We can derive this structure by clustering the data based on relationships among the variables in the data.</p> <p>With unsupervised learning there is no feedback based on the prediction results.</p> <p>For example,</p> <ul> <li>Clustering: Take a collection of 1000000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles and so on.</li> <li>Non-Clustering: The \"Cocktail Party Problem\", allows you to find structure in a chaotic environment.</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#linear-regression-with-one-variable","title":"Linear Regression with One Variable","text":""},{"location":"Deep-Learning/00_mechine_learning/#model-representation","title":"Model Representation","text":"<p>To establish notation for future use, we use:</p> <ul> <li>\\(x_i\\) to denote the \"input\" variables(also called input features);</li> <li>\\(y_i\\) to denote the \"output\" variables we are trying to predict.</li> </ul> <p>A pair \\((x_i, y_i)\\) is called a training example and a list of training example is called a training set.</p> <p>We also use:</p> <ul> <li>\\(X\\) to denote the space of input values;</li> <li>\\(Y\\) to denote the space of output values;</li> </ul> <p>To describe the supervised learning problem more formally, our goal is, given a training set, to learn a function \\(h: X \\to Y\\) so that \\(h(x)\\) is a \"good\" predictor for the corresponding value of \\(y\\). For history reason, the function \\(h\\) is called a hypothesis. The process is like this: <pre><code>  +----------------+\n  |                |\n  |  Training set  |\n  |                |\n  +-------+--------+\n          |\n          |\n          |\n  +-------v--------+\n  |                |\n  |  Learning      |\n  |  algorithm     |\n  +-------+--------+\n          |\n          |\n          |\n       +--v--+\n       |     |\nx +----&gt;  h  +-----&gt; y\n       |     |\n       +-----+\n</code></pre></p>"},{"location":"Deep-Learning/00_mechine_learning/#cost-function","title":"Cost Function","text":"<p>we can measure the accuracy of our hypothesis function by using a cost function. The most common cost function is \"Squared error function\" or called \"Mean squared error\": $$ J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i = 1}^{m}(\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i = 1}^{m}(h_{\\theta}(x_i) - y_i)^2 $$ The mean is halved \\((\\frac{1}{2})\\) as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the \\(\\frac{1}{2}\\) term.</p> <p>We should try to minimize the cost function to find the best \\(h\\) to predict the output data.</p>"},{"location":"Deep-Learning/00_mechine_learning/#gradient-descent","title":"Gradient Descent","text":"<p>So we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.</p> <p>We put \\(\\theta_0\\) on the \\(x\\) axis and \\(\\theta_1\\) on the \\(y\\) axis, with the cost function on the vertical \\(z\\) axis. The points on our graph will be the result of the cost function using our hypothesis with those specific \\(\\theta\\) parameters. The goal is to find the very bottom point of the graph.</p> <p>The gradient descent algorithm is:</p> \\[ \\theta_j = \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j}J(\\theta_0, \\theta_0) \\] <p>where:</p> <ul> <li>\\(j = 0, 1\\) represents the feature index number.</li> <li>\\(\\alpha\\) is called \"learning rate\" to ensure that the gradient descent algorithm converges in a reasonable time.</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#gradient-descent-for-cost-function","title":"Gradient Descent For Cost Function","text":"<p>We can substitute our cost function and our actual hypothesis function and modify the equation to:</p> \\[ \\theta_{0} := \\theta_{0} - \\alpha\\frac{1}{m}\\sum_{i = 1}^{m}(h_{\\theta}(x_{i}) - y_{i}) \\] \\[ \\theta_{1} := \\theta_{1} - \\alpha\\frac{1}{m}\\sum_{i = 1}^{m}((h_{\\theta}(x_{i}) - y_{i})x_{i}) \\] <p>where:</p> <ul> <li>\\(m\\) is the size of the training set;</li> <li>\\(\\theta_{0}\\) is a constant that will be changing simultaneously with \\(\\theta_{1}\\)</li> <li>\\(x_{i}, y_{i}\\) are values of the given training set.</li> </ul> <p>With the equation, we can repeat calculating \\(\\theta_{0}\\) and \\(\\theta_{1}\\) until convergence.</p> <p>This method looks at every example in the entire training set on every step, and is called <code>batch gradient descent</code>.</p>"},{"location":"Deep-Learning/00_mechine_learning/#linear-regression-with-multiple-variables","title":"Linear Regression with Multiple Variables","text":""},{"location":"Deep-Learning/00_mechine_learning/#multiple-features","title":"Multiple Features","text":"<p>Linear regression with multiple variables is also known as <code>multivariate linear regression</code>.</p> <p>The notation for equations where we can have any number of input variables is as below:</p> <ul> <li>\\(x_{j}^i\\) is the value of feature \\(j\\) in the \\(ith\\) training example;</li> <li>\\(x^{i}\\) is the input (features) of the \\(ith\\) training exmaple;</li> <li>\\(m\\) is the number of training examples;</li> <li>\\(n\\) is the number of features.</li> </ul> <p>The multivariable form of the hepothesis function with multiple features is as follows:</p> \\[ h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\theta_{3}x_{3} + ... + \\theta_{n}x_{n} \\] <p>Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:</p> \\[ h_{\\theta}(x) = \\begin{bmatrix} \\theta_0 \\theta_1 \\cdots \\theta_n \\end{bmatrix} \\begin{bmatrix} x_0 \\\\\\\\ x_1 \\\\\\\\ \\vdots \\\\\\\\ x_n \\end{bmatrix} = \\theta^Tx \\]"},{"location":"Deep-Learning/00_mechine_learning/#gradient-descent-for-multiple-variables","title":"Gradient Descent for Multiple Variables","text":"<p>The gradient descent equation is the same form, we just have to repeat it for our \\(n\\) feature:</p> \\[ \\begin{cases} \\theta_{0} := \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_{\\theta_0}(x^i) - y^i) \\cdot x_0^i \\\\\\\\ \\theta_1 := \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_{\\theta_1}(x^i) - y^i) \\cdot x_1^i \\\\\\\\ \\theta_2 := \\theta_2 - \\alpha\\frac{2}{m}\\sum_{i=2}^m(h_{\\theta_2}(x^i) - y^i) \\cdot x_2^i \\\\\\\\ ... \\end{cases} \\] <p>In other words:</p> \\[ \\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^i) - y^i) \\cdot x_j^i \\] <p>where:</p> <ul> <li>\\(j = 0, 1, ..., n\\)</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#feature-scaling-to-speed-up-gradient-descent","title":"Feature Scaling to Speed up Gradient Descent","text":"<p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because \\(\\theta\\) will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p> <p>The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally:</p> \\[ -1 &lt;= x_i &lt;= 1 \\] <p>or</p> \\[ -0.5 &lt;= x_i &lt;= 0.5 \\] <p>These are not exact requirements, we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.</p> <p>Two techiques to help with this are:</p> <ul> <li>feature scaling: involves diving the input values by the range of the input variable, resulting in a new range of just \\(1\\);</li> <li>mean normalization: involves subtracing the average value for an input variable from the values for that input variable, resulting in a new average value for the input variable of just zero.</li> </ul> <p>To impliment both of these techniques, adjust your input values as shown in this formula:</p> \\[ x_i := \\frac{x_i - \\mu_i}{s_i} \\] <p>where:</p> <ul> <li>\\(\\mu_i\\) is the average of all the values for feature;</li> <li>\\(s_i\\) is the range of values(\\(max - min\\)).  </li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#choosing-correct-learning-rate","title":"Choosing Correct Learning Rate","text":"<p>To debug gradient descent, we can make a plot with number of iterations on the x-axis. Now plot the cost function \\(J(\\theta)\\) over the number of iterations of gradient descent. If \\(J(\\theta)\\) increases, then you probably need to decrease \\(\\alpha\\).</p> <p>The learning rate effects the convergence of the \\(J(\\theta)\\):</p> <ul> <li>\\(\\alpha\\) is too small: slow convegence;</li> <li>\\(\\alpha\\) is too large: may not decrease on every iteration and shus may not converge.</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#improve-features-and-hypothesis","title":"Improve features and hypothesis","text":"<p>We can improve our features and the form of our hypothesis function in a couple different ways.</p>"},{"location":"Deep-Learning/00_mechine_learning/#feature","title":"Feature","text":"<p>We can combine multiple features into one. For example, we can combine \\(x_1\\) and \\(x_2\\) into a new feature \\(x_3\\) by taking \\(x_3 = x_1 * x_2\\).</p>"},{"location":"Deep-Learning/00_mechine_learning/#hypothesis-function","title":"Hypothesis Function","text":"<p>Our hypothesis function need not to be linear (a straight line) if that does not fit the data well. We can change the behavior or curve of our hypothesis function by making it a:</p> <ul> <li>quadratic;</li> <li>cubic;</li> <li>square root</li> </ul> <p>function.</p> <p>One important thing to keep in mind is, if you choose your features this way, the feature scaling becomes very important.</p>"},{"location":"Deep-Learning/00_mechine_learning/#normal-equation-for-multiple-variables","title":"Normal Equation for Multiple Variables","text":"<p>Gradient descent gives one way to solve the minimizing \\(J\\), the <code>normal equation</code> method is another way of doing so. In this way, we will minimizing \\(J\\) by explicitly taking its derivatives with respect to the \\(\\theta_j\\) and set them to \\(0\\). This allows us to find the optimum theta without iteration. The normal equation is given below:</p> \\[ \\theta = (X^TX)^{-1}X^Ty \\] <p>Following is a comparison of gradient descent and the normal equation:</p> Gradient Descent Normal Equation Need to choose \\(\\alpha\\) No need to choose \\(\\alpha\\) Need many iterations No need to iterate Time complexity \\(O(kn^2)\\) Time complexity \\(O(n^3)\\), need to calculate inverse of \\(X^TX\\) Works well when \\(n\\) is large Slow if \\(n\\) is very large <p>With the normal equation, computing the inversion has comlexity \\(O(n^3)\\). So if we have a very large number of features, the normal equation will be slow. In practice, when \\(n\\) exceeds \\(10000\\) it might be a good time to go from normal solution to an iterative process.</p>"},{"location":"Deep-Learning/00_mechine_learning/#noninvertibility","title":"Noninvertibility","text":"<p>The normal equation used \\(X^TX\\) to calculate variables, but \\(X^TX\\) might be \"noninvertible\", the common causes may be:</p> <ul> <li>Redundant features, where two features are very closely related;</li> <li>Too many features(e.g. \\(m &lt;= n\\)), in this case, delete some featues or use \"regularization\".</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#logistic-regression","title":"Logistic Regression","text":"<p>Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.</p> <p>The classification problem is just like the regression problem, except that the values we now want to predict take on only a small number of discrete values. To attempt classification, one method is to use linear regression and map all predictions greater than \\(0.5\\) as \\(1\\) and all less than \\(0.5\\) as \\(0\\). However, this method doesn't work well because classification is not really a linear function.</p>"},{"location":"Deep-Learning/00_mechine_learning/#hypothesis-representation","title":"Hypothesis Representation","text":"<p>We could approach the classification problem ignoring the fact that y is discrete value and use our old linear function to predict y with given x. However, it doesn't make sense for \\(h_{\\theta}(x)\\) to take value larger than \\(1\\) or smaller than \\(0\\) when we know that \\(y \\in {0, 1}\\). To fix this, we plug \\(\\theta^Tx\\) into the <code>Logistic Function</code>.</p> <p><code>Logistic Function</code>(or <code>Sigmoid Function</code>) is defined as:</p> \\[ h_{\\theta}(x) = g(\\theta^Tx) \\] \\[ z = \\theta^Tx \\] \\[ g(z) = \\frac{1}{1 + e^{-z}} \\] <p>more details can be found here. The function \\(g(z)\\) maps any real number to the \\((0, 1)\\) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification.</p> <p>\\(h_{\\theta}(x)\\) will give us the probability that our output is \\(1\\). For example, \\(h_{\\theta}(x) = 0.7\\) gives us the probability of \\(0.7\\) that our output is \\(1\\).</p> \\[ h_{\\theta}(x) = P(y = 1 |x; \\theta) = 1 - P(y = 1 | x ; \\theta) \\] \\[ P(y = 1 |x; \\theta) + 1 - P(y = 1 | x ; \\theta) = 1 \\]"},{"location":"Deep-Learning/00_mechine_learning/#decision-boundary","title":"Decision Boundary","text":"<p>In order to get our discrete \\(0 or 1\\), we can translate the output of the hypothesis function as follows:</p> \\[ h_{\\theta}(x) \\ge 0.5 \\to y = 1 \\] \\[ h_{\\theta}(x) \\le 0.5 \\to y = 0.5 \\] <p>The way our logistic function \\(g\\) behaves when its input is greater than or equal to zero, its output is greater than or equal to \\(0.5\\):</p> \\[ \\begin{array}{lcl} g(z) \\ge 0.5 \\\\\\\\ \\mbox{if } z \\ge 0 \\end{array} \\] <p>So if the input to \\(g\\) is \\(\\theta^TX\\), then that means:</p> \\[ h_{\\theta}(x) = g(\\theta^Tx) \\ge 0.5 \\] <p>when</p> \\[ \\theta^Tx \\ge 0 \\] <p>From these statements we can now say:</p> \\[ \\theta^Tx \\ge 0 \\to y = 1 \\] \\[ \\theta^Tx \\le 0 \\to y = 0 \\] <p>The <code>decision boundary</code> is the line that separates the area where \\(y = 0\\) and where \\(y = 1\\). It is created by our hypothesis function.</p>"},{"location":"Deep-Learning/00_mechine_learning/#cost-function_1","title":"Cost Function","text":"<p>We cannot use the same cost function that we use in linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it isn't a convex function.</p> <p>Instead, our cost function for logistic regression looks like:</p> \\[ \\begin{align} J(\\theta) &amp; = \\frac{1}{m}\\sum_{i=1}^{m}Cost(h_{\\theta}(x^i), y^i) \\\\\\\\ Cost(h_{\\theta}(x^i), y^i) &amp; = -log(h_{\\theta}(x)) &amp; \\mbox{ if } y = 1 \\\\\\\\ Cost(h_{\\theta}(x^i), y^i) &amp; = -log(1 - h_{\\theta}(x)) &amp; \\mbox{ if } y = 0 \\end{align} \\] <p>When \\(y = 1\\), we get the following plot for \\(J(\\theta)\\) vs \\(h_{\\theta}(x)\\):</p> <pre><code>^      X        y = 1\n|      XX\n|       X\n|       XX\n|        XX\n|         XX\n|          XX\n|           XXX\n|             XX\n|               XX\n|                XXX\n|                  XXX\n|                    XXX\n|                      XX\n|                        XXX\n|                          XXX\n|                             XXX \n+-------------------------------XX+-----------&gt;\n0            h(x)                 1\n</code></pre> <p>Similarly, when \\(y = 0\\), we get the following plot for \\(J(\\theta)\\) vs \\(h_{\\theta}(x)\\):</p> <pre><code>^               y = 0\n|\n|\n|\n|                             XX\n|                             XX\n|                            XX\n|                           XX\n|                          XX\n|                       XXX\n|                    XXXX\n|                  XXX\n|               XXX\n|             XXX\n|          XXX\n|      XXXX\n| XXXXX\nXX--------------------------------+-----------&gt;\n0            h(x)                 1\n</code></pre> \\[ \\begin{align} Cost(h_{\\theta}(x), y) &amp; = 0 &amp; \\mbox{if } h_{\\theta}(x) = y &amp; \\\\\\\\ Cost(h_{\\theta}(x), y) &amp; \\to \\infty &amp; \\mbox{if }  y = 0 \\mbox{ and } h_{\\theta}(x) = 1 \\\\\\\\ Cost(h_{\\theta}(x), y) &amp; \\to \\infty &amp; \\mbox{if }  y = 1 \\mbox{ and } h_{\\theta}(x) = 0 \\end{align} \\]"},{"location":"Deep-Learning/00_mechine_learning/#simplified-cost-function","title":"Simplified Cost Function","text":"<p>We can compress our cost function's two conditianal cases into one case:</p> \\[ Cost(h_{\\theta}(x), y) = -ylog(h_{\\theta}(x)) - (1 - y) log(1 - h_{\\theta}(x)) \\] <p>Then the entire const function is as follows:</p> \\[ J(\\theta) = -\\frac{1}{m} \\sum_{i = 1}^m[y^ilog(h_{\\theta}(x^i)) + (1 + y^i)log(1 - h_{\\theta}(x^i))] \\] <p>A vectorized implementation is:</p> \\[ \\begin{align} h &amp; = g(X\\theta) \\\\\\\\ J(\\theta) &amp; = \\frac{1}{m} \\cdot (-y^Tlog(h) - (1 - y)^Tlog(1 - h)) \\end{align} \\]"},{"location":"Deep-Learning/00_mechine_learning/#gradient-descent_1","title":"Gradient Descent","text":"<p>The general form of gradient descent is:</p> \\[ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta) \\] <p>We can work out the derivative part using calculus to get:</p> \\[ \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}{m}(h_{\\theta}(x^i) - y^i)x_j^i \\] <p>A vectorized implementation is:</p> \\[ \\theta := \\theta - \\frac{\\alpha}{m} X^T(g(X\\theta) - \\overrightarrow{y}) \\]"},{"location":"Deep-Learning/00_mechine_learning/#advanced-optimization","title":"Advanced Optimization","text":"<p>Instead of gradient descent,</p> <ul> <li>\"Conjugate gradient\",</li> <li>\"BFGS\",</li> <li>\"L-BFGS\"</li> </ul> <p>are more sophisticated, faster ways to optimize \\(\\theta\\). You can use a existed libaray to apply these mathods.</p>"},{"location":"Deep-Learning/00_mechine_learning/#multiclass-classification-one-vs-all","title":"Multiclass Classification: One-vs-all","text":"<p>Now we will approach the classification of data when we have more than two . Instead of \\(y = {0, 1}\\), we will expand our definition so that \\(y = {0, 1, ..., n}\\).</p> <p>Since \\(y = {0, 1, ..., n}\\), we divide our problem into \\(n+1\\) (\\(+1\\) because the index start at 0) binary classification problems. In each one, we predict the probability that \\(y\\) is a member of one of our classes.</p> \\[ \\begin{align} y &amp; \\in {0, 1, ..., n} \\\\\\\\ h_{\\theta}^{(0)}(x) &amp; = P(y = 0 | x; \\theta) \\\\\\\\ h_{\\theta}^{(1)}(x) &amp; = P(y = 1 | x; \\theta) \\\\\\\\ h_{\\theta}^{(2)}(x) &amp; = P(y = 2 | x; \\theta) \\\\\\\\ \\cdots \\\\\\\\ h_{\\theta}^{(n)}(x) &amp; = P(y = n | x; \\theta) \\\\\\\\ prediction &amp; = \\max_i(h_{\\theta}^{(i)}(x)) \\end{align} \\] <p>We are basically choosing one class and then lumping all the others into a single second class. We do this repeatedly, applying binary logistic regression to each case, and then use the hypothesis that returned the highest value as prediction.</p> <p>To sumerize:</p> <ul> <li>Train a logistic regression classifier \\(h_{\\theta}(x)\\) for each class to predict the probability that \\(y = i\\);</li> <li>To make a prediction on a new \\(x\\), pick the class that maximized \\(h_{\\theta}(x)\\).</li> </ul>"},{"location":"Deep-Learning/00_mechine_learning/#neural-networks","title":"Neural Networks","text":""},{"location":"Deep-Learning/00_mechine_learning/#model-representation_1","title":"Model Representation","text":"<p>In this chapter, we will represent a hypothesis function using neural networks. At a very simple level, neurons are basically computational units that take inputs(dendrites) as electrical inputs(called \"spikes\") that are channeled to outputs(axons). In our model, our dendrites are like the input features \\(x_{1} \\cdots x_{n}\\) and the output is the result of our hypothesis function. In this model our \\(x_{0}\\) input node is sometimes called the \"bias unit\". It is always euqal to \\(1\\). In neural networks, we use the same logistic function as in classification, \\(\\frac{1}{1+e^{-\\theta^Tx}}\\), yet we sometimes call it a sigmoid(logistic) activation function. In this situation, our \"theta\" parameters are sometimes called \"weights\".</p> <p></p> <p>Visually, a simplistic representation looks like:</p> \\[ \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\end{bmatrix} \\to \\mbox{[ ]} \\to h_{\\theta}(x) \\] <p>Our input nodes(layer 1), also known as the \"input layer\", go into another node(layer 2), which finally outputs the hypothesis function, known as \"output layer\".</p> <p>We can have intermediate layers of nodes between \"input layers\" and \"output layers\" called the \"hidden layers\".</p> <p>In this example, we label these intermediate or \"hidden\" layer nodes \\(a_{0}^2 \\cdots an_{n}^2\\) and call them \"activation units\".</p> \\[ a_{i}^{(j)} = \\mbox{\"activation\" of unit i in layer j} \\] \\[ \\Theta^{(j)} = \\mbox{matrix of weights controlling function mapping from layer j to layer j + 1} \\] <p>If we have hidden layer, it would like:</p> \\[ \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\\\\\\\ x_{3} \\end{bmatrix} \\to  \\begin{bmatrix} a_{0}^{(2)} \\\\\\\\ a_{1}^{(2)} \\\\\\\\ a_{2}^{(2)} \\\\\\\\ a_{3}^{(2)} \\end{bmatrix} \\to h_{\\theta}(x) \\] <p>The values for each of the \"activation\" nodes is obtained as follows:</p> \\[ \\begin{bmatrix} \\Theta_{10}^{(1)} &amp; \\Theta_{11}^{(1)} &amp; \\Theta_{12}^{(1)} &amp; \\Theta_{13}^{(1)} \\\\\\\\ \\Theta_{20}^{(1)} &amp; \\Theta_{21}^{(1)} &amp; \\Theta_{22}^{(1)} &amp; \\Theta_{33}^{(1)} \\\\\\\\ \\Theta_{30}^{(1)} &amp; \\Theta_{31}^{(1)} &amp; \\Theta_{32}^{(1)} &amp; \\Theta_{33}^{(1)}  \\end{bmatrix} \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\\\\\\\ x_{3} \\end{bmatrix} = \\begin{bmatrix} a_{1}^{(2)} \\\\\\\\ a_{2}^{(2)} \\\\\\\\ a_{3}^{(2)} \\end{bmatrix} \\] \\[ h_{\\Theta}^{(x)} = a_{1}^{(3)} = g( \\begin{bmatrix} \\Theta_{10}^{(2)} &amp; \\Theta_{11}^{(2)} &amp; \\Theta_{12}^{(2)} &amp; \\Theta_{13}^{(2)}  \\end{bmatrix} \\begin{bmatrix} a_{0}^{(2)} \\\\\\\\ a_{1}^{(2)} \\\\\\\\ a_{2}^{(2)} \\\\\\\\ a_{3}^{(2)} \\end{bmatrix} ) \\] <p>This is saying that we compute our activation nodes by using a \\(3 \\times 4\\) matrix of parameters. We apply each row of the parameters to our inputs to obtain the value for one activation node. Our hypothesis output is the logistic function applied to the sum of the values of our activation nodes, which have been multiplied by yet another another parameter matrix \\(\\Theta^{(2)}\\) containing the weights for our second layer of nodes. Each layer gets its own matrix of weights, \\(\\Theta^{(j)}\\). The dimension of these marices of weights is determined as follows:</p> <p>If network has \\(s_{j}\\) units in layer \\(j\\) and \\(s_{j + 1}\\) in layer \\(j + 1\\), then \\(\\Theta_{0}^{j}\\) will be of dimension \\(s_{j + 1} \\times (s_{j} + 1)\\).</p> <p>The \\(+1\\) comes from the addition in \\(\\Theta^{(j)}\\) of the \"bias node\" \\(x_{0}\\) and \\(\\Theta_{0}^{(j)}\\). In other words, the output nodes will not include the bias node while the input nodes will.</p>"},{"location":"Deep-Learning/00_mechine_learning/#application","title":"Application","text":""},{"location":"Deep-Learning/00_mechine_learning/#implement-a-logical-operator","title":"Implement A Logical Operator","text":"<p>A simple example of applying neural networks is by predicting \\(x_{1} \\mbox{ AND } x_{2}\\) which is the logical <code>and</code> operator and is only true if both \\(x_{1}\\) and \\(x_{2}\\) are \\(1\\).</p> <p>The graph of our functions will look like:</p> \\[ \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\end{bmatrix} \\to  \\begin{bmatrix} g(z^{(2)}) \\end{bmatrix} \\to h_{\\Theta}^{(x)} \\] <p>Remember that \\(x_{0}\\) is our bias variable and is always \\(1\\).</p> <p>Let's set our first \\(\\Theta\\) matrix as:</p> \\[ \\Theta^{(1)} = \\begin{bmatrix} -30 &amp; 20 &amp; 20 \\end{bmatrix} \\] <p>This will case the output of our hypothesis to only be positive if both \\(x_{1}\\) and \\(x_{2}\\) are \\(1\\). In other words:</p> \\[ h_{\\Theta}(x) = g(-30 + 20x_{1} + 20x_{2}) \\] <p>And \\(g(z)\\) is the sigmoid fucntion, it's \\(1\\) if \\(z &gt; 0\\), and \\(0\\) if \\(z &lt; 0\\). So the result is:</p> \\(x_{1}\\) \\(x_{2}\\) g(z) \\(h_{\\Theta}(x)\\) 0 0 g(-30) 0 0 1 g(-10) 0 1 0 g(-10) 0 1 0 g(10) 1 <p>So we have constructed one of the fundamental operation in computers by using a small neural network rather than an actual <code>AND</code> gate. Neural network can also be used to simulate all the other logical gates.</p>"},{"location":"Deep-Learning/00_mechine_learning/#implement-a-complex-logical-operator","title":"Implement A Complex Logical Operator","text":"<p>The \\(\\Theta^{(1)}\\) matrices for <code>AND</code>, <code>NOR</code> and <code>OR</code> are:</p> <ul> <li>AND:</li> </ul> \\[ \\Theta^{(1)} = \\begin{bmatrix} -30 &amp; 20 &amp; 20 \\end{bmatrix} \\] <ul> <li>NOR:</li> </ul> \\[ \\Theta^{(1)} = \\begin{bmatrix} 10 &amp; -20 &amp; -20 \\end{bmatrix} \\] <ul> <li>OR:</li> </ul> \\[ \\Theta^{(1)} = \\begin{bmatrix} -10 &amp; 20 &amp; 20 \\end{bmatrix} \\] <p>We can combine these to get the <code>XNOR</code> logical operator(which gives 1 if \\(x_{1}\\) and \\(x_{2}\\) are both 0 or both 1).</p> \\[ \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\end{bmatrix} \\to \\begin{bmatrix} a_{1}^{(2)} \\\\\\\\ a_{2}^{(2)} \\end{bmatrix} \\to \\begin{bmatrix} a^{(3)} \\end{bmatrix} \\to h_{\\Theta}(x) \\] <p>For the transition between the second and third layer, we'll use a \\(\\Theta^{(2)}\\) matrix that combines the values for AND and NOR:</p> \\[ \\Theta^{(1)} =  \\begin{bmatrix} -30 &amp; 20 &amp; 20 \\\\\\\\ 10 &amp; -20 &amp; -20 \\end{bmatrix} \\] <p>For the transition between the second and third layer, we'll use a \\(\\Theta^{(2)}\\) matrix that uses the value for OR:</p> \\[ \\Theta^{(2)} = \\begin{bmatrix} -10 &amp; 20 &amp; 20 \\end{bmatrix} \\] <p>Let's write out the values for all our nodes:</p> \\[ a^{(2)} = g(\\Theta^{(1)} \\cdot x) \\] \\[ a^{(3)} = g(\\Theta^{(2)} \\cdot a^{(2)}) \\] \\[ h_{\\Theta}(x) = a^{(3)} \\] <p>The neural networks is like this:</p> <p></p>"},{"location":"Deep-Learning/00_mechine_learning/#multiclass-classification","title":"Multiclass Classification","text":"<p>To classify data into multiple classes, we let our hypothesis function return a vector of values. We still use the <code>One-vs-all</code> method.</p> <p>For example, if we want to classify our data into one of four , we can define our set of resulting classes as:</p> \\[ y^{(i)} =  \\begin{bmatrix} 1 \\\\\\\\ 0 \\\\\\\\ 0 \\\\\\\\ 0 \\end{bmatrix},  \\begin{bmatrix} 0 \\\\\\\\ 1 \\\\\\\\ 0 \\\\\\\\ 0 \\end{bmatrix},  \\begin{bmatrix} 0 \\\\\\\\ 0 \\\\\\\\ 1 \\\\\\\\ 0 \\end{bmatrix},  \\begin{bmatrix} 0 \\\\\\\\ 0 \\\\\\\\ 1 \\\\\\\\ 1 \\end{bmatrix} \\] <p>Each \\(y^{(i)}\\) represents a different image conrresponding to either class 1, class 2, class 3 or class 4. The inner layers, each provide us with some new information which leads to our final hypothesis function. The step looks like:</p> \\[ \\begin{bmatrix} x_{0} \\\\\\\\ x_{1} \\\\\\\\ x_{2} \\\\\\\\ \\cdots \\\\\\\\ x_{n} \\end{bmatrix} \\to \\begin{bmatrix} a_{0}^{(2)} \\\\\\\\ a_{1}^{(2)} \\\\\\\\ a_{2}^{(2)} \\\\\\\\ \\cdots \\\\\\\\ x_{n}^{(2)} \\end{bmatrix} \\to \\begin{bmatrix} a_{0}^{(3)} \\\\\\\\ a_{1}^{(3)} \\\\\\\\ a_{2}^{(3)} \\\\\\\\ \\cdots \\\\\\\\ x_{n}^{(3)} \\end{bmatrix} \\to \\cdots \\to \\begin{bmatrix} h_{\\Theta1}(x) \\\\\\\\ h_{\\Theta2}(x) \\\\\\\\ h_{\\Theta3}(x) \\\\\\\\ h_{\\Theta4}(x) \\end{bmatrix} \\] <p>Our resulting hypothesis for one set of inputs may look like:</p> \\[ h_{\\Theta}(x) =  \\begin{bmatrix} 0 \\\\\\\\ 1 \\\\\\\\ 0 \\\\\\\\ 0 \\end{bmatrix} \\]"},{"location":"Deep-Learning/00_mechine_learning/#cost-function_2","title":"Cost Function","text":"<p>Let's define a few variables that we will need to use:</p> <ul> <li>\\(L\\): total number of layers int the network;</li> <li>\\(s_{l}\\): number of units(not counting bias unit) in layer \\(l\\);</li> <li>\\(K\\): number of output units/classes.</li> </ul> <p>In neural networks, we may have many output nodes, we donate \\(h_{\\Theta}(x)\\_{k}\\) as being a hypothesis that results in the \\(k^{th}\\) output.</p> <p>Our cost function for neural networks is going to be a generalization of the one we used for logistic function. Recall that the cost function for regularized logistic regression was:</p> \\[ J(\\Theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)})log(1 - h_{\\theta}(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n}\\theta_{j}^{2} \\] <p>For neural networks, it is going to be slightly more complicated:</p> \\[ J(\\Theta) = -\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}[y_{k}^{(i)}log(h_{\\Theta}(x^{(i)})\\_k) + (1-y_{k}^{(i)})log(1 - (h_{\\Theta}(x^{(i)})\\_k)] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}}(\\Theta_{j,i}^{(l)})^{2} \\] <p>We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, before the square brackets, we have an additional nested summation that loops through the number of output nodes.</p> <p>In the regularization part, after the square brackets, we must account for multiple theta matrices. The number of colums in our current theta matrix is equal to the number of nodes in our current layer(including the bias unit). The number of rows in our current theta matrix is equal to the nubmer of node in the next layer(excluding the bias unit). As before with logistic regression, we suqare every term.</p>"},{"location":"Deep-Learning/00_mechine_learning/#backpropagation-algorithm","title":"Backpropagation Algorithm","text":"<p>\"BackPropagation\" is neural-network terminology for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression. Our goal is to compute:</p> \\[ \\min_{\\Theta}J(\\Theta) \\] <p>That is, we want to minimize our cost function \\(J\\) using an optimal set of parameters in \\(\\Theta\\). In this section we'll look at the equations we used to compute the partial derivative of \\(J(\\Theta)\\):</p> \\[ \\frac{\\partial}{\\partial\\Theta_{i,j}^{(l)}}J(\\Theta) \\] <p>To do so:</p> <ol> <li>Given training set \\({(x^{(1), y^{(1)}}) \\cdots (x^{(m)}, y^{(m)})}\\),<ol> <li>Set \\(\\Delta_{i, j}^{(l)} := 0\\) for all \\((l, i, j)\\)(hence you end up having a matrix full of zeros)</li> </ol> </li> <li> <p>For training example \\(t = 1 \\to m\\):</p> <ol> <li>Set \\(a^{(1)} := x^{(t)}\\)</li> <li> <p>Perform <code>forward propagation</code> to compute \\(a^{(l)}\\) for \\(l=2,3,\\cdots,L\\) </p> </li> <li> <p>Using \\(y^{(t)}\\) to compute \\(\\delta^{(L)} = a^{(L)} - y^{(t)}\\).</p> </li> <li>Where \\(L\\) is our total number of layers and \\(a^{(L)}\\) is the vector of outputs of the activation units for the last layer. So our \"error values\" for the last layer are simply the differences of our actual results in the last layer and the correct outputs in \\(y\\). To get the \\(\\delta\\) values of the layers before the last layer, we can use an equation that steps us back from right to left.</li> <li>Computing \\(\\delta^{(L-1)},\\delta^{(L-2)},\\cdots,\\delta^{(2)}\\) using</li> </ol> </li> </ol> \\[ \\delta^{(l)}=((\\Theta^{(l)})^{T}\\delta^{(l+1)}).*a^{(l)}.*(1-a^{(l)}) \\] <p>The equation for b.:</p> \\[ \\begin{array}{lcl} a^{(1)} &amp; = &amp; x \\\\ z^{(2)} &amp; = &amp; \\Theta^{(1)}a^{(1)} \\\\ a^{(2)} &amp; = &amp; g(z^{(2)}) \\quad (add \\quad a_{0}^{(2)}) \\\\ z^{(3)} &amp; = &amp; \\Theta^{(2)}a^{(2)} \\\\ a^{(3)} &amp; = &amp; g(z^{(3)}) \\quad (add \\quad a_{0}^{(3)}) \\\\ z^{(4)} &amp; = &amp; \\Theta^{(3)}a^{(3)} \\\\ a^{(4)} &amp; = &amp; h_{\\Theta}(x) = g(z^{(4)}) \\\\ \\end{array} \\] <p>We then element-wise multiple that with a function called \\(g'\\) which is the derivative of the activation function \\(g\\) evaluated with the input values given by \\(z^{(l)}\\):</p> \\[ g'(z^{(l)}) = a^{(l)}.*(1-a^{(l)}) \\] <p>\\(\\Delta_{i,j}^{(l)} := \\Delta_{i,j}^{(l)} + a_{j}^{(l)}\\delta_{i}^{(l+1)}\\) or with vectorization:</p> \\[ \\Delta^{(1)} := \\Delta^{(l)} + \\delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T \\] <p>Hence we update our new \\(\\Delta\\) matrix:</p> \\[ D_{i,j}^{(l)} = \\begin{cases} \\frac{1}{m}(\\Delta_{i,j}^{(l)} + \\lambda\\Theta_{i,j}^{(l)}), &amp; if \\quad j \\ne 0 \\\\\\\\ \\frac{1}{m}\\Delta_{i,j}^{(l)} &amp; if \\quad j \\ne 0 \\end{cases} \\] <p>The \\(\\Delta\\) matrix \\(D\\) is used as an \"accumulator\" to add up our values as we go along and eventually compute our partial derivative. Thus we get:</p> \\[ \\frac{\\partial}{\\partial\\Theta_{i,j}^{(l)}}J(\\Theta) = D_{i,j}^{(l)} \\]"},{"location":"Deep-Learning/10_nn_and_deep_learning/","title":"Neural Network and Deep Learning","text":""},{"location":"Deep-Learning/10_nn_and_deep_learning/#introduce-to-deep-learning","title":"Introduce to deep learning","text":""},{"location":"Deep-Learning/10_nn_and_deep_learning/#what-is-a-neural-network","title":"What is a Neural Network","text":"<p>At a very simple level, neurons are basically computational units that take inputs(dendrites) as electrical inputs(called \"spikes\") that are channeled to outputs(axons). A single neuron will calculate weighted sum of input(\\(W.T \\cdot X\\)) and we can set a threshold to predict output in a perceptron. If weighted sum of input across the threshold, perceptron fires and if not then perceptron doesn't predict.</p> <p>The disadvantage of perceptron is that it only outputs binary values. To make output of perceptron flips we add a bias, here comes: \\(W.T \\cdot X + b\\). We need some system which can modify the output slightly accordding to small change in weight and bias, here comes activation functions(\\(g(W.T \\cdot X + b)\\)).</p> <p><code>Sigmoid</code> is a kind of activation functions, we can make slight change in output with sigmoid function, and the single neuron with sigmoid activation function will act as <code>Logistic Regression</code>.</p> <p><code>ReLU</code> which stands for rectified linear unit, is the most popular activation function right now that makes deep neural network trains faster.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#supervised-learning-with-neural-networks","title":"Supervised learning with neural networks","text":"<p>There are different types of neural networks for supervised learning:</p> <ul> <li><code>CNN</code>(Convolutional Neural Network) is useful in computer vision;</li> <li><code>RNN</code>(Recurrent Neural Network) is useful in speech recognition or NLP(Nature Language Process);</li> <li><code>Standard NN</code> is useful for structured data;</li> <li>Hybrid/custom NN or a Collection of NNs types</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#why-is-deep-learning-taking-off","title":"Why is deep learning taking off","text":"<p>Deep learning is taking off for 3 reasons:</p> <ol> <li>Data scale:<ul> <li>For small data NN can performs as traditional algorithms like Linear regression or SVM(Support vector mechine);</li> <li>For bigger data a small NN performs better than traditional algos;</li> <li>For really big data, a large NN is better than middle NN that is better than small NN;</li> <li>Hopefully we have a lot of data because the world is using the computer a little bit more.</li> </ul> </li> <li>Computation:<ul> <li>GPUs;</li> <li>Powerful CPUs;</li> <li>Distributed computing;</li> <li>ASICs.</li> </ul> </li> <li>Algorithm:<ul> <li>Creative algorithms have appeared that changed the way NN works: For example, using <code>ReLU</code> is so much better than using <code>Sigmoid</code> function in training a NN because it helps with the vanishing gradient problem.</li> </ul> </li> </ol>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#neural-network-basics","title":"Neural Network Basics","text":"<p>This part we learn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your models.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#logistic-regression","title":"Logistic regression","text":"<p>Algorithm is used for classification of 2 classes. We use the equation:</p> \\[ y = wx + b \\] <p>to calculate the output.  If \\(x\\) is a vector, the equation becomes:</p> \\[ y = w^Tx + b \\] <p>If we need \\(y\\) to be in \\([0, 1]\\)(probability):</p> \\[ y = sigmoid(w^Tx + b) \\]"},{"location":"Deep-Learning/10_nn_and_deep_learning/#logistic-regression-cost-function","title":"Logistic regression cost function","text":"<p>The cost function can be the one half a square error:</p> \\[ L(\\hat{y}, y) = \\frac{1}{2} \\cdot (\\hat{y} - y)^2 \\] <p>but we won't use this notation because it leads to optimization problem which is non convex, means it contains local optimum points.</p> <p>Alternately, we use the function:</p> \\[ L(\\hat{y}, y) = - (y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y})) \\] <p>this leads to two cases:</p> <ul> <li>if \\(y = 1\\), \\(L(\\hat{y}, 1) = -log(\\hat{y})\\), we want \\(\\hat{y}\\) to be the largest, and the largest value of \\(\\hat{y}\\) is \\(1\\);</li> <li>if \\(y = 0\\), \\(L(\\hat{y}, 1) = -log(1 - \\hat{y})\\), we want \\(1 - \\hat{y}\\) to be the largest, and the smallest value of \\(\\hat{y}\\) is \\(0\\);</li> </ul> <p>Then the cost function will be:</p> \\[ J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} {(L(\\hat{y}^{[i]}, y^{[i]}))} \\] <p>The difference between loss function and cost function:</p> <ul> <li>the loss function calculates the error for a single training example;</li> <li>the cost function calculates the average of the loss function of the entire training set.</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#gradient-descent","title":"Gradient Descent","text":"<p>Our target is to predict \\(w\\) and \\(b\\) that minimize the cost function while the cost function itself is convex.</p> <p>The gradient descent repeats:</p> \\[ w = w - \\alpha \\cdot dw \\] \\[ b = b - \\alpha \\cdot db \\] <p>to reach the minimum of cost function, while the \\(\\alpha\\) is the <code>learning rate</code> and \\(dw\\) is the derivative of \\(w\\), \\(db\\) is the derivative of \\(b\\).</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#vectorization","title":"Vectorization","text":"<p>Deep learning shines when the dataset is big. However, <code>for loop</code> will make you wait a lot for a result. That's why we need vectorization to get rid of  some of our <code>for loop</code>s.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#general-steps","title":"General steps","text":"<p>The main steps for building a Neural Network are:</p> <ul> <li>Define the model structure(such as number of input features and outputs);</li> <li>Initialize the model's parameters;</li> <li>Loop:<ul> <li>Calculate current loss(forward propagation);</li> <li>Calculate current gradient(backward propagation)</li> <li>Update parameters(gradient descent)</li> </ul> </li> </ul> <p>Tunning the learning rate(which is an example of a \"hyperparameter\") can make a big difference to the algorithm.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#shallow-neural-network","title":"Shallow neural network","text":"<p>This part we learn to build a neural network with one hidden layer, using forward propagation and backward propagation.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#neural-network-overview","title":"Neural network overview","text":"<p>In the left logistic regression we had:</p> \\[ z = W^TX + B \\Rightarrow a = sigmoid(z) \\Rightarrow L(a, Y) \\] <p>where \\(W\\), \\(X\\) and \\(B\\) are matirx.</p> <p>In neural networks with one layer we will have:</p> \\[ Z_1 = W_1^TX + B \\Rightarrow A1 = sigmoid(Z_1) \\Rightarrow Z_2 = W_2^TA_1 + B_2 \\Rightarrow A_2 = sigmoid(Z_2) \\Rightarrow L(A2,Y) \\] <p>Neural Network is a stack of logistic regression objects.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#neural-network-notations","title":"Neural network notations","text":""},{"location":"Deep-Learning/10_nn_and_deep_learning/#general-comments","title":"General comments","text":"<ul> <li>Superscript \\((i)\\) will denote the \\(i^{th}\\) training example while the superscript \\([l]\\) will denote the \\(l^{th}\\) layer.</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#sizes","title":"Sizes","text":"<ul> <li>\\(m\\): number of examples in the dataset;</li> <li>\\(n_x\\): input size;</li> <li>\\(n_y\\): output size(or number of classes);</li> <li>\\(n_h^{[l]}\\): number of hidden units of the \\(l^{th}\\) layer;</li> <li>\\(L\\): number of layers in the network.</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#objects","title":"Objects","text":"<ul> <li>\\(X\\): the input matrix</li> <li>\\(x^{(i)}\\): the \\(i^{th}\\) example represented as a column vector;</li> <li>\\(Y\\): the label matrix;</li> <li>\\(y^{(i)}\\): the output label for the \\(i^{th}\\) example;</li> <li>\\(W^{[l]}\\): the \\(l^{th}\\) lyaer weight matrix;</li> <li>\\(b^{[l]}\\): the bias vector of \\(l^{th}\\) layer;</li> <li>\\(\\hat{y}\\): the predicted output vector. It can also be denoted \\(a^{[L]}\\) where \\(L\\) is the number of layers in the network.</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#forward-propagation","title":"Forward propagation","text":"<ul> <li>\\(a = g^{[l]}(W_xx^{(i)} + b_1) = g^{[l]}(z_1)\\), where \\(g^{[l]}\\) denotes the \\(l^{th}\\) layer activation function;</li> <li>\\(J(x, W, b, y)\\) or \\(J(\\hat{y}, y)\\) denotes the cost function.</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#activation-functions","title":"Activation functions","text":""},{"location":"Deep-Learning/10_nn_and_deep_learning/#sigmoid","title":"sigmoid","text":"<p>So far we are using sigmoid, but it works not so well:</p> <ul> <li>sigmoid can lead us to gradient decent problem where the updates are so slow;</li> <li>the range of function is \\([0, 1]\\).</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#tanh","title":"tanh","text":"<p><code>tanh</code> is a shifted version of sigmoid with the range \\([-1, 1]\\). It usually works better than sigmoid activation for hidden units because the mean of its outputs is closer to \\(0\\), and so it centers the data better for the next layer.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#relu","title":"ReLU","text":"<p><code>sigmoid</code> or <code>tanh</code> function disadvantage is that if the input is too small or too high, the slope will be near zero which will cause the gradient decent problem.</p> <p>One of the popular activation functions that solved the slow gradient decent is the ReLU function.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#leaky-relu","title":"Leaky ReLU","text":"<p>The difference between Leaky ReLU and ReLU is that if the input is negtive the slope will be so small. It works as ReLU but most people use ReLU.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#why-we-need-non-linear-activation-functions","title":"Why we need non-linear activation functions","text":"<p>Linear activation will output linear activations, that means whatever hidden layers you add, the activation will be always linear like logistic regression, so it's useless in a lot of complex problems.</p> <p>You might use linear activation function in one place, the output layer, if the output is real number(regression problem). But even in this case if the output value is non-negtive you could still use ReLU instead.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#derivative-of-activation-functions","title":"Derivative of activation functions","text":"<ul> <li>Derivation of sigmoid activation function:</li> </ul> \\[ g(z) = \\frac{1}{1 + e^{-z}} \\] \\[ g'(z) = \\frac{1}{1 + e^{-z}} \\cdot (1 - \\frac{1}{1 + e^{-z}}) = g(z) \\cdot (1 - g(z)) \\] <ul> <li>Derivation of tanh activation function:</li> </ul> \\[ g(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} \\] \\[ g'(z) = 1 - tanh^2(z) = 1 - g^2(z) \\] <ul> <li>Derivation of ReLU activation function:</li> </ul> \\[ g(z) = max(0, z) \\] \\[ g'(z) =  \\begin{cases} 0, \\quad \\mbox{if} \\quad z &lt; 0 \\\\\\\\ 1, \\quad \\mbox{if} \\quad z &gt;= 0 \\end{cases} \\] <ul> <li>Derivation of leaky ReLU activation function:</li> </ul> \\[ g(z) = max(0.01 \\cdot z, z) \\] \\[ g'(z) =  \\begin{cases} 0.01, \\quad \\mbox{if} \\quad z &lt; 0 \\\\\\\\ 1, \\quad \\mbox{if} \\quad z &gt;=0 \\end{cases} \\]"},{"location":"Deep-Learning/10_nn_and_deep_learning/#random-initialization","title":"Random initialization","text":"<p>In logistic regression it wasn't important to initialize the weights randomly, while in neural network we have to initialize them randomly.</p> <p>While initializing bias with \\(0\\) is OK, neural network won't work if we initialize all weights with zeros:</p> <ul> <li>all hidden units will be completely identical(symmetric) and compute exactly the same function;</li> <li>on each gradient descent iteration all the hidden units will always update the same.</li> </ul> <p>We need small values because in sigmoid(or tanh) activation function, for example, if the weights is too large you are more likely to end up with very large values of \\(Z\\). Which causes your tanh or sigmoid activation function to be saturated, thus slowing down learning. If you don't have any sigmoid or tanh activation function throughout your neural network, this is less of an issue.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#deep-neural-network","title":"Deep neural network","text":"<p>Shallow Neural Network is a Neural Network with \\(1\\) or \\(2\\) layers. Deep Neural Network is a Neural Network with \\(3\\) or more layers.</p>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#getting-your-matrix-dimensions-right","title":"Getting your matrix dimensions right","text":"<p>With the equation:</p> \\[ Z = W^TX + B \\] <p>where \\(X\\) has the shape of \\((x, n^{[l-1]})\\).</p> <ul> <li>Dimension of \\(W\\) is \\((n^{[l]}, n^{[l-1]})\\);</li> <li>Dimension of \\(B\\) is \\((n^{[l]}, 1)\\);</li> <li>\\(dw\\) has the same shape as \\(W\\);</li> <li>\\(db\\) has the same shape as \\(B\\);</li> <li>Dimension of \\(Z^{[l]}\\), \\(A^{[l]}\\), \\(dZ^{[l]}\\), \\(dA^{[l]}\\) is \\((n^{[l]}, m)\\).</li> </ul>"},{"location":"Deep-Learning/10_nn_and_deep_learning/#hyperparameters","title":"Hyperparameters","text":"<p>The main parameters of Neural Network is:</p> <ul> <li>\\(w\\);</li> <li>\\(b\\).</li> </ul> <p>Hyperparameters are the parameters that control the algorithm:</p> <ul> <li>learning rate;</li> <li>Number of iteration;</li> <li>Number of hidden layers;</li> <li>Number of hidden units;</li> <li>Choice of activations.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/","title":"Improving Deep Neural Networks: Hyperparameter Tuning, Regularition and Optimization","text":""},{"location":"Deep-Learning/11_improve_nn/#practical-aspects-of-deep-learning","title":"Practical aspects of deep learning","text":""},{"location":"Deep-Learning/11_improve_nn/#traindevtest-sets","title":"Train/dev/test Sets","text":"<p>It's impossible to get all your hyperparameters right on a new application from the first time, so, the idea is to go through the loop: <pre><code>   Idea --&gt; Code --&gt; Experiment\n    ^                     |\n    |                     |\n    -----------------------\n</code></pre> You can go through the loop many times to figure out your hyperparameters.</p> <p>Generally, we divid the data into three parts:</p> <ul> <li>Train set, which used to train the neural network and is usually the largest set;</li> <li>Develop(dev) set, which is used to validate the traing result;</li> <li>Test set, which is used to test the trained neural network.</li> </ul> <p>You will try to build a model upon <code>train set</code> then try to optimize hyperparamters on <code>dev set</code> as much as possible. After your model is ready, you can evaluate the model with <code>test set</code>.</p> <p>The ratio of splitting the models is:</p> <ul> <li><code>6:2:2</code>, if the size of the dataset is \\(100\\) to \\(1000000\\);</li> <li><code>98:1:1</code> or <code>99.5:0.25:0.25</code>, if the size of the dataset is \\(&gt; 1000000\\).</li> </ul> <p>You should make sure the <code>dev set</code> and <code>test set</code> comes from the same distribution.</p>"},{"location":"Deep-Learning/11_improve_nn/#biasvariance","title":"Bias/variance","text":"<p>Bias and variance techiques are easy to learn but difficult to master. Generally, your model is:</p> <ul> <li><code>underfitting</code>, if it has a <code>high bias</code>;</li> <li><code>overfitting</code>, if it has a <code>high variance</code>. </li> </ul> <p>You can plot the result as the figure above, but if this is not possible, another idea to get bias/ variance is to check the error:</p> <ul> <li>High variance(overfitting):<ul> <li>Training error: 1%;</li> <li>Dev error: 11%.</li> </ul> </li> <li>High bias(underfitting):<ul> <li>Training error: 15%;</li> <li>Dev error: 14%.</li> </ul> </li> <li>High bias (underfitting) &amp;&amp; High variance(overfitting):<ul> <li>Training error: 15%;</li> <li>Test error: 30%.</li> </ul> </li> <li>Best:<ul> <li>Training error: 0.5%;</li> <li>Test error: 1%.</li> </ul> </li> </ul> <p>These conclusions come from the assumption that human has \\(0%\\) error. If the problem isn't meeting this assumption, you will need to use human error as baseline.</p>"},{"location":"Deep-Learning/11_improve_nn/#basic-recipe-for-high-bias-and-variance","title":"Basic recipe for high bias and variance","text":"<p>If your algorithm has a high bias, you can:</p> <ul> <li>Try to make your neural network bigger(more hidden units or more layers);</li> <li>Try a different model that fits your data well;</li> <li>Try more batches;</li> <li>Try difference(advanced) optimization algorithms.</li> </ul> <p>If your algorithm has a high variance, you can:</p> <ul> <li>Use more data;</li> <li>Try regularization;</li> <li>Try a different model that is suitable for your data.</li> </ul> <p>No matter what the problem is, training a bigger neural network never hurts, although this may lead to longer runing time.</p>"},{"location":"Deep-Learning/11_improve_nn/#regularizing-your-neural-network","title":"Regularizing your neural network","text":"<p>For variance(overfitting) problems, we can try a bigger training data to fix it. But some times you can't just get more training data, or it would be quite expensive to get more data. In this case regularization will often help to prevent overfitting, or reduce the errors in your network.</p>"},{"location":"Deep-Learning/11_improve_nn/#regularization","title":"Regularization","text":""},{"location":"Deep-Learning/11_improve_nn/#regularization-for-logistic-regression","title":"Regularization for logistic regression","text":"<ul> <li>\\(L_1\\) regularization</li> </ul> \\[ J(w,b) = \\frac{1}{m} \\sum_{i = 1}^mL(\\hat{y^{(i)}}, y^{(i)}) + \\frac{\\lambda}{2m} \\lVert w \\rVert_2^2 \\] \\[ \\lVert w \\rVert_2^2 = \\sum_{j = i}^{n_x}|w_j| \\] <p>where \\(\\lambda\\) is called regularization parameter(hyperparameter), you can try different value and choose the one with best performance.</p> <ul> <li>\\(L_1\\) regularization(for arcane technical math, this is called <code>Frobenius norm</code>)</li> </ul> \\[ J(w,b) = \\frac{1}{m} \\sum_{i = 1}^mL(\\hat{y^{(i)}}, y^{(i)}) + \\frac{\\lambda}{2m} \\lVert w \\rVert_1 \\] \\[ \\lVert w \\rVert_1 = \\sum_{j = i}^{n_x}w_j^2 = w^Tw \\]"},{"location":"Deep-Learning/11_improve_nn/#regularization-for-neural-network","title":"Regularization for neural network","text":"<p>The normal cost function that we want to minimize is:</p> \\[ J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m} \\sum_{i = 1}^{m}L(\\hat{y^{(i)}}, y^{(i)}) \\] <p>Then the \\(L_2\\) regularization is:</p> \\[ J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m} \\sum_{i = 1}^{m}L(\\hat{y^{(i)}}, y^{(i)}) + \\frac{1}{2m} \\sum_{l = 1}^{L} \\lVert w^{[l]} \\rVert^2 \\] <p>The old way we do back propagation is:</p> \\[ dw^{[l]} = (back propagation) \\] \\[ w^{[l]} = w^{[l]} - \\alpha \\cdot dw^{[l]} \\] <p>Then we change to:</p> \\[ dw^{[l]} = (back propagation) + \\frac{\\lambda}{m} \\cdot w^{[l]} \\] <p>So:</p> \\[ \\begin{align} w^{[l]}  &amp; = w^{[l]} - \\alpha \\cdot dw^{[l]} \\\\\\\\ &amp; = w^{[l]} - \\alpha * ((back propagation) + \\frac{\\lambda}{m} \\cdot w^{[l]}) \\\\\\\\ &amp; = w^{[l]} - \\alpha * (back propagation) - \\alpha * (\\frac{\\lambda}{m} \\cdot w^{[l]}) \\\\\\\\ &amp; = (1 - \\frac{\\alpha\\lambda}{m}) \\cdot w^{[l]} - \\alpha * (back propagation) \\end{align} \\] <p>In practice this will penalize large weights and effectively limits the freedom in your model, because the them \\((1 - \\frac{\\alpha\\lambda}{m}) \\cdot w^{[l]}\\) causes the <code>weight to decay</code> in propartion to its size.</p>"},{"location":"Deep-Learning/11_improve_nn/#why-regularization-reduces-overfitting","title":"Why regularization reduces overfitting","text":"<p>Here are some intuitions:</p> <ul> <li>If \\(\\lambda\\) is too large: a lot of \\(w\\) part will be close to \\(0\\), which makes the neural network more simple;</li> <li>If \\(\\lambda\\) is good enough: it will reduce some weights that makes the neural network overfitting.</li> </ul> <p>And for \\(tanh\\) activation function:</p> <ul> <li>If \\(\\lambda\\) is too large, \\(w\\) part will be small(close to \\(0\\)), which will use the linear part of the \\(tanh\\) activation function, so we will go from non-linear activation to roughly linear which would make the neural network a roughly linear classifier.</li> <li>If \\(\\lambda\\) is good enough, it will just make some of \\(tanh\\) activations roughly linear which will prevent overfitting.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#dropout-regularization","title":"Dropout regularization","text":"<p>In most case, we use \\(L_2\\) regularization. The dropout regularization eliminates some neurons/weights on each iteration based on a probability. A most common techinque to implement dropout is called <code>Inverted dropout</code>: <pre><code>keep_prob = 0.8   # 0 &lt;= keep_prob &lt;= 1\nl = 3  # this code is only for layer 3\n## the generated number that are less than 0.8 will be dropped. 80% stay, 20% dropped\nd3 = np.random.rand(a[l].shape[0], a[l].shape[1]) &lt; keep_prob\n\na3 = np.multiply(a3,d3)   # keep only the values in d3\n\n## increase a3 to not reduce the expected value of output\n## (ensures that the expected value of a3 remains the same) - to solve the scaling problem\na3 = a3 / keep_prob\n</code></pre></p>"},{"location":"Deep-Learning/11_improve_nn/#understanding-dropout","title":"Understanding dropout","text":"<ul> <li>Dropout knocks out units in neural network randomly, so it works like on every iteration you're working with a smaller neural network which has a regulizing effect.</li> <li>Neural network can not rely on any one feature because it may be knocked out, so it has to spread out weights.</li> <li>Dropout can have different <code>keep_prob</code> per layer.</li> <li>The input layer dropout has to be near \\(1\\)(or just \\(1\\)) because you don't want to eliminate a lot of featrues.</li> <li>A lot of researchers are using dropout with Computer Vision(CV), bacause they have a very big input size and almost nerver have enough data, so overfitting is the usual problem. And dropout is a regularization technique to prevent overfitting.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#other-regularization-methods","title":"Other regularization methods","text":""},{"location":"Deep-Learning/11_improve_nn/#data-augmentation","title":"Data augmentation","text":"<ul> <li>In a computer vision data, you can:<ul> <li>flip all your pictures horizontally which will give you more data instances;</li> <li>apply a random position and rotation to an image to get more data.</li> </ul> </li> <li>In OCR you can impose random ratation and distortions to digits/letters.</li> <li>New data obtained using this technique isn't as good as the real independent data, but still can be used as a regularization techniques.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#early-stopping","title":"Early stopping","text":"<p>We plot the <code>training set cost</code> and the <code>dev set cost</code> together for each iteration. At some iteration the <code>dev set cost</code> will stop decreasing and will start <code>increasing</code>. We will pick the point at wich the training set error and dev set error are best(lowest training cost with lowest dev cost). </p> <p>We prefer to use \\(L_2\\) regularization instead of early stop because this technique simultaneously tries to mimimize the cost function and not to overfit which contradicts the orthogonalization approch. But its advantage is that you don't need to search a hyperparameter.</p>"},{"location":"Deep-Learning/11_improve_nn/#model-ensembles","title":"Model ensembles","text":"<p>You can train multiple independent models and average their results, this can get you extra 2% performance and reduces the generalization error.</p>"},{"location":"Deep-Learning/11_improve_nn/#setting-up-your-optimization-problem","title":"Setting up your optimization problem","text":""},{"location":"Deep-Learning/11_improve_nn/#normallizing-inputs","title":"Normallizing inputs","text":"<p>Normalizing inputs will speed up the training process a lot. </p> <p>Normalization are going on these steps:</p> <ol> <li>Get the mean of the training set: \\(mean = \\frac{1}{m} * \\sum_{i=1}^mx^{(i)}\\)</li> <li>Subtract the mean from each input: \\(X = X - mean\\), this will make your inputs centered around \\(0\\).</li> <li>Get the variance of the training set: \\(variance = \\frac{1}{m} * \\sum_{i = 1}^m(x^{(i)})^2\\)</li> <li>Normalize the variance: \\(X = X / variance\\)</li> </ol> <p>So why we normalize our inputs?</p> <ul> <li>If we don't normalize the inputs our cost function will be deep and its shape will be inconsistent(elongated), then optimizing it will take a long time.</li> <li>If we normalized the inputs, the shape of the cost function will be consistent(look more symmetric like circle in 2D exmaple) and we can use a larger learning rate \\(\\alpha\\), the optimization will be faster.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#vanishingexploding-gradients","title":"Vanishing/exploding gradients","text":"<p>The vanishing/exploding gradients occurs when your derivates becomes very small or very big. To understand the problem, suppose that we have a deep neural network with number of layer \\(L\\), and all the activation functions are <code>linear</code> and each \\(b = 0\\), then:</p> \\[ \\hat{y} = w^{[L]}w^{[L - 1]}w^{[L - 2]} \\cdots w^{[2]} w^{[1]} x \\] <p>and if we have 2 hidden units per layer and \\(x_1 = x_2 = 1\\), we will result in:</p> \\[ \\hat{y} = w^{[L]} \\begin{bmatrix}x &amp; 0 \\\\\\\\ 0 &amp; x \\end{bmatrix}^{L-1} = x^L \\\\\\\\ \\] <p>as:</p> \\[ w^{[L]} = \\begin{bmatrix}x &amp; 0 \\\\\\\\ 0 &amp; x \\end{bmatrix}^{L-1} \\] <p>If \\(x &lt; 1\\), \\(\\hat{y}\\) will be very small; if \\(x &gt; 1\\), \\(\\hat{y}\\) will be really big. This example explains that the activations (and similarly derivatives) will be decreased/increased exponentially as a function of number of layers.</p>"},{"location":"Deep-Learning/11_improve_nn/#weight-initialization-for-deep-networks","title":"Weight initialization for deep networks","text":"<p>A partial solution to the vanishing/exploding gradients in neural network is better or more careful choice of the random initialization of weights. In a simgle neuron: \\(Z = w_1x_1 + w_2x_2 + \\cdots + w_nx_n\\), if the number of node \\(n_x\\) is large, we want \\(w\\) to be smaller to not explode the cost, which turns out that we need the variance(equal to \\(\\frac{1}{n_x}\\)) to be the range of \\(W\\). So we initialize \\(W\\) like this(better to use with <code>tanh</code> activation): <pre><code>np.random.rand(shape) * np.sqrt(1/n[l-1])\n</code></pre> or variation of this: <pre><code>np.random.rand(shape) * np.sqrt(2/(n[l-1] + n[l]))\n</code></pre> Setting initialization part inside sqrt to <code>2/n[l-1]</code> for <code>ReLU</code> is better: <pre><code>np.random.rand(shape) * np.sqrt(2/n[l-1])\n</code></pre> This is one of the best way of partially solution to Vanishing / Exploding gradients (ReLU + Weight Initialization with variance) which will help gradients not to vanish/explode too quickly.</p>"},{"location":"Deep-Learning/11_improve_nn/#optimization-algorithms","title":"Optimization algorithms","text":"<p>Training neural network with a large data is slow, so it's necessary to optimize the algorithm to run faster.</p>"},{"location":"Deep-Learning/11_improve_nn/#mini-batch-gradient-descent","title":"Mini-batch gradient descent","text":"<p>Suppose we have a data set with the size of <code>50m</code>, training it will take a huge processing time for one step because 50 million won't fit in the memory at once. To deal with this we can use <code>mini-batch</code> to process some of our items even before finishing the 50 million items. The process is:</p> <ul> <li>Split \\(X\\)(with the size <code>m</code>) into <code>mini-batch</code> of size <code>b</code>:<ul> <li>\\(X^{ \\\\{ 1 \\\\} } = 0,  \\cdots, b\\)</li> <li>\\(X^{ \\\\{ 2 \\\\} } = b + 1, \\cdots, 2b\\)</li> <li>\\(\\cdots\\)</li> <li>\\(X^{ \\\\{ \\frac{m}{b} \\\\} } = (\\frac{m}{b} - 1) * b, \\cdots, \\frac{m}{b} * b\\cdots 2b\\)</li> </ul> </li> <li>Split \\(Y\\) into <code>mini-batch</code> of size <code>b</code>, so we get the definition of <code>mini-batch</code>: \\(t: X^{\\\\{ t \\\\}}, Y^{\\\\{ t \\\\}}\\)</li> <li>Like old <code>batch gradient descent</code>, with <code>mini-batch gradient descent</code> we run the gradient descent on the mini datasets:</li> </ul> <pre><code>for t = 1 : Sum_of_mini-batches  # this is called an epoch\n    AL, caches = forward_prop(X{t}, Y{t})\n    cost = compute_cost(AL, Y{t})\n    grads = backward_prop(AL, caches)\n    update_parameters(grads)\n</code></pre>"},{"location":"Deep-Learning/11_improve_nn/#understanding-mini-batch-gradient-descent","title":"Understanding mini-batch gradient descent","text":"<p>Unlike batch gradient descent where cost function decreases each iteration, mini-batch's cost function won't go down with each step, it may contain ups and downs but generally it goes down.</p> <p></p> <p>The gradient descent type depends on mini-batch size:</p> <ul> <li>mini-batch-size = m: batch gradient descent, which is too long per iteration(epoch);</li> <li>mini-batch-size = 1: stochastic gradient descent(SGD), which:<ul> <li>is too noisy regarding cost minimization(can be reduced by using smaller learning rate);</li> <li>won't ever converge(reach the minimum cost);</li> <li>loses speedup from vectorization.</li> </ul> </li> <li>mini-batch-size = (1, m): mini-batch gradient descent, which:<ul> <li>has faster learning speed:<ul> <li>it can take the advantage of vectorization;</li> <li>it makes progress without waiting to process the entire training set.</li> </ul> </li> <li>doesn't always exactly converge(oscelates in a very small region)</li> </ul> </li> </ul> <p>How to choose the <code>mini-batch</code> size? Here are the suggestions:</p> <ul> <li>m &lt; 2000: Batch gradient descent;</li> <li>It has to be the power of \\(2\\)(64, 128, ..., 1024, ...), because of the way computer memory is layed and accessed your code might run faster;</li> <li>Make sure that the <code>mini-batch</code> fits in CPU/GPU memory.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#exponentially-weighted-average","title":"Exponentially weighted average","text":"<p>If you have data like the temparature of day throughout the year:</p> \\[ \\begin{array}{l} \\theta_1 = 40 \\\\\\\\ \\theta_2 = 49 \\\\\\\\ \\theta_3 = 45 \\\\\\\\ \\cdots \\\\\\\\ \\theta_{180} = 60 \\end{array} \\] <p>This data is samll in winter but big in summer. It's noisy if we plot it out. Now we use the <code>exponentially weighted averages</code> equation</p> \\[ v_t = \\beta * v_{t - 1} + (1 - \\beta) * \\theta_t \\] <p>The result is:</p> \\[ \\begin{array}{l} v_0 = 0 \\\\\\\\ v_1 = \\beta * v_0 + (1 - \\beta) * \\theta_1 \\\\\\\\ v_2 = \\beta * v_0 + (1 - \\beta) * \\theta_2 \\\\\\\\ v_3 = \\beta * v_0 + (1 - \\beta) * \\theta_3 \\\\\\\\ \\cdots \\end{array} \\] <p>If we plot this it will represent averages about \\(\\frac{1}{1 - \\beta}\\) entries:</p> <ul> <li>\\(\\beta = 0.9\\) will average last 10 entries;</li> <li>\\(\\beta = 0.98\\) will average last 50 entries;</li> <li>\\(\\beta = 0.5\\) will average last 2 entries.</li> </ul> <p>The reason why <code>exponentially weighted averages</code> is useful for further optimizing gradient descent is that, it can give different weights to recent data points(\\(\\beta\\)) based on value of \\(\\beta\\). If \\(\\beta\\) is high(around 0.9),  it smoothens out the averages of skewed data points, which will reduce oscillations in gradient descent and hence make faster and smoother path towards minima. </p> <p>The advantage of this algorithm is that its implementation is efficient and fast because it has only one param: \\(\\beta\\).</p>"},{"location":"Deep-Learning/11_improve_nn/#bias-correction-in-exponentially-weighted-averages","title":"Bias correction in exponentially weighted averages","text":"<p>Because \\(v_0 = 0\\), the bias of the weighted averages is shifted and the accuracy suffers at the start. We use following equation to solve the bias issue:</p> \\[ v_t = \\frac{\\beta * v_{t - 1} + (1 - \\beta) * \\theta_t}{1 - \\beta^t} \\] <p>As \\(t\\) becomes larger the \\(1 - \\beta^t\\) term will become close to \\(1\\).</p>"},{"location":"Deep-Learning/11_improve_nn/#gradient-descent-with-momentum","title":"Gradient descent with momentum","text":"<p>The momentum algorithm almost always works faster than standard gradient descent. The simple idea is to calculate the exponentially weighted averages for your gradients and then update your weights with the new values:</p> \\[ \\begin{array}{l} v_{dW} = \\beta \\cdot v_{dW} + (1 - \\beta) \\cdot dW \\\\\\\\ v_{db} = \\beta \\cdot v_{db} + (1 - \\beta) \\cdot db \\\\\\\\ W = W - \\alpha \\cdot v_{dW} \\\\\\\\ b = b - \\alpha \\cdot v_{db} \\end{array} \\] <p>where \\(\\alpha\\) is learning rate, \\(\\beta\\) is another <code>hyperparameter</code>, \\(\\beta = 0.9\\) is very common and works very well in most cases.</p> <p>In practice we don't bother implementating <code>bias correction</code></p>"},{"location":"Deep-Learning/11_improve_nn/#rmsprop","title":"RMSprop","text":"<p><code>RMSprop</code> stands for <code>Root Mean Square prop</code>. It speeds up the gradient descent:</p> \\[ \\begin{array}{l} s_{dW} = \\beta \\cdot s_{dW} + (1 - \\beta) \\cdot dW^2 \\\\\\\\ s_{db} = \\beta \\cdot s_{db} + (1 - \\beta) \\cdot db^2 \\\\\\\\ W = W - \\alpha \\cdot \\frac{dW}{\\sqrt{s_{dW}}} \\\\\\\\ b = b - \\alpha \\cdot \\frac{dW}{\\sqrt{s_{db}}} \\end{array} \\] <p>RMSprop will make the cost function move slower on the vertical direction and faster on the horizontal direction:</p> <p></p> <p>To ensure \\(s_{dw}\\) is not zero, we add \\(\\epsilon\\) (e.g. \\(\\epsilon = 10^{-8}\\))to the demoninator: </p> \\[ W = W - \\alpha \\cdot \\frac{dW}{\\sqrt{s_{dW}} + \\epsilon} \\]"},{"location":"Deep-Learning/11_improve_nn/#adam-optimization-algorithm","title":"Adam optimization algorithm","text":"<p><code>Adam</code> stands for <code>Adaptive Moment Estimation</code>. Adam and RMSprop are among the optimization algorithms that works very well with a lot of neural network architecture. Adam simply puts RMSprop and momentum together:</p> \\[ \\begin{align} v_{dW} &amp;= \\beta_1 \\cdot v_{dW} + (1 - \\beta_1) \\cdot dW \\\\\\\\ v_{db} &amp;= \\beta_1 \\cdot v_{db} + (1 - \\beta_1) \\cdot db \\\\\\\\ s_{dW} &amp;= \\beta_2 \\cdot s_{dW} + (1 - \\beta_2) \\cdot dW^2 \\\\\\\\ s_{db} &amp;= \\beta_2 \\cdot s_{db} + (1 - \\beta_2) \\cdot db^2 \\\\\\\\ v_{dW} &amp;= \\frac{v_{dW}}{1 - \\beta_1^t} \\\\\\\\ v_{db} &amp;= \\frac{v_{db}}{1 - \\beta_1^t} \\\\\\\\ s_{dW} &amp;= \\frac{s_{dW}}{1 - \\beta_1^t} \\\\\\\\ s_{db} &amp;= \\frac{s_{db}}{1 - \\beta_1^t} \\\\\\\\ W &amp;= W - \\alpha \\cdot \\frac{v_{dW}}{\\sqrt{s_{dW}} + \\epsilon} \\\\\\\\ b &amp;= b - \\alpha \\cdot \\frac{v_{db}}{\\sqrt{s_{db}} + \\epsilon} \\end{align} \\] <p>In equation:</p> <ul> <li>(5) and (6) are momentum;</li> <li>(7) and (8) are RMSprop;</li> <li>(9) - (12) are bias correction;</li> <li>\\(\\alpha\\) is learning rate and needs to be tuned;</li> <li>\\(\\beta_1\\) is the parameter of momentum, \\(0.9\\) is recommanded by default;</li> <li>\\(\\beta_2\\) is the parameter of RMSprop, \\(0.999\\) is recommanded by default;</li> <li>\\(\\epsilon = 10^{-8}\\) recommanded by default.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#learning-rate-decay","title":"Learning rate decay","text":"<p>Learning rate decay is to reduce the learning rate slowly. As mentioned before, mini-batch gradient descent won't reach the optimum point(converge). But by making the learning rate decay with iterations it will be much closer to it because the steps near the optimum are smaller.</p> <p>One technique equations is:</p> \\[ \\alpha = \\frac{1}{1 + k_{decay} \\cdot t} \\cdot \\alpha_0 \\] <p>where \\(k_{decay}\\) is decay rate, \\(t\\) is the epoch number. Other learning rate decay can be:</p> \\[ \\alpha = 0.95^{t} \\cdot \\alpha_0 \\] <p>or</p> \\[ \\alpha = \\frac{k}{\\sqrt{t}} \\cdot \\alpha_0 \\] <p>Learning rate decay has less priority than other optimization methods.</p>"},{"location":"Deep-Learning/11_improve_nn/#hyperparameter-tuning-and-batch-nomalization","title":"Hyperparameter tuning and batch nomalization","text":""},{"location":"Deep-Learning/11_improve_nn/#tuning-process","title":"Tuning process","text":"<p>When we train a neural network, we usually need to tune our hyperparameters to get the best out of them. The importance rank of these hyperparameters is:</p> <ol> <li>Learning rate, \\(\\alpha\\);</li> <li>Momentum, \\(\\beta\\);</li> <li>Mini-batch size, \\(b\\);</li> <li>Number of hidden units;</li> <li>Number of layers;</li> <li>Learning rate decay;</li> <li>Ragularization \\(\\lambda\\);</li> <li>Activation functions;</li> <li>Adam \\(\\beta_1\\), \\(\\beta_2\\) and \\(\\epsilon\\).</li> </ol> <p>One of the ways to tune is to sample a grid with \\(N\\) hyperparameter settings and then try all setting combinations on your problem. You should try random values, not the grid. You can use <code>Coarse to fine sampling scheme</code>:</p> <p>When you find some hyperparameters values that give you a better performance, zoom into a smaller region around these values and sample more densely within this space.</p>"},{"location":"Deep-Learning/11_improve_nn/#using-an-appropriate-scale-to-pick-hyperparameters","title":"Using an appropriate scale to pick hyperparameters","text":"<p>Assume that you have a specific range for a hyperparameter from <code>a</code> to <code>b</code>, it's better to search for the right ones using logarithmic scale rather than in linear scale:</p> <ul> <li>\\(a_{log} = log(a)\\): if \\(a = 0.001\\) then \\(a_{log} = -4\\)</li> <li>\\(b_{log} = log(b)\\): if \\(b = 1\\) then \\(a_{log} = 0\\)</li> </ul> <p>Then: \\(r = (a_{log} - b_{log}) * rand + b_{log}\\), the range will be [-4, 0] and result \\(r = 10^r\\).</p> <p>For example, we have known that the best range for <code>Momentum</code> \\(\\beta\\) is \\([0.9, 0.999]\\), you should search for \\(1 - \\beta\\) in the range \\([0.001, 0.1]\\), and use \\(a = 0.001\\) and \\(b = 0.1\\). Then:</p> <ul> <li>\\(a_{log} = -3\\)</li> <li>\\(b_{log} = -1\\)</li> <li>\\(r = (a_{log} - b_{log}) * rand + b_{log}\\)</li> <li>\\(\\beta = 1 - 10^r\\)</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#hyperparameters-tuning-in-practice-pandas-vs-caviar","title":"Hyperparameters tuning in practice: Pandas vs. Caviar","text":"<p>Intuitions about hyperparameter settings from one application area may or may not trasfer to a different one.</p> <p>If you don't have much computational resources you can use <code>Panda</code> approach:</p> <ul> <li>Day 0 you might initialize your parameter as random and then start training;</li> <li>Then you watch your learning curve gradually decrease over the day;</li> <li>And each day you nudge your parameters a little during training.</li> </ul> <p>If you have enough computational resources, you can use <code>Caviar</code> approach: </p> <ul> <li>Run some models in parallel and at the end of the day you check the result.</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#normalizing-activations-in-a-network","title":"Normalizing activations in a network","text":"<p>Normalizing input by subtracting the mean and dividing by variance helps a lot for the shape of the cost function and for reaching the minimum point faster.  The question is:</p> <p>for any hidden layer can we normalize \\(A^{[l]}\\) to train \\(W^{[l+1]}\\) and \\(b^{[l+1]}\\) faster? This is what batch normalization is about.</p> <p>There are some debates about whether you should normalize values before the activation function \\(Z^{[l]}\\) or after applying the activation function \\(A^{[l]}\\). In practice, nomalizing \\(Z^{[l]}\\) is much more often. The algorithm porcess is:</p> <ul> <li>Given \\(Z^{[l]} = [z^{(1)}, \\cdots, z^{(m)}]\\);</li> <li>Compute \\(mean = \\frac{1}{m} * \\sum^m\\_{i=1}{z^{[i]}}\\)</li> <li>Compute \\(variance = \\frac{1}{m} * \\sum_{i=1}^m(z^{[i]}-mean)^2\\)</li> <li>Then \\(Z_{norm}^{[i]} = \\frac{z^{[i]}}{\\sqrt{variance + epsilon}}\\)<ul> <li>forcing the inputs to distribution with 0 mean and variance of 1</li> </ul> </li> <li>Then \\(\\tilde{z}^{[i]} = \\gamma * z_{norm}^{[i]} + \\beta\\)<ul> <li>Make inputs belong to other distribution(with other mean and variance);</li> <li>\\(\\gamma\\) and \\(\\beta\\) are learnable parameters of the model;</li> <li>Make the neural network learn the distribution of the outputs;</li> <li>Note: if \\(\\gamma = \\sqrt{variance + epsilon}\\) and \\(\\beta = mean\\), then \\(\\tilde{z}^{[i]} = z^{[i]}\\)</li> </ul> </li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#fitting-batch-normalization-into-a-neural-network","title":"Fitting Batch normalization into a neural network","text":"<p>Batch normalization is usually applied with mini-batches. If we use batch normalization parameters \\(b^{[1]}, \\cdots, b^{[l]}\\) doesn't count because they will be eliminated after mean subtraction step. So the parameters will be:</p> <ul> <li>\\(W^{[l]}\\);</li> <li>\\(\\beta^{[l]}\\);</li> <li>\\(\\alpha^{[l]}\\).</li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#why-does-batch-normalization-work","title":"Why does batch normalization work?","text":"<ul> <li>The first reason is the same reason as why we normalize \\(X\\);</li> <li>The second reason is that batch normalization reduces the problem of input values changing(shifting);</li> <li>Batch normalization does some regularization:<ul> <li>Each mini-batch is scaled by the mean/variance computed of that mini-batch;</li> <li>This adds some noise to the value \\(Z^{[l]}\\) within that mini-batch, so similar to dropout it adds some noise to each hidden layer's activation;</li> <li>This has a slight regularization effect;</li> <li>Using bigger size of the mini-batch you are reducing noise and therefore regularization effect;</li> <li>Don't rely on batch normalization as a regularization, it's intended for normalization of hidden units, activations and therefore speeding up learning. For regularization use other regularization techniques.</li> </ul> </li> </ul>"},{"location":"Deep-Learning/11_improve_nn/#batch-normalization-at-test-time","title":"Batch normalization at test time","text":"<p>When we train a neural network with batch normalization, we compute the mean and the variance of the mini-batch. But in testing we might need to process examples one each time, whose mean and variance won't make sense. So we have to compute the average across the mini-batch, this is called <code>Running average</code>.</p>"},{"location":"Deep-Learning/11_improve_nn/#softmax-regression","title":"Softmax Regression","text":"<p>The neural networks we trained so far are binary classifications, but there are a generalization of logistic regression called <code>Softmax regression</code> that is used for multiclass classification/regression. In the last layer of the neural network we use the <code>Softmax regression</code> activation instead of <code>sigmoid</code> to classify the classes.</p> \\[ t = e^{Z^{[L]}} \\] \\[ A_{[L]} = \\frac{e^{Z^{[L]}}}{\\sum{t}} \\]"},{"location":"Deep-Learning/11_improve_nn/#trainning-a-softmax-classifier","title":"Trainning a Softmax classifier","text":"<p>There is an activation called <code>hard max</code> which get \\(1\\) for the maximum value and \\(0\\) for others. The <code>softmax</code> named because it's not so <code>hard</code>, it can be values in \\([0, 1]\\).</p> <p>Softmax is a generalization of logistic activation function to <code>C</code> classes. If <code>C = 2</code> then <code>softmax</code> reduces to logistic regression.</p> <p>The loss function used which <code>softmax</code>:</p> \\[ L(y, \\hat{y}) = - \\sum_{j=0}^{C-1}(y^{[j]} * log(\\hat{y}^{[j]})) \\] <p>The cost function used with <code>softmax</code>:</p> \\[ J(w^{[1]}, b^{[1]}, \\cdots) = -\\frac{1}{m} * \\sum_{i=0}^{m}(L(y^{[i]}, \\hat{y}^{[i]})) \\] <p>Back propagation with <code>softmax</code>:</p> \\[ dZ^{[L]} = \\hat{Y} - Y \\] <p>The derivative of softmax is:</p> \\[ \\hat{Y} * (1 - \\hat{Y}) \\] <p></p>"},{"location":"Deep-Learning/12_structure_ml/","title":"Structuring mechine learning projects","text":"<p>You have a lot of ideas for how to improve the accuracy of your deep learning systems:</p> <ul> <li>Collect more data;</li> <li>Collect more diverse training set;</li> <li>Train algorithm longer with gradient descent;</li> <li>Try different optimization algorithm(e.g. Adam);</li> <li>Try bigger network;</li> <li>Try smaller network;</li> <li>Try drop out;</li> <li>Add L2 regularization;</li> <li>Change network architecture(activation functions, number of hidden units, etc.).</li> </ul> <p>This chapter will give you some strategies to help analyze your problem to go in a direction that will help you get better result.</p>"},{"location":"Deep-Learning/12_structure_ml/#orthogonalization","title":"Orthogonalization","text":"<p>Some deep learning developers know exactly what hyperparameter to tune to try to achieve one effect. This is a process we call orthogonalization. In orthogonalization, you have some controls, but each control does a specific task and doesn't affect other controls.</p> <p>For a supervised learning system to do well, you usually need to tune the knobs of your system to make sure that four things hold true:</p> <ol> <li>You'll have to fit trainning set well on cost function(near human level performance if posiible);</li> <li>Fit dev set well on cost function;</li> <li>Fit test set well on cost function;</li> <li>Performs well in real world.</li> </ol>"},{"location":"Deep-Learning/12_structure_ml/#single-number-evaluation-metric","title":"Single number evaluation metric","text":"<p>It's better and faster to set a single number evaluation metric for your project before you start i.</p>"},{"location":"Deep-Learning/12_structure_ml/#precision-and-recall","title":"Precision and recall","text":"<p>Suppose we run the classifier on 10 images which are 5 cats and 5 non-cats. The classifier idetifies that there are 4 cats, but it identified 1 wrong cat. The confusion matrix is:</p> iterm Predicted cat Predicted non-cat Actual cat 3 2 Actual non-cat 1 4 <p>The </p> <ul> <li><code>Precision</code>: perception of true cats in the recognized result: \\(P = \\frac{3}{3+1}\\);</li> <li><code>Recall</code>: perception of the true recognition cats of the all cat predictions: \\(R = \\frac{3}{3+2}\\);</li> <li><code>Accuracy</code>: \\(A = \\frac{3 + 4}{10}\\).</li> </ul> <p>Using a precision/recall for evaluation is good in a lot of cases, but separately they don't tell you which algorithm is better. A better idea is to combine precision and recall in one single number evaluation metric called <code>F1</code>:</p> \\[ F_1 = \\frac{2}{\\frac{1}{P} + \\frac{1}{R}} \\] <p>Sometimes it's hard to get a single number evaluation metrix, ex:</p> Classifier F1 Running time A 90% 80ms B 92% 95ms C 92% 1500ms <p>So we can solve this problem by choosing a single optimizing metric and set that other metrics are satisfying, ex:</p> Metric type Metric optimizing metric Maximizing F1 satisfying metric running time &lt; 100ms <p>The general rule is:</p> <ul> <li>Set \\(1\\) optimizing metric;</li> <li>Set \\(N-1\\) satisfying metric.</li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#traindevtest-distributions","title":"Train/dev/test distributions","text":"<ul> <li>Dev and test sets have to come from the same distribution;</li> <li>Choose dev set and test set to reflect data you expect to get in the future and consider important to do well on;</li> <li>Setting up the dev set as well as the validation metric really depends on what target you want to aim at.</li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#size-of-the-dev-and-test-sets","title":"Size of the dev and test sets","text":"<ul> <li>The old way(number &lt; 100000) of splitting the data was 70% training, 30%  test or 60% training, 20% dev, 20% test;</li> <li>If you have more data, a reasonable split would be 98% training, 1% dev, 1% set.</li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#human-level-performance","title":"Human level performance","text":"<p>We compare to human-level performance because of two main reason:</p> <ol> <li>Because of advances in deep learning, machine learning algorithms are suddenly working much better and so it has become much more feasible in a lot of application areas for machine learning algorithms to actually become competitive with human-level performance.</li> <li>It turns out that the workflow of designing and building a machine learning system is much more efficient when you're trying to do something that humans can also do.</li> </ol> <p>After an algorithm reaches the human-level performance the progress and accuracy slow down.</p> <p></p> <p>You won't surpass an error called \"Bayes optimal error\", and there isn't much error range between human-level error and Bayes optimal error. Humans are good at a lot of tasks. So as long as Mechine learning error is worse than human's, you can:</p> <ul> <li>Get labeled data from humans;</li> <li>Gain insight from manual error analysis: why did a person get it right?</li> <li>Better analysis of bias/variance.</li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#avoidable-bias","title":"Avoidable bias","text":"<p>Suppose that the cat classification algorithm gives these results:</p> Humans 1% 7.5% Trainning error 8% 8% Dev error 10% 10% <p>In the left example, we have to focus on the <code>bias</code> because the human level error is 1%; in the right example, we have to focus on the <code>variance</code> because the human level error is 7.5%. The human-level error is a proxy for Bayes optimal error, Bayes optimal error is always less, but human-level in most case is not far from it. You can't do better than Bayes error unless you are overfitting.</p> <ul> <li><code>Avoidable bias = Traning error - Human(Bayes) error</code></li> <li><code>Variance = Dev error - Trainning error</code></li> </ul> <p>Having an estimate of human-level performance gives you an estimate of Bayes error, this allows you to more quickly make decision which error you should focus to reduce:</p> <ul> <li>If <code>avoidable bias</code> difference is the bigger, then it's a <code>bias</code> problem, and you should use a strategy for <code>bias</code> resolving;</li> <li>If <code>variance</code> difference is bigger, then you should use a strategy for <code>variance</code> resolving.</li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#improving-your-model-performance","title":"Improving your model performance","text":"<p>There are two fundamental assumptions of supervised learning:</p> <ol> <li>You can fit the training set pretty well, this is roughly saying that you can achieve <code>low avoidable bias</code>.</li> <li>The training set performance generalizes pretty well to the dev/test set. This is roughly saying that the <code>variance</code> is not too bad.</li> </ol> <p>Depends on the error difference, we have following guidelines:</p> <ul> <li>If <code>avoidable bias</code> is large, you can:<ol> <li>Train bigger model;</li> <li>Train longer/better optimization algorithm(e.g. Momentum, RMSprop, Adam);</li> <li>Find better neural network architecture or hyperparameters.</li> </ol> </li> <li>If <code>variance</code> is large you can:<ol> <li>Get more training data;</li> <li>Regularization(L2, Dropout, data augmentation);</li> <li>Find better neural network architecture or hyperparameters.</li> </ol> </li> </ul>"},{"location":"Deep-Learning/12_structure_ml/#carrying-out-error-analysis","title":"Carrying out error analysis","text":"<p>Error analysis is the process of manually examining mistakes that your algorihtm is making. It can give you insights into what you should do next. For example, if you have 10% error on your dev set and you want to decrease error. You discovered that some of the mislabled data are dog pictures that look like cats, you should:</p> <ol> <li>Get 100 mislabeled dev set examples at random;</li> <li>Count up how many are dogs.</li> <li>Check the result:<ul> <li>If 5 of 100 are dogs, then training your classifier to do better on dogs will decrease your error up to 9.5%, which means it may not worth it.</li> <li>If 50 of 100 are dogs, then you could decrease your error up to 5%, which is reasonable and you should work on that.</li> </ul> </li> </ol> <p>Sometimes you can evaluate multiple error analysis ideas in parallel and choose the best idea:</p> Image Dot Great Cats Blurry Instagram Filters Comments 1 Y Y Pitbull 2 Y Y Y 3 Rainy day at zoo 4 Y ... total"},{"location":"Deep-Learning/13_cnn/","title":"Convolutional Neural Networks","text":"<p>todo</p>"},{"location":"Deep-Learning/14_rnn/","title":"Sequence models","text":""},{"location":"Deep-Learning/14_rnn/#recurrent-neural-networks","title":"Recurrent neural networks","text":"<p>This type of model has been proven to perform extremely well on temporal data. It has several variants including LSTM, GRU and Bidirectional RNN.</p>"},{"location":"Deep-Learning/14_rnn/#why-sequence-models","title":"Why sequence models","text":"<p>Sequence models like RNN and LSTMs have greatly transformed learning on sequences in the past few years. Here are some sequence data examples in applications:</p> <ul> <li>Speech recognition(sequence to sequence):<ul> <li>X: wave sequence</li> <li>Y: text sequence</li> </ul> </li> <li>Music generation(one to sequence):<ul> <li>X: nothing or an integar</li> <li>Y: wave sequence</li> </ul> </li> <li>Sentiment classification(sequence to sequence):<ul> <li>X: text sequence</li> <li>Y: integar rating from one to five</li> </ul> </li> <li>DNA sequence analysis(sequence to sequence):<ul> <li>X: DNA sequence</li> <li>Y: DNA labels</li> </ul> </li> <li>Machine translation(sequence to sequence):<ul> <li>X: text sequence(in one language)</li> <li>Y: text sequence(in another language)</li> </ul> </li> <li>Video activity recognition(sequence to one):<ul> <li>X: video frames</li> <li>Y: label(activity)</li> </ul> </li> <li>Name entity recognition(sequence to sequence):<ul> <li>X: text sequence</li> <li>Y: label sequence</li> </ul> </li> </ul> <p>All these problems with different input and output(sequence or not) can be addressed as supervised learning with labeled data X/Y as the training set.</p>"},{"location":"Deep-Learning/14_rnn/#notation","title":"Notation","text":"<p>We now discuss the notation we used in this course.</p> <p>We name entity recognition:</p> <ul> <li>X: \"Harry Potter and Hermoine Granger invented a new spell.\"</li> <li>Y:  1     1      0   1        1       0        0 0   0</li> </ul> <p>Both elements have a shape of \\((9, 1)\\). \\(1\\) means it's a name and \\(0\\) means it's not a name.</p> <p>We will index the first element of \\(x\\) by \\(x^{&lt;1&gt;}\\), the second \\(x^{&lt;2&gt;}\\) and so on:</p> \\[ x^{&lt;1&gt;}, x^{&lt;2&gt;}, \\cdots, x^{&lt;n&gt;} \\] <p>Similarly, we will index the first element of \\(y\\) by \\(y^{&lt;1&gt;}\\) and the second \\(y^{&lt;2&gt;}\\) and so on:</p> \\[ y^{&lt;1&gt;}, y^{&lt;2&gt;}, \\cdots, y^{&lt;n&gt;} \\] <p>We use:</p> <ul> <li>\\(T_x\\) to represent the size of input sequence;</li> <li>\\(T_y\\) to represent the size of output sequence;</li> <li>\\(x^{(i)&lt;t&gt;}\\) is the \\(t\\)th element of the sequence of input vector \\(i\\);</li> <li>\\(y^{(i)&lt;t&gt;}\\) is the \\(t\\)th element in the output sequence of \\(i\\)th training exmaple;</li> <li>\\(T_x^{(i)}\\) is the sequence length for training example \\(i\\), it can be different across the examples;</li> <li>\\(T_y^{(i)}\\) is the length for output sequence in the \\(i\\)th training example.</li> </ul> <p>One of the challenges of natural language processing(NLP) is how can we represent a word.</p> <p>We need a <code>vocabulary</code> list that contains all the words in our target sets, for example:</p> \\[ \\begin{bmatrix} a \\\\\\\\ \\vdots \\\\\\\\ And \\\\\\\\ \\vdots \\\\\\\\ Harry \\\\\\\\ \\vdots \\\\\\\\ Potter \\\\\\\\ \\vdots \\\\\\\\ Zulu \\end{bmatrix} \\] <p>Each word will have a unique index that it can be represented with, and the sorting here is in alphabetical order. vocabulary sizes in modern applications are from \\(30000\\) to \\(50000\\), \\(100000\\) is not uncommon, some of the bigger companies use even a million.</p> <p>And then you create a <code>one-hot</code> encoding sequence for each word in your dataset given the vocabulary you have created.</p> \\[ \\begin{bmatrix} 0 \\\\\\\\ \\vdots \\\\\\\\ 0 \\\\\\\\ \\vdots \\\\\\\\ 1 \\\\\\\\ \\vdots \\\\\\\\ 0 \\\\\\\\ \\vdots \\\\\\\\ 0 \\end{bmatrix} \\] <p>While converting, if a word is not in your dictionary, you can add a token in the vocabulary with name <code>&lt;UNK&gt;</code> wich stands for unknown text and use its index for your <code>one-hot</code> vector.</p>"},{"location":"Deep-Learning/14_rnn/#recurrent-neural-network-model","title":"Recurrent neural network model","text":"<p>Why not using a standard network for sequence tasks? There are two problems:</p> <ol> <li>inputs and outputs can be different lengths in different example.</li> <li>this doesn't share features learned across different positions of text/sequence.</li> </ol> <p>Recurrent neural network doesn't have either of the two mentioned problems.</p> <p>Let's build a <code>RNN</code> to solve the <code>name entity recognition</code> task: </p> <p>In this problem, \\(T_x = T_y\\). In other problems they may be not equal.</p> <p>\\(a^{&lt;0&gt;}\\) is usually initialized with zeros, but some other problems may initialize it randomly.</p> <p>There are three weight matrices here with shape:</p> <ul> <li>\\(W_{ax}\\): (NumberOfHiddenNeurons, \\(n_x\\));</li> <li>\\(W_{aa}\\): (NumberOfHiddenNeurons, NumberOfHiddenNeurons)</li> <li>\\(W_{ya}\\): (\\(n_y\\), NumberOfHiddenNeurons)</li> </ul> <p>The weight matrix \\(W_{aa}\\) is the memory that RNN is trying to maintain from previous layers.</p> <p>A lot of papers and books write the same architecture in right figure way.</p> <p>The limitation fo the discussed architecture is that it can not learn from elements later in the sequence.</p> <p>The forward propagation is as follows:</p> \\[ a^{&lt;0&gt;} = \\vec{0} \\] \\[ a^{&lt;1&gt;} = g_1(w_{aa}a^{&lt;0&gt;} + w_{ax}x^{&lt;1&gt;} + b_a) \\gets tanh | Relu \\] \\[ y^{&lt;1&gt;} = g_2(w_{ya}a^{&lt;1&gt;} + b_y) \\gets sigmoid \\] \\[ a^{&lt;t&gt;} = g(w_{aa}a^{&lt;t-1&gt;} + w_{ax}x^{&lt;t&gt;} + b_a) \\] \\[ y^{&lt;t&gt;} = g_2(w_{ya}a^{&lt;t&gt;} + b_y) \\] <p>where:</p> <ul> <li>The activation function of \\(a\\) is usually \\(tanh\\) or \\(ReLU\\);</li> <li>The activation function for \\(y\\) is depending on your task and choosing \\(sigmoid\\) or \\(softmax\\).</li> </ul> <p>Inorder to help us develop complex RNN architecture, the last equations needs to be simplified a lot:</p> <p>Simplify:</p> \\[ a^{&lt;t&gt;} = g(w_{aa}a^{&lt;t-1\\&gt;} + w_{ax}x^{&lt;t\\&gt;} + b_a) \\] <p>to:</p> \\[ a^{&lt;t&gt;} = g(w_{a}[a^{&lt;t-1\\&gt;}, x^{&lt;t&gt;}]^T + b_a) \\] <p>where</p> \\[ w_a = \\begin{bmatrix} w_{aa}, w_{ax}\\end{bmatrix} \\] <p>In the equation,</p> <ul> <li>\\(w_a\\) is \\(w_{aa}\\) and \\(w_{ax}\\) stacked horizontally;</li> <li>\\([a^{&lt;t-1&gt;}, x^{&lt;t&gt;}]^T\\) is \\(a^{&lt;t-1&gt;}\\) and \\(x^{&lt;t&gt;}\\) stacked vertically;</li> <li>the shape of \\(w_a\\) is \\((NumberOfHiddenNeurons, NumberOfHiddenNeurons + n_x)\\);</li> <li>the shape of \\([a^{&lt;t-1&gt;}, x^{&lt;t&gt;}]^T\\) is \\((NumberOfHiddenNeurons + n_x, NumberOfHiddenNeurons)\\).</li> </ul> <p>Following is the architecture for a single cell: </p>"},{"location":"Deep-Learning/14_rnn/#backpropagation-through-time","title":"Backpropagation through time","text":"<p>Usually deep learning frameworks do backpropagation automatically for you, but it's useful to know how it works in RNN.</p> <p>To calculate backpropagation, and update RNN parameters with gradient descent methods, we define the cross-entropy loss function:</p> \\[ L^{&lt;t&gt;}(\\hat y^{&lt;t&gt;}, y^{&lt;t&gt;}) = -y^{&lt;t&gt;}log(\\hat y^{&lt;t&gt;}) - (1 - y^{&lt;t&gt;})log(1-\\hat y^{&lt;t&gt;}) \\] <p>This equation is the loss for one example, and the loss for the whole sequence is given by the summation over all the calculated single example losses:</p> \\[ L(\\hat y, y) = \\sum_{t=1}^{T_x}{L^{&lt;t&gt;}(\\hat y^{&lt;t&gt;}, y^{&lt;t&gt;})} \\] <p></p> <p>The backpropagation here is called <code>backpropagation through time</code> because we pass activation \\(a\\) from one sequence element to another like backwards in time.</p>"},{"location":"Deep-Learning/14_rnn/#different-types-of-rnn","title":"Different types of RNN","text":"<p>So far we have seen only one RNN architecture in which \\(T_x = T_y\\). Other architectures can be: </p>"},{"location":"Deep-Learning/14_rnn/#vanishing-gradient","title":"Vanishing gradient","text":"<p>One of the problems with naive RNNs is that they run into <code>vanishing gradient</code> problem. An RNN that process a sequence data with the size of 10000 time steps has 10000 deep layers which is very hard to optimize.</p> <p>Let's take an example. Suppose we are working with language modeling problem and there are two sequences that model tries to learn:</p> <ul> <li>The <code>cat</code>, which already ate ..., <code>was</code> full.</li> <li>The <code>cats</code>, which already ate ..., <code>were</code> full.</li> </ul> <p>What we need to learn is that <code>was</code> came with <code>cat</code> and <code>were</code> came with <code>cats</code>. The naive RNN is not very good at capturing very long-term dependencies like this.</p> <p>As we discussed before, deeper networks are getting into vanishing gradient problem, this also happens with RNNs with long sequence size. For computing the word <code>was</code>, we need to compute the gradient for everything behind. Multiplying fractions tends to vanish the gradient, while the multiplication of large number tends to explode it.</p> <p>The conclusion is:</p> <p>RNNs are not good at long-term dependencies.</p> <p>Exploding gradients can be easily seen when your weight values become <code>Nan</code>. So one of the methods to solve exploding gradient is to apply <code>gradient clipping</code>, which means if your gradient is more than some threshold, rescale some of your gradient vector so that it's not too big.</p> <p>The solution for <code>exploding gradient</code> problems:</p> <ul> <li>Truncated backpropagation<ul> <li>Not to update all the weights in the way back</li> <li>Not optimal. You won't update all the weights</li> </ul> </li> <li>Gradient clipping</li> </ul> <p>The solution for <code>vanishing gradient</code> problems:</p> <ul> <li>Weight initialization<ul> <li>Like He initialization</li> </ul> </li> <li>Echo state networks</li> <li>Use LSTM/GRU networks<ul> <li>Most popular</li> </ul> </li> </ul>"},{"location":"Deep-Learning/14_rnn/#gated-recurrent-unitgru","title":"Gated Recurrent Unit(GRU)","text":"<p>GRU is an RNN type that can help solve the vanishing gradient problem and can remember the long-term dependencies.</p> <p>The basic RNN unit can be visualized to:</p> <p></p> <p>The drawing for GRU is similar. Each layer in GRU has a new variable <code>C</code> called <code>memory cell</code> which can tell whether meorize something or not. In GRUs, \\(C^{&lt;t&gt;} = a^{&lt;t&gt;}\\), the equations are:</p> \\[ \\tilde c^{&lt;t&gt;} = tanh(W_c[c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c) \\] \\[ \\Gamma_u = \\sigma(W_u[c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u) \\] \\[ c^{&lt;t&gt;} = \\Gamma_u \\times \\tilde c^{&lt;t&gt;} + (1 - \\Gamma_u) \\times c^{&lt;t-1&gt;} \\] <p>The \\(\\Gamma_u\\) is called <code>update gate</code>, and it's value is between 0 and 1.</p> <p></p> <p>Because the update gate U is usually a small number like \\(0.000001\\), GRUs doesn't suffer the vanishing gradient problem.</p> <p>The GRU above is the simplified GRU unit, the full one is:</p> \\[ \\tilde c^{&lt;t&gt;} = tanh(W_c[\\Gamma_r \\times c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c) \\] \\[ \\Gamma_u = \\sigma(W_u[c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u) \\] \\[ \\Gamma_r = \\sigma(W_r[c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_r) \\] \\[ c^{&lt;t&gt;} = \\Gamma_u \\times \\tilde c^{&lt;t&gt;} + (1 - \\Gamma_u) \\times c^{&lt;t-1&gt;} \\]"},{"location":"Deep-Learning/14_rnn/#long-short-term-memorylstm","title":"Long Short Term Memory(LSTM)","text":"<p>LSTM is another type of RNN that can enable you to account for long-term dependencies. It's more powerful and general than GRU.</p> <p>In LSTM, \\(C^{&lt;t&gt;} != a^{&lt;t&gt;}\\):</p> \\[ \\tilde{C}^{&lt;t&gt;} = tanh(W_c[a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c) \\] \\[  \\Gamma_u = \\delta(W_u[a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u) \\] \\[  \\Gamma_f = \\delta(W_f[a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_f) \\] \\[  \\Gamma_o = \\delta(W_o[a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_o) \\] \\[ C^{&lt;t&gt;} = \\Gamma_u \\times \\tilde{C}^{&lt;t&gt;} + \\Gamma_f \\times C^{&lt;t-1&gt;} \\] \\[ a^{&lt;t&gt;} = \\Gamma_o \\times tanh C^{&lt;t&gt;} \\] <p>In LSTM, we have:</p> <ul> <li>update gate: \\(\\Gamma_u\\);</li> <li>forget gate: \\(\\Gamma_f\\);</li> <li>output gate: \\(\\Gamma_o\\);</li> <li>candidate cell variable: \\(\\tilde{C}^{&lt;t&gt;}\\).</li> </ul> <p>  One of the advantages of GRU is that it's simpler and can be used to build much bigger network but the LSTM is more powerful and general.</p>"},{"location":"Deep-Learning/14_rnn/#bidirectional-rnn","title":"Bidirectional RNN","text":"<p>There are still some idea to let you build much more powerful sequence models. One of them is bidirectional RNNs and another is Deep RNN.</p> <p>One directional RNN can only learned the information before this position, but BiRNN fixes this issue. </p> <ul> <li>BiRNN is an acyclic graph.</li> <li>Part of the forward propagation goes from left to right and part from right to left. It learns from boths side.</li> <li>To make prediction we use \\(\\tilde y^{&lt;t&gt;}\\) with two activation that come from left and right.</li> <li>The blocks here can be any RNN block including the basic RNNs, LSTMs or GRUs.</li> <li>For a lot of NLP or text processing problems, a BiRNN with LSTM appears to be commonly used.</li> <li>The disadvantage of BiRNNs is that you need the entire sequence before you can process it. For example, in live speech recognition if you use BiRNNs you will need to wait for the speaker to stop to take the entire sequence and then make your predictions.</li> </ul>"},{"location":"Deep-Learning/14_rnn/#deep-rnns","title":"Deep RNNs","text":"<p>In a lot of cases the standard one layer RNNs will solve your problem. But in some problems its useful to stack some RNN layers to make a deeper network. For example, a deep RNN with 3 layers would look like this: </p> <p>In feed-forward deep nets, there could be 100 or even 200 layers. In deep RNNs stacking 3 layers is already considered deep and expensive to train.</p>"},{"location":"Math/Calculus/000_summary/","title":"Summary","text":"<p>There are the notes I took while learning the book The Calculus Lifesaver</p> <p>TODO:</p> <ul> <li> add last chapter of the book</li> <li> add mind map for this course</li> </ul> <p></p>"},{"location":"Math/Calculus/00_functions/","title":"Functions","text":"<p>A <code>function</code> is a rule for transforming an object into another object. The object you start with is called the <code>input</code>, and comes from some set called the <code>domain</code>. What you get back is called the <code>output</code>; it comes from some set called the <code>codomain</code>, and the output's value is within a <code>range</code>. A function must assign a unique output for each valid input.</p> <p>We say that a function \\(f\\) is:</p> <ul> <li><code>even</code>, if \\(f(-x) = f(x)\\) for all \\(x\\) in the domain of \\(f\\); </li> <li><code>odd</code>, if \\(f(-x) = -f(x)\\) for all \\(x\\) in the domain of \\(f\\).</li> </ul> <p>The graph of an even function has mirror symmetry about the y-axis and the graph of an odd function has \\(180^\\circ\\) point symmetry about the origin.</p> <p>Let's look at some common functions and their graphs.</p>"},{"location":"Math/Calculus/00_functions/#linear-functions","title":"Linear Functions","text":"<p>Functions of the form \\(f(x) = mx + b\\) are called <code>linear</code>. There's a good reason for this: the graph of these functions are lines. The slop of the line is given by \\(m\\), and the y-intercept is equal to \\(b\\). To sketch the graph of a linear function, you only need to identify two points on the graph. Set \\(x = 0\\), you get a point \\((0, b)\\), and set \\(y = 0\\) you get another point \\((-\\frac{b}{a}, 0)\\). Examples are like this:</p> <p></p>"},{"location":"Math/Calculus/00_functions/#polynomials","title":"Polynomials","text":"<p>These are functions built out of nonnegative integer powers of \\(x\\). You start with the building blocks \\(1\\), \\(x\\), \\(x^2\\), \\(x^3\\), and so on, and you are allowed to multiply these basic functions by numbers and add a finite number of them together. The amount that you multiply the building block \\(x^n\\) by is called the <code>coefficient</code> of \\(x^n\\). The highest number \\(n\\) such that \\(x^n\\) has a non zero coefficient is called the <code>degree</code> of the polynomial. The mathematical way to write a general polynomial of degree \\(n\\) is:</p> \\[ p(x) = a_n x^n + a_{n - 1}x^{n - 1} + ... + a_2x^2 + a_1x + a_0 \\] <p>where \\(a_n\\) is the coefficient of \\(x^n\\), \\(a_{n - 1}\\) is the coefficient of \\(x^{n - 1}\\), ans so on down to \\(a_0\\), which is the coefficient of \\(1\\).</p> <p>Since the functions \\(x^n\\) are the building blocks of all polynomials, you should know what their graphs look like. The even powers mostly look similar to each other, and the same can be said for the odd powers. Here's what the graphs look like, from \\(x^0\\) up to \\(x^7\\):</p> <p></p> <p>Sketching the graphs of more general polynomials is more difficult. Even finding the x-intercepts is often impossible unless the polynomial is very simple. There is one aspect of the graph that is fairly straightforward, which is what happens at the far left and right sides of the graph. This is determined by the so-called <code>leading coefficient</code>, which is the coefficient of the highest-degree term.In fact, it only matters whether the leading coefficient is positive or negative. It also matters whether the degree of the polynomial is odd or even; so there are four possibilities for what the edges of the graph can look like:</p> <p></p>"},{"location":"Math/Calculus/00_functions/#rational-functions","title":"Rational functions","text":"<p>The functions with the form:</p> \\[ f(x) = \\frac{p(x)}{q(x)} \\] <p>are called <code>Rational functions</code>, where <code>p</code> and <code>q</code> are polynomials. Rational functions will pop up in many different contexts, and the graphs can look really different depending on the polynomials <code>p</code> and <code>q</code>. The simplest examples of rational functions are polynomials themselves, which arise when <code>q(x)</code> is the constant polynomial \\(1\\). The next simplest examples are the functions \\(\\frac{1}{x^n}\\), where \\(n\\) is a positive integer. Let's look at some of the graph of these functions:</p> <p></p> <p>The odd powers look similar to each other, and the even powers look similar to each other too. </p>"},{"location":"Math/Calculus/00_functions/#exponential-functions","title":"Exponential functions","text":"<p>Functions with the form:</p> \\[ f(x) = a \\cdot b^x \\] <p>are called <code>Exponential functions</code>, where \\(a\\) is a coefficient, \\(b\\) is a positive real number, and \\(x\\) occurs as an <code>exponent</code>.</p> <p>The graph of \\(f(x) = b^x\\) for any other base \\(b &gt; 0\\) looks similar to this:</p> <p></p> <p>and the graph of \\(f(x) = b^{-x}\\) is just the reflection of \\(f(x) = b^{x}\\) in <code>y-axis</code>.</p> <p></p> <p>If \\(a\\) is negtive, the graph will be the reflection of its positive one.</p>"},{"location":"Math/Calculus/00_functions/#logarithm-functions","title":"Logarithm functions","text":"<p>When a functions has the form:</p> \\[ f(x) = a \\cdot \\log_b(x) \\] <p>we called it a <code>logarithm function</code>. Logarithm functions are the inverse functions of the exponential functions. Using the line \\(y = x\\) as a mirror, the graph of \\(y = \\log_{2}(x)\\) looks like this:</p> <p></p>"},{"location":"Math/Calculus/00_functions/#trig-functions","title":"Trig functions","text":""},{"location":"Math/Calculus/00_functions/#definitions","title":"Definitions","text":""},{"location":"Math/Calculus/00_functions/#radians","title":"Radians","text":"<p>The first thing we need to know is the notion of <code>radian</code>. Instead of saying that there are 360 degrees in a full revolution, we'll say that there are \\(2\\pi\\) radians. The arc length of a wedge of the circle is the angle of the wedge:</p> <p></p>"},{"location":"Math/Calculus/00_functions/#trigonometry-functions","title":"Trigonometry Functions","text":"<p>Suppose you have a right-angled triangle and one of the angles, other than the right angle, is labeled \\(\\theta\\), like this:</p> <p></p> <p>the formulas are defined:</p> \\[ \\sin(\\theta) = \\frac{opposite}{hypotenuse}, \\cos(\\theta) = \\frac{adjacent}{hypotenuse}, \\tan(\\theta) = \\frac{opposite}{adjacent} \\] <p>We'll also be using the reciprocal functions, which are defined as:</p> \\[ \\csc(x) = \\frac{1}{\\sin(x)}, \\sec(x) = \\frac{1}{\\cos(x)}, \\cot(x) = \\frac{1}{\\tan(x)} \\]"},{"location":"Math/Calculus/00_functions/#value-of-trigonometry","title":"Value of Trigonometry","text":"<p>Now it's time to figure out the value of trig functions.</p>"},{"location":"Math/Calculus/00_functions/#with-the-domain-of-0-fracpi2","title":"With the Domain of \\(0 - \\frac{\\pi}{2}\\)","text":"<p>It may be really difficult to calculate the value of trig functions with out a calculator, but some common angles's vlaue you must keep in mind:</p> <p></p>"},{"location":"Math/Calculus/00_functions/#with-the-domain-of-0-2pi","title":"With the Domain of \\(0 - 2\\pi\\)","text":"<p>If an angle is bigger than \\(2\\pi\\), for example, \\(\\frac{7\\pi}{6}\\), we can draw it on the coordinate plane:</p> <p></p> <p>So the angle \\(7\\pi/6\\) is in the third quadrant. We've chosen the point on the ray which has distance \\(r = 1\\) from the origin, then dropped a perpendicular. The angle between the ray and the \\(-\\pi\\) axis is \\(\\pi / 6\\), and we already know that \\(\\sin(\\theta) = \\frac{y}{1}\\), \\(y &lt; 0\\), so we got:</p> \\[ \\sin(\\frac{7\\pi}{6}) = -\\sin(\\frac{\\pi}{6}) = -\\frac{1}{2} \\] <p>The key in the previous example is that \\(\\sin(\\frac{7\\pi}{6})\\) is related to \\(\\sin(\\frac{\\pi}{6})\\), where \\(\\frac{\\pi}{6}\\) is the reference angle for \\(\\frac{7\\pi}{6}\\). It's not difficult to find that the trig functions of any anlge is puls or minus value of the reference angle. This can be described as the <code>ASTC Method</code>:</p> <p></p> <p>The letters <code>ASTC</code> on the diagram are all you need to remember. <code>A</code> stands for <code>All</code>, meaning all the functions are positive in the first quadrant; the other letters obviously stand for sin, tan, and cos, respectively.</p>"},{"location":"Math/Calculus/00_functions/#with-the-domain-outside-0-2pi","title":"With the Domain outside \\(0 - 2\\pi\\)","text":"<p>If the angle is bigger than \\(2\\pi\\) or less than \\(0\\), we can simple add or subtract multiples of \\(2\\pi\\) until you get between \\(0\\) and \\(2\\pi\\)</p>"},{"location":"Math/Calculus/00_functions/#graphs","title":"Graphs","text":"<p>It's really useful to remember what the graphs of the sin, cos, and tan functions look like. These functions are all <code>periodic</code>, meaning that they repeat themselves over and over again from left to right:</p> <p> </p> <p>It's also worthwhile learning the graph of \\(y = \\sec(x)\\), \\(y = \\csc(x)\\), and \\(y = \\cot(x)\\):</p> <p> </p> <p>From their graphs, we can get the following symmetry properties:</p> <p>\\(\\sin(x)\\), \\(\\tan(x)\\), \\(\\cot(x)\\), and \\(csc(x)\\) are odd functions of \\(x\\). \\(\\cot(x)\\) and \\(\\sec(x)\\) are even functions of \\(x\\).</p>"},{"location":"Math/Calculus/00_functions/#identities","title":"Identities","text":"<p>There are relations between trig functions which will come in handy. </p>"},{"location":"Math/Calculus/00_functions/#tan-and-cot","title":"\\(tan\\) and \\(cot\\)","text":"<p>First, tan and cot may be expressed in terms of sin and cos as follows:</p> \\[ \\tan(x) = \\frac{\\sin(x)}{\\cos(x)}, \\cot(x) = \\frac{\\cos(x)}{\\sin(x)} \\]"},{"location":"Math/Calculus/00_functions/#pythagoras-theorem","title":"Pythagoras' Theorem","text":"<p>The most important of all the trig identities is <code>Pythagoras' Theorem</code>:</p> \\[ \\cos^2(x) + \\sin^2(x) = 1 \\] <p>Now divide this equation by \\(\\cos^2(x)\\), we got:</p> \\[ 1 + \\tan^2(x) = \\sec^2(x) \\] <p>If you dived the <code>Pythagorean equation</code> above by \\(\\sin^2(x)\\), you got:</p> \\[ \\cot^2(x) + 1 = \\csc^2(x) \\]"},{"location":"Math/Calculus/00_functions/#trig-functions-and-co-trig-functions","title":"trig functions and co-trig functions","text":"<p>There are some more relationships between trig functions. Have you noticed that some of the names begin with the syllable <code>co</code>? This is short for the word <code>complementary</code>. The fact is that we have the following general relationship:</p> \\[ trig functions(x) = co-trig functions(\\frac{\\pi}{2} - x) \\] <p>So in particular, we have</p> \\[ \\sin(x) = \\cos(\\frac{\\pi}{2} - x), \\tan(x) = \\cot(\\frac{\\pi}{x} - x), \\sec(x) = \\csc(\\frac{\\pi}{2} - x) \\] <p>It even works when the trig function is already a <code>co</code>:</p> \\[ \\cos(x) = \\sin(\\frac{\\pi}{2} - x), \\cot(x) = \\tan(\\frac{\\pi}{2} - x), \\csc(x) = \\sec(\\frac{\\pi}{2} - x) \\]"},{"location":"Math/Calculus/00_functions/#sums-of-angles","title":"Sums of Angles","text":"<p>Specifically, you should remember that:</p> \\[ \\sin(A + B) = \\sin(A)\\cos(B) + \\cos(A)\\sin(B) \\] \\[ \\cos(A + B) = \\cos(A)\\cos(B) - \\sin(A)\\sin(B) \\] <p>It's useful to remember that you can switch all the pluses and minuses to get some related formulas:</p> \\[ \\sin(A - B) = \\sin(A)\\cos(B) - \\cos(A)\\sin(B) \\] \\[ \\cos(A - B) = \\cos(A)\\cos(B) + \\sin(A)\\sin(B) \\] <p>And if \\(A = B\\), we got:</p> \\[ \\sin(2x) = 2\\sin(x)\\cos(x) \\] \\[ \\cos(2x) = 2\\cos^2(x) - 1 = 1 - 2\\sin^2(x) \\]"},{"location":"Math/Calculus/01_limits/","title":"Limits","text":"<p>Calculus wouldn't exist without the concept of limits. It turns out that it's pretty tricky to define a limit properly, but you can get an intuitive understanding of limits even without going into the glory details</p>"},{"location":"Math/Calculus/01_limits/#the-basic-idea","title":"The basic idea","text":"<p>We start with some function \\(f\\) and a point on the \\(x\\)-axis which we call \\(a\\). Here is what we'd like to understand:</p> <p>What does \\(f(x)\\) look like when \\(x\\) is really close to \\(a\\), but not equal to \\(a\\) ? </p> <p>Suppose that we have a a function \\(f\\) with domain \\(\\mathbb{R}\\backslash\\{2\\}\\), and set \\(f(x) = x - 1\\) on this domain. Formally we wright:</p> \\[ f(x) = x - 1 \\quad when \\quad x \\ne 2 \\] <p>The graph of the function is like:</p> <p></p> <p>You can get as close as you want to \\(1\\), without actually getting to \\(1\\) by letting \\(x\\) be close enough to \\(2\\). Without getting bogged down, we just write:</p> \\[ \\lim_{x \\to 2}f(x) = 1 \\] <p>which read as:</p> <p>the limit, as \\(x\\) goes to \\(2\\), of \\(f(x)\\) is equal to \\(1\\). As \\(x\\) journeys along the number line from the left or the right toward the number \\(2\\), the value of \\(f(x)\\) gets very very close to \\(1\\)(and stays close!).</p> <p>And what if the function has special value at limit point? For example, we have:</p> \\[ g(x) =  \\begin{cases} x - 1 &amp; if \\quad x \\ne 2, \\\\ 3 &amp; if \\quad x = 2. \\end{cases} \\] <p>What is \\(\\lim_{x \\to 2}g(x)\\)? The tricky here is that the value of \\(g(x)\\) is irrenlevent with \\(\\lim_{x \\to 2}g(x)\\), it's only the values of \\(g(x)\\) where  \\(x\\) is close to \\(2\\), not actually at 2, which matter.</p> <p>So, \\(\\lim_{x \\to 2}g(x) = 1\\) as before, even though \\(g(x) = 3\\).</p>"},{"location":"Math/Calculus/01_limits/#left-hand-and-right-hand-limits","title":"Left-hand and right-hand limits","text":"<p>If we have a function graph like this: </p> <p>Of course \\(h(x) = 2\\) is irrelevant as far as the limiting behavior is concerned.  </p> <p>Imagine that you're the hiker in the picture, climbing up and down the hill. The value of \\(h(x)\\) tells you how high up you are when your horizontal position is at \\(x\\). So if you walk right ward from the left of the picture, you get the <code>left-hand limit</code> of \\(h(x)\\) at \\(x = 3\\) is equal to \\(1\\). On the other hand, if you are walking leftward from the right-hand side of the picutre, your height becomes close to \\(-2\\) as your horizontal position gets close to \\(x =3\\). This means that the <code>right-hand limit</code> is equal to \\(-2\\).</p> <p>We can summarize our findings from above by writing: $$ \\lim_{x \\to 3^-} h(x) = 1 $$</p> <p>and</p> \\[ \\lim_{x \\to 3^+} h(x) = -2 \\] <p>The minus sign after \\(3\\) means the limit is a <code>left-hand limit</code>, and the plus sign means the limit is a <code>right-hand limit</code>.</p> <p>The regular two-sided limit at \\(x = a\\) exists exactly when both left-hand and right-hand limits at \\(x = a\\) exist and are equal to each other. If the left-hand limit and right-hand limit are not equal, the two-sided limit does not exist, written as:</p> \\[ \\lim_{x \\to 3} h(x) = DNE \\]"},{"location":"Math/Calculus/01_limits/#limits-at-infty-and-infty","title":"Limits at \\(\\infty\\) and \\(-\\infty\\)","text":"<p>In above parts we've concentrated on the behavior of a function near a point \\(x = a\\), however sometimes it's important to understand how a function behaves when \\(x\\) gets really huge. We defines the <code>large</code> and <code>small</code> number as this:</p> <p>A number is</p> <ul> <li><code>large</code>, if its absolute value is really big number;</li> <li><code>small</code>, if it is really close to \\(0\\)(but not actually equal to \\(0\\)).</li> </ul> <p>We can say the limit at infinity as:</p> <ul> <li>\"f has a right-hand horizontal asymptote at y = L\", means:</li> </ul> \\[ \\lim_{x \\to \\infty} f(x) = L \\] <ul> <li>\"f has a left-hand horizontal asymptote at y = M\", means:</li> </ul> \\[ \\lim_{x \\to -\\infty} f(x) = M \\]"},{"location":"Math/Calculus/01_limits/#two-common-misconceptions-about-asymptotes","title":"Two common misconceptions about asymptotes","text":""},{"location":"Math/Calculus/01_limits/#a-function-doesnt-have-to-have-the-same-horizontal-asymptote-on-the-left-as-on-the-right","title":"A function doesn't have to have the same horizontal asymptote on the left as on the right.","text":"<p>For example, the graph of \\(y = tan^{-1}(x)\\) looks like:</p> <p></p> <p>it has the limit of:</p> <ul> <li>\\(\\lim_{x \\to \\infty} tan^{-1}(x) = \\frac{\\pi} {2}\\)</li> <li>\\(\\lim_{x \\to -\\infty} tan^{-1}(x) = -\\frac{\\pi} {2}\\)</li> </ul>"},{"location":"Math/Calculus/01_limits/#a-function-can-cross-its-asymptote","title":"A function can cross its asymptote.","text":"<p>The graph of \\(y = \\frac{\\sin(x)}{x}\\) is like:</p> <p></p> <p>and it crosses its aymptote many times.</p>"},{"location":"Math/Calculus/01_limits/#the-sandwich-principle","title":"The sandwich principle","text":"<p>The <code>sandwich principle</code>, also known as <code>squeeze principle</code>, says that:</p> <p>If a function \\(f\\) is sandwiched between two functions \\(g\\) and \\(h\\) that converge to the same limit \\(L\\) as \\(x \\to a\\), then \\(f\\) also converges to \\(L\\) as \\(x \\to a\\).</p> <p>There is a similar version of the sandwich principle for one-sided limits, except this time the inequality \\(g(x) &lt; f(x) &lt; h(x)\\) only has to hold for \\(x\\) on the side of \\(a\\) that you care about. </p> <p>For example, the function \\(f(x) = x sin(\\frac{1}{x})\\) is sandwiched by \\(h(x) = x\\) and \\(g(x) = -x\\):</p> <p></p> <p>we can say that:</p> \\[ \\lim_{x \\to +0} x \\sin(\\frac{1}{x}) = 0. \\] <p>In summary if:</p> \\[ g(x) \\le f(x) \\le h(x) \\] <p>for all \\(x\\) near \\(a\\), and</p> \\[ \\lim_{x \\to a} g(x) = \\lim_{x \\to a} h(x) = L \\] <p>then:</p> \\[ \\lim_{x \\to a} f(x) = L. \\]"},{"location":"Math/Calculus/02_limits_polynomials/","title":"Limit Problems of Polynomials","text":"<p>When you're talking about the limit of a ratio of two polynomials, it's really important to notice where the limit is being taken. In particular, the techniques for dealing with \\(x \\to \\infty\\) and \\(x \\to a\\) (some finite \\(a\\)) are completely different.</p>"},{"location":"Math/Calculus/02_limits_polynomials/#limits-involving-rational-functions-as-x-to-a","title":"Limits Involving Rational Functions as \\(x \\to a\\)","text":"<p>If the denominator is not \\(0\\), you can just substitute the variable \\(x\\) with its value:</p> \\[ \\lim_{x \\to -1} \\frac{x^2 - 3x + 2} {x - 2} = \\frac{(-1)^2 - 3(-1) + 2}{-1 - 2} = \\frac{6}{-3} = -2 \\] <p>But if you want to find:</p> \\[ \\lim_{x \\to 2} \\frac{x^2 - 3x + 2} {x - 2} \\] <p>the substitutiong method may not work, you'll get \\((4 - 6 + 2) / (2 - 2)\\), which is \\(0 / 0\\). This is called an indeterminate form. The technique we used to solve this is called <code>factoring</code>:</p> \\[ \\lim_{x \\to 2} \\frac{x^2 - 3x + 2} {x - 2} = \\lim_{x \\to -2} \\frac{(x - 2)(x - 1)} {x - 2} = \\lim_{x - 2}(x - 1) \\] <p>Now we plug \\(x = 2\\) into the expression \\((x - 1)\\), then we get \\(1\\). That's the value of the limit we're looking for.</p> <p>In addition to knowing how to factor quadratics, it's really useful to know the formula for the difference of two cubes:</p> \\[ a^3 - b^3 = (a - b)(a^2 + ab + b^2) \\] <p>But what if the denominator is \\(0\\) but the numerator is not \\(0\\)? There are four types of behavior that could arise: </p> <p></p>"},{"location":"Math/Calculus/02_limits_polynomials/#limits-involving-square-roots-as-x-to-a","title":"Limits Involving Square Roots as \\(x \\to a\\)","text":"<p>Consider the following limit:</p> \\[ \\lim_{x \\to 5} \\frac{\\sqrt{x^2 - 9} - 4} {x - 5} \\] <p>If you plug in \\(x = 5\\), you get the indeterminate form \\(0 / 0\\). What you need to do is multiply and divide by \\(\\sqrt{x^2 - 9} + 4\\), which is called <code>conjugate expression</code> of \\(\\sqrt{x^2 - 9} - 4\\):</p> \\[ \\lim_{x \\to 5} \\frac{\\sqrt{x^2 - 9} - 4} {x - 5} = \\lim_{x \\to 5} \\frac{\\sqrt{x^2 - 9} - 4} {x - 5} \\times \\frac{\\sqrt{x^2 - 9} + 4} {\\sqrt{x^2 - 9} + 4} = \\lim_{x \\to 5} \\frac{x + 5} {\\sqrt{x^2 - 9} + 4} = \\frac{10}{8} \\]"},{"location":"Math/Calculus/02_limits_polynomials/#limits-involving-rational-functions-as-x-to-infty","title":"Limits Involving Rational Functions as \\(x \\to \\infty\\)","text":"<p>In symbols, we are now trying to find limits of the form:</p> \\[ \\lim_{x \\to \\infty} \\frac{p(x)}{q(x)} \\] <p>where p and q are polynomials.</p> <p>The very important property of a polynomial:</p> <p>When x is large, the leading term dominates.</p> <p>And we have the theoram:</p> \\[ \\lim_{x \\to \\infty} \\frac{C}{x^n} = 0 \\] <p>For example, the limit is solved:</p> \\[ \\lim_{x \\to \\infty} \\frac{3x^3 - 1000x^2 + 5x - 7} {3x^3} = \\lim_{x \\to \\infty}(1 - \\frac{1000}{3x} + \\frac{5}{3x^2} - \\frac{7}{3x^3}) = 1 - 0 + 0 + 0 = 1 \\]"},{"location":"Math/Calculus/02_limits_polynomials/#limits-involving-poly-type-function-as-x-to-infty","title":"Limits Involving Poly-type Function as \\(x \\to \\infty\\)","text":"<p>The principles for poly-type functions are similar to those for polynomials, except that this time it may not be so clear what the leading term is.</p>"},{"location":"Math/Calculus/02_limits_polynomials/#limits-involving-rational-functions-as-x-to-infty_1","title":"Limits Involving Rational Functions as \\(x \\to -\\infty\\)","text":"<p>Now we solve the limits of the form:</p> \\[ \\lim_{x \\to \\infty} \\frac{p(x)} {q(x)} \\] <p>where p and q are polynomials or even poly-type functions.</p> <p>All the principles we've been using apply equally well here.</p> <p>The only situation we need to pay attention is:</p> <p>if \\(x &lt; 0\\) and you want to write \\(^n\\sqrt{x^y} = x^m\\), the only time you need a minus sign in front of \\(x^m\\) is when \\(n\\) is even and m is odd.</p>"},{"location":"Math/Calculus/03_continuity_and_differentiability/","title":"Continuity and Differentiability","text":"<p>Now we're going to look at two types of <code>smoothness</code>:</p> <ul> <li><code>continuity</code>, which means the graph now has to be drawn in one piece, whithout taking the pen off the page;</li> <li><code>differentiability</code>, which means there are no sharp corners in the graph.</li> </ul>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#continuity","title":"Continuity","text":"<p>The intuition of continuity is that you can draw the graph of the function in one piece without lifting your pen off the page.</p>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#continuity-at-a-point","title":"Continuity at A Point","text":"<p>When we talk about continuity at a point, we want a stream of points \\((x, f(x))\\) which get closer and closer to the point \\((a, f(a))\\). In other words, as \\(x \\to a\\) we need \\(f(x) \\to f(a)\\). We can now give a proper definition:</p> <p>A function \\(f\\) is <code>continuity</code> at \\(x = a\\) if \\(\\lim_{x \\to a} f(x) = f(a)\\)</p> <p>So if a function is continuity, it requires:</p> <ol> <li>The two-side limit \\(\\lim_{x \\to a}f(x)\\) exists(and is finite);</li> <li>The function is defined at \\(x = a\\); that is, \\(f(a)\\) exists(and is finite);</li> <li>The two above quantities are equal: \\(\\lim_{x \\to a}f(x) = f(a)\\)</li> </ol>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#continuity-on-an-interval","title":"Continuity on An Interval","text":"<p>We now know what it means for a function to be continuous at a single point, we extend this definition and say that a function \\(f\\) is continuous on the interval \\((a, b)\\) if it is continuous at every point in the interval.</p> <p>We say a function \\(f\\) is continuous on \\([a, b]\\) if:</p> <ol> <li>the function \\(f\\) is continuous at every point in \\((a, b)\\);</li> <li>the function \\(f\\) is right-continuous at \\(x = a\\), that is, \\(\\lim_{x \\to a^+}f(x)\\) exists(and is finite), \\(f(a)\\) exists, and these two quantities are equal; </li> <li>the function \\(f\\) is left-continuous at \\(x = a\\), that is, \\(\\lim_{x \\to b^-}f(x)\\) exists(and is finite), \\(f(b)\\) exists, and these two quantities are equal. ;</li> </ol>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#the-intermediate-value-theoremivt","title":"The Intermediate Value Theorem(IVT)","text":"<p>Knowing that a function is continuous brings some benefits:</p> <ol> <li>Intermediate Value Theoram(IVT);</li> <li>Max-Min Theorem.</li> </ol> <p>We can state the Intermediate Value Theorem as:</p> <p>If \\(f\\) is continuous on \\([a, b]\\) and \\(f(a) &lt; 0\\) and \\(f(b) &gt; 0\\), then there is at least one number \\(c\\) in the interval \\((a, b)\\) such that \\(f(c) = 0\\). The same is true if instread \\(f(a) &gt; 0\\) and \\(f(b) &lt; 0\\).</p>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#maxima-and-minima-of-continuous-functions","title":"Maxima and Minima of Continuous Functions","text":"<p>The Max-Min Theorem can be stated as:</p> <p>If \\(f\\) is continuous on \\([a, b]\\), then \\(f\\) has at least one maximum and one minimum on \\([a, b]\\).</p>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#differentiability","title":"Differentiability","text":"<p>The differentiablility essentially means that the function has a derivative.</p>"},{"location":"Math/Calculus/03_continuity_and_differentiability/#instantaneous-velocity","title":"Instantaneous Velocity","text":"<p>How can we measure the velocity of the car at a given instant? The idea is to take the average velocity of the car over smaller and smaller time periods.</p> <p>Suppose that \\(u\\) is a short time later than \\(t\\), let's write \\(v_{t \\leftrightarrow u}\\) to mean the average velocity of the car during the time interval beginning at time \\(t\\) and ending at time \\(u\\). Now we just push \\(u\\) closer and closer to \\(t\\):</p> \\[ v_{t \\leftrightarrow u} = \\frac{P_u - P_t} {u - t} = \\frac{f(u) - f(t)} {u - t} \\] <p>Notice that the denominator \\(u - t\\) is the length of time involved, we can just take a limit as \\(u \\to t\\):</p> \\[ v_{t} = \\lim_{u \\to t} \\frac{f(u) - f(t)} {u - t} \\] <p>Since \\(u\\) is very close to \\(t\\), we can just write the equotion as:</p> \\[ v_{t} = \\lim_{h \\to 0} \\frac{f(t + h) - f(t)} {h} \\]"},{"location":"Math/Calculus/03_continuity_and_differentiability/#tanget-lines","title":"Tanget Lines","text":"<p>We pick a number \\(z\\) which is close to \\(x\\) and plot the point \\((z, f(z))\\) on the curve and draw the graph:</p> <p></p> <p>Since the slope is the rise over the run, the slope of the dashed line is:</p> \\[ \\frac{f(z) - f(x)} {z - x} \\] <p>Let's set \\(h = z - x\\) then we see that as \\(z \\to x\\), we have \\(h \\to 0\\), so we also have:</p> \\[ slope\\_of\\_tangent\\_line\\_through (x, f(x)) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} \\]"},{"location":"Math/Calculus/03_continuity_and_differentiability/#the-derivative-function","title":"The Derivative Function","text":"<p>In the following picture, I've drawn in the tangent lines through three different points on the curve: </p> <p>These lines have different slopes. That is, the slope of the tangent line <code>depends</code> on which value of \\(x\\) you start with. Another way of saying this is that the slope of the tangent line through \\((x, f(x))\\) is itself a function of \\(x\\). This function is called the <code>derivative</code> of \\(f\\) and is witten as \\(f'\\):</p> \\[ f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} \\] <p>If \\(y = f(x)\\), then you can write \\(\\frac{dy}{dx}\\) instead of \\(f'(x)\\). For example, if \\(y = x^2\\), then \\(\\frac{dy}{dx} = 2x\\). In fact, if you replace \\(y\\) by \\(x^2\\), you get a variety of different ways of expressing the same thing:</p> \\[ f'(x) = \\frac{dy}{dy}{dx} = \\frac{d(x^)} {dy} = \\frac{d}{dx}(x^2) = 2x \\]"},{"location":"Math/Calculus/03_continuity_and_differentiability/#differentiability-and-continuity","title":"Differentiability and Continuity","text":"<p>Now it's time to relate the two big concepts in this chapter:</p> <p>If a function \\(f\\) is differentiable at \\(x\\), then it's continuous at \\(x\\).</p> <p>To prove this claim, we have known that \\(f\\) is continuous at \\(x\\):</p> \\[ \\lim_{u \\to x} f(u) = f(x) \\] <p>as \\(u \\to x\\) we can also replace above equation as:</p> \\[ \\lim_{h \\to 0} f(x + h) = f(x) \\] <p>Now we are aware of our destination, let's start with what we actually know that \\(f\\) is differentiable at \\(x\\), which means that \\(f'(x)\\) exists:</p> \\[ \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} = f'(x) \\] \\[ \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\times h = \\lim_{h \\to 0}f'(x) \\times h \\] \\[ \\lim_{h \\to 0} f(x + h) - f(x) = \\lim_{h \\to 0}f'(x) \\times h = 0 \\] <p>so we got:</p> \\[ \\lim_{h \\to 0} f(x + h) = f(x) \\]"},{"location":"Math/Calculus/04_solve_diff/","title":"Differentiation Problems","text":"<p>Finding derivatives from the formula is possible but cumbersome, so we'll look at a few rules that make life a lot easier.</p>"},{"location":"Math/Calculus/04_solve_diff/#using-the-definition","title":"Using the Definition","text":"<p>The basic way to find derivatives is to use its definition:</p> \\[ f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} \\] <p>so the derivative of \\(f(x) = \\frac{1}{x}\\) is:</p> \\[ \\begin{align} f'(x)  &amp;= \\lim_{h \\to 0} \\frac {\\frac{1}{x + h} - \\frac{1}{x}} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac{\\frac{x - (x + h)}{x(x + h)}} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac{-h} {hx(x + h)} \\\\ &amp;= \\lim_{h \\to 0} \\frac{-1} {x(x + h)} \\\\ &amp;= -\\frac{1}{x^2} \\end{align} \\] <p>In fact, if we replace \\(x^n\\) to \\(x\\) to get \\(f(x) = x^n\\) we can get more general equation:</p> \\[ \\begin{align} f'(x)  &amp;= \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac{(x + h)^n - x^n} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac{x^n + nhx^{n - 1} + h^2 \\times (something...) - x^n} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac{nhx^{n - 1} + h^2 \\times (something...)} {h} \\\\ &amp;= \\lim_{h \\to 0} (nx^{n - 1} + h \\times (something...)) \\\\ &amp;= nx^{n - 1} \\end{align} \\]"},{"location":"Math/Calculus/04_solve_diff/#using-rules","title":"Using rules","text":"<p>Let's define a function \\(f\\) as following:</p> \\[ f(x) = \\frac{3x^7 + x^4\\sqrt{2x^5 + 14x^{\\frac{4}{3}} - 23x + 9}} {6x^2 - 4} \\] <p>The key to differentiating a function is to understand how it is synthesized from simpler functions. Here are some rules we can use.</p>"},{"location":"Math/Calculus/04_solve_diff/#constant-multiples-of-functions","title":"Constant multiples of functions","text":"<p>You just multiply by the constant after your differentiate.</p> \\[ (nf(x))' = nf'(x) \\]"},{"location":"Math/Calculus/04_solve_diff/#sums-and-differences-of-functions","title":"Sums and differences of functions","text":"<p>You just differentiate each piece and then add or subtract.</p> \\[ (f(x) + g(x))' = f'(x) + g'(x) \\]"},{"location":"Math/Calculus/04_solve_diff/#products-of-functions-via-product-rule","title":"Products of functions via product rule","text":"<p>To solve the problems involving products of functions, you have to mix and match. That is the product rule(version 1):</p> \\[ (f(x)g(x))' = f'(x)g(x) + f(x)g'(x) \\] <p>If we replace \\(f(x)\\) with \\(u\\) and \\(g(x)\\) with \\(v\\), we got(version 2);</p> \\[ \\frac{dy} {dx} = v\\frac{du}{dx} + u\\frac{dv}{dx} \\] <p>What if you have a product of three terms? We have the product rule for three terms(three variable):</p> \\[ \\frac{duvw} {dx} = \\frac{du}{dx}vw + u\\frac{dv}{dx}w + uv\\frac{dw}{dx} \\]"},{"location":"Math/Calculus/04_solve_diff/#quotients-of-functions-via-the-quotient-rule","title":"Quotients of functions via the quotient rule","text":"<p>Quotients are handled in a way similar to products, except that the rule is a little different. The form of quotients is \\(h(x) = \\frac{f(x)}{g(x)}\\), here is the quotient rule(version 1):</p> \\[ (\\frac{f(x)} {g(x)})' = \\frac{f'(x)g(x) - f(x)g'(x)} {(g(x))^2} \\] <p>There is also another version(version 2):</p> \\[ \\frac{d}{dx}(\\frac{u}{v}) = \\frac{v\\frac{du}{x} - u\\frac{dv}{dx}} {v^2} \\]"},{"location":"Math/Calculus/04_solve_diff/#composition-of-functions-via-the-chain-rule","title":"Composition of functions via the chain rule","text":"<p>The Chain rule is discrebed as(version 1):</p> \\[ (f(g(x)))' = f'(g(x))g'(x) \\] <p>And replace \\(f\\) and \\(g\\) with \\(y\\) and \\(u\\), we can invoke the other version of the chain rule(version 2):</p> \\[ \\frac{dy}{dx} = \\frac{dy}{du}\\frac{du}{dx} \\]"},{"location":"Math/Calculus/04_solve_diff/#derivatives-of-piecewise-defined-functions","title":"Derivatives of Piecewise-Defined Functions","text":"<p>Consider the following piecewise-defined function:</p> \\[ f(x) = \\begin{cases} 1, &amp;if \\quad x \\le 0, \\\\ x^2 + 1, &amp;if \\quad x &gt; 0. \\\\ \\end{cases} \\] <p></p> <p>To check that a piecewise-defined function is differentiable at a point where the pieces join together, you need to check:</p> <ul> <li>pieces agree at the join point(for continuity);</li> <li>the derivatives of the pieces agree at the join point.</li> </ul> <p>Otherwise it's not differentiable at the join point.</p>"},{"location":"Math/Calculus/05_trig_derivative/","title":"Trig Limits and Derivatives","text":"<p>So far, most of our limits and derivativess have involved only polynomials or poly-type functions. Lets expand our horizons by looking aat trig functions.</p>"},{"location":"Math/Calculus/05_trig_derivative/#limits-involving-trig-functions","title":"Limits Involving Trig Functions","text":"<p>Consider the following two limits:</p> \\[ \\lim_{x \\to 0} \\frac{sin(5x)} {x} \\] <p>and </p> \\[ \\lim_{x \\to \\infty} \\frac{sin(5x)} {x} \\] <p>They look almost the same, the only difference is that the first limit is taken as \\(x \\to 0\\) while the second it taken as \\(x \\to \\infty\\).</p>"},{"location":"Math/Calculus/05_trig_derivative/#the-small-case","title":"The small case","text":"<p>We know that \\(sin(0) = 0\\), so what does \\(sin(x)\\) look like when \\(x\\) is near \\(0\\)? It turns out that \\(sin(x)\\) is approximately the same as \\(x\\) itself:</p> <p></p> <p>The graphs of \\(y = sin(x)\\) and \\(y = x\\) are very similar, especially when \\(x\\) is close to \\(0\\). So we have the conclusion:</p> \\[ \\lim_{x \\to 0} \\frac{sin(x)} {x} = 1 \\] <p>How about \\(cos(x)\\)? Well, \\(cos(0) = 1\\), so we write:</p> \\[ \\lim_{x \\to 0} cos(x) = 1 \\] <p>As for \\(tan(x)\\), we can write \\(tan(x)\\) as \\(\\frac{sin(x)}{cos(x)}\\) and get the equation:</p> \\[ \\lim_{x \\to 0} \\frac{tan(x)} {x} = 1 \\]"},{"location":"Math/Calculus/05_trig_derivative/#the-large-case","title":"The large case","text":"<p>As we all know:</p> \\[ -1 \\le sin(x) \\le 1 \\] <p>So the limit is:</p> \\[ \\lim_{x \\to \\infty} \\frac{sin(x)} {x} = 0 \\]"},{"location":"Math/Calculus/05_trig_derivative/#derivatives-involving-trig-functions","title":"Derivatives Involving Trig Functions","text":"<p>Using the definition of derivative:</p> \\[ f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} \\] <p>and the conclusion above:</p> \\[ \\lim_{h \\to 0} \\frac{sin(h)} {h} = 1 \\] <p>we can get:</p> \\[ \\begin{align} sin'(x)  &amp;= \\lim_{h \\to 0} \\frac{sin(x + h) - sin(x)} {h} \\\\ &amp;= \\lim_{h \\to 0} \\frac {sin(x)cos(h) + cos(x)sin(h) - sin(x)} {h} \\\\ &amp;= \\lim_{h \\to 0} (sin(x)(\\frac{cos(h) - 1} {h}) + cos(x)(\\frac{sin(h)}{h})) \\\\ &amp;= \\lim_{h \\to 0} (sin(x) \\times 0 + cos(x) \\times 1) \\\\ &amp;= cos(x) \\end{align} \\] <p>Use the samme method, we can get other equations:</p> \\[ \\begin{align} cos'(x) &amp;= -sin(x) \\\\ tan'(x) &amp;= \\frac{1}{cos^2(x)} = sec^2(x) \\\\ sec'(x) &amp;= sec(x)tan(x) \\\\ csc'(x) &amp;= -csc(x)cot(x) \\\\ cot'(x) &amp;= -csc^2(x) \\end{align} \\]"},{"location":"Math/Calculus/06_exp_and_log/","title":"Exponentials and Logarithms","text":"<p>It turns out that there's a special base, the number \\(e\\), that works out particularly nicely, doing calculus with \\(e^x\\) and \\(log_e(x)\\) is much easier than dealing with \\(2^x\\) or \\(log_3(x)\\). Let's spend some time looking at \\(e\\) and its calculus.</p>"},{"location":"Math/Calculus/06_exp_and_log/#the-basics","title":"The Basics","text":"<p>Before you start doing calculus with exponentials, you really need to understand their properties.</p>"},{"location":"Math/Calculus/06_exp_and_log/#exponentials","title":"Exponentials","text":"<p>The rough idea is that we'll take a positive number, called the <code>base</code>, and raise it to a power called the <code>exponent</code>:</p> \\[ base^{exponent} \\] <p>For any base \\(b &gt; 0\\) and real numbers \\(x\\) and \\(y\\):</p> <ul> <li>\\(b^0 = 1\\)</li> <li>\\(b^1 = b\\)</li> <li>\\(b^xb^y = b^{x + y}\\)</li> <li>\\(\\frac{b^x}{b^y} = b^{x - y}\\)</li> <li>\\((b^x)^y = b^{xy}\\)</li> </ul>"},{"location":"Math/Calculus/06_exp_and_log/#logarithms","title":"Logarithms","text":"<p>\\(\\log_b{y}\\) is the power you have to raise the base \\(b\\) to in order to get \\(y\\), which means that \\(x = \\log_by\\) is the solution of the equation \\(b^x = y\\) for given \\(b\\) and \\(y\\):</p> \\[ b^{\\log_b(y)} = y \\] <p>Here are the rules valid for any base \\(b &gt; 1\\) and positive real numbers \\(x\\) and \\(y\\):</p> <ul> <li>\\(\\log_b(1) = 0\\)</li> <li>\\(\\log_b(b) = 1\\)</li> <li>\\(\\log_b(xy) = \\log_b(x) + \\log_b(y)\\)</li> <li>\\(\\log_b(x/y) = \\log_b(x) - \\log_b(y)\\)</li> <li>\\(\\log_b(x^y) = y\\log_b(x)\\)</li> <li>\\(\\log_b(x) = \\frac{\\log_c(x)} {\\log_c(b)}\\)</li> </ul>"},{"location":"Math/Calculus/06_exp_and_log/#definition-of-e","title":"Definition of \\(e\\)","text":"<p>The \\(e\\) is a special constant number like \\(\\pi\\). One way of seeing where \\(e\\) comes from involves a bit of a finance lesson.</p>"},{"location":"Math/Calculus/06_exp_and_log/#a-question-about-compound-interest","title":"A question about compound interest","text":"<p>A long time ago, a dude named Bernoulli answers a question about compound interest. Here is the setup for his question. Let's suppose you have a bank account that pays interest at a generous rate of \\(12%\\) annually, compounded once a year. You put in an initial deposit; every year, your fortune increase by \\(12%\\). This means that after \\(n\\) years, your fortune has increased by a factor of \\((1 + 0.12)^n\\). In particular, after one year, your fortune is just \\((1 + 0.12) = 1.12\\) times the original amount. If you started with $100, you'd finish the year with $112.</p> <p>Now suppose you find another bank that also offers an annual interest rate of \\(12%\\), but now it compounds twice a year. Of course you aren't going to get \\(12%\\) for half a year; you have to divide that by \\(2\\). Basically this means that you are getting \\(6%\\) interest for every 6 months. So if you put money into this bank account, then after one year it has compounded twice at \\(6%\\); the result is that your fortune has expanded by a factor of \\((1 + 0.06)^2 = 1.1236\\). So if you started with $100, you'd finish with $112.36.</p> <p>The second account is a little better than the first. It makes sense when you think about it--compounding is beneficial, so compounding more often at the same annual rate should be better. Let's try 3 times a year at the annual rate of \\(12%\\). We take \\(12%\\) and divide by \\(3\\) to get \\(4%\\), then compound three times; our fortune has increased by \\((1 + 0.04)^3\\), which works out to be \\(1.124864\\). This is a little higher still. How about 4 times a year? That'd be \\((1 + 0.03)^4\\), which is approximately \\(1.1255\\). That's even higher. Now, the question is, where does it stop? If you compound more and more often at the same annual rate, do you get wads and wads of cash after a year, or is there some limitation on all this?</p>"},{"location":"Math/Calculus/06_exp_and_log/#the-answer-to-our-question","title":"The answer to our question","text":"<p>Let's turn to some symbols. First, let's suppose that we are compounding n times a year at an annual rate of \\(r\\), this means that each time we compound, the amount of compounding is \\(r / n\\). After this happens n times in one year, our original fortune has grown by a factor of:</p> \\[ (1 + \\frac{r}{n})^n \\] <p>We would like to know what happens in the limit as \\(n \\to \\infty\\):</p> \\[ L = \\lim_{n \\to \\infty} (1 + \\frac{r}{n})^n \\] <p>If this limit turns out to be finite, then by compounding more and more often, you could get more and more money in a single year. On the other hand, if it turns out to be finite, we'll have to conclude that there is a limitation on how much we can increase our fortune with an annual interest rate of \\(r\\), no matter how often we compound.</p> <p>First, lets' set \\(h = \\frac{r}{n}\\), so that \\(n = \\frac{r}{h}\\). Then as \\(n \\to \\infty\\), we seet that \\(h \\to 0^+\\)(since \\(r\\) is constant), so:</p> \\[ L = \\lim_{h \\to 0^+}(1 + h)^{\\frac{r}{h}} \\] <p>Use the exponential rule:</p> \\[ L = \\lim_{h \\to 0^+}((1 + h)^{\\frac{1}{h}})^r \\] <p>Let's pull a huge rabbit out of the hat and set:</p> \\[ e = \\lim_{h \\to 0^+}(1 + h)^{\\frac{1}{h}} \\] <p>and we have:</p> \\[ L = \\lim_{h \\to 0^+}((1 + h)^{\\frac{1}{h}})^r = e^r \\] <p>The number \\(e\\) turns out to be an irrational number whose decimal expansion begins like this:</p> \\[ e = 2.71828182845904523... \\] <p>The base \\(e\\) logarithm is called the <code>natural logarithm</code>. Since we have a new base \\(e\\), and a new way of writing logarithms in that base, the basic rules of logarithm can be rewritten as:</p> <ul> <li>\\(e^{\\ln(x)} = x\\)</li> <li>\\(\\ln(e^x) = x\\)</li> <li>\\(\\ln(1) = 0\\)</li> <li>\\(\\ln(e) = 1\\)</li> <li>\\(\\ln(xy) = \\ln(x) + \\ln(y)\\)</li> <li>\\(\\ln(\\frac{x}{y}) = \\ln(x) - \\ln(y)\\)</li> <li>\\(\\ln(x^y) = y\\ln(x)\\)</li> </ul>"},{"location":"Math/Calculus/06_exp_and_log/#differentiation-of-logs-and-exponentials","title":"Differentiation of Logs and Exponentials","text":"<p>With the definition of limit, we can find the derivatives of logs and exponentials:</p> <ul> <li>\\((\\ln(x))' = \\frac{1}{x}\\)</li> <li>\\((\\log_b(x))' = \\frac{1}{x\\ln(b)}\\)</li> <li>\\((e^x)' = e^x\\)</li> <li>\\((b^x)' = b^xln(b)\\)</li> </ul>"},{"location":"Math/Calculus/06_exp_and_log/#behavior-of-exponentials-near-0","title":"Behavior of exponentials near 0","text":"<p>In fact, we know that:</p> \\[ \\lim_{x \\to 0} e^{x^2} = e^0 = 1 \\] <p>But what about the limit:</p> \\[ \\lim_{h \\to 0} \\frac{e^h - 1} {h} \\] <p>Well, try setting \\(f(x) = e^x\\), we have:</p> \\[ f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)} {h} = \\lim_{h \\to 0} \\frac{e^{x + h} - e^x} {h} = e^x \\] <p>Simplify the equation, we have:</p> \\[ \\lim_{h \\to 0} \\frac{e^h - 1} {h} = 1 \\]"},{"location":"Math/Calculus/06_exp_and_log/#behavior-of-logarithms-near-1","title":"Behavior of logarithms near 1","text":"<p>It turns out that the situation is pretty simillar to the case of exponentials near 0:</p> \\[ \\lim_{h \\to 0} \\frac{\\ln(1 + h)} {h} = 1 \\]"},{"location":"Math/Calculus/06_exp_and_log/#behavior-of-exponentials-near-infty-or-infty","title":"Behavior of exponentials near \\(\\infty\\) or \\(-\\infty\\)","text":"<p>Let's take a look at the graph of \\(y = e^x\\):</p> <p></p> <p>and get the conclusion:</p> \\[ \\lim_{x \\to \\infty} e^x = \\infty \\] <p>and</p> \\[ \\lim_{x \\to -\\infty} e^x = 0 \\] <p>What if we the base \\(e\\) is replaced by some other base?</p> \\[ \\lim_{x \\to \\infty} r^x =  \\begin{cases} \\infty, &amp; if \\quad r &gt; 1, \\\\ 1, &amp; if \\quad r = 1, \\\\ 0, &amp; if \\quad r &lt; 1. \\end{cases} \\] <p>In addtion to all equations above, as <code>Exponentials grow quickly</code>:</p> \\[ \\lim_{x \\to \\infty} \\frac{x^n}{e^x} = 0 \\] <p>no matter how large \\(n\\) is.</p>"},{"location":"Math/Calculus/06_exp_and_log/#behavior-of-logs-near-infty","title":"Behavior of logs near \\(\\infty\\)","text":"<p>The sage continues. Here is the graph of \\(y = \\ln(x)\\):</p> <p></p> \\[ \\lim_{x \\to \\infty} \\ln(x) = \\infty \\] <p>And as the logs grow slowly, if \\(a &gt; 0\\):</p> \\[ \\lim_{x \\to \\infty} \\frac{\\ln(x)} {x^a} = 0 \\] <p>no matter how small \\(a\\) is.</p>"},{"location":"Math/Calculus/06_exp_and_log/#behavior-of-logs-near-0","title":"Behavior of logs near 0","text":"<p>Logs grow slowly at \\(0\\), so if \\(a &gt; 0\\):</p> \\[ \\lim_{x \\to 0^+} x^a\\ln(x) = 0 \\] <p>no matter how small \\(a\\) is.</p>"},{"location":"Math/Calculus/07_extrema/","title":"Extrema of Functions","text":"<p>We have seen how to differentiate functions from several different families, now we can use this knowledge to help us understand the maxima and minima of functions.</p>"},{"location":"Math/Calculus/07_extrema/#extrema-of-functions_1","title":"Extrema of Functions","text":"<p>If we say \\(x = a\\) is an <code>extremum</code> of a function \\(f\\), this means that \\(f\\) has a maximum or minimum at \\(x = a\\). (The plural of \"extremum\" is \"extrema\", of course.)</p>"},{"location":"Math/Calculus/07_extrema/#definition","title":"Definition","text":"<p>The basic idea of a maximum is that it occurs when the function value is highest:</p> <p></p> <p>Let's say that a</p> <ul> <li><code>global maximum</code>(or absolute maximum) occurs at \\(x = a\\) if \\(f(a)\\) is the highest value of \\(f\\) on the entire domain of \\(f\\);</li> <li><code>local maximum</code>(or relative maximum) occurs at \\(x = a\\) if \\(f(a)\\) is the highest value of \\(f\\) on some small interval containing a.</li> </ul> <p>Every global maximum is also a local maximum.</p>"},{"location":"Math/Calculus/07_extrema/#the-extreme-value-theorem","title":"The Extreme Value Theorem","text":"<p>Let's say that \\(x = c\\) is a critical point for the function \\(f\\) is either \\(f'(c) = 0\\) or \\(f'(c) = DNE\\). Then we have the <code>Extreme Value Theorem</code>:</p> <p>Suppose that \\(f\\) is defined on \\((a,b)\\) and \\(c\\) is in \\((a, b)\\). If \\(c\\) is a local maximum or minimum of \\(f\\), then \\(c\\) must be a critical point for \\(f\\). That is, either \\(f'(c) = 0\\) or \\(f'(c) = DNE\\).</p>"},{"location":"Math/Calculus/07_extrema/#how-to-find-global-maxima-and-mimima","title":"How to Find Global Maxima and Mimima","text":"<p>In glory detail, here's how to find the global maximum and minimum of the function \\(f\\) with domain \\([a, b]\\):</p> <ol> <li>Find \\(f'(x)\\). Make a list of all the points in \\((a, b)\\) where \\(f'(x) = 0\\) or \\(f'(x) = DNE\\). That is, make a list of all the critical points in the interval \\((a, b)\\).</li> <li>Add the endpoints \\(x = a\\) and \\(x = b\\) to the list.</li> <li>For each of the points in the list, find the y-coordinates by substituting into the equation \\(y = f(x)\\).</li> <li>Pick the highest y-coordinate and note all the values of x from the list coresponding to that y-coordinate. These are the global maxima.</li> <li>Do the same for the lowest y-coordinate to find the global minima.</li> </ol>"},{"location":"Math/Calculus/07_extrema/#rolles-theorem","title":"Rolle's Theorem","text":"<p>Suppose that \\(f\\) is continuous on \\([a, b]\\) and differentiable on \\((a, b)\\). If \\(f(a) = f(b)\\), then there must be at least one number \\(c\\) in \\((a, b)\\) such that \\(f'(c) = 0\\).</p>"},{"location":"Math/Calculus/07_extrema/#the-mean-value-theorem","title":"The Mean Value Theorem","text":"<p>Suppose that \\(f\\) is continuous on \\([a, b]\\) and differentiable on \\((a, b)\\). Then there's at least one number \\(c\\) in \\((a, b)\\) such that:</p> \\[ f'(c) = \\frac{f(b) - f(a)} {b - a} \\] <p>The Mean Value Theorem looks a lot like Rolle's Theorem. In fact, the conditions for applying the two theorems are almost the same. In both cases, your function \\(f\\) has to be continuous on a closed interval \\([a, b]\\) and differentiable on \\((a, b)\\). Rolle's Theorem also requires that \\(f(a) = f(b)\\), but Mean Value Theorem doesn't require that. In fact, if you apply the Mean Value Theorem to a function \\(f\\) statisfying \\(f(a) = f(b)\\), you'll see that \\(f(b) - f(a) = 0\\), so you get a number \\(c\\) in \\((a, b)\\) statisfying \\(f'(c) = 0\\). So Mean Value Theorem reduces to Rolle's Theorem.</p>"},{"location":"Math/Calculus/08_optim_and_linear/","title":"Optimization and Linearization","text":"<p>Basically, optimization involves finding the best situation possible, wether that be the cheapest way to build a bridge without falling down or something as mundane as finding the fastest driving route to a specific destination.</p> <p>Linearization is a useful technique for finding approximate values of hard-to-calculate quantities.</p>"},{"location":"Math/Calculus/08_optim_and_linear/#optimization","title":"Optimization","text":"<p>To \"optimize\" something means to make it as good as possible. The term \"optimize\" just means \"maximize or minimize, as appropriate.\"</p> <p>In general, here's the way to tackle optimization problems:</p> <ol> <li>Identify all the variables you might possibly need. One of them should be the quantity you want to maximize or minimize--make sure you know which one! Let's call it Q for now, although of course it might be another letter like P, m, or \\(\\alpha\\).</li> <li>Get a fell for the extremes of the situation, seeing how far you can push your variables.</li> <li>Write down equations relating the variables. One of them should be an equation for Q.</li> <li>Try to make Q a function of only one variable, using all your equations to eliminate the other variables.</li> <li>Differentiate Q with respect to that variable, then find the critical points; remember, these occur where the derivative if 0 or \\(DNE\\).</li> <li>Find the values of Q at all the critical points and at the endpoints. Pick out the maximum and minimum values. As a verification, use a table of signs or the sign of the second derivative to classify the critical points.</li> <li>Write out a summary of what you've found, identifying the variables in words rather than symbols(wherever possible).</li> </ol>"},{"location":"Math/Calculus/08_optim_and_linear/#linearization","title":"Linearization","text":"<p>The general method is to use the formula:</p> \\[ f(a + \\Delta x) \\cong f(a) + f'(x)\\Delta x \\] <p>For example, you want to find the value of \\(\\sqrt{11}\\), let</p> <ul> <li>\\(f(x) = \\sqrt{x}\\),</li> </ul> <p>then:</p> <ul> <li>\\(f'(x) = \\frac{1}{2\\sqrt{x}}\\),</li> <li>\\(\\Delta x = 2\\),</li> <li>\\(a = 3\\),</li> </ul> <p>We get:</p> \\[ \\sqrt{11} = f(9 + 2) \\cong f(9) + f'(9)\\Delta x = 3 + \\frac{1}{3} \\] <p>Here is the graph of the situation:</p> <p></p> <p>The graph shows the curve \\(y = f(x)\\) and the linearization \\(y = L(x)\\), which is the tangent line to the curve at \\(x = a\\). We want to estimate the value of \\(f(a + \\Delta x)\\). That's the height of the point \\(F\\) in the above picture. As an approximate value, we're actually using \\(L(x + \\Delta x)\\), which is the height of \\(P\\) in the picture. The difference between the two quantities is labeled \"error\".</p> <p>Since \\(L(a + \\Delta x) = f(a) + f'(a) \\Delta x\\), we see that:</p> \\[ df = f'(a) \\Delta x \\] <p>The quantities \\(df\\) is called the differential of \\(f\\) at \\(x = a\\).</p> <p>We set:</p> \\[ r(x) = f(x) - L(x) \\] <p>where \\(r(x)\\) is the error in using the linearization at \\(x = a\\) in order to estimate \\(f(x)\\). It turns out that if the second derivative of \\(f\\) exists, at least between x and a, then there's a nice formula for \\(r(x)\\):</p> \\[ r(x) = \\frac{1}{2} f''(x)(x - a)^2 \\] <p>The above formula is related to the Mean Value Theorem.</p> <ul> <li>if \\(f'' &gt; 0\\) between a and x, then using the linearization leads to an underestimate(\\(L(x) &lt; f(x)\\)).</li> <li>if \\(f'' &lt; 0\\) between a and x, then using the linearization leads to an overestimate(\\(L(x) &gt; f(x)\\)).</li> </ul> <p>If we find the maximum M in \\([a, x]\\), we get the folowing:</p> \\[ |error| \\le \\frac{1}{2} M |x - a|^2 \\] <p>In summary, the basic strategy for estimating, or approximating, anasty number:</p> <ol> <li>Write down the main formula:</li> </ol> \\[ f(x) \\cong L(x) = f(a) + f'(a)(x - a) \\] <ol> <li>Choose a function \\(f\\), and a number \\(x\\) such that the nasty number is equal to \\(f(x)\\). Also, choose \\(a\\) to \\(x\\) such that \\(f(a)\\) can easily be computed.</li> <li>Differentiate \\(f\\) to find \\(f'\\)</li> <li>In the above formula, replace \\(f\\) and \\(f'\\) by the actual functions, and \\(a\\) by the actual number you've chosen.</li> <li>Finally, plug in the value of \\(x\\) from step 2 above. Also note that the differential \\(df\\) is the quantity \\(f'(a)(x - a)\\)</li> </ol>"},{"location":"Math/Calculus/08_optim_and_linear/#newtons-method","title":"Newton's Method","text":"<p>Here's another useful application of linearization. Suppose that you have an equation of the form \\(f(x) = 0\\) that you'd like to solve, but you just can't solve the darned thing. So you do the next best thing: you take a guess at a solution, which you can call \\(a\\). The situation might look like this:</p>"},{"location":"Math/Calculus/09_l_hopital_rule/","title":"L'Hopital's Rule and Limits","text":"<p>We've used limits to find derivatives. Now we'll turn things upside-down and use derivatives to find limits, by way of a nive technique called <code>L'Hopital's Rule</code>.</p> <p>Most of the limits we've looked at are naturally in one of the following forms:</p> <ul> <li>\\(\\lim_{x \\to a}\\frac{f(x)}{g(x)}\\)</li> <li>\\(\\lim_{x \\to a}(f(x) - g(x))\\)</li> <li>\\(\\lim_{x \\to a}f(x)g(x)\\)</li> <li>\\(\\lim_{x \\to a}f(x)^{g(x)}\\)</li> </ul> <p>Sometimes you can just substitute \\(x = a\\) and evaluate the limit directly, effectively using the continuity of \\(f\\) and \\(g\\). This method doesn't always work, for example:</p> \\[ \\lim_{x \\to 3} \\frac{x^2 - 9}{x - 3} \\] <p>replacing \\(x\\) by 3 gives the indeterminate form \\(\\frac{0}{0}\\).</p> <p>It turns out that the first type, involving the ratio \\(\\frac{f(x)}{g(x)}\\), is the most suitable for applying the rule, so we'll call it <code>Type A</code>. The next two types, involving \\(f(x) - g(x)\\) and \\(f(x)g(x)\\), both reduce directly to <code>Type A</code>, so we'll call them <code>Type B1</code> and <code>Type B2</code> respectively. Finally, we'll say that limits involving exponentials like \\(f(x)^{g(x)}\\) are <code>Type C</code>, since you can solve them by reducing them to <code>Type B2</code> and then back to <code>Type A</code>.</p>"},{"location":"Math/Calculus/09_l_hopital_rule/#type-a00-or-pm-infty-pm-infty","title":"Type A(\\(0/0\\) or \\(\\pm \\infty/ \\pm \\infty\\))","text":"<p>Consider limits of the form:</p> \\[ \\lim_{x \\to a} \\frac{f(x)}{g(x)} \\] <p>where \\(f\\) and \\(g\\) are nice differentiable functions. If \\(g(a) \\ne 0\\), everything's great, you just substitude \\(x = a\\) to see the limit is \\(\\frac{f(a)}{g(a)}\\). </p> <p>The only other possibility is that \\(f(a) = 0\\) and \\(g(a) = 0\\). That is, the fraction \\(\\frac{f(a)}{g(a)}\\) is the indeterminate form \\(\\frac{0}{0}\\).  Let's return to the definition of limits:</p> \\[ f'(x) = lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\] <p>Since \\(f\\) and \\(g\\) are differentiable, we can find the linearization of both of them at \\(x = a\\). In fact, as we saw in the previous chapter, if \\(x\\) is close to \\(a\\), then:</p> \\[ f(x) \\cong f(a) + f'(a)(x - a) \\] <p>and </p> \\[ g(x) \\cong g(a) + g'(a)(x - a) \\] <p>Now we assume that \\(f(a)\\) and \\(g(a)\\) are both \\(0\\). This means:</p> \\[ f(x) \\cong f'(a)(x - a) \\] <p>and </p> \\[ g(x) \\cong g'(a)(x - a) \\] <p>If you divide the first equation by the second one, then assuming that \\(x \\ne a\\), we get:</p> \\[ \\frac{f(x)}{g(x)} \\cong \\frac{f'(a)(x - a)}{g'(a)(x - a)} = \\frac{f'(a)}{g'(a)} \\] <p>The closer \\(x\\) is to \\(a\\), the better the approximation. This leads to one version of l'Hopital's Rule:</p> <p>If \\(f(a) = g(a) = 0\\), then</p> \\[ \\lim_{x \\to a}\\frac{f(x)}{g(x)} = \\lim_{x \\to a}\\frac{f'(x)}{g'(x)} \\]"},{"location":"Math/Calculus/09_l_hopital_rule/#type-b1infty-infty","title":"Type B1(\\(\\infty - \\infty\\))","text":"<p>Here is a limit form:</p> \\[ \\lim_{x \\to 0}(\\frac{1}{sin(x)} - \\frac{1}{x}) \\] <p>As \\(x \\to 0^+\\), both \\(1/sin(x)\\) and \\(1/x\\) go to \\(\\infty\\). As \\(x \\to 0^-\\), both quantities go to \\(-\\infty\\). We can reduce this to <code>Type A</code>, just take a common denominator:</p> \\[ \\lim_{x \\to 0}(\\frac{1}{sin(x)} - \\frac{1}{x}) = \\lim_{x \\to 0} \\frac{x - sin(x)}{xsin(x)} \\] <p>Now you can put \\(x = 0\\) and see \\(0/0\\) case. So we can apply l'Hopital's Rule:</p> \\[ \\lim_{x \\to 0} (\\frac{1}{sin(x)} - \\frac{1}{x}) = \\lim_{x \\to 0} \\frac{x - sin(x)}{xsin(x)} = \\lim_{x \\to 0}\\frac{1 - cos(x)}{sin(x) + xcos(x)} = \\lim_{x \\to 0} \\frac{sin(x)}{cos(x) + cos(x) - xsin(x)} = 0 \\]"},{"location":"Math/Calculus/09_l_hopital_rule/#type-b2-0-times-pm-infty","title":"Type B2 (\\(0 \\times \\pm \\infty\\))","text":"<p>Here's the example:</p> \\[ \\lim_{x \\to 0^+} x\\ln(x) \\] <p>The idea is to move \\(x\\) into a new denominator by putting it there as \\(\\frac{1}{x}\\):</p> \\[ \\lim_{x \\to 0^+} x\\ln(x) = \\lim_{x \\to 0^+} \\frac{\\ln(x)}{1/x} \\] <p>Now the form is \\(-\\infty / \\infty\\), so we can use the l'Hopital's Rule:</p> \\[ \\lim_{x \\to 0^+}x\\ln(x) = \\lim_{x \\to 0^+}\\frac{\\ln(x)}{1/x} = \\lim_{x \\to 0^+}\\frac{1/x}{-1/x^2} = 0 \\]"},{"location":"Math/Calculus/09_l_hopital_rule/#type-c1pm-infty-00-infty0","title":"Type C(\\(1^{\\pm \\infty}, 0^0, \\infty^0\\))","text":"<p>Finally, the trickiest type involves limits like:</p> \\[ \\lim_{x \\to 0^+} x^{sin(x)} \\] <p>where both the base and exponent involve the dummy variable. The idea is to take the logarithm of the quatity \\(x^{sin(x)}\\) first, and work out its limit as \\(x \\to 0^+\\):</p> \\[ \\lim_{x \\to 0^+}ln(x^{sin(x)}) = \\lim_{x \\to 0^+}{sin(x)}\\ln(x) = \\lim_{x \\to 0^+}ln(\\frac{\\ln(x)}{csc(x)}) = \\lim_{x \\to 0^+}ln(\\frac{1/x}{-csc(x)cot(x)}) = ln(-1 \\times 0) = ln(0) = 1 \\]"},{"location":"Math/Calculus/10_calculus/","title":"The Fundamental Theorems of Calculus","text":"<p>Now it's time to get some facts straight about definite integrals.</p>"},{"location":"Math/Calculus/10_calculus/#the-basic-idea","title":"The Basic Idea","text":"<p>We start off with some function \\(f\\) and an interval \\([a, b]\\). Take the graph of \\(y = f(x)\\), and consider the region between the curve, the x-axis, and the two vertical lines \\(x = a\\) and \\(x = b\\):</p> <p></p> <p>It would be nice to have a compact way to express the area of the shaded region. Let's say the the area of the shaded region above, is</p> \\[ \\int_{a}^b f(x)dx \\] <p>This is a <code>definite integral</code>. You would read it out loud as <code>the integral from a to b of f(x) with respect to x</code>.</p> <ul> <li>\\(f(x)\\) is called <code>integrand</code>, and tells you what the curved part looks like;</li> <li>\\(a\\) and \\(b\\) is called <code>limits of integration</code> or <code>endpoints of integration</code>, tell you where the two vertical lines go;</li> <li>\\(dx\\) tells you that x is the variable on the horizontal axis.</li> </ul> <p>What if the function dips below the x-axis? Actually, the part of the area below the x-axis counts as negtive area. In general, the integral gives the total amount of signed area.</p> <p>And, if \\(f\\) is an odd function, then:</p> \\[ \\int_{-a}^a f(x) dx = 0 \\] <p>\\(a\\) can be any number.</p>"},{"location":"Math/Calculus/10_calculus/#definition-of-the-definite-integral","title":"Definition of the Definite Integral","text":"<p>We have a nice working definition of the definite integral in terms of area, but that doesn't really help us to calculate specific integrals. We can state the definition:</p> \\[ \\int_a^b f(x) dx = \\lim_{mesh \\to 0} \\sum_{j = 1}^n f(c_j)(x_j - x_{j - 1}) \\] <p>where \\(a = x_0 &lt; x_1 &lt; \\cdots &lt; x_{n - 1} &lt; x_n = b\\) and \\(c_j\\) is in \\([x_{j - 1}, x_j]\\) for each \\(j = 1, \\cdots, n\\).</p>"},{"location":"Math/Calculus/10_calculus/#properties-of-definite-integral","title":"Properties of Definite Integral","text":"<ul> <li>If you reverse the limits of integration, you need to put in a minus sign out front.</li> </ul> \\[ \\int_{b}^{a} f(x) dx = -\\int_{a}^{b} f(x) dx \\] <ul> <li>If the limits of integration are equal, the integration is 0.</li> </ul> \\[ \\int_{a}^{a} f(x) dx = 0 \\] <ul> <li>You can split an integral into two pieces.</li> </ul> \\[ \\int_{a}^{b} f(x) dx = \\int_{a}^{c} f(x) dx + \\int_{c}^{b} f(x) dx \\] <ul> <li>Constants can move through integral signs.</li> </ul> \\[ \\int_{a}^{b} C f(x) dx = C \\int_{a}^{b} f(x) dx \\] <ul> <li>Integrals respect sums and differences.</li> </ul> \\[ \\int_{a}^{b} (f(x) + g(x)) dx = \\int_{a}^{b} f(x) dx + \\int_{a}^{b} g(x) dx \\]"},{"location":"Math/Calculus/10_calculus/#averages-and-the-mean-value-theorem-for-integrals","title":"Averages and the Mean Value Theorem for Integrals","text":"<p>Let's return to average velocities. All you have to do is to find the displacement and divide it by the total time. If the time interval goes from a to b, and the velocity at time t is \\(v(t)\\), then we've already seen that:</p> \\[ displacement = \\int_{a}^{b} v(t) dt \\] <p>Since the total time is \\(b - a\\), we have</p> \\[ average \\quad velocity = \\frac{displacement} {total time} = \\frac{1}{b - a} \\int_a^b v(t) dt \\] <p>More general, we can define the average value of an integrable function \\(f\\) on the interval \\([a, b]\\) as follow:</p> \\[ average \\quad value \\quad of \\quad f \\quad on \\quad [a, b] = \\frac{1}{b - a} \\int_a^b f(x) dx \\] <p>As for a function, the average theorem actually says that the following two areas are equal:</p> <p></p> <p>Let's label the correspongding point on the x-axis as c, like this:</p> <p></p> <p>So we have \\(f(x) = f_{av}\\). It turns out that if \\(f\\) is continuous, then there is always such a number c(Mean Value Theorem for integral):</p> <p>If \\(f\\) is continous on \\([a, b]\\), then there exists c in \\((a, b)\\) such that:</p> \\[ f(c) = \\frac{1}{b - a} \\int_{a}^{b} f(x) dx \\]"},{"location":"Math/Calculus/11_tech_to_solve_int/","title":"Techniques to Solve Integration Problems","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#substitution","title":"Substitution","text":"<p>Substitution, also known as \"change of variables\", comes from the chain rule. What saves us in the case of \\(\\int 2x e^{x^2} dx\\) is the presence of the 2x factor, which is exactly what popped out when we used the chain rule to differentiate \\(e^{x^2}\\). Now imagine starting with an indefinite integral like this:</p> \\[ \\int x^2 cos(x^3) dx \\] <p>The derivative of the quantity \\(x^3\\) is \\(3x^2\\). This almost matches the factor \\(x^2\\) in the integrand, it's only the constant 3 that makes things a little more difficult. Still, constants can move in or out of integrals, so that should not be a problem.</p> <p>Start off by setting \\(t = x^3\\), we can get:</p> \\[ \\int x^2 cos(x^3) dx = \\int cost(x^3) (x^2 dx) = \\int cos(t) (\\frac{1}{3} dt) \\] <p>The middle step isn't really necessary, but it helps to see \\(x^2\\) \\(dx\\) next to each other so that you can justify replacing theme by \\(\\frac{1}{3} dt\\). Anyway, now we can drag the factor of \\(\\frac{1}{3}\\) outside the integral, then integrate:</p> \\[ \\int x^2 cos(x^3) dx = \\int cos(t) \\frac{1}{3} dt = \\frac{1}{3} \\int cos(t) dt = \\frac{1}{3} + C \\] <p>It's pretty lazy to leave the answer as \\(\\frac{1}{3} sin(t) + C\\). We started in x-land, then migrated over to t-land; now we have to come back to x-land. This isn't hard to do: just replace t by \\(x^3\\) once agin:</p> \\[ \\int x^2 cos(x^3) dx = \\frac{1}{3} sin(x^3) + C \\] <p>In general, if \\(f\\) is a differentiable function, then:</p> \\[ \\int \\frac{f'(x)}{f(x)} dx = \\ln |f(x)| + C \\] <p>And for the type of \\(\\sqrt[n]{ax + b}\\), we can set \\(t = \\sqrt[n]{ax + b}\\) and differentiate both sides of \\(t^n = ax + b\\)</p> <p>To summarize the method of substitution:</p> <ul> <li>for indefinite integrals, change everytyhing to do with \\(x\\) and \\(dx\\) to stuff involving \\(t\\) and \\(dt\\), do the new integral, then change back to \\(x\\) stuff;</li> <li>for definite integrals, change everything to do with \\(x\\) and \\(dx\\) to stuff involving \\(t\\) and \\(dt\\), and change the limits of integration to the corresponding \\(t\\) values as well, then do the new integral(no need to go back to x-land here).</li> </ul>"},{"location":"Math/Calculus/11_tech_to_solve_int/#integration-by-parts","title":"Integration by Parts","text":"<p>We saw how to reverse the chain rule by using the method of substitution. There is also a way to reverse the product rule, which is called integration by parts.</p> <p>The product rule is:</p> \\[ \\frac{d}{dx} (uv) = v \\frac{du}{dx} + u \\frac{dv}{dx} \\] <p>Let's rearrange this equation and then integrate both sides with respect to \\(x\\):</p> \\[ \\int u \\frac{dv}{dx} dx = \\int \\frac{d}{x} (uv) dx - \\int v \\frac{du}{dx} \\] <p>The first term on the right-hand side is the antiderivative of the derivative of \\(uv\\), so it's just equal to \\(uv + C\\). The \\(+C\\) is unnecessary, though, because the second term ont the right-hand side is already an indefinite integral, so we have:</p> \\[ \\int u \\frac{dv}{dx} dx = uv - \\int v \\frac{du}{dx} \\] <p>If we replace \\(\\frac{dv}{dx} dx\\) by \\(dv\\), and replace \\(\\frac{du}{dx}\\) by \\(du\\), we get the formula:</p> \\[ \\int u dv = uv - \\int v du \\]"},{"location":"Math/Calculus/11_tech_to_solve_int/#partial-fractions","title":"Partial Fractions","text":"<p>Let's focus our attention on how to integrate a rational function. So we want to find an integral like:</p> \\[ \\int \\frac{p(x)}{q(x)} dx \\] <p>where \\(p\\) and \\(q\\) are polynomials.</p> <p>Here is the complete method for finding the integral of a rational functions:</p> <ul> <li>Step1, check degrees, divide if necessary: check to see if the degree of the numerator is less than the degree of the denominator. If it is, then you're golden, go to step 2. If not do a long division, then to step 2. </li> <li>Step2, factor the denominator: use the quadratic formula, or guess roots and divide, to factor the denominator of your integrand.</li> <li> <p>Step3, the form: write down the \"form\", with undetermined constants, </p> <ul> <li>\\(\\frac{A}{x + a}\\)</li> <li>\\(\\frac{A}{(x + a)^2} + \\frac{B}{x + a}\\)</li> <li>\\(\\frac{Ax + B}{x^2 + ax + b}\\)</li> <li>\\(\\frac{A}{(x + a)^3} + \\frac{B}{(x + a)^2} + \\frac{C}{x + a}\\)</li> </ul> </li> <li> <p>Step4, evaluate constants: multiply both sides of this equation by the denominator, then find the constants by:</p> <ul> <li>substituting clever values of x;</li> <li>equating coefficients;</li> <li>some combination of aboves.</li> </ul> </li> <li> <p>Step5, integrate terms with linear powers on the bottom: solve any integrals whose denominators are powers of linear functions; the answers will involve logs or negative powers of the linear term.</p> </li> <li> <p>Step6, integrate terms with quadratics on the bottom: for each integral with nonfactorable quadratic term in the denominator, complete the square, make a change of variable, then possibly split up into two integrals. This formula is very useful most of the time:</p> </li> </ul> \\[ \\int \\frac{1}{t^2 + a^2} dt = \\frac{1}{a} tan^{-1}(\\frac{t}{a}) + C \\]"},{"location":"Math/Calculus/11_tech_to_solve_int/#integrals-involving-trig-identities","title":"Integrals Involving Trig Identities","text":"<p>There are three families of trig identities which are particularly useful in evaluating integrals.</p> <p>The first family arises from the double-angle formular for \\(cos(2x)\\). We have known that \\(cos(2x) = 2cos^2(x) - 1\\) and \\(cos(2x) = 1 - 2sin^2(x)\\). So we have:</p> \\[ cos^2(x) = \\frac{1}{2}(1 + cos(2x)) \\] \\[ sin^2(x) = \\frac{1}{2}(1 - cos(2x)) \\] <p>The second family of trig identities involving Pythagorean identities:</p> \\[ sin^2(x) + cos^2(x) = 1 \\] \\[ tan^2(x) + 1 = sec^2(x) \\] \\[ 1 + cot^2(x) = csc^2(x) \\] <p>Let's look at the third family of identities, the so-called products-to-sums identities:</p> \\[ cos(A) cos(B) = \\frac{1}{2}(cos(A - B) + cos(A + B)) \\] \\[ sin(A) sin(B) = \\frac{1}{2}(cos(A - B) - cos(A + B)) \\] \\[ sin(A) cos(B) = \\frac{1}{2}(sin(A - B) + sin(A + B)) \\]"},{"location":"Math/Calculus/11_tech_to_solve_int/#integrals-involving-powers-of-trig-functions","title":"Integrals Involving Powers of Trig Functions","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#powers-of-sin-andor-cos","title":"Powers of \\(sin\\) and/or \\(cos\\)","text":"<p>If one of the powers of \\(sin(x)\\) or \\(cos(x)\\) is odd, then grab it. If you've grabbed your odd power, then you need to pull out one power to go with the \\(dx\\); then deal with what's left by using one of the identities:</p> \\[ cos^2(x) = 1 - sin^2(x) \\] \\[ sin^2(x) = 1 - cos^2(x) \\]"},{"location":"Math/Calculus/11_tech_to_solve_int/#powers-of-tan","title":"Powers of \\(tan\\)","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#powers-of-sec","title":"Powers of \\(sec\\)","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#powers-of-cot","title":"Powers of \\(cot\\)","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#powers-of-csc","title":"Powers of \\(csc\\)","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#reduction-formula","title":"Reduction formula","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#integrals-involving-trig-substitutions","title":"Integrals Involving Trig Substitutions","text":""},{"location":"Math/Calculus/11_tech_to_solve_int/#type-1-sqrta2-x2","title":"Type 1: \\(\\sqrt{a^2 - x^2}\\)","text":"<p>If you have an integral involving an odd power of \\(\\sqrt{a^2 - x^2}\\), the correct substitution to use is \\(x = a sin(\\theta)\\). The reason that this substituation is effective is that:</p> \\[ a^x - x^2 = a^2 - a^2 sin^2(\\theta) = a^2 (1 - sin^2(\\theta)) = a^2 cos^2 (\\theta) \\] <p>and we can get \\(dx = a cos(\\theta)d\\theta\\). Now you can easily take a square root.</p> <p></p>"},{"location":"Math/Calculus/11_tech_to_solve_int/#type-2-sqrta2-x2","title":"Type 2: \\(\\sqrt{a^2 + x^2}\\)","text":"<p>If an integral involves an odd power of \\(\\sqrt{x^2 + a^2}\\), the correct substitution is \\(x = a tan(\\theta)\\), this works because:</p> \\[ x^2 + a^2 = a^2 tan^2(\\theta) + a^2 = a^2 (tan^2(\\theta) + 1) = a^2 sec^2 (\\theta) \\] <p>Also, we'll need to know that \\(dx = a sec^2(\\theta) d\\theta\\). </p>"},{"location":"Math/Calculus/11_tech_to_solve_int/#type-3-sqrtx2-a2","title":"Type 3: \\(\\sqrt{x^2 - a^2}\\)","text":"<p>Finally, as for \\(\\sqrt{x^2 - a^2}\\), the correct substitution is \\(x = a sec(\\theta)\\)</p> \\[ x^2 - a^2 = a^2 sec^2(\\theta) - a^2 = a^2 (sec^2(\\theta) - 1) = a^2 tan^2(\\theta) \\] <p>To take the substitution, we'll also need the fact that \\(dx = a sec(\\theta)tan(\\theta)d\\theta\\)</p> <p></p>"},{"location":"Math/Calculus/12_improper_integral/","title":"Improper Integrals","text":"<p>The integral \\(\\int_{a}^{b} f(x) dx\\) is improper if any of the following conditions apply:</p> <ol> <li>\\(f\\) isn't bounded in the closed interval \\([a, b]\\);</li> <li>\\(b = \\infty\\);</li> <li>\\(a = -\\infty\\).</li> </ol> <p>If \\(f(x)\\) is unbounded for \\(x\\) near some number \\(c\\), we'll say that \\(f\\) has a blow-up point at \\(x = c\\).</p> <p></p> <p>We can define the integral of improper integral if we have a blow-up point at \\(x = a\\):</p> \\[ \\int_{a}^{b} f(x) dx = \\lim_{\\epsilon \\to 0^+} \\int_{a + \\epsilon}^{b} f(x) dx \\] <p>If the limit is \\(L\\) as \\(\\epsilon \\to 0^+\\), we say that \\(\\int_{a}^{b} f(x) dx\\) converge to L. If there's no limit, we say that the above integral diverges.</p> <p>Now we still have to look at what happens when one or both of the limits of integration are infinite, this means that the region of integration is unbounded:</p> \\[ \\int_{a}^{\\infty} f(x) dx \\] <p>In symbols, we are define:</p> \\[ \\int_{a}^{\\infty} f(x) dx = \\lim_{N \\to \\infty} \\int_{a}^{N} f(x) dx \\]"},{"location":"Math/Calculus/12_improper_integral/#the-comparison-testtheory","title":"The Comparison Test(Theory)","text":"<p>Suppose we have two functions which are never negative, at least in some region of interest. If the first function is bigger than the second function, and the integral of the second function diverges, then the first function also diverges.</p> <p>Mathematically, it looks like this: if \\(f(x) \\ge g(x) \\ge 0\\) for \\(x\\) in the interval \\((a, b)\\), and we know that \\(\\int_{a}^{b} g(x) dx\\) diverges, then so does \\(\\int_{a}^{b} f(x) dx\\).</p> \\[ \\int_{a}^{b} f(x) dx \\ge \\int_{a}^{b} g(x) dx = \\infty \\] <p></p> <p>On the other hand, for convergence, if \\(0 \\le f(x) \\le g(x)\\) on \\((a, b)\\) and \\(\\inf_{a}^{b} g(x) dx\\) converges, then so does \\(\\int_{a}^{b} f(x) dx\\):</p> \\[ \\int_{a}^{b} f(x) dx \\le \\int_{a}^{b} g(x) dx &lt; \\infty \\] <p></p>"},{"location":"Math/Calculus/12_improper_integral/#the-limit-comparison-testtheory","title":"The Limit Comparison Test(Theory)","text":"<p>Suppose we have two function \\(f\\) and \\(g\\) such that:</p> \\[ \\lim_{x \\to a} \\frac{f(x)} {g(x)} = 1 \\] <p>We'll say that \\(f(x) \\sim g(x)\\) as \\(x \\to a\\) if the limit of the ratio is 1.</p>"},{"location":"Math/Calculus/12_improper_integral/#the-p-testtheory","title":"The p-Test(Theory)","text":"<p>Now that we have the comparison test and limit comparison test, we need to know how to use them. The question is, what are some functions we could choose as g? Well, the most useful are the functions \\(\\frac{1}{x^p}\\) for some \\(p &gt; 0\\). Since these functions are so easy to integrate, we can use the limit formula to get the p-test:</p> <ul> <li>p-test, \\(\\int^{\\infty}\\) version: For any finite \\(a &gt; 0\\), the integral below converges if \\(p &gt; 1\\) and diverges if \\(p &lt; 1\\)</li> </ul> \\[ \\int_{a}^{\\infty} \\frac{1}{x^p} dx \\] <ul> <li>p-test, \\(\\int_{0}\\) version: For any finite \\(a &gt; 0\\), the integral below converges if \\(p &lt; 1\\) and diverges if \\(p &gt; 1\\)</li> </ul> \\[ \\int_{0}^{a} \\frac{1}{x^p} dx \\]"},{"location":"Math/Calculus/13_sequances_and_series/","title":"Sequences and Series","text":"<p>Infinite series are pretty similar to improper integrals.</p>"},{"location":"Math/Calculus/13_sequances_and_series/#convergence-and-divergence-of-sequences","title":"Convergence and Divergence of Sequences","text":"<p>A sequence is a collection of numbers in order. It might have a finite number of terms, or it might go on forever, in which case it is called an <code>infinite sequence</code>. For example:</p> \\[ 0, 1, 2, 3, 4, ... \\] <p>Sequences are normally written using subscript notation, where \\(a_1\\) denotes the first element of the series, \\(a_2\\) the second, \\(a_3\\) the third, and so on.</p> <p>Given an infinite sequence, our main focus is going to be on the limiting behavior of the values of the sequence as the index \\(n\\) tends to infinity. That is, what happens to the sequence as you look farther and farther along it? In math notation, does</p> \\[ \\lim_{n \\to \\infty} a_n \\] <p>exist, and if so, what is it?</p> <p>The basic idea is that the statement</p> \\[ \\lim_{n \\to \\infty} a_n = L \\] <p>means that \\(a_n\\) might wander around for a little while, but eventually gets very close to \\(L\\) and stays at least as close to \\(L\\) for ever after. If there's such a number \\(L\\), then the sequence \\(\\{a_n\\}\\) <code>converges</code>; otherwise it <code>diverges</code>. Just like functions, sequences can diverge to \\(\\infty\\) or \\(-\\infty\\), or they can oscillate around and not get close to any particular value.</p>"},{"location":"Math/Calculus/13_sequances_and_series/#two-important-sequences","title":"Two important sequences","text":"<p>Pick some constant number \\(r\\) and consider the sequence given by \\(a_n = r^n\\) starting at \\(n = 0\\). This is a <code>geometric progression</code>.</p> <p>These are all special cases of the general rule, which is as follows:</p> \\[ \\lim_{n \\to \\infty} r^n =  \\begin{cases} = 0 &amp; if \\quad -1 &lt; r &lt; 1, \\\\ = 1 &amp; if \\quad r = 1, \\\\ = \\infty &amp; if \\quad r &gt; 1, \\\\ = DNE &amp; if \\quad r \\le -1. \\end{cases} \\] <p>In particular, if \\(k\\) is any constant, then</p> \\[ \\lim_{n \\to \\infty} (1 + \\frac{k}{n})^n = e^k \\]"},{"location":"Math/Calculus/13_sequances_and_series/#convergence-and-divergence-of-series","title":"Convergence and Divergence of Series","text":"<p>A series is just a sum. We'd like to add up all of the terms of a sequence \\(a_n\\). Let's define a new sequence, which we'll call \\(\\{A_N\\}\\), by setting:</p> \\[ A_N = a_1 + a_2 + a_3 + \\cdots + a_{N - 1} + a_{N} \\] <p>The new sequence is called the sequence of <code>partial sums</code>. The weird equaton now looks like this:</p> \\[ a_1 + a_2 + a_3 + \\cdots = \\lim_{N \\to \\infty} A_N \\] <p>If the limit exists and equals \\(L\\), then we'll say that the seriess on the left-hand side <code>converges</code> to \\(L\\). If the limit doesn't exist, then the series <code>diverges</code>.</p> <p>The formula for \\(A_N\\) is:</p> \\[ A_N = a_1 + a_2 + a_3 + \\cdots + a_{N - 1} + a_N = \\sum_{n = 1}^N a_n \\] <p>The infinite seriess is written as:</p> \\[ a_1 + a_2 + a_3 + \\cdots = \\sum_{n = 1} ^{\\infty} a_n \\] <p>So, here's how to define the value of an infinite series using sigma notation:</p> \\[ \\sum_{n = 1} ^{\\infty} a_n = \\lim_{N \\to \\infty} \\sum_{n = 1} ^N a_n \\]"},{"location":"Math/Calculus/13_sequances_and_series/#geometric-seriestheory","title":"Geometric series(theory)","text":"<p>Let's look at an important example of an infinite series. Suppose we start with the geometric progression \\(1, r, r^2, r^3, \\cdots\\), we can use this sequence as the terms of an infinit series:</p> \\[ 1 + r + r^2 + r^3 + \\cdots = \\sum_{n = 0} ^{\\infty} r^n \\] <p>This is called a <code>geometric series</code>. It turns out that the geometric series:</p> \\[ \\sum_{n = 0}^{\\infty} r^n = \\frac{1}{1 - r} \\] <ul> <li>if \\(-1 &lt; r &lt; 1\\);</li> <li>otherwise, if \\(r \\ge 1\\) or \\(r \\le -1\\), the series diverges.</li> </ul>"},{"location":"Math/Calculus/13_sequances_and_series/#the-n-th-term-testtheory","title":"The n-th Term Test(Theory)","text":"<p>For a series to converge, the sequence of partial sums has to have a limit. The partial sum after N steps represents your position after you have taken N steps. If you  finally converge to some special limiting position as you keep on taking more and more steps, then your steps have to become really really small.</p> <p>So your step sizes, which are just given by the sequence \\(\\{a_n\\}\\), eventually have to become very small, at least if you want your series to converge. This leads to the <code>n-th term</code> test:</p> <p>if \\(\\lim_{n \\to \\infty} a_n != 0\\), or the limit doesn't exist, then the seriess \\(\\sum_{n = 1}^{\\infty} a_n\\) diverges.</p> <p>Just beware:</p> <p>the n-th term test cannot be used to show that a series converges!</p>"},{"location":"Math/Calculus/13_sequances_and_series/#the-p-testtheory","title":"The p-test(Theory)","text":"<p>The p-test is basically the same as the p-test for improper integrals with problem spot at \\(\\infty\\):</p> \\[ \\sum_{n = a}^{\\infty} \\frac{1}{n^p} \\begin{cases} converges &amp; if \\quad p &gt; 1, \\\\ diverges &amp; if \\quad p \\le 1. \\end{cases} \\]"},{"location":"Math/Calculus/13_sequances_and_series/#new-tests-for-series","title":"New Tests for Series","text":"<p>The tests above are from improper integral. Here are four tests for convergence of series which have no corresponding improper integral versions.</p>"},{"location":"Math/Calculus/13_sequances_and_series/#the-ratio-test","title":"The ratio test","text":"<p>To test the series \\(\\sum_{n=1}^{\\infty}a_n\\), let's consider a new sequence \\(b_n\\), and </p> \\[ b_n = |\\frac{a_{n + 1}}{a_n}| \\] <p>The the series \\(\\{\\sum_{n=1}^{\\infty}a_n\\}\\):</p> <ul> <li>converges, if the sequence \\({b_n}\\) converges to a number less than \\(1\\);</li> <li>diverges, if the sequence \\({b_n}\\) converges to a number greater than \\(1\\);</li> </ul>"},{"location":"Math/Calculus/13_sequances_and_series/#the-root-test","title":"The root test","text":"<p>The root test(also called the n-th root test) is a close cousin of the ratio test. Instead of considering ratios of successive terms, just consider the n-th root of the absolute value of n-th term.</p> <p>Starting with a series \\(\\sum_{n = 1}^{\\infty} a_n\\), let's make a new sequence given by:</p> \\[ b_n = |a_n|^{\\frac{1}{n}} \\] <p>If the limit of sequence \\(\\{b_n\\}\\) converges and is:</p> <ul> <li>less than 1, then the series \\(\\sum_{n=1}^{\\infty} a_n\\) converges;</li> <li>greater than 1, then the series \\(\\sum_{n=1}^{\\infty} a_n\\) diverges;</li> <li>equals 1, then you can't tell what the hecks is going on.</li> </ul>"},{"location":"Math/Calculus/13_sequances_and_series/#the-integral-test","title":"The integral test","text":"<p>If \\(f\\) is a decreasing positive function such that \\(f(n) = a_n\\) for all positive integers \\(n\\), then:</p> \\[ \\int_{1}^{\\infty} f(x) dx \\] <p>and</p> \\[ \\sum_{n = 1}^{\\infty} a_n \\] <p>either both converge or both diverge.</p>"},{"location":"Math/Calculus/13_sequances_and_series/#the-alternating-series-test","title":"The alternating series test","text":"<p>The <code>alternating series test</code> says that if a series \\(\\sum_{n = 1}^{\\infty}\\), and the absolute values of its terms are decreasing to \\(0\\), then the series converges.</p>"},{"location":"Math/Calculus/13_sequances_and_series/#how-to-solve-series-problems","title":"How to Solve Series Problems","text":"<ol> <li><code>Is the series geometric?</code> If your series only involves exponentials like \\(2^n\\) or \\(e^{3n}\\), it might be a geometric series, or it might be the sum of one or more geometric series.</li> <li><code>Do the terms got to 0?</code> If the series isn't geometric, try n-th term test.</li> <li><code>Are there negative terms in the series?</code> If so, you may have to use the absolute convergence test or the alternating series test.</li> <li><code>Are factorials involved?</code> If so, use ratio test</li> <li><code>Are there tricky exponentials with n in the base and the exponent?</code> If so, try root test.</li> <li><code>Do the terms have a factor ef exactly $1/n$ as well as logarithms?</code>, In this case, try integral test.</li> <li><code>Do none of the above tests seem to work?</code> You may have to use the comparison test or the limit comparison test.</li> </ol>"},{"location":"Math/Calculus/14_taylor/","title":"Tylor Polynomials, Tylor Series and Power Series","text":""},{"location":"Math/Calculus/14_taylor/#approximations-and-taylor-polynomials","title":"Approximations and Taylor Polynomials","text":"<p>Here's a nice fact: for any real number x, we have:</p> \\[ e^x \\cong 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} \\] <p>Also, the closer x is to 0, the better the approximation.</p> <p>Let's say we have some function \\(f\\) which is very smooth, so that it can be repeatedly differentiated as many times as you like without causing any problems. Here is the question: what is the equation of the line which best approximates the curve \\(y = f(x)\\) near the point \\((a, f(a))\\)? The answer to this question is that the line we're looking for is the tangent line to the curve at the point \\((a, f(a))\\):</p> \\[ y = f(a) + f'(a)(x - a) \\] <p></p> <p>Why stick to lines? What is the equation of the quadratic which best approximates the curve \\(y = f(x)\\) near \\((a, f(a))\\)? It turns out that the formula for the quadratic which best approximates the curve \\(y = f(x)\\) for \\(x\\) near \\(a\\) is given by:</p> \\[ y = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2} (x - a)^2 \\] <p>This is actually a quadratic in \\(x\\), because if you expand \\((x -a)^2\\), the highest power of \\(x\\) floating around is \\(x^2\\)</p> <p>Let's call the quadratic \\(P_2\\):</p> \\[ P_2(x) = f(a) + f'(a) (x - a) + \\frac{f''(a)}{2} (x -  a)^2 \\] <p>Let's continue the same pattern, except that we'll use some arbitrary degree \\(N\\) instead of just 1 or 2. So, here's our question: which polynomial of degree \\(N\\) or less gives the best approximation to \\(f(x)\\) for values of \\(x\\) near \\(a\\)? The answer is given by A Tylor approximation theorem:</p> <p>If \\(f\\) is smooth at \\(x = a\\), then of all the polynomials of degree \\(N\\) or less, the one which best approximates \\(f(x)\\) for \\(x\\) near \\(a\\) is given by:</p> \\[ P_N(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2!}(x - a)^2 + \\frac{f^{(3)}(a)}{3!} (x - a)^3 + \\cdots + \\frac{f^{(n)}(a)}{N!} (x - a)^N \\] <p>In sigma notation, the formula looks like this:</p> \\[ P_N(x) = \\sum_{n = 0}^{N} \\frac{f^{(n)}(a)}{n!} (x - a)^n \\] <p>We call the polynomial \\(P_N\\) <code>the Nth-order Taylor polynomial of $f(x)$</code></p> <p>Now we have a approximation for \\(f(x)\\), but how good is it? Here comes another formula for the error, the <code>Taylor' Theorem</code>:</p> <p>In above contents we have a function's Nth-order Taylor polynomial about \\(x = a\\):</p> \\[ P_N(x) = \\sum_{n = 0}^{N} \\frac{f^{(n)}(a)}{n!} (x - a)^n \\] <p>We want to use the value of \\(P_N(x)\\) to approximate the true value \\(f(x)\\), so we consider the error term, which is the difference between the true value and the approximate value:</p> \\[ R_N(x) = f(x) - P_N(x) \\] <p>Actually, \\(R_N(x)\\) is called the <code>Nth-order term</code>, it's also referred to as the <code>Nth-order remainder term</code>. Tylor's Theorem gives an alternative formula for \\(R_N(x)\\):</p> \\[ R_N(x) = \\frac{f^{(N + 1)}(c)}{(N + 1)!} (x - a)^{N + 1} \\] <p>where \\(c\\) is some number which lies between \\(x\\) and \\(a\\).</p> <p>Since \\(f(x) = P_N(x) + R_N(x)\\), we can write:</p> \\[ f(x) = \\sum_{n = 0}^{N} \\frac{f^{(n)}(a)} {n!} (x - a)^n + \\frac{f^{(N + 1)}(c)} {(N + 1)!} (x - a)^{N + 1} \\]"},{"location":"Math/Linear-Algebra/00_summary/","title":"Summary","text":"<p>Here are the notes for the MIT Linear Algebra.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/","title":"The Geometry of Linear Equations","text":"<p>The fundamental problem of n linear equations in n unknowns, for example:</p> \\[ \\begin{align} 2x - y = 0 \\\\ -x + 2y = 3 \\end{align} \\] <p>In this first lecture on linear algebra we view this problem in three ways.</p> <p>The system above is two dimensional(\\(n = 2\\)). By adding a third variable z we could expand it to three dimensions.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/#row-picture","title":"Row Picture","text":"<p>Plot the points that satisfy each equation. The interaction of the plots(if they do intersect) represents the solution to the system of equations. Looking at the figure below we see that the solution to this system of equations is \\(x = 1, y = 2\\).</p> <p></p> <p>We plug this solution into the original system of equations to check our work:</p> \\[ \\begin{align} 2 \\times 1 - 2 = 0 \\\\ -1 + 2 \\times 2 = 3 \\end{align} \\] <p>The solution to a three dimensional system of equations is the common point of intersection of three planes(if there is one).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/#column-picture","title":"Column Picture","text":"<p>In the column picture we rewrite the system of linear equations as a single equation by turning the coefficients in the columns of the system into vectors.</p> \\[ x \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} + y \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix} \\] <p>Given two vector \\(\\mathbf{c}\\) and \\(\\mathbf{d}\\) and scalars \\(x\\) and \\(y\\), the sum \\(x\\mathbf{c} + y\\mathbf{d}\\) is called a <code>linear combination</code> of \\(\\mathbf{c}\\) and \\(\\mathbf{d}\\). Linear combinations are important throughout this course.</p> <p>Geometrically, we want to find numbers \\(x\\) and \\(y\\) so that \\(x\\) copies of vector \\(\\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}\\) added to \\(y\\) copies of vector \\(\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}\\) equals the vector \\(\\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix}\\). As we see from the figure below, \\(x = 1\\) and \\(x = 2\\), agreeing with the row picture.</p> <p></p> <p>In three dimensions, the column picture requires us to find a linear combination of three 3-dimensional vectors that equals the vector \\(\\mathbf{b}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/#matrix-picture","title":"Matrix Picture","text":"<p>We write the system of equations:</p> \\[ \\begin{align} 2x - y = 0 \\\\ -x + 2y = 3 \\end{align} \\] <p>as a single equation by using matrices and vectors:</p> \\[ \\begin{bmatrix} 2 &amp; -1 \\\\ -1 &amp; 2\\end{bmatrix} \\begin{bmatrix} x \\\\ y\\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3\\end{bmatrix} \\] <p>The matrix \\(A = \\begin{bmatrix} 2 &amp; -1 \\\\ -1 &amp; 2 \\end{bmatrix}\\) is called the <code>coefficient matrix</code>. The vector \\(x = \\begin{bmatrix} x \\\\ y\\end{bmatrix}\\) is the vector of unknowns. The values on the right hand side of the equations form the vector \\(\\mathbf{b}\\):</p> \\[ A \\mathbf{x} = \\mathbf{b} \\] <p>The three dimensional matrix picture is very like the two dimensional one, except that the vectors and matrices increase in size.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>How do we multiply a matrix \\(A\\) by a vector \\(\\mathbf{x}\\)?</p> \\[ \\begin{bmatrix} 2 &amp; 5 \\\\ 1 &amp; 3\\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix} = ? \\] <p>One method is to think of the entries of \\(\\mathbf{x}\\) as the coefficients of a linear combination of the column vectors of the matrix:</p> \\[ \\begin{bmatrix} 2 &amp; 5 \\\\ 1 &amp; 3\\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix} = 1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + 2 \\begin{bmatrix} 5 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 7 \\end{bmatrix} \\] <p>This technique shows that \\(A \\mathbf{x}\\) is a linear combination of the columns of \\(A\\).</p> <p>You may also calculate the product \\(A\\mathbf{x}\\) by taking the dot product of each row of \\(A\\) with the vector \\(\\mathbf{x}\\):</p> \\[ \\begin{bmatrix} 2 &amp; 5 \\\\ 1 &amp; 3\\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix} = \\begin{bmatrix} 2 \\cdot 1 + 5 \\cdot 2 \\\\ 1 \\cdot 1 + 3 \\cdot 2 \\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 7 \\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/01_geometry_of_linear_equations/#linear-independence","title":"Linear Independence","text":"<p>In the column and matrix pictures, the right hand side of the equation is a vector \\(\\mathbf{b}\\). Given a matrix \\(A\\), can we solve:</p> \\[ A \\mathbf{x} = \\mathbf{b} \\] <p>for every possible vector \\(\\mathbf{b}\\)? In other words, do the linear combination of the column vectors fill the \\(xy\\)-plane(or space, in the three dimensional case)?</p> <p>If the answer is \"no\", we say that \\(A\\) is a <code>singular matrix</code>. In this singular case its column vectors are <code>linear dependent</code>; all linear combinations of those vectors lie on a point or line(in two dimensions) or plane(in three dimensions). The combinations don't fill the whole space.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/02_overview/","title":"An Overview of Linear Algebra","text":"<p>Linear algebra progresses from vectors to matrices to subspaces.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/02_overview/#vectors","title":"Vectors","text":"<p>What do you do with vectors? Take combinations.</p> <p>We can multiply vectors by scalars, add, and subtract. Given vectors \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) we can form the <code>linear combination</code> \\(x_1 \\mathbf{u} + x_2\\mathbf{v} + x_3\\mathbf{w} = \\mathbf{b}\\).</p> <p>An example in \\(\\mathbb{R}^3\\) would be:</p> \\[ \\mathbf{u} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\end{bmatrix}, \\mathbf{v} = \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\end{bmatrix}, \\mathbf{w} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\] <p>The collection of all multiples of \\(\\mathbf{u}\\) forms a line through the origin. The collection of all multiples of \\(\\mathbf{v}\\) forms another line. The collection of all combinations of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) forms a plane. Taking all combinations of some vectors creates a <code>subspace</code>.</p> <p>We could continue like this, or we can use a matrix to add in all multiples of \\(\\mathbf{w}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/02_overview/#matrices","title":"Matrices","text":"<p>Create a matrix \\(A\\) with vectors \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) in its colums:</p> \\[ A = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -11 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\end{bmatrix} \\] <p>The product:</p> \\[ A \\mathbf{x} =  \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -1 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} =  \\begin{bmatrix} x_1 \\\\ -x_1 + x_2 \\\\ -x_2 + x_3 \\end{bmatrix} \\] <p>equals the sum \\(x_1\\mathbf{u} + x_2\\mathbf{v} + x_3\\mathbf{w} = \\mathbf{b}\\). The product of a matrix and a vector is a combination of the columns of the matrix. (This particular matrix A is a <code>difference matrix</code> because the components of \\(A\\mathbf{x}\\) are differences of the components of that vector.)</p> <p>When we say \\(x_1 \\mathbf{u} + x_2 \\mathbf{v} + x_3 \\mathbf{w} = \\mathbf{b}\\), we're thinking about multiplying numbers by vectors; when we say \\(A\\mathbf{x} = \\mathbf{b}\\), we're thinking about multiplying a matrix(whose columns are \\(\\mathbf{u}\\), \\(\\mathbf{v}\\), and \\(\\mathbf{w}\\)) by the numbers. The calculations are the same, but our perspective has changed.</p> <p>For any input vector \\(\\mathbf{x}\\), the output of the operation \"multiplication by A\" is some vector \\(\\mathbf{b}\\):</p> \\[ A \\begin{bmatrix} 1 \\\\ 4 \\\\ 9 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 5 \\end{bmatrix} \\] <p>A deeper question is to start with a vector \\(\\mathbf{b}\\) and ask \"for what vectors \\(\\mathbf{x}\\) does \\(A\\mathbf{x} = \\mathbf{b}\\)?\" In our example, this means solving three equations in three unknowns, solving:</p> \\[ A\\mathbf{x} = \\begin{bmatrix} 1 &amp; 0 &amp; \\\\ -1 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} x_1 \\\\ x_2 - x_1 \\\\ x_3 - x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\] <p>is equivalent to solving:</p> \\[ \\begin{align} x_1 = b_1 \\\\ x_2 - x_1 = b_2 \\\\ x_3 - x_2 = b_3 \\end{align} \\] <p>In vector form, the solution is:</p> \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_1 + b_2 \\\\ b_1 + b_2 + b_3 \\end{bmatrix} \\] <p>But this just says:</p> \\[ \\mathbf{x} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\] <p>or</p> \\[ \\mathbf{x} = A^{-1} \\mathbf{b} \\] <p>If the matrix \\(A\\) is invertible, we can multiply on both sides by \\(A^{-1}\\) to find the unique solution \\(\\mathbf{x}\\) to \\(A\\mathbf{x} = \\mathbf{b}\\). We might say that \\(A\\) represents a transform \\(\\mathbf{x} \\to \\mathbf{b}\\) that has an inverse transform \\(\\mathbf{b} \\to \\mathbf{x}\\).</p> <p>In particular, if \\(\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\) then \\(\\mathbf{x} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\)</p> <p>The second example has the same columns \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) and replaces column vector \\(\\mathbf{w}\\):</p> \\[ C = \\begin{bmatrix} 1 &amp; 0 &amp; -1 \\\\ -1 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\end{bmatrix} \\] <p>Then</p> \\[ C\\mathbf{x} = \\begin{bmatrix} 1 &amp; 0 &amp; -1 \\\\ -1 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} x_1 - x_3 \\\\ x_2 - x_1 \\\\ x_3 - x_2 \\end{bmatrix} \\] <p>And our system of three equations in three unknowns become circular.</p> <p>Where before \\(A\\mathbf{x} = \\mathbf{0}\\) implied \\(\\mathbf{x} = \\mathbf{0}\\), there are non-zero vectors \\(\\mathbf{x}\\) for which \\(C\\mathbf{x} = \\mathbf{0}\\). For any vector \\(\\mathbf{x}\\) which \\(x_1 = x_2 = x_3, C\\mathbf{x} = \\mathbf{0}\\). This is a significant difference; we can't multiply both sides of \\(C\\mathbf{x} = \\mathbf{0}\\) by an inverse to find a non-zero solution \\(\\mathbf{x}\\).</p> <p>The system of equations encoded in \\(C\\mathbf{x} = \\mathbf{b}\\) is:</p> \\[ \\begin{align} x_1 - x_3 = b_1 \\\\ x_2 - x_1 = b_2 \\\\ x_3 - x_2 = b_3 \\end{align} \\] <p>If we all these three equations together, we get:</p> \\[ 0 = b_1 + b_2 + b_3 \\] <p>This tells us that \\(C\\mathbf{x} = \\mathbf{b}\\) has a solution \\(\\mathbf{x}\\) only when the components of \\(\\mathbf{b}\\) sum to \\(0\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/02_overview/#subspaces","title":"Subspaces","text":"<p>Geometrically, the columns of \\(C\\) lie in the same  plane(they are <code>dependent</code>, the columns of \\(A\\) are <code>independent</code>). There are many vectors in \\(\\mathbb{R}^3\\) which do not lie in that plane. Those vectors cannot be written as a linear combination of the columns of \\(C\\) and so correspond to values of \\(\\mathbf{b}\\) for which \\(C\\mathbf{x} = \\mathbf{b}\\) has no solution \\(\\mathbf{x}\\). The linear combinations of the columns of \\(C\\) form a two dimensional <code>subspace</code> of \\(\\mathbb{R}^3\\).</p> <p>This plane of combinations of \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) can be described as \"all vectors \\(C\\mathbf{x}\\)\". But we know that the vectors \\(\\mathbf{b}\\) for which \\(C\\mathbf{x} = \\mathbf{b}\\) satisfy the condition \\(b_1 + b_2 + b_3 = 0\\). So the plane of all combinations of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) consists of all vectors whose components sum to \\(0\\).</p> <p>If we take all combinations of:</p> \\[ \\mathbf{u} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0\\end{bmatrix}, \\mathbf{v} = \\begin{bmatrix} 0 \\\\ 1 \\\\ -1\\end{bmatrix}, \\mathbf{w} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\end{bmatrix} \\] <p>we get the entire space \\(\\mathbb{R}^3\\); the equation \\(A\\mathbf{x} = \\mathbf{b}\\) has a solution for every \\(\\mathbf{b}\\) in \\(\\mathbb{R}^3\\). We say that \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) form a <code>basis</code> for \\(\\mathbb{R}^3\\).</p> <p>A <code>basis</code> for \\(\\mathbb{R}^n\\) is a collection of \\(n\\) independent vectors in \\(\\mathbb{R}^n\\). Equaivalently, a <code>basis</code> is a collection of \\(n\\) vectors whose combinations cover the whole space. Or, a collection of vectors forms a basis whenever a matrix which has those vectors as its columns is invertible.</p> <p>A <code>vector space</code> is a collection of vectors that is closed under linear combinations. A <code>subspace</code> is a vector space inside another vector space; a plane through the origin in \\(\\mathbb{R}^3\\) is an example of a subspace. A subspace could be equal to the space it's contained in; the smallest subspace contians only the zero vector.</p> <p>The subspace of \\(\\mathbb{R}^3\\) are:</p> <ul> <li>the origin;</li> <li>a line through the origin;</li> <li>a plane through the origin;</li> <li>all of \\(\\mathbb{R}^3\\).</li> </ul>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/02_overview/#conclusion","title":"Conclusion","text":"<p>When you look at a matrix, try to see \"what is it doing\".</p> <p>Matrices can be rectangular; we can have seven equations in three unknowns. Rectangular matrices are not invertible, but the symmetric, square matrix \\(A^TA\\) that often appears when studying rectangular matrices may be invertible.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/03_elimination/","title":"Elimination with Matrices","text":""},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/03_elimination/#method-of-elimination","title":"Method of Elimination","text":"<p><code>Elimination</code> is the technique most commonly used by computer software to solve systems of linear equations. It finds a solution \\(\\mathbf{x}\\) to \\(A\\mathbf{x} = \\mathbf{b}\\) whenever the matrix \\(A\\) is invertible. In the example used in class:</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 3 &amp; 8 &amp; 1 \\\\ 0 &amp; 4 &amp; 1 \\end{bmatrix} \\] <p>and</p> \\[ \\mathbf{b} = \\begin{bmatrix} 2 \\\\ 12 \\\\ 2 \\end{bmatrix} \\] <p>The steps are:</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 3 &amp; 8 &amp; 1 \\\\ 0 &amp; 4 &amp; 1 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; 2 &amp; -2 \\\\ 0 &amp; 4 &amp; 1 \\end{bmatrix} \\to U = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; 2 &amp; -2 \\\\ 0 &amp; 0 &amp; 5 \\end{bmatrix} \\] <p>The number \\(1\\) in the upper left corner of \\(A\\) is called the <code>first pivot</code>. We recopy the first row, then multiply the numbers in it by an appropriate value(in this case, 3) and substract those values from the numbers in the second row. The first number in the second row becomes \\(0\\). We have thus <code>eliminated</code> the \\(3\\) in row 2 and column 1.</p> <p>The next step is to perform another elimination to get a \\(0\\) in row 3 column 1; here this is already the case.</p> <p>The <code>second pivot</code> is the value 2 which now appears in row 2 column 2. We find a multiplier (in this case 2) by which we multiply the second row to eliminate the 4 in row 3 column 2. The <code>third pivot</code> is then the 5 now in row 3 column 3.</p> <p>We started with an invertible matrix \\(A\\) and ended with an <code>upper triangular</code> matrix \\(U\\); the lower left portion of \\(U\\) is filled with zeros. Pivots \\(1, 2, 5\\) are on the <code>diagonal</code> of \\(U\\).</p> <p>When calculating by hand, we can substract the vector \\(\\mathbf{b} = \\begin{bmatrix} 2 \\\\ 12 \\\\ 2 \\end{bmatrix}\\) efficiently by <code>augmenting</code> the matrxi \\(A\\), appending the vector \\(\\mathbf{b}\\) as a fourth or final column:</p> \\[ \\begin{bmatrix} 1 &amp; 2 &amp; 1  &amp; \\vdots &amp; 2 \\\\ 3 &amp; 8 &amp; 1 &amp; \\vdots &amp; 12 \\\\ 0 &amp; 4 &amp; 1 &amp; \\vdots &amp; 2 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 1 &amp; \\vdots &amp; 2 \\\\ 0 &amp; 2 &amp; -2 &amp; \\vdots &amp; 6 \\\\ 0 &amp; 4 &amp; 1 &amp; \\vdots &amp; 2 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 1 &amp; \\vdots &amp; 2 \\\\ 0 &amp; 2 &amp; -2 &amp; \\vdots &amp; 6 \\\\ 0 &amp; 0 &amp; 5 &amp; \\vdots &amp; -10 \\end{bmatrix} \\] <p>Finally, we have \\(U = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; 2 &amp; -2 \\\\ 0 &amp; 0 &amp; 5 \\end{bmatrix}\\) from \\(A\\) and \\(\\mathbf{c} = \\begin{bmatrix} 2 \\\\ 6 \\\\ -10 \\end{bmatrix}\\) comes from \\(\\mathbf{b}\\).</p> <p>The equation \\(U\\mathbf{x} = \\mathbf{c}\\) is easy to solve by <code>back substitution</code>:</p> \\[ \\begin{align} x + 2y + z = 2 \\\\ 2y - 2z = 6 \\\\ 5z = -10 \\end{align} \\] <p>We have \\(z = -2, y = 1\\) and \\(x = 2\\). This is also the solution to the original system \\(A\\mathbf{x} = \\mathbf{b}\\)</p> <p>The <code>determinant</code> of \\(U\\) is the product of the pivots. We will see this again.</p> <p>Pivots may not be \\(0\\). If there is a zero in the pivot position, we must exchange that row with one below to get a non-zero value in the pivot position.</p> <p>If there is a zero in the pivot position and no non-zero value below it, then the matrix \\(A\\) is <code>not invertible</code>. Elimination can not be used to find a unique solution to this system of equations--it doesn't exist.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/03_elimination/#elimination-matrices","title":"Elimination Matrices","text":"<p>The product of a matrix(3x3) and a column vector(3x1) is a column vector(3x1) that is a linear combination of the columns of the matrix.</p> <p>The product of a row(1x3) and a matrix(3x3) is a row(1x3) that is a linear combination of the rows of the matrix.</p> <p>We can subtract 3 times row 1 of matrix A from row 2 of A by calculating the matrix product:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -3 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 3 &amp; 8 &amp; 1 \\\\ 0 &amp; 4 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; 2 &amp; -2 \\\\ 0 &amp; 4 &amp; 1 \\end{bmatrix} \\] <p>The <code>elimination matrix</code> used to eliminate the entry in row m column n is denoted \\(E_{mn}\\). The calculation above took us from \\(A\\) to \\(E_{21}A\\). The three elimination steps leading to \\(U\\) were \\(E_{32}(E_{31}(E_{21}A)) = U\\), where \\(E_{31} = I\\). Thus \\(E_{32}(E_{21}A) = U\\).</p> <p>Matrix multiplication is <code>associative</code>, so we can also write \\((E_{32}E_{21})A = U\\). The product \\(E_{32}E_{21}\\) tells us how to get from \\(A\\) to \\(U\\). The <code>inverse</code> of matrix \\(E_{32}E_{21}\\) tells us how to get from \\(U\\) to \\(A\\).</p> <p>If we solve \\(U\\mathbf{x} = EA\\mathbf{x} = E\\mathbf{b}\\), then it is also true that \\(A\\mathbf{x} = \\mathbf{b}\\). This is why the method of elimination works: all steps can be reversed.</p> <p>A <code>permutation matrix</code> exchanges two rows of matrix:</p> \\[ P = \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>The first and second rows of the matrix \\(PA\\) are the second and first rows of the matrix \\(A\\). The matrix \\(P\\) is constructed by exchanging rows of the identity matrix.</p> <p>To exchange the columns of a matrix, multiply on the right (as in \\(AP\\)) by a permutation matrix. Note that matrix multiplication is not <code>commutative</code>: \\(PA \\ne AP\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/03_elimination/#inverse","title":"Inverse","text":"<p>We have a matrix:</p> \\[ E_{21} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -3 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>which substracts 3 times row 1 from row 2. To \"undo\" this operation, we must add 3 times row 1 to row 2 using the inverse matrix:</p> \\[ E_{21}^{-1} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 3 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>In fact, \\(E_{21}^{-1}E_{21} = I\\)</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/","title":"Multiplication and Inverse Matrices","text":""},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>We discuss four different ways of thinking about the product of two matrices. </p> \\[ AB = C \\] <p>If \\(A\\) is an \\(m \\times n\\) matrix and \\(B\\) is an \\(n \\times p\\) matrix, then \\(C\\) is an \\(m \\times p\\) matrix. We use \\(c_{ij}\\) to denote the entry in row i and column j of matrix \\(C\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#standard-row-times-column","title":"Standard (row times column)","text":"<p>The standard way of describing a matrix product is to say that \\(c_{ij}\\) equals the dot product  of row i of matrix A and column j of matrix B:</p> \\[ c_{ij} = \\sum_{k = 1}^{n} a_{ik}b_{kj} \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#columns","title":"Columns","text":"<p>The product of matrix A and column j of matrix B equals column j of matrix C. This tells us that the columns of C are combinations of columns of A.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#rows","title":"Rows","text":"<p>The product of row i of matrix A and matrix B equals row i of matrix C. So the rows of C are combinations of rows of B.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#column-times-row","title":"Column Times Row","text":"<p>A column of A is an \\(m \\times 1\\) vector and a row of B is a \\(1 \\times p\\) vector. Their product is a matrix:</p> \\[ \\begin{bmatrix} 2 \\\\ 3 \\\\ 4 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 6 \\end{bmatrix} = \\begin{bmatrix} 2 &amp; 12 \\\\ 3 &amp; 18 \\\\ 4 &amp; 24 \\end{bmatrix} \\] <p>The columns of this matrix are multiplies of the column of A and the rows are multiplies of the row of B. If we think of the entries in these rows as the coordinates \\((2, 12)\\) or \\((3, 18)\\) or \\((4, 24)\\), all these points lie on the same line; similarly for the two column vectors. Later we'll see that this is equaivalent to saying that the <code>row space</code> of this matrix is a single line, as is the <code>column space</code>.</p> <p>The product of A and B is the sum of these \"column times rows\" matrices:</p> \\[ AB = \\sum_{k = 1}^{n} \\begin{bmatrix} a_{1k} \\\\ \\vdots \\\\ a_{mk}\\end{bmatrix} \\begin{bmatrix} b_{k1} &amp; \\cdots &amp; b_{kn}\\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#blocks","title":"Blocks","text":"<p>If we subdivide A and B into blocks that match properly, we can write the product \\(AB = C\\) in terms of products of the blocks:</p> \\[ \\begin{bmatrix} A_1 &amp; A_2 \\\\ A_3 &amp; A_4 \\end{bmatrix} \\begin{bmatrix} B_1 &amp; B_2 \\\\ B_3 &amp; B_4 \\end{bmatrix} =\\begin{bmatrix} C_1 &amp; C_2 \\\\ C_3 &amp; C_4 \\end{bmatrix} \\] <p>Here \\(C_1 = A_1B_1 + A_2B_3\\)</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#inverses","title":"Inverses","text":""},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#square-matrices","title":"Square Matrices","text":"<p>If \\(A\\) is a square matrix, the most important question you can ask it is whether it has an inverse \\(A^{-1}\\). If it does, then \\(A^{-1}A = I = AA^{-1}\\) and we say that \\(A\\) is <code>invertible</code> or <code>nonsingular</code>.</p> <p>If \\(A\\) is <code>singular</code>, its determinant is zero and we can find some non-zero vector \\(\\mathbf{x}\\) for which \\(A\\mathbf{x} = 0\\). For example:</p> \\[ \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 6 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix} =  \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\] <p>In this example, three times the column minus one times the second column equals the zero vector; the two column vectors lie on the same line.</p> <p>Finding the inverse of a matrix is closely related to solving systems of linear equations:</p> \\[ \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 7 \\end{bmatrix} \\begin{bmatrix} a &amp; c \\\\ b &amp; d \\end{bmatrix} =  \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\] \\[ A A^{-1} = I \\] <p>can be read as saying \"A times column j of \\(A^{-1}\\) equals column j of the identity matrix\". This is just a special form of the equation \\(A\\mathbf{x} =\\mathbf{b}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/04_multi_inverse/#gauss-jordan-elimination","title":"Gauss-Jordan Elimination","text":"<p>We can use the method of elimination to solve two or more linear equations at the same time. Just augment the matrix with the whole identity matrix \\(I\\):</p> \\[ \\begin{bmatrix} 1 &amp; 3 &amp; \\vdots &amp; 1 &amp; 0 \\\\ 2 &amp; 7 &amp; \\vdots &amp; 0 &amp; 1 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 3 &amp; \\vdots &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; \\vdots &amp; -2 &amp; 1 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 0 &amp; \\vdots &amp; 7 &amp; -3 \\\\ 0 &amp; 1 &amp; \\vdots &amp; -2 &amp; 1 \\end{bmatrix} \\] <p>Once we have used Gauss's elimination method to convert the origin matrix to upper triangular form, we go on to use Jorden's idea of eliminating entries  in the upper right portion of the matrix.</p> \\[ A^{-1} = \\begin{bmatrix} 7 &amp; -3 \\\\ -2 &amp; 1 \\end{bmatrix} \\] <p>As in the last lecture, we can write the results of the elimination method as the product of a number of elimination matrix \\(E_{ij}\\) whith the matrix \\(A\\). Letting \\(E\\) be the product of all \\(E_{ij}\\), we write the result of this Guass-Jorden elimination using block matrix \\(E [A | I] = [I | E]\\). But if \\(EA = I\\), then \\(E = A^{-1}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/","title":"Factorization into A=LU","text":"<p>One goal of today's lecture is to understand Gaussian elimination int terms of matrices; to find a matrix \\(L\\) such that \\(A = LU\\). We start with some useful facts about matrix multiplication.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/#inverse-of-a-product","title":"Inverse of a product","text":"<p>The inverse of a matrix product \\(AB\\) is \\(B^{-1}A^{-1}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/#transpose-of-a-product","title":"Transpose of a product","text":"<p>We obtain the <code>transpose</code> of a matrix by exchanging its rows and columns. In other words, the entry in row \\(i\\) column \\(j\\) of \\(A\\) is the entry in row \\(j\\) column \\(i\\) of \\(A^T\\).</p> <p>The transpose of a matrix product \\(AB\\) is \\(B^TA^T\\). For any invertible matrix \\(A\\), the inverse of \\(A^T\\) is \\((A^{-1})^T\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/#a-lu","title":"A = LU","text":"<p>We've seen how to use elimination to convert a suitable matrix \\(A\\) into upper triangular matrix \\(U\\). This leads to the factorization \\(A = LU\\), which is very helpful in understanding the matrix \\(A\\).</p> <p>Recall that (when there are no row exchanges) we can describe the elimination of the entries of matrix \\(A\\) in terms of multiplication by a succession of elimination matrices \\(E_{ij}\\), so that \\(A \\to E_{21}A \\to E_{31}E_{21}A \\to \\cdots \\to U\\). In the two by two case this looks like:</p> \\[ E_{21} \\quad A \\quad = \\quad U \\] \\[ \\begin{bmatrix} 1 &amp; 0 \\\\ -4 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 2 &amp; 1 \\\\ 8 &amp; 7 \\end{bmatrix} = \\begin{bmatrix} 2 &amp; 1 \\\\ 0 &amp; 3 \\end{bmatrix} \\] <p>We can convert this to a factorization \\(A = LU\\) by \"canceling\" the matrix \\(E_{21}\\); multiply by its inverse to get \\(E_{21}^{-1}E_{21}A = E_{21}^{-1}U\\).</p> \\[ A \\quad = \\quad L \\quad U \\] \\[ \\begin{bmatrix} 2 &amp; 1 \\\\ 8 &amp; 7 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 \\\\ 4 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 2 &amp; 1 \\\\ 0 &amp; 7 \\end{bmatrix} \\] <p>The matrix \\(U\\) is <code>upper triangular</code> with pivots on the diagonal. The matrix \\(L\\) is <code>lower triangular</code> and has ones on the diagonal. Sometimes we will also want to factor out a diagonal matrix whose entries are the pivots:</p> \\[ A \\qquad = \\qquad L \\qquad D \\qquad U' \\] \\[ \\begin{bmatrix} 2 &amp; 1 \\\\ 8 &amp; 7 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 \\\\ 4 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 2 &amp; 0 \\\\ 0 &amp; 3 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1/2 \\\\ 0 &amp; 1 \\end{bmatrix} \\] <p>In the three dimensional case, if \\(E_{32}E_{31}E_{21}A = U\\) then \\(A = E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}U = LU\\).</p> <p>For example, suppose \\(E_{31}\\) is the identity matrix and \\(E_{32}\\) and \\(E_{21}\\) are as shown below:</p> \\[ E_{32} \\qquad E_{21} \\qquad = \\qquad E \\] \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; -5 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ 10 &amp; -5 &amp; 1 \\end{bmatrix} \\] <p>The \\(10\\) in the below left corner arises because we subtracted twice the first row from the second row from the second row, then subtracted five times the new second row from the third.</p> <p>The factorization \\(A = LU\\) is preferable to the statement \\(EA = U\\) because the combination of row subtractions does not have the effect on \\(L\\) that it did on \\(E\\). Here \\(L = E^{-1} = E_{21}^{-1}E_{32}^{-1}\\):</p> \\[ E_{21}^{-1} \\qquad E_{32}^{-1} \\qquad = \\qquad L \\] \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 5 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 0 &amp; 5 &amp; 1 \\end{bmatrix} \\] <p>Notice the \\(0\\) in row three column one of \\(L = E^{-1}\\), where \\(E\\) had a \\(10\\). If there are no row exchanges, the multipliers from the elimination matrices are copied directly into \\(L\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/#how-expensive-is-elimination","title":"How expensive is elimination?","text":"<p>Some application require inverting very large matrices. This is done using a computer, of course. How hard will the compulter have to work? How long will it take?</p> <p>When using elimination to find the factorization \\(A = LU\\) we just saw that we can build \\(L\\) as we go by keeping track of row subtractions. We have to remember \\(L\\) and (the matrix which will become) \\(U\\); we don't have to store \\(A\\) or \\(E_{ij}\\) in the computer's memory. How many operations does the computer perform during the elimination process for an \\(n \\times n\\) matrix? A typical operation is to multiply one row and then subtract it from another, which requires on the order of \\(n\\) operations. There are \\(n\\) rows, so the total number of operaations used in eliminating entries in the first column is about \\(n^2\\). The second row and column are shorter; that product costs about \\((n - 1)^2\\) operations, and so on. The total number of operations needed to factor \\(A\\) into \\(LU\\) is on the order of \\(n^3\\):</p> \\[ 1^2 + 2^2 + \\cdots + (n - 1)^2 + n^2 = \\sum_{i = 1}^n i^2 \\approx \\int_{0}^n x^2 dx = \\frac{1}{3} n^3 \\] <p>While we're factoring \\(A\\) we're also operating on \\(\\mathbf{b}\\). That costs about \\(n^2\\) operations, which is hardly worth couting compared to \\(\\frac{1}{3}n^3\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/05_a_lu/#row-exchanges","title":"Row exchanges","text":"<p>What if there are row exchanges? In other words, what happens if there's a zero in a pivot position? To swap two rows, we multiply on the left by a permutation matrix. Fro example,</p> \\[ P_{12} = \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>swaps the first and second rows of a \\(3 \\times 3\\) matrix. The inverse of any permu7tation matrix \\(P\\) is \\(P^{-1} = P^T\\).</p> <p>There are \\(n!\\) different ways to permute the rows of an \\(n \\times n\\) matrix (including the permutation that leaves all rows fixed) so there are \\(n!\\) permutation matrices. These matrices form a <code>multiplicative group</code>.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/","title":"Transpose, permutations, spaces R^n","text":"<p>In this lecture we introduce vector spaces and their subspaces.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#permutations","title":"Permutations","text":"<p>Multiplication by a permutation matrix \\(P\\) swaps the rows of a matrix; when applying the method of elimination we use permutation matrices to move zeros out of pivot positions. Our factorization \\(A = LU\\) then becomes \\(PA = LU\\), where \\(P\\) is a permutation matrix which reorders any number of rows of \\(A\\). Recall that \\(P^{-1} = P^T\\), i.e. that \\(P^TP = I\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#transposes","title":"Transposes","text":"<p>When we take the transpose of a matrix, its rows become columns and its columns become rows. If we denote the entry in row \\(i\\) and column \\(j\\) of matrix \\(A\\) by \\(A_{ij}\\), then we can describe \\(A^T\\) by \\(A^T_{ij} = A_{ij}\\). For example:</p> \\[ \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 3 \\\\ 4 &amp; 1 \\\\ \\end{bmatrix}^T = \\begin{bmatrix} 1 &amp; 2 &amp; 4\\\\ 3 &amp; 3 &amp; 1\\\\ \\end{bmatrix} \\] <p>A matrix \\(A\\) is <code>symmetric</code> if \\(A^T = A\\). Given any matrix \\(R\\)(not necessarily square) the product \\(R^TR\\) is always symmetric, because \\((R^TR)^T = R^T(R^T)^T = R^TR\\).(Note that \\((R^T)^T = R\\).)</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#vector-spaces","title":"Vector spaces","text":"<p>We can add vectors and multiply them by numbers, which means we can discuss <code>linear combinations</code> of vectors. These combinationss follow the rules of a <code>vector space</code>.</p> <p>One such vector space is \\(\\mathbb{R}^2\\), the set of all vectors with exactly two real number components. We depict the vector \\(\\begin{bmatrix}a \\\\ b \\end{bmatrix}\\) by drawing an arrow from the origin to the point \\((a, b)\\) which is \\(a\\) units to the right of the origin and \\(b\\) units above it, and we call \\(\\mathbb{R}^2\\) the <code>x-y plane</code>.</p> <p>Another example of a space is \\(\\mathbb{R}^n\\), the set of (column) vectors with \\(n\\) real number components.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#closure","title":"Closure","text":"<p>The collection of vectors with exactly two <code>positive</code> real valued components is <code>not</code> a vector space. The sum of any two vectors in that collection is again in the collection, but multiplying any vector by, say, \\(-5\\), gives a vector that's not in the collection. We say that this collection of positive vectors is <code>closed</code> under addition but not under multiplication.</p> <p>If a collection of vectors is closed under linear combinations(i.e. under addtion and multiplication by any real numbers), and if multiplication and addtion behave in a reasonable way, then we call that collection a <code>vector space</code>.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#subspaces","title":"Subspaces","text":"<p>A vector space that is contained inside of another vector space is called a <code>subspace</code> of that space. For example, take any non-zero vector \\(\\mathbf{v}\\) in \\(\\mathbb{R}^2\\). Then the set of all vectors \\(c\\mathbf{v}\\), where \\(c\\) is a real number, forms a subspace of \\(\\mathbb{R}^2\\). This collection of vectors describes a line through \\(\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}\\) in \\(\\mathbb{R}^2\\) and is closed under addition.</p> <p>A line in \\(\\mathbb{R}^2\\) that does not pass through the origin is <code>not</code> a subspace of \\(\\mathbb{R}^2\\). Multiplying any vector on that line by \\(0\\) gives the zero vector, which does not lie on the line. Every subspace must contain the zero vector because vector spaces are closed under multiplication.</p> <p>The subspaces of \\(\\mathbb{R}^2\\) are:</p> <ol> <li>all of \\(\\mathbb{R}^2\\);</li> <li>any line through \\(\\begin{bmatrix} 0 \\\\ 0\\end{bmatrix}\\);</li> <li>the zero vector(\\(Z\\)) alone.</li> </ol> <p>The subspaces of \\(\\mathbb{R}^3\\) are:</p> <ol> <li>all of \\(\\mathbb{R}^3\\);</li> <li>any plane through \\(\\begin{bmatrix} 0 \\\\ 0 \\\\ 0\\end{bmatrix}\\);</li> <li>any line through \\(\\begin{bmatrix} 0 \\\\ 0 \\\\ 0\\end{bmatrix}\\);</li> <li>the zero vector(\\(Z\\)) alone.</li> </ol>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/06_trans_perm/#column-space","title":"Column space","text":"<p>Given a matrix \\(A\\) with columns in \\(\\mathbb{R}^3\\), these columns and all their linear combinations form a subspace of \\(\\mathbb{R}^3\\). This is the <code>column space</code> \\(C(A)\\). If \\(A = \\begin{bmatrix} 1 &amp; 3 \\\\ 2 &amp; 3 \\\\ 4 &amp; 1 \\end{bmatrix}\\), the column space of \\(A\\) is the plane through the origin in \\(\\mathbb{R}^3\\) containing \\(\\begin{bmatrix} 1 \\\\ 2 \\\\ 4\\end{bmatrix}\\) and \\(\\begin{bmatrix} 3 \\\\ 3 \\\\ 1\\end{bmatrix}\\).</p> <p>Our next task will be to understand the equation \\(A\\mathbf{x} = \\mathbf{b}\\) in terms of subspaces and the column space of \\(A\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/","title":"Column Space and Nullspace","text":"<p>In this lecture we continue to study subspaces, particularly the column space and nullspace of a matrix.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/#review-of-subspaces","title":"Review of subspaces","text":"<p>A vector space is a collection of vectors which is closed under linear combinations. In other words, for any two vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) in the space and any two real numbers \\(c\\) and \\(d\\), the vector \\(c\\mathbf{v} + d\\mathbf{w}\\) is also in the vector space. A subspace is a vector space contianed inside a vector space.</p> <p>A plane \\(P\\) containing \\(\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\) and a line \\(L\\) containing \\(\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\) are both subspaces of \\(\\mathbb{R}^3\\). The union \\(P \\cup L\\) of those two subspaces is generally not a subspace, because the sum of a vector in \\(P\\) and a vector in \\(L\\) is probably not contained in \\(P \\cup L\\). The intersection \\(S \\cap T\\) of two subspace \\(S\\) and \\(T\\) is a subspace. To prove this, use the fact that both \\(S\\) and \\(T\\) are closed under linear combinations to show that their intersection is closed under linear combinations.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/#column-space-of-a","title":"Column space of A","text":"<p>The <code>column space</code> of a matrix \\(A\\) is the vector space made up of all linear combinations of the columns of \\(A\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/#solving-ax-b","title":"Solving Ax = b","text":"<p>Given a matrix \\(A\\), for what vectors \\(\\mathbf{b}\\) does \\(A\\mathbf{x} = \\mathbf{b}\\) have a solution \\(\\mathbf{x}\\)?</p> \\[ A = \\begin{bmatrix} 1 &amp; 1 &amp; 2 \\\\ 2 &amp; 1 &amp; 3 \\\\ 3 &amp; 1 &amp; 4 \\\\ 4 &amp; 1 &amp; 5 \\end{bmatrix} \\] <p>Then \\(A\\mathbf{x} = \\mathbf{b}\\) does not have a solution for every choice of \\(\\mathbf{b}\\) because solving \\(A\\mathbf{x} = \\mathbf{b}\\) is equivalent to solving four linear equations in three unknowns. If there is a solution \\(\\mathbf{x}\\) to \\(A\\mathbf{x} = \\mathbf{b}\\), then \\(\\mathbf{b}\\) must be a linear combination of the columns of \\(A\\). Only three columns cannot fill the entire four dimensional vector space, some vectors \\(\\mathbf{b}\\) can not be expressed as linear combinations of columns of \\(A\\).</p> <p>Big question: what \\(\\mathbf{b}\\)'s allow \\(A\\mathbf{x} = \\mathbf{b}\\) to be solved?</p> <p>A useful approach is to choose \\(\\mathbf{x}\\) and find the vector \\(\\mathbf{b} = A\\mathbf{x}\\)  corresponding to that solution. The components of \\(\\mathbf{x}\\) are just the coefficients in a linear combination of columns of \\(A\\).</p> <p>The system of linear equations \\(A\\mathbf{x} = \\mathbf{b}\\) is <code>solvable</code> exactly when \\(\\mathbf{b}\\) is a vector in the <code>column space</code> of \\(A\\).</p> <p>For our example matrix \\(A\\), what can we say about the column space of \\(A\\)? Are the columns of \\(A\\) <code>independent</code>? In other words, does each column contribute something new to the subspace?</p> <p>The third column of \\(A\\) is the sum of the first two columns, so does not add anything to the subspace. The column space of our matrix \\(A\\) is a two dimensional subspace of \\(\\mathbb{R}^4\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/#nullspace-of-a","title":"Nullspace of A","text":"<p>The <code>nullspace</code> of a matrix is the collection of all solutions \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\) to the equation \\(A\\mathbf{x} = \\mathbf{0}\\).</p> <p>The column space of the matrix in our example was a subspace of \\(\\mathbb{R}^4\\). The nullspace of \\(A\\) is a subspace of \\(\\mathbb{R}^3\\). To see that it's a vector space, check that any sum or multiple of solutions to \\(A\\mathbf{x} = \\mathbf{0}\\) is also a solution:</p> \\[ A(\\mathbf{x}_ 1 + \\mathbf{x}_ 2) = A\\mathbf{x}_ 1 + A\\mathbf{x}_ 2 = \\mathbf{0} + \\mathbf{0} = \\mathbf{0} \\] \\[ A(c\\mathbf{x}) = cA\\mathbf{x} = \\mathbf{0} \\] <p>In the example:</p> \\[ \\begin{bmatrix} 1 &amp; 1 &amp; 2 \\\\ 2 &amp; 1 &amp; 3 \\\\ 3 &amp; 1 &amp; 4 \\\\ 4 &amp; 1 &amp; 5 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\] <p>The nullspace \\(N(A)\\) consists of all multiples of \\(\\begin{bmatrix} 1 \\\\ 1 \\\\ -1 \\end{bmatrix}\\); column 1 plus column 2 minus column 3 equals the zero vector. This nullspace is a line in \\(\\mathbb{R}^3\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/07_col_null_space/#other-values-of-b","title":"Other values of b","text":"<p>The solutions to the equation:</p> \\[ \\begin{bmatrix} 1 &amp; 1 &amp; 2 \\\\ 2 &amp; 1 &amp; 3 \\\\ 3 &amp; 1 &amp; 4 \\\\ 4 &amp; 1 &amp; 5 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix} \\] <p>do not form a subspace. The zero vector is not a solution to this equation. The set of solutions forms a line in \\(\\mathbb{R}^3\\) that passes through the points \\(\\begin{bmatrix} 1 \\\\ 0 \\\\ 0  \\end{bmatrix}\\) and \\(\\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix}\\) but not \\(\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/08_ax_0/","title":"Soving Ax = 0: pivot variables, special solutions","text":"<p>We have definition for the column space and the nullspace of a matrix, but how do we compute these subspaces?</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/08_ax_0/#computing-the-nullspace","title":"Computing the nullspace","text":"<p>The <code>nullspace</code> of a matrix \\(A\\) is made up of the vectors \\(\\mathbf{x}\\) for which \\(A\\mathbf{x} = \\mathbf{0}\\).</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 2 &amp; 4 &amp; 6 &amp; 8 \\\\ 3 &amp; 6 &amp; 8 &amp; 10 \\end{bmatrix} \\] <p>(Note that the columns of this matrix \\(A\\) are not independent.) Our algorithm for computing the nullspace of this matrix uses the method of elimination, despite the fact that \\(A\\) is not invertible. We don't need to use an augmented matrix because the right side (the vector \\(\\mathbf{b}\\)) is \\(\\mathbf{0}\\) in this computation.</p> <p>The row operations used in the method of elimination don't change the solution to \\(A\\mathbf{x} = \\mathbf{b}\\) so they don't change the nullspace. (They do affect the column space.)</p> <p>The first step of elimination gives us:</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 2 &amp; 4 &amp; 6 &amp; 8 \\\\ 3 &amp; 6 &amp; 8 &amp; 10 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\end{bmatrix} \\] <p>We don't find a pivot in the second column, so our next pivot is the 2 in the third column of the second row:</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} = U \\] <p>The matrix \\(U\\) is in <code>echelon</code>(staircase) form. The third row is zero because row 3 was a linear combination of rows 1 and 2; it was eliminated.</p> <p>The <code>rank</code> of a matrix A equals the number of pivots it has. In this example, the rank of \\(A\\) (and of \\(U\\)) is \\(2\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/08_ax_0/#special-solutions","title":"Special solutions","text":"<p>Once we've found \\(U\\), we can back-substitution to find the solution \\(\\mathbf{x}\\) to the equation \\(U\\mathbf{x} = \\mathbf{0}\\). In our example, columns 1 and 3 are <code>pivot columns</code> containing pivots, and columns 2 and 4 are <code>free columns</code>. We can assign any value to \\(x_2\\) and \\(x_4\\); we call these <code>free variables</code>. Suppose \\(x_2 = 1\\) and \\(x_4 = 0\\). Then:</p> \\[ 2 x_3 + 4 x_4 = 0 \\to x_3 = 0 \\] <p>and:</p> \\[ x_1 + 2x_2 + 2x_3 + 2x_4 = 0 \\to x_1 = -2 \\] <p>So one solution is \\(\\mathbf{x} = \\begin{bmatrix} -2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\) (because the second column is just twice the first column). Any multiple of this vector is in the nullspace.</p> <p>Letting a different free variable equal 1 and setting the other free variables equal to zero gives us other vectors in the nullspace. For example:</p> \\[ \\mathbf{x} = \\begin{bmatrix} 2 \\\\ 0 \\\\ -2 \\\\ 1 \\end{bmatrix} \\] <p>has \\(x_4 = 1\\) and \\(x_2 = 0\\). The nullspace of \\(A\\) is the collection of all linear combinations of these \"special solution\" vectors.</p> <p>The rank \\(r\\) of \\(A\\) equals the number of pivot columns, so the number of free columns is \\(n - r\\): the number of columns(variables) minus the number of pivot columns. This equals the number of special solution vectors and the dimension of the nullspace.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/08_ax_0/#reduced-row-echelon-form","title":"Reduced row echelon form","text":"<p>By continuing to use the method of elimination we can convert \\(U\\) to a matrix \\(R\\) in <code>reduced row echelon form</code>(rref), which pivots equal to 1 and zeros above and below the pivots.</p> \\[ U = \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} = R \\] <p>By exchanging some columns, \\(R\\) can be rewritten with a copy of the identity matrix in the upper left corner, possibly followed by some free columns on the right. If some rows of \\(A\\) are linearly dependent, the lower rows of the matrix \\(R\\) will be filled with zeros:</p> \\[ R = \\begin{bmatrix} I &amp; F \\\\ 0 &amp; 0 \\end{bmatrix} \\] <p>Here \\(I\\) is an \\(r\\) by \\(r\\) square matrix.</p> <p>If \\(N\\) is the <code>nullspace matrix</code> \\(N = \\begin{bmatrix} -F \\\\ I \\end{bmatrix}\\) then \\(RN = 0\\). Here \\(I\\) is an \\(n - r\\) by \\(n - r\\) square matrix and \\(0\\) is an \\(m\\) by \\(n - r\\) matrix. The columns of \\(N\\) are the special solutions.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/","title":"Solving Ax = b: row reduced form R","text":"<p>When does \\(A\\mathbf{x} = \\mathbf{b}\\) have solutions \\(\\mathbf{x}\\), and how can we describe those solutions?</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#solvability-conditions-on-b","title":"Solvability conditions on b","text":"<p>We again use the exmaple:</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 \\\\ 2 &amp; 4 &amp; 6 &amp; 8 \\\\ 3 &amp; 6 &amp; 8 &amp; 10 \\end{bmatrix} \\] <p>The third row of \\(A\\) is the sum of its first and second rows, so we know that if \\(A\\mathbf{x} = \\mathbf{b}\\) the third component of \\(\\mathbf{b}\\) equals the sum of its first and second components. If \\(\\mathbf{b}\\) does not satisfy \\(b_3 = b_1 + b_2\\) the system has no solution. If a combination of the rows of \\(A\\) gives the zero row, then the same combination of the entries of \\(\\mathbf{b}\\) must equal zero.</p> <p>One way to find out whether \\(A\\mathbf{x} = \\mathbf{b}\\) is solvable is to use elimination on the augmented matrix. If a row of \\(A\\) is completely eliminated, so is the corresponding entry in \\(\\mathbf{b}\\). In our example, row 3 of \\(A\\) is completely eliminated:</p> \\[ \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 &amp; b_1 \\\\ 2 &amp; 4 &amp; 6 &amp; 8 &amp; b_2 \\\\ 3 &amp; 6 &amp; 8 &amp; 10 &amp; b_3 \\end{bmatrix} \\to \\begin{bmatrix} 1 &amp; 2 &amp; 2 &amp; 2 &amp; b_1 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 &amp; b_2 - 2b_1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; b_3 - b_2 - b_1 \\\\ \\end{bmatrix} \\] <p>If \\(A\\mathbf{x} = \\mathbf{b}\\) has a solution, then \\(b_3 - b_2 - b_1 = 0\\). For example, we could choose \\(\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 5 \\\\ 6 \\end{bmatrix}\\).</p> <p>From an earlier lecture, we know that \\(A\\mathbf{x} = \\mathbf{b}\\) is solvable exactly when \\(\\mathbf{b}\\) is in the column space \\(C(A)\\). We have these two conditions on \\(\\mathbf{b}\\); in fact they are equivalent.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#complete-solution","title":"Complete solution","text":"<p>In order to find all solutions to \\(A\\mathbf{x} = \\mathbf{b}\\) we first check that the equation is solvable, then find a particular solution. We get the complete solution of the equation by adding the particular solution to all the vectors in the nullspace.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#a-particular-solution","title":"A particular solution","text":"<p>One way to find a particular solution to the equation \\(A\\mathbf{x} = \\mathbf{b}\\) is to set all free variables to zero, then solve for the pivot variables. For our example matrix \\(A\\), we let \\(x_2 = x_4 = 0\\) to get the system of equations:</p> \\[ \\begin{align} x_1 + 2x_3 &amp;= 1 \\\\ 2x_3 &amp;= 3 \\\\ \\end{align} \\] <p>which has the solution \\(x_3 = 3/2\\), \\(x_1 = -2\\). Our particular solution is:</p> \\[ x_p = \\begin{bmatrix} -2 \\\\ 0 \\\\ 3/2 \\\\ 0 \\\\ \\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#combined-with-the-nullspace","title":"Combined with the nullspace","text":"<p>The general solution to \\(A\\mathbf{x} = \\mathbf{b}\\) is given by \\(x_{complete} = x_p + x_n\\), where \\(x_n\\) is a generic vector in the nullspace. To see this, we add \\(Ax_p = \\mathbf{b}\\) to \\(Ax_n = \\mathbf{0}\\) and get \\(A(x_p + x_n) = \\mathbf{b}\\) for every vector \\(x_n\\) in the nullspace.</p> <p>Last lecture we learned that the nullspace of \\(A\\) is the collection of all combinations of the special solutions \\(\\begin{bmatrix} -2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\) and \\(\\begin{bmatrix} 2 \\\\ 0 \\\\ -2 \\\\ 1 \\end{bmatrix}\\). So the complete solution to the equation \\(A\\mathbf{x} = \\begin{bmatrix} 1 \\\\ 5 \\\\ 6\\end{bmatrix}\\) is:</p> \\[ x_{complete} = \\begin{bmatrix} -2 \\\\ 0 \\\\ 3/2 \\\\ 0 \\\\ \\end{bmatrix} + c_1 \\begin{bmatrix} -2 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} + c_2 \\begin{bmatrix} 2 \\\\ 0 \\\\ -2 \\\\ 1 \\\\ \\end{bmatrix} \\] <p>where \\(c_1\\) and \\(c_2\\) are real numbers.</p> <p>The nullspace of \\(A\\) is a two dimensional subspace of \\(\\mathbb{R}^4\\), and the solutions to the equation \\(A\\mathbf{x} = \\mathbf{b}\\) form a plane parallel to that through \\(x_p = \\begin{bmatrix} -2 \\\\ 0 \\\\ 3/2 \\\\ 0 \\end{bmatrix}\\)</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#rank","title":"Rank","text":"<p>The rank of a matrix equals the number of pivots of that matrix. If \\(A\\) is an \\(m\\) by \\(n\\) matrix of rand \\(r\\), we know:</p> <ul> <li>\\(r \\le m\\)</li> <li>\\(r \\le n\\)</li> </ul>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#full-column-rank","title":"Full column rank","text":"<p>If \\(r = n\\), then from the previous lecture we know that the nullspace has dimension \\(n - r = 0\\) and contains only the zero vector. There are no free variables or special solutions.</p> <p>If \\(A\\mathbf{x} = \\mathbf{b}\\) has solution, it is unique; there is either 0 or 1 solution. Examples like this, in which the columns are independent, are common in applications.</p> <p>We know \\(r \\le m\\), so if \\(r = n\\) the number of columns of the matrix is less than or equal to the number of rows. The row reduced echelon form of the matrix will look like \\(R = \\begin{bmatrix} I \\\\ 0 \\end{bmatrix}\\). For any vector \\(\\mathbf{b}\\) in \\(\\mathbb{R}^m\\) that's not a linear combination of the columns of \\(A\\), there is no solution to \\(A\\mathbf{x} = \\mathbf{b}\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#full-row-rank","title":"Full row rank","text":"<p>If \\(r = m\\), then the reduced matrix \\(R = \\begin{bmatrix} I &amp; F\\end{bmatrix}\\) has no rows of zeros and so there are no requirements for the entries of \\(\\mathbf{b}\\) to satisfy. The equation \\(A\\mathbf{x} = \\mathbf{b}\\) is solvable for every \\(\\mathbf{b}\\). There are \\(n - r = n - m\\) free variables, so there are \\(n - m\\) special solutions to \\(A\\mathbf{x} = \\mathbf{b}\\)</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#full-row-and-column-rank","title":"Full row and column rank","text":"<p>If \\(r = m = n\\) is the number of pivots of \\(A\\), then \\(A\\) is an invertible square matrix and \\(R\\) is the identity matrix. The nullspace has dimension zero, and \\(A\\mathbf{x} = \\mathbf{b}\\) has a unique solution for every \\(\\mathbf{b}\\) in \\(\\mathbb{R}^m\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/09_ax_b/#summary","title":"Summary","text":"<p>If \\(R\\) is in row reduced form with pivot columns first(rref), the table below summarizes our results.</p> r = m = n r = n &lt; m r = m &lt; n r &lt; m, r &lt; n R \\(I\\) \\begin{bmatrix} I \\\\ 0 \\end{bmatrix} \\begin{bmatrix} I &amp; F \\end{bmatrix} \\begin{bmatrix} I &amp; F \\\\ 0 &amp; 0 \\end{bmatrix} #solutions to \\(Ax = b\\) 1 0 or 1 infinite 0 or infinite"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/","title":"Independence, Basis and Dimension","text":"<p>What does it mean for vectors to be independent? How does the idea of independence help us describe subspaces like the nullspace?</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#linear-independence","title":"Linear independence","text":"<p>Suppose \\(A\\) is an \\(m\\) by \\(n\\) matrix with \\(m &lt; n\\)(so \\(A\\mathbf{x} = \\mathbf{b}\\) has more unknowns than equations). \\(A\\) has at least one free variable, so there are nonzero solutions to \\(A\\mathbf{x} = \\mathbf{0}\\). A combination of the columns is zero, so the columns of this \\(A\\) are <code>dependent</code>.</p> <p>We say vectors \\(\\mathbf{x}_ 1, \\mathbf{x}_ 2, \\cdots, \\mathbf{x}_n\\) are <code>linear independent</code> (or just <code>independent</code>) if \\(c_1\\mathbf{x}_ 1 + c_2\\mathbf{x}_2 + \\cdots + c_n\\mathbf{x}_n = \\mathbf{0}\\) only when \\(c_1, c_2, \\cdots, c_n\\) are all \\(0\\). When those vectors are the columns of \\(A\\), the only solution to \\(A\\mathbf{x} = \\mathbf{0}\\) is \\(\\mathbf{x} = \\mathbf{0}\\).</p> <p>Two vectors are independent if they do not lie on the same line. Three vectors are independent if they do not lie on the same plane. Thinking of \\(A\\mathbf{x}\\) as a linear combination of the column vectors of \\(A\\), we see that the column vectors of \\(A\\) are independent exactly when the nullspace of \\(A\\) contains only the zero vector.</p> <p>If the columns of \\(A\\) are independent then all columns are pivot columns, the rank of \\(A\\) is \\(n\\), and there are no free variables. If the columns of \\(A\\) are dependent then the rank of \\(A\\) is less than \\(n\\) and there are free variables.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#spanning-a-space","title":"Spanning a space","text":"<p>Vectors \\(\\mathbf{v}_1, \\mathbf{v}_2, \\cdots, \\mathbf{v}_k\\) <code>span</code> a space when the space consists of all combinations of those vectors. For example, the columns vectors of \\(A\\) span the column space of \\(A\\).</p> <p>If vectors \\(\\mathbf{v}_1, \\mathbf{v}_2, \\cdots, \\mathbf{v}_k\\) span a space \\(S\\), then \\(S\\) is the smallest space containing those vectors.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#basis-and-dimension","title":"Basis and dimension","text":"<p>A <code>basis</code> for a vector space is a sequence of vectors \\(\\mathbf{v}_1, \\mathbf{v}_2, \\cdots, \\mathbf{v}_d\\) with two properties:</p> <ul> <li>\\(\\mathbf{v}_1, \\mathbf{v}_2, \\cdots, \\mathbf{v}_d\\) are independent;</li> <li>\\(\\mathbf{v}_1, \\mathbf{v}_2, \\cdots, \\mathbf{v}_ d\\) span the vector space.</li> </ul> <p>The basis of a space tells us everything we need to know about that space.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#example-mathbbr3","title":"Example: \\(\\mathbb{R}^3\\)","text":"<p>One basis for \\(\\mathbb{R}^3\\) is \\({ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}}\\). These are independent because:</p> \\[ c_1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} + c_2 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} + c_3 \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\] <p>is only possible when \\(c_1 = c_2 = c_3 = 0\\). These vectors span \\(\\mathbb{R}^3\\).</p> <p>As discussed at previous lecture, the vector \\(\\begin{bmatrix} 1 \\\\ 1 \\\\ 2 \\end{bmatrix}\\), \\(\\begin{bmatrix} 2 \\\\ 2 \\\\ 5 \\end{bmatrix}\\) and \\(\\begin{bmatrix} 3 \\\\ 3 \\\\ 8 \\end{bmatrix}\\) do not form a basis for \\(\\mathbb{R}^3\\) because these are the column vectors of a matrix that has two identical rows. The three vectors are not linearly independent.</p> <p>In general, \\(n\\) vectors in \\(\\mathbb{R}^n\\) form a basis if they are the column vectors of an invertible matrix.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#basis-for-a-subspace","title":"Basis for a subspace","text":"<p>The vectors \\(\\begin{bmatrix} 1 \\\\ 1 \\\\ 2 \\end{bmatrix}\\) and \\(\\begin{bmatrix} 2 \\\\ 2 \\\\ 5 \\end{bmatrix}\\) span a plane in \\(\\mathbb{R}^3\\) but they cannot form a basis for \\(\\mathbb{R}^3\\). Given a space, every basis for that space has the same number of vectors; that number is the <code>dimension</code> of the space. So there are exactly \\(n\\) vectors in every basis for \\(\\mathbb{R}^n\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/10_ind_basis_dim/#bases-of-a-column-space-and-nullspace","title":"Bases of a column space and nullspace","text":"<p>Suppose:</p> \\[ A =  \\begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 1 \\\\ 1 &amp; 1 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 3 &amp; 1 \\\\ \\end{bmatrix} \\] <p>By definition, the four column vectors of \\(A\\) span the column space of \\(A\\). The third and fourth column vectors are dependent on the first and second, and the first two columns are independent. Therefore, the first two column vectors are the pivot columns. They form a basis for the column space \\(C(A)\\). The matrix has rank 2. In fact, for any matrix \\(A\\) we can say:</p> \\[ rank(A) = \\text{number of pivot columns of } A = \\text{dimension of } C(A) \\] <p>Note that matrices have a rank but not a dimension. Subspaces have a dimension but not a rank.</p> <p>The column vectors of this \\(A\\) are not independent, so the nullspace \\(N(A)\\) contains more than just the zero vector. Because the third column is the sum of the first two, we know that the vector \\(\\begin{bmatrix} -1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{bmatrix}\\) is in the nullspace. Similarly, \\(\\begin{bmatrix} -1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\) is also in \\(N(A)\\). These are the two special solutions to \\(A \\mathbf{x} = \\mathbf{0}\\). We'll see that:</p> \\[ \\text{dimension of } N(A) = \\text{number of free variables} = n - r \\] <p>so we know that the dimension of \\(N(A)\\) is \\(4 - 2 = 2\\). These two special solutions form a basisi for the nullspace.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/","title":"The Four Fundamental Subspaces","text":"<p>In this lecture we discuss the four fundamental spaces associated with a matrix and the relations between them.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#four-subspaces","title":"Four subspaces","text":"<p>Any \\(m\\) by \\(n\\) matrix \\(A\\) determines four subspaces (possibly containing only zero vectors);</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#column-space-ca","title":"Column space, C(A)","text":"<p>\\(C(A)\\) consists of all combinations of the columns of \\(A\\) and is a vector space in \\(\\mathbb{R}^m\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#nullspace-na","title":"Nullspace, N(A)","text":"<p>This consists of all solutions \\(\\mathbf{x}\\) of the equation \\(A\\mathbf{x} = \\mathbf{0}\\) and lies in \\(\\mathbf{R}^n\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#row-space-rat","title":"Row space, R(A^T)","text":"<p>The combinations of the row vectors of \\(A\\) form a subspace of \\(\\mathbf{R}^n\\). We equate this with \\(C(A^T)\\), the column space of the transpose of \\(A\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#left-nullspace-nat","title":"Left nullspace, N(A^T)","text":"<p>We call the nullspace of \\(A^T\\) the <code>left nullspace</code> of \\(A\\). This is a subspace of \\(\\mathbb{R}^m\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#basis-and-dimension","title":"Basis and Dimension","text":""},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#column-space","title":"Column space","text":"<p>The \\(r\\) pivot columns form a basis for \\(C(A)\\):</p> \\[ \\text{dim } C(A) = r \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#nullspace","title":"Nullspace","text":"<p>The special solutions to \\(A\\mathbf{x} = \\mathbf{0}\\) correspond to free variables and form a basis for \\(N(A)\\). An \\(m\\) by \\(n\\) matrix has \\(n - r\\) free variables:</p> \\[ \\text{dim } N(A) = n - r \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#row-space","title":"Row space","text":"<p>We could perform row reduction on \\(A^T\\), but instead we make use of \\(R\\), the row reduced echelon form of \\(A\\).</p> \\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 1 \\\\ 1 &amp; 1 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 3 &amp; 1 \\\\ \\end{bmatrix} \\to \\cdots \\to \\begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} I &amp; F \\\\ 0 &amp; 0 \\\\ \\end{bmatrix} = R \\] <p>Although the column spaces of \\(A\\) and \\(R\\) are different, the row space of \\(R\\) is the same as the row space of \\(A\\). The rows of \\(R\\) are combinations of the rows of \\(A\\), and because reduction is reversible the rows of \\(A\\) are combinations of the rows of \\(R\\).</p> <p>The first \\(r\\) rows of \\(R\\) are the <code>echelon</code> basis for the row space of \\(A\\):</p> \\[ \\text{dim } C(A^T) = r \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#left-nullspace","title":"Left nullspace","text":"<p>The matrix \\(A^T\\) has \\(m\\) columns. We just saw that \\(r\\) is the rank of \\(A^T\\), so the number of free columns of \\(A^T\\) must be \\(m - r\\):</p> \\[ \\text{dim } N(A^T) = m - r \\] <p>The left nullspace is the collection of vectors \\(y\\) for which \\(A^Ty = 0\\). Equivalently, \\(y^TA = 0\\); there \\(y\\) and \\(0\\) are row vectors. We say <code>left nullspace</code> because \\(y^T\\) is on the left of \\(A\\) in this equation.</p> <p>To find a basis for the left nullspace we reduce an augmented version of \\(A\\):</p> \\[ \\begin{bmatrix} A_{m \\times n} &amp; I_{m \\times n} \\end{bmatrix} \\to \\begin{bmatrix} R_{m \\times n} &amp; E_{m \\times n} \\end{bmatrix} \\] <p>From this we get the matrix \\(E\\) for which \\(EA = R\\). (If \\(A\\) is a square, invertible matrix then \\(E = A^{-1}\\).) In our example,</p> \\[ EA = \\begin{bmatrix} -1 &amp; 2 &amp; 0 \\\\ 1 &amp; -1 &amp; 0 \\\\ -1 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 1\\\\ 1 &amp; 1 &amp; 2 &amp; 1\\\\ 1 &amp; 2 &amp; 3 &amp; 1\\\\ \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; 1\\\\ 0 &amp; 1 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0\\\\ \\end{bmatrix} =R \\] <p>The bottom \\(m - r\\) rows of \\(E\\) describe linear dependencies of rows of \\(A\\), because the bottom \\(m - r\\) rows of \\(R\\) are zero. Here \\(m - r = 1\\)(one zero row in R).</p> <p>The bottom \\(m - r\\) rows of \\(E\\) satisfy the equation \\(\\mathbf{y}^TA=\\mathbf{0}\\) and form a basis for the left nullspace of \\(A\\).</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/11_four_subspace/#new-vector-space","title":"New vector space","text":"<p>The collection of all \\(3 \\times 3\\) matrices forms a vector space; call it \\(M\\). We can add matrices and multiply them by scalars and there's a zero matrix(additive identity). If we ignore the fact that we can multiply matrices by each other, they behave just like vectors.</p> <p>Some subspace of \\(M\\) include:</p> <ul> <li>all upper trianglar matrices;</li> <li>all symmetric matrices;</li> <li>D, all diagonal matrices</li> </ul> <p>\\(D\\) is the intersection of the first two spaces. Its dimension is \\(3\\); one basis for \\(D\\) is:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 3 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 7 \\\\ \\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/","title":"Matrix spaces, Rand 1 and Small World Graphs","text":"<p>We've talked a lot about \\(\\mathbb{R}^n\\), but we can think about vector spaces made up of any sort of <code>vectors</code> that allow addition and scalar multiplication.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#new-vector-spaces","title":"New vector spaces","text":""},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#3-by-3-matrices","title":"3 by 3 matrices","text":"<p>We were looking at the space \\(M\\) of all 3 by 3 matrices. We identified some subspaces:</p> <ul> <li>the symmetric 3 by 3 matrices \\(S\\),</li> <li>the upper triangular 3 by 3 matrices \\(U\\)</li> <li>and the intersection \\(D\\) of these two spaces - the space of diagonal 3 by 3 matrices.</li> </ul> <p>The dimension of \\(M\\) is 9; we must choose 9 numbers to specify an element of \\(M\\). The space \\(M\\) is very similar to \\(\\mathbb{R}^9\\). A good choice of basis is:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\cdots \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\] <p>The subspace of symmetric matrices \\(S\\) has dimension 6. When choosing an element of \\(S\\) we pick three numbers on the diagonal and three in the upper right, which tell us what must appear in the lower left of the matrix. One basis for \\(S\\) is the collection:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\] <p>The dimension of \\(U\\) is again 6; we have the same amount of freedom in selecting the entries of an upper triangular matrix as we did in choosing a symmetric matrix. A basis for \\(U\\) is:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\] <p>This happens to be a subset of the basis we chose for \\(M\\), but there is no basis for \\(S\\) that is subset of the basis we chose for M.</p> <p>The subspace \\(D = S \\cap U\\) of diagonal 3 by 3 matrices has dimension 3. Because of the way we chose bases for \\(U\\) and \\(S\\), a good basis for \\(D\\) is the intersection of those bases.</p> <p>Is \\(S \\cup U\\), the set of 3 by 3 matrices which are either symmetric or upper triangular, a subspace of \\(M\\)? No. This is like taking two liness in \\(\\mathbb{R}^2\\) and asking if together they form a subspace; we have to fill in between them. If we take all possible sums of elements of \\(S\\) and elements of \\(U\\) we get what we call the sum \\(S + U\\). This is a subspace of \\(M\\). In fact, \\(S + U = M\\). For unions and sums, dimensions follow this rule:</p> \\[ \\text{dim } S + \\text{dim } U = \\text{dim } S \\cup U + \\text{dim } S \\cap U \\]"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#differential-equations","title":"Differential equations","text":"<p>Another example of a vector space that's not \\(\\mathbb{R}^n\\) appears in differential equations.</p> <p>We can think of the solution \\(y\\) to \\(\\frac{d^2y}{dx^2} + y = 0\\) as the elements of a nullspace. Some solutions are:</p> \\[ y = cos(x), y = sin(x), y = e^{ix} \\] <p>The complete solution is:</p> \\[ y = c_1 cos(x) + c_2 sin(x) \\] <p>where \\(c_1\\) and \\(c_2\\) can be any complex numbers. This solution space is a two dimension vector space with basis vectors \\(cos(x)\\) and \\(sin(x)\\). Even though these don't <code>look like</code> vectors, we can build a vector space from them because they can be added and multiplied by a constant.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#rank-4-matrices","title":"Rank 4 matrices","text":"<p>Now let \\(M\\) be the space of \\(5 \\times 17\\) matrices. The subset of \\(M\\) containing all rank 4 matrices is not a subspace, even if we include the zero matrix, because the sum of two rank 4 matrices may not have rank 4.</p> <p>In \\(\\mathbb{R}^4\\), the set of all vectors \\(\\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{bmatrix}\\) for which \\(v_1 + v_2 + v_3 + v_4 = 0\\) is a subspace. It contains the zero vector and is closed under addition and scalar multiplication. It is the nullspace of the matrix \\(A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix}\\). Because A has rank 1, the dimension of this nullspace is \\(n - r = 3\\). The subspace has the basis of special solutions:</p> \\[ \\begin{bmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{bmatrix} \\] <p>The column space of \\(A\\) is \\(\\mathbb{R}^1\\). The left nullspace contains only the zero vector, has dimension zero, and its basis is the empty set. The row space of \\(A\\) has dimension 1.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#rank-one-matrices","title":"Rank one matrices","text":"<p>The rank of a matrix is the dimension of its column(or row) space. The matrix</p> \\[ A = \\begin{bmatrix} 1 &amp; 4 &amp; 5 \\\\ 2 &amp; 8 &amp; 10 \\\\ \\end{bmatrix} \\] <p>has rank 1 because of its columns is a multiple of the first column.</p> \\[ A = \\begin{bmatrix} 1 \\\\ 2 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 &amp; 4 &amp; 5 \\end{bmatrix} \\] <p>Every rank 1 matrix A can be written \\(A = \\mathbf{U}\\mathbf{V}^T\\), where \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\) are column vectors. We'll use rank 1 matrices as building blocks for more complex matrices.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/12_matrix_space/#small-world-graphs","title":"Small world graphs","text":"<p>In this class, a <code>graph</code> G is a collection of nodes joined by edges:</p> \\[ G = \\{nodes, edges\\} \\] <p>A typical graph appears in figure below.</p> <p></p> <p>Another example of a graph is one in which each node is a person. Two nodes are connected by an edge if the people are friends. We can ask how close two people are to each other in the graph, what's the smallest number of friend to friend connections joining them? The question \"what's the farthest distance between two people in the graph?\" lies behind phrases like \"six degrees of separation\" and \"it's a small world\".</p> <p>Another graph is the world wide web: its nodes are websites and its edges are linkes.</p> <p>We'll describe graphs in terms of matrices, which will make it easy to answer questions about distance between nodes.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/13_graph/","title":"Graphs, Networks and Incidence Matrices","text":"<p>When we use linear algebra to understand physical systems, we often find more structure in the matrices and vectors than appears in the examples we make up in class. There are many applications of linear algebra; for example, chemists might use row reduction to get a clearer picture of what elements go into a complicated reaction. In this lecture we explore the linear algebra associated with electrical networks.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/13_graph/#graphs-and-networks","title":"Graphs and networks","text":"<p>A <code>graph</code> is a collection of nodes joined by edges; figure below shows one small graph with 4 nodes and 5 edges:</p> <p></p> <p>We put an arrow on each edge to indicate that the positive direction for currents running through the graph.</p> <p></p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/13_graph/#incidence-matrices","title":"Incidence matrices","text":"<p>The <code>incidence matrix</code> of this directed graph has one column for each node of the graph and one row for each edge of the graph:</p> \\[ A = \\begin{bmatrix} -1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; -1 &amp; 0 &amp; 0 \\\\ -1 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; -1 &amp; 1 \\\\ \\end{bmatrix} \\] <p>If an edge runs from node \\(a\\) to node \\(b\\), the row corresponding to that edge has \\(-1\\) in column \\(a\\) and \\(1\\) in column \\(b\\); all other entries in that row are \\(0\\). If we were studying a larger graph we would get a larger matrix but it would be <code>sparse</code>; most of the entries in that matrix would be 0. This is one of the ways matrices arising from the applications might have extra structure.</p> <p>Note that nodes \\(1, 2\\) and \\(3\\) and edge \\((1), (2)\\) and \\((3)\\) form a loop. The matrix describing just those nodes and edges looks like:</p> \\[ \\begin{bmatrix} -1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 &amp; 0 \\\\ -1 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\] <p>Note that the third row is the sum of the first two rows; loops in the graph corresponds to linearly dependent rows of the matrix.</p> <p>To find the nullspace of A, we solve \\(A\\mathbf{x}= \\mathbf{0}\\):</p> \\[ A\\mathbf{x}= \\begin{bmatrix} x_2 - x_1 \\\\ x_3 - x_2 \\\\ x_3 - x_1 \\\\ x_4 - x_1 \\\\ x_4 - x_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} \\] <p>If the components \\(x_i\\) of the vector \\(\\mathbf{x}\\) describe the electrical potential at the nodes \\(i\\) of the graph, then \\(A\\mathbf{x}\\) is a vector discribing the <code>difference</code> in potential across each edge of the graph. We see \\(A\\mathbf{x} = \\mathbf{0}\\) when \\(x_1 = x_2 = x_3 = x_4\\), so the nullspace has dimension 1. In terms of an electrical network, the potential difference is zero on each edge if each node has the same potential. We can't tell what that potential is by observing the flow of electricity through the network, but if one node of the network is grounded then its potential is zero. From that we can determine the potential of all other nodes of the graph.</p> <p>The matrix has 4 columns and a 1 dimensional nullspace, so its rank is 3. The first, second and fourth columns are its pivot columns; these edges connect all the nodes of the graph without forming a loop - a graph with no loops is called a <code>tree</code>.</p> <p>The left nullspace of \\(A\\) consists of the solutions \\(\\mathbf{y}\\) to the equation: \\(A^T \\mathbf{y} = \\mathbf{0}\\). Since \\(A^T\\) has 5 columns and rank 3 we know that the dimension of \\(N(A^T)\\) is \\(m - r = 2\\). Note that 2 is the number of loops in the graph and \\(m\\) is the number of edges. The rank \\(r\\) is \\(n - 1\\), one less than the number of nodes. This gives us:</p> \\[ \\# loops = \\# edges - (\\# nodes - 1) \\] <p>or</p> \\[ \\text{number of nodes } - \\text{number of edges } + \\text{number of loops } = 1 \\] <p>This is Eular's formula for connected graphs.</p>"},{"location":"Math/Linear-Algebra/Ax-equal-b-and-the-Four-Subspaces/13_graph/#kirchhoffs-law","title":"Kirchhoff's law","text":"<p>In our example of an electrical network, we started with the potentials \\(x_i\\) of the nodes. The matrix \\(A\\) then told us something about potential differences. An engineer could create a matrix \\(C\\) using Ohm's law and information about the conductance of the edges and use that matrix to determine the current \\(y_i\\) on each edge. <code>Kirchhoff's Current Law</code> then says that \\(A^T\\mathbf{y} = \\mathbf{0}\\), where \\(\\mathbf{y}\\) is the vector with components \\(y_1, y_2, y_3, y_4, y_5\\). Vectors in the nullspace of \\(A^T\\) correspond to collections of currents that satisfy Kirchhoff's law.</p> <p></p> <p>Written out, \\(A^T\\mathbf{y} = \\mathbf{0}\\) looks like:</p> \\[ \\begin{bmatrix} -1 &amp; 0 &amp; -1 &amp; -1 &amp; 0 \\\\ 1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\ \\end{bmatrix} \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} \\] <p>Multiplying the first row by the column vector \\(\\mathbf{y}\\) we get \\(-y_1 - y_3 - y_4 = 0\\). This tells us that the total current flowing out of node 1 is zero - its a balance equation, or conservation law. Multiplying the second row by \\(\\mathbf{y}\\) tells us \\(y_1 - y_2 = 0\\); the current coming into node 2 is balanced with the current going out. Multiplying the bottom rows, we get \\(y_2 + y_3 - y_5 = 0\\) and \\(y_4 + y_5 = 0\\).</p> <p>We could use the method of elimination on \\(A^T\\) to find its column space, but we already know the rank. To get a basis for \\(N(A^T)\\) we just need to ind two independent vectors in this space. Looking at the equations \\(y_1 - y_2 = 0\\) we might guess \\(y_1 = y_2 = 1\\). Then we could use the conservation laws for node 3 to guess \\(y_3 = -1\\) and \\(y_5 = 0\\). We satisfy the conservation conditions on node 4 with \\(y_4 = 0\\), giving us a basis vector \\(\\begin{bmatrix}1 \\\\ 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\). This vector represents one unit of current flowing around the loop joining nodes 1, 2 and 3; a multiple of this vector represents a different amount of current around the same loop.</p> <p>We find a second basis vector for \\(N(A^T)\\) by looking at the loop formed by nodes 1, 3 and 4:  \\(\\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\). The vector \\(\\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\) that represents a current around the outer loop is also in the nullspace, but it is the sum of the first two vectors we found.</p> <p>We've almost completely convered the mathematics of simple circuits. More complex circuits might have batteries in the edge, or current sources between nodes. Adding current sources changes the \\(A^T\\mathbf{y}=\\mathbf{0}\\) in Kirchhoff's current law to \\(A^T \\mathbf{y} = \\mathbf{f}\\). Combining the equation \\(\\mathbf{e}= A\\mathbf{x}\\), \\(\\mathbf{y} = C\\mathbf{e}\\) and \\(A^T\\mathbf{y} = \\mathbf{f}\\) gives us:</p> \\[ A^T C A \\mathbf{x} = \\mathbf{f} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/14_orthogonal/","title":"Orthogonal vectors and subspaces","text":"<p>In this lecture we learn what it means for vectors, bases and subspaces to be <code>orthogonal</code>. The symbol for this is \\(\\bot\\).</p> <p>The <code>big picture</code> of this course is that the row space of a matrix is orthogonal to its nullspace, and its column space is orthogonal to its left nullspace.</p> <p></p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/14_orthogonal/#orthogonal-vectors","title":"Orthogonal vectors","text":"<p><code>Orthogonal</code> is just another word for <code>perpendicular</code>. Two vectors are <code>orthogonal</code> if the angle between them is 90 degrees. If two vectors are orthogonal, they form a right triangle whose hypotenuse is the sum of the vectors. Thus, we can use the <code>Pythagorean theorem</code> to prove that the <code>dot product</code> \\(\\mathbf{x}^T\\mathbf{y} = \\mathbf{y}^T \\mathbf{x}\\) is \\(zero\\) exactly when \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are orthogonal. (The length squared \\(||\\mathbf{x}||^2\\) equals \\(\\mathbf{x}^T\\mathbf{x}\\)).</p> <p>Note that all vectors are orthogonal to the zero vector.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/14_orthogonal/#orthogonal-subspaces","title":"Orthogonal subspaces","text":"<p>Subspace \\(S\\) is <code>orthogonal</code> to subspace \\(T\\) means: every vector in \\(S\\) is orthogonal to every vector in \\(T\\). The blackboard is not orthogonal to the floor; two vectors in the line where the blackboard meets the floor aren't orthogonal to each other.</p> <p>In the plane, the space containing only the zero vector and any line through the origin are orthogonal subspaces. A line through the origin and the whole plane are never orthogonal subspaces. Two lines through the origin are orthogonal subspaces if they meet at right angles.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/14_orthogonal/#nullspace-is-perpendicular-to-row-space","title":"Nullspace is perpendicular to row space","text":"<p>The row space of a matrix is orthogonal to the nullspace, because the definition of nullspace is the subspace with all the \\(\\mathbf{x}\\)s that meet \\(A\\mathbf{x}= \\mathbf{0}\\), which means the dot product of \\(\\mathbf{x}\\) with each row of \\(A\\) is \\(0\\). Then the product of \\(\\mathbf{x}\\) with any combination of rows of \\(A\\) must be \\(0\\).</p> <p>The column space is orthogonal to the left nullspace of \\(A\\) because the row space of \\(A^T\\) is perpendicular to the nullspace of \\(A^T\\).</p> <p>In some sense, the row space and the nullspace of a matrix subdivide \\(\\mathbb{R}^n\\) into two perpendicular subspaces. For \\(A=\\begin{bmatrix} 1 &amp; 2 &amp; 5 \\\\ 2 &amp; 4 &amp; 10 \\end{bmatrix}\\), the row space has dimension \\(1\\) and basis \\(\\begin{bmatrix} 1 \\\\ 2 \\\\ 5 \\end{bmatrix}\\) and the nullspace has dimension \\(2\\) and is the plane through the origin perpendicular to the vector \\(\\begin{bmatrix} 1 \\\\ 2 \\\\ 5 \\end{bmatrix}\\).</p> <p>Not only is the nullspace orthogonal to the row space, their dimensions add up to the dimension of the whole space. We say that the nullspace and the row space are <code>orthogonal complements</code> in \\(\\mathbb{R}^n\\). The nullspace contains all the vectors that are perpendicular to the row space, and vice versa.</p> <p>We could say that this is part two of the fundamental theorem of linear algebra. Part one gives the dimensions of the four subspaces, part two says those subspaces come in orthogonal pairs, and part three will be about orthogonal bases for these subspaces.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/14_orthogonal/#nata-na","title":"N(A^TA) = N(A)","text":"<p>Due to measurement error, \\(A\\mathbf{x} = \\mathbf{b}\\) is often unsolvable if \\(m &gt; n\\). Our next challenge is to find the best possible solution in this case. The matrix \\(A^TA\\) plays a key role in this effort: the central equation is</p> \\[ A^TA \\hat{\\mathbf{x}} = A^T \\mathbf{b} \\] <p>We know that \\(A^TA\\) is square \\(n \\times n\\) and symmetric. When is it invertible?</p> <p>Suppose \\(A = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 2 \\\\ 1 &amp; 5 \\end{bmatrix}\\). Then:</p> \\[ A^T A = \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 5 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 2 \\\\ 1 &amp; 5 \\end{bmatrix} = \\begin{bmatrix} 3 &amp; 8 \\\\ 8 &amp; 30 \\end{bmatrix} \\] <p>is invertible. \\(A^TA\\) is not always invertible. In fact:</p> \\[ N(A^TA) = N(A) \\] \\[ \\text{rank of } A^T A = \\text{rank of } A \\] <p>We conclude that \\(A^TA\\) is invertible exaclty when \\(A\\) has independent columns.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/","title":"Projections onto Subspaces","text":""},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/#projection","title":"Projection","text":"<p>If we have a vector \\(\\mathbf{b}\\) and a line determined by a vector \\(\\mathbf{a}\\), how do we find the point on the line that is closet to \\(\\mathbf{b}\\)?</p> <p></p> <p>We can see from the figure that this closet point \\(p\\) is at the intersection formed by a line through \\(\\mathbf{b}\\) that is orthogonal to \\(\\mathbf{a}\\). If we think of \\(\\mathbf{p}\\) as an approximation of \\(\\mathbf{b}\\), then the length of \\(\\mathbf{e} = \\mathbf{b} - \\mathbf{p}\\) is the error in that approximation.</p> <p>We could try to find \\(\\mathbf{p}\\) using trigonometry or calculus, but it's easier to use linear algebra. Since \\(\\mathbf{p}\\) lies on the line through \\(\\mathbf{a}\\), we know \\(\\mathbf{p} = \\mathbf{a}x\\) for some number \\(x\\). We also know that \\(\\mathbf{a}\\) is perpendicular to \\(\\mathbf{e} = \\mathbf{b} - \\mathbf{a}x\\):</p> \\[ \\begin{align} \\mathbf{a}^T (\\mathbf{b} - \\mathbf{a}x) &amp;= 0 \\\\ \\mathbf{a}^T\\mathbf{a}x &amp;= \\mathbf{a}^T\\mathbf{b} \\\\ x &amp;= \\frac{\\mathbf{a}^T\\mathbf{b}}{\\mathbf{a}^T\\mathbf{a}} \\end{align} \\] <p>and</p> \\[ \\mathbf{p} = \\mathbf{a}x = \\mathbf{a} \\frac{\\mathbf{a}^T\\mathbf{b}}{\\mathbf{a}^T\\mathbf{a}} \\] <p>Doubling \\(\\mathbf{b}\\) will double \\(\\mathbf{p}\\), doubling \\(\\mathbf{a}\\) does not affect \\(\\mathbf{p}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/#projection-matrix","title":"Projection Matrix","text":"<p>We'd like to write this projection in terms of a <code>projection matrix</code> \\(P\\):</p> \\[ \\mathbf{p} = P\\mathbf{b} \\] <p>As</p> \\[ \\mathbf{p} = \\mathbf{a}x = \\mathbf{a} \\frac{\\mathbf{a}^T\\mathbf{b}}{\\mathbf{a}^T\\mathbf{a}} \\] <p>so the matrix is:</p> \\[ P = \\frac{\\mathbf{a}\\mathbf{a}^T}{\\mathbf{a}^T\\mathbf{a}} \\] <p>Note that \\(\\mathbf{a}\\mathbf{a}^T\\) is a \\(3 \\times 3\\) matrix, not a number; matrix multiplication is not commutative.</p> <p>The column space of \\(P\\) is spanned by \\(\\mathbf{a}\\) because for any \\(\\mathbf{b}\\), \\(P\\mathbf{b}\\) lies on the line determined by \\(\\mathbf{a}\\). The rank of \\(P\\) is \\(1\\). \\(P\\) is symmetric. \\(P^2\\mathbf{b} = P\\mathbf{b}\\) because the projection of a vector already on the line through \\(\\mathbf{a}\\) is just that vector. In general, projection matrices have the properties:</p> \\[ P^T = P \\] \\[ P^2 = P \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/#why-projection","title":"Why Projection?","text":"<p>As we know, the equation \\(A\\mathbf{x} = \\mathbf{b}\\) may have no solution. The vector \\(A\\mathbf{x}\\) is always in the column space of \\(A\\), and \\(\\mathbf{b}\\) is unlikely to be in the column space. So, we project \\(\\mathbf{b}\\) onto a vector \\(\\mathbf{p}\\) in the column space of \\(A\\) and solve \\(A\\mathbf{\\hat{x}} = \\mathbf{p}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/#projection-in-higher-dimension","title":"Projection in Higher Dimension","text":"<p>In \\(\\mathbb{R}^3\\), how do we project a vector \\(\\mathbf{b}\\) onto the closet point \\(\\mathbf{p}\\) in a plane?</p> <p>If \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\) form a basis for the plane, then that plane is the column space of the matrix \\(A = \\begin{bmatrix} \\mathbf{a_1} &amp; \\mathbf{a_2} \\end{bmatrix}\\).</p> <p>We know that \\(\\mathbf{b} = \\hat{x_1}\\mathbf{a_1} + \\hat{x_2}\\mathbf{a_2} = A\\mathbf{\\hat{x}}\\). We want to find \\(\\mathbf{\\hat{x}}\\). There are many ways to show that \\(\\mathbf{e} = \\mathbf{b} - \\mathbf{p} = \\mathbf{b} - A\\mathbf{\\hat{x}}\\) is orthogonal to the plane we're projecting onto, after wihch we can use the fact that \\(\\mathbf{e}\\) is perpendicular to \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\):</p> \\[ \\begin{align} \\mathbf{a_1}^T (\\mathbf{b} - A\\mathbf{\\hat{x}}) = 0 \\\\ \\mathbf{a_2}^T (\\mathbf{b} - A\\mathbf{\\hat{x}}) = 0 \\\\ \\end{align} \\] <p>In matrix form:</p> \\[ A^T (\\mathbf{b} - A \\mathbf{\\hat{x}}) = 0 \\] <p>When we were projecting onto a line, \\(A\\) only had one column and so this equation looked like: </p> \\[ A^T (\\mathbf{b} - A \\mathbf{\\hat{x}}) = 0 \\] <p>Note that \\(\\mathbf{e} = \\mathbf{b} - A\\mathbf{\\hat{x}}\\) is in the nullspace of \\(A^T\\) and so is in the left nullspace of \\(A\\). We know that everything in the left nullspace of \\(A\\) is perpendicular to the column space of \\(A\\), so this is another confirmation that our calculation are correct.</p> <p>We can rewrite the equation \\(A^T(\\mathbf{b} - A\\mathbf{\\hat{x}})\\) as:</p> \\[ A^TA\\mathbf{\\hat{x}} = A^T \\mathbf{b} \\] <p>When projecting onto a line, \\(A^TA\\) was just a number; now it is a square matrix.</p> <p>So instead of dividing by \\(\\mathbf{a}^T\\mathbf{a}\\) we now have to multiply by \\((A^TA)^{-1}\\).</p> <p>In \\(n\\) dimensions:</p> \\[ \\begin{align} \\mathbf{\\hat{x}} &amp;= (A^TA)^{-1}A^T\\mathbf{b} \\\\ \\mathbf{p} = A\\mathbf{\\hat{x}} &amp;= A(A^TA)^{-1}A^T\\mathbf{b} \\\\ P &amp;= A(A^TA)^{-1}A^T \\end{align} \\] <p>It's tempting to try to simplify these expressions, but if \\(A\\) isn't a square matrix we can't say that \\((A^TA)^{-1} = A^{-1}(A^T)^{-1}\\).</p> <p>If \\(A\\) does happen to be a square, invertible matrix then it's column space is the whole space and contains \\(\\mathbf{b}\\). In this case \\(P\\) is the identity, as we find when we simplify. It is still true that:</p> \\[ \\begin{align} P^T = P \\\\ P^2 = P \\\\ \\end{align} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/15_proj_subspace/#least-squares","title":"Least Squares","text":"<p>Suppose we're given a collection of data points \\((t, b)\\):</p> \\[ \\{(1, 1), (2, 2), (3, 2)\\} \\] <p>and we want to find the closet line \\(b = C + Dt\\) to that collection. If the line went through all three points, we'd have:</p> \\[ \\begin{align} C + D = 1 \\\\ C + 2D = 2 \\\\ C + 3D = 2 \\\\ \\end{align} \\] <p>Which is equivalent to:</p> \\[ \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 2 \\\\ 1 &amp; 3 \\\\ \\end{bmatrix} \\begin{bmatrix} C \\\\ D \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\\\ \\end{bmatrix} \\] \\[ A \\mathbf{x} = \\mathbf{b} \\] <p>In our example the line does not go through all three points, so this equation is not solvable. Instead we'll solve:</p> \\[ A^TA\\mathbf{\\hat{x}} = A^T \\mathbf{b} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/16_least_square/","title":"Projection Matrices and Least Squares","text":""},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/16_least_square/#projections","title":"Projections","text":"<p>Last lecture, we learned that \\(P = A(A^TA)^{-1}A^T\\) is the matrix that projects a vector \\(\\mathbf{b}\\) onto the space spanned by the columns of \\(A\\). If \\(\\mathbf{b}\\) is perpendicular to the column space, then it's in the left nullspace \\(N(A^T)\\) of \\(A\\) and \\(P\\mathbf{b} = \\mathbf{0}\\). If \\(\\mathbf{b}\\) is in the column space then \\(\\mathbf{b} = A\\mathbf{x}\\) for some \\(\\mathbf{x}\\), and \\(P\\mathbf{b} = \\mathbf{b}\\).</p> <p>A typical vector will have a component \\(\\mathbf{p}\\) in the column space and a component \\(\\mathbf{e}\\) perpendicular to the column space (in the left nullspace); its projection is just the component in the column space.</p> <p>The matrix projecting \\(\\mathbf{b}\\) onto \\(N(A^T)\\) is \\(I - P\\):</p> \\[ \\mathbf{e} = \\mathbf{b} - \\mathbf{p} = (I - P)\\mathbf{b} \\] <p>Naturally, \\(I - P\\) has all the properties of a projection matrix.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/16_least_square/#least-squares","title":"Least Squares","text":"<p>We want to find the closet line \\(b = C + Dt\\) to the points \\((1, 1), (2, 2)\\) and \\((3, 2)\\). The process we're going to use is called <code>linear regression</code>; this technique is most useful if none of the data points are <code>outlier</code>.</p> <p>By <code>closet</code> line we mean one that minimizes the error represented by the distance from the points to the line. We measure that error by adding up the squares of these distances. In other words, we want to minimize</p> \\[ ||A\\mathbf{x} - \\mathbf{b}||^2 = ||\\mathbf{e}||^2 \\] <p>If the line went through all three points, we'd have:</p> \\[ \\begin{align} C + D = 1 \\\\ C + 2D = 2 \\\\ C + 3D = 2 \\\\ \\end{align} \\] <p>but this system is unsolvable. It's equivalent to \\(A \\mathbf{x} = \\mathbf{b}\\), where:</p> \\[ A = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 2 \\\\ 1 &amp; 3 \\end{bmatrix}, \\mathbf{x} = \\begin{bmatrix} C \\\\ D \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2\\end{bmatrix} \\] <p>There are two ways of viewing this. In the space of the line we're trying to find, \\(e_1, e_2\\) and \\(e_3\\) are the vertical distance from the data points to the line. The components \\(p_1\\), \\(p_2\\) and \\(p_3\\) are the values of \\(C + Dt\\) near each data point; \\(\\mathbf{p} \\approx \\mathbf{b}\\).</p> <p>In the other view we have a vector \\(\\mathbf{b}\\) in \\(\\mathbb{R}^3\\), its projection \\(\\mathbf{p}\\) onto the column space of \\(A\\), and its projection \\(\\mathbf{e}\\) onto \\(N(A^T)\\).</p> <p>We will now find \\(\\mathbf{\\hat{x}} = \\begin{bmatrix} \\hat{C} \\\\ \\hat{D} \\end{bmatrix}\\) and \\(\\mathbf{b}\\). We know:</p> \\[ A^TA\\mathbf{\\hat{x}} = A^T\\mathbf{b} \\] \\[ \\begin{bmatrix} 3 &amp; 6 \\\\ 6 &amp; 14 \\\\ \\end{bmatrix} \\begin{bmatrix} \\hat{C} \\\\ \\hat{D} \\\\ \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 11 \\\\ \\end{bmatrix} \\] <p>From this we get the <code>normal equations</code>:</p> \\[ \\begin{align} 3 \\hat{C} + 6 \\hat{D} = 5 \\\\ 6 \\hat{C} + 14 \\hat{D} = 11 \\\\ \\end{align} \\] <p>We solve these to find \\(\\hat{D} = 1 / 2\\) and \\(\\hat{C} = 2 / 3\\).</p> <p>We could also have used calculus to find the minimum of the following function of two variables:</p> \\[ e_1^2 + e_2^2 + e_3^2 = (C + D - 1)^2 + (C + 2D - 2)^2 + (C + 3D - 2)^2 \\] <p>Either way, we end up solving a system of linear equations to find that the closet line to our points is</p> \\[ b = \\frac{2}{3} + \\frac{1}{2}t \\] <p>this gives us:</p> i \\(p_i\\) \\(e_i\\) 1 7/6 -\u2159 2 5/3 \u2153 3 13/6 -\u2159 <p>or</p> \\[ \\begin{align} \\mathbf{p} = \\begin{bmatrix} 7/6 \\\\ 5/3 \\\\ 13/6 \\end{bmatrix} \\\\ \\mathbf{e} = \\begin{bmatrix} -1/6 \\\\ 2/6 \\\\ -1/6 \\end{bmatrix} \\\\ \\end{align} \\] <p>Note that \\(\\mathbf{p}\\) and \\(\\mathbf{e}\\) are orthogonal, and also that \\(\\mathbf{e}\\) is perpendicular to the columns of \\(A\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/16_least_square/#the-matrix-ata","title":"The matrix \\(A^TA\\)","text":"<p>We've been assuming that the matrix \\(A^TA\\) is invertable. Is this justified?</p> <p>If \\(A\\) has independent columns, then \\(A^TA\\) is invertible.</p> <p>To prove this, we assume that</p> \\[ A^TA\\mathbf{x} = \\mathbf{0} \\] <p>then show that it must be true that</p> \\[ \\mathbf{x} = \\mathbf{0} \\] <p>So we got:</p> \\[ \\begin{align} A^TA\\mathbf{x} = \\mathbf{0} \\\\ \\mathbf{x}^TA^TA\\mathbf{x} = \\mathbf{x}^T\\mathbf{0} \\\\ (A\\mathbf{x})^T(A\\mathbf{x}) = \\mathbf{0} \\\\ A\\mathbf{x} = \\mathbf{0} \\end{align} \\] <p>Since \\(A\\) has independent columns, \\(A\\mathbf{x} = \\mathbf{0}\\) only when \\(\\mathbf{x} = \\mathbf{0}\\). </p> <p>As long as the columns of \\(A\\) are independent, we can use linear regression to find approximate solutions to unsolvable systems of linear equations. The columns of \\(A\\) are guaranteed to be independent if they are <code>orthonormal</code>, i.e. if they are perpendicular unit vectors like:</p> \\[ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\] <p>or like:</p> \\[ \\begin{bmatrix} cos{\\theta} \\\\ sin{\\theta} \\end{bmatrix}, \\begin{bmatrix} -sin\\theta \\\\ cos\\theta \\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/17_gram_schmidt/","title":"Orthogonal Matrices and Gram-Schmidt","text":"<p>In this lecture we finish introducing orthogonality. Using an orthonormal basis or a matrix with orthonormal columns makes calculations much easier. The Gram-Schmidt process starts with any basis and produces an orthonormal basis that spans the same space as the original basis.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/17_gram_schmidt/#orthonormal-vectors","title":"Orthonormal Vectors","text":"<p>The vectors \\(\\mathbf{q_1}, \\mathbf{q_2}, \\cdots, \\mathbf{q_n}\\) are <code>orthonormal</code> if:</p> \\[ \\mathbf{q_i}^T \\mathbf{q_j} = \\begin{cases} 0,\\text{ if } i \\ne j \\\\ 1,\\text{ if } i = j \\\\ \\end{cases} \\] <p>In other words, they all have (normal) length \\(1\\) and are perpendicular(orthonormal) to each other. Orthonormal vectors are always independent.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/17_gram_schmidt/#orthonormal-matrix","title":"Orthonormal Matrix","text":"<p>If the columns of \\(Q = [\\mathbf{q_1} \\cdots \\mathbf{q_n}]\\) are orthonormal, then \\(Q^TQ = I\\) is the identity.</p> <p>Matrices with orthonormal columns are a new class of important matrices to add to those on our list:</p> <ul> <li>triangular</li> <li>diagonal</li> <li>permutation</li> <li>symmetric</li> <li>reduced row echelon</li> <li>projection</li> </ul> <p>We'll call them <code>orthonormal matrices</code>.</p> <p>A square orthonormal matrix \\(Q\\) is called an <code>orthogonal matrix</code>. If \\(Q\\) is square, then \\(Q^TQ = I\\) tells us that:</p> \\[ Q^T = Q^{-1} \\] <p>For example, if \\(Q = \\begin{bmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{bmatrix}\\) then \\(Q^T = \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\end{bmatrix}\\). Both \\(Q\\) and \\(Q^T\\) are orthogonal matrices, and their product is the identity.</p> <p>The matrix \\(Q = \\begin{bmatrix} cos\\theta &amp; -sin\\theta \\\\ sin\\theta &amp; cos\\theta \\end{bmatrix}\\) is orthogonal. The matrix \\(\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\end{bmatrix}\\) is not, but we can adjust that matrix to get the orthogonal matrix \\(Q = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\end{bmatrix}\\). We can use the same tactic to find some larger orthogonal matrices called <code>Hadamard matrices</code>:</p> \\[ Q = \\frac{1}{2} \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; 1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; 1 \\\\ \\end{bmatrix} \\] <p>An example of a rectangular matrix with orthonormal columns is:</p> \\[ Q = \\frac{1}{3} \\begin{bmatrix} 1 &amp; -2 \\\\ 2 &amp; -1 \\\\ 2 &amp; 2 \\\\ \\end{bmatrix} \\] <p>We can extend this to a (square) orthogonal matrix:</p> \\[ \\frac{1}{3} \\begin{bmatrix} 1 &amp; -2 &amp; 2 \\\\ 2 &amp; -1 &amp; -2 \\\\ 2 &amp; 2 &amp; 1 \\\\ \\end{bmatrix} \\] <p>These examples are particularly nice because they don't include complicated square roots.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/17_gram_schmidt/#orthonormal-columns-are-good","title":"Orthonormal Columns are Good","text":"<p>Suppose \\(Q\\) has orthonormal columns, The matrix that projects onto the column space of \\(Q\\) is:</p> \\[ P = Q(Q^TQ)^{-1}Q^T \\] <p>If the columns of \\(Q\\) are orthonormal, then \\(Q^TQ = I\\) and \\(P = QQ^T\\). If \\(Q\\) is square, then \\(P = I\\) because the columns of \\(Q\\) span the entire space.</p> <p>Many equations become trivial when using a matrix with orthonormal columns. If our basis is orthonormal, the projection component \\(\\hat{x_i}\\) is just \\(\\mathbf{q_i}^T\\mathbf{b}\\) because \\(A^TA\\hat{x} = A^T\\mathbf{b}\\) becomes \\(\\mathbf{\\hat{x}} = Q^T\\mathbf{b}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/17_gram_schmidt/#gram-schmidt","title":"Gram-Schmidt","text":"<p>With elimination, our goal was <code>make the matrix triangular</code>. Now our goal is <code>make the matrix orthonormal</code>.</p> <p>We start with two independent vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) and want to find orthonormal vectors \\(\\mathbf{q_1}\\) and \\(\\mathbf{q_2}\\) that span the same plane. We start by finding orthogonal vectors \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) that span the same space as \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\). Then the unit vectors \\(\\mathbf{q_1} = \\frac{\\mathbf{A}}{||\\mathbf{A}||}\\) and \\(\\mathbf{q_2} = \\frac{\\mathbf{B}}{||\\mathbf{B}||}\\) from the desired orthonormal basis.</p> <p>Let \\(\\mathbf{A} = \\mathbf{a}\\). We get a vector orthogonal to \\(\\mathbf{A}\\) in the space spanned by \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) by projecting \\(\\mathbf{b}\\) onto \\(\\mathbf{a}\\) and letting \\(\\mathbf{B} = \\mathbf{b} - \\mathbf{p}\\). (\\(\\mathbf{B}\\) is what we previously called \\(\\mathbf{e}\\).)</p> \\[ \\mathbf{B} = \\mathbf{b} - \\frac{\\mathbf{A}^T\\mathbf{b}}{\\mathbf{A}^T\\mathbf{A}} \\mathbf{A} \\] <p>If we multiply both sides of this equation by \\(\\mathbf{A}^T\\), we see that \\(\\mathbf{A}^T\\mathbf{B} = \\mathbf{0}\\)</p> <p>What if we had started with three independent vectors, \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\)? Then we'd find a vector \\(\\mathbf{C}\\) orthogonal to both \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) by subtracting from \\(\\mathbf{c}\\) its components in the \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) directions:</p> \\[ \\mathbf{C} = \\mathbf{c} - \\frac{\\mathbf{A}^T \\mathbf{c}} {\\mathbf{A}^T\\mathbf{A}} \\mathbf{A} - \\frac{\\mathbf{B}^T \\mathbf{c}} {\\mathbf{B}^T \\mathbf{B}} \\mathbf{B} \\] <p>For example, suppose \\(\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\\) and \\(\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix}\\). Then \\(\\mathbf{A} = \\mathbf{a}\\) and:</p> \\[ \\begin{align} \\mathbf{B} &amp; = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} - \\frac{\\mathbf{A}^T \\mathbf{b}} {\\mathbf{A}^T\\mathbf{A}} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\ &amp; = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} - \\frac{3}{3} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\ &amp; = \\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix} \\end{align} \\] <p>Normalizing, we get:</p> \\[ Q = [ \\mathbf{q_1} \\mathbf{q_2}] = \\begin{bmatrix} 1/\\sqrt{3} &amp; 0 \\\\ 1/\\sqrt{3} &amp; -1/\\sqrt{2} \\\\ 1/\\sqrt{3} &amp; 1/\\sqrt{2} \\\\ \\end{bmatrix} \\] <p>The column space of \\(Q\\) is the plane spanned by \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\).</p> <p>When we studied elimination, we wrote the process in terms of matrices and found \\(A = LU\\). A similar equation \\(A = QR\\) relates our starting matrix \\(A\\) to the result \\(Q\\) of the Gram-Schmidt process. Where \\(L\\) was lower triangular, \\(R\\) is upper triangular.</p> <p>Suppose \\(A = [ \\mathbf{a_1} \\mathbf{a_2} ]\\), then:</p> \\[ A = Q R \\] \\[ \\begin{bmatrix} \\mathbf{a_1} &amp; \\mathbf{a_2} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{q_1} &amp; \\mathbf{q_2} \\end{bmatrix} \\begin{bmatrix} \\mathbf{a_1}^T\\mathbf{q_1} &amp; \\mathbf{a_2}^T\\mathbf{q_1} \\\\ \\mathbf{a_1}^T\\mathbf{q_2} &amp; \\mathbf{a_2}^T\\mathbf{q_2} \\\\ \\end{bmatrix} \\] <p>If \\(R\\) is upper triangular, then it should be true that \\(\\mathbf{a_1}^T\\mathbf{q_2} = 0\\). This must be true because we chose \\(\\mathbf{q_1}\\) to be a unit vector in the direction of \\(\\mathbf{a_1}\\). All the latter \\(\\mathbf{q_i}\\) were chosen to be perpendicular to the earlier ones.</p> <p>Notice that \\(R = Q^TA\\). This makes sense; \\(Q^TQ = I\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/18_property_determinant/","title":"Properties of Determinants","text":""},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/18_property_determinant/#determinants","title":"Determinants","text":"<p>Now halfway through the course, we leave behind rectangular matrices and focus on square ones. Our next big topics are determinants and eigenvalues.</p> <p>The <code>determinant</code> is a number associated with any square matrix; we'll write it as <code>det A</code> or \\(|A|\\). The determinant encodes a lot of information about the matrix; the matrix is invertible exactly when the determinant is non-zero.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/18_property_determinant/#properties","title":"Properties","text":"<p>Rather than start with a big formula, we'll list the properties of the determinant. We already know that \\(\\begin{vmatrix} a &amp; b \\\\ c &amp; d  \\end{vmatrix} = ad - bc\\); these properties will give us a formula for the determinant of square matrices of all sizes.</p> <p>1 . |I| = 1</p> <p>2 . If you exchange two rows of a matrix, you reverse the sign of its determinant from positive to negative or from negative to positive.</p> \\[ \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} = - \\begin{vmatrix} c &amp; d \\\\ a &amp; b \\\\ \\end{vmatrix} \\] <p>3 . (a) If we multiply one row of a matrix by \\(t\\), the determinant is multiplied by \\(t\\):</p> \\[ \\begin{vmatrix} ta &amp; tb \\\\ c &amp; d \\\\ \\end{vmatrix} = t \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} \\] <p>3 . (b) The determinant behaves like a linear function on the rows of the matrix:</p> \\[ \\begin{vmatrix} a + a' &amp; b + b' \\\\ c &amp; d \\\\ \\end{vmatrix} = \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} + \\begin{vmatrix} a' &amp; b' \\\\ c &amp; d \\\\ \\end{vmatrix} \\] <p>Property 1 tells us that \\(\\begin{vmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{vmatrix} = 1\\).  Property 2 tells us that \\(\\begin{vmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{vmatrix} = -1\\). The determinant of a permutation matrix \\(P\\) is \\(1\\) or \\(-1\\) depending o whether \\(P\\) exchanges an even or odd number of rows.</p> <p>From these three properties we can deduce many others:</p> <p>4 . If two rows of a matrix are equal, its determinant is zero.</p> \\[ \\begin{vmatrix} a &amp; b \\\\ a &amp; b \\\\ \\end{vmatrix} = 0 \\] <p>This is because of property 2, the exchange rule. On the one hand, exchanging the two identical rows does not change the determinant. On the other hand, exchanging the two rows changes the sign of the determinant. Therefore the determinant must be \\(0\\).</p> <p>5 . If \\(i \\ne j\\), subtracting \\(t\\) times row \\(i\\) from row \\(j\\) doesn't change the determinant.</p> <p>In two dimensions, this argument looks like:</p> \\[ \\begin{align} \\begin{vmatrix} a &amp; b \\\\ c - ta &amp; d - tb \\\\ \\end{vmatrix} &amp;= \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} - \\begin{vmatrix} a &amp; b \\\\ ta &amp; tb \\\\ \\end{vmatrix} \\text{   property 3(b)} \\\\ &amp;= \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} - t \\begin{vmatrix} a &amp; b \\\\ a &amp; b \\\\ \\end{vmatrix} \\text{  property 3(a)} \\\\ &amp;= \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\\\ \\end{vmatrix} \\text{  property 4} \\end{align} \\] <p>The proof for higher dimensional matrices is similar.</p> <p>6 . If \\(A\\) has a row that is all zeros, then \\(\\det A = 0\\).</p> <p>We get this from property 3(a) by letting \\(t = 0\\).</p> <p>7 . The determinant of a triangular matrix is the product of the diagonal entries(pivots) \\(d_1, d_2, \\cdots, d_n\\).</p> <p>Property 5 tells us that the determinant of the triangular matrix won't change if we use elimination to convert it to a diagonal matrix with the entries \\(d_i\\) on its diagonal. Then property 3(a) tells us that the determinant of this digonal matrix is the product \\(d_1d_2 \\cdots d_n\\) times the determinant of the identity matrix. Property 1 completes the arguments.</p> <p>Note that we cannot use elimination to get a diagonal matrix if one of the \\(d_i\\) is zero. In that case elimination will give us a row of zeros and property 6 gives us the conclusion we want.</p> <p>8 . \\(\\det A = 0\\) exactly when \\(A\\) is singular.</p> <p>If \\(A\\) is singular, then we can use elimination to get a row of zeros, and property 6 tells us that determinant is zero.</p> <p>If \\(A\\) is not singular, then elimination produces a full set of pivots \\(d_1, d_2, \\cdots, d_n\\) and the determinant is \\(d_1d_2 \\cdots d_n \\ne 0\\) (with minus signs from row exchanges).</p> <p>We now have a very practical formula for the determinant of a non-singular matrix. In fact, the way computers find the determinants of large matrices is to first perform elimination (keeping track of whether the row exchanges is odd or even) and then multiply the pivots:</p> \\[ \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix} \\to \\begin{bmatrix} a &amp; b \\\\ 0 &amp; d - \\frac{c}{a}b \\end{bmatrix} \\] <p>where \\(a \\ne 0\\), so</p> \\[ \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} = a(d - \\frac{c}{a}b) = ad - bc \\] <p>9 . \\(\\det AB = (\\det A)(\\det B)\\)</p> <p>This is very useful. Although the determinant of a sum does not equal the sum of the determinants, it is true that the determinant of a product equals the product of the determinants.</p> <p>For example:</p> \\[ \\det A^{-1} = \\frac{1}{\\det A} \\] <p>because \\(A^{-1}A = 1\\). (Note that if \\(A\\) is singular then \\(A^{-1}\\) does not exist and \\(\\det A^{-1}\\) is undefined.) </p> <p>Also, \\(\\det A^2 = (\\det A)^2\\) and \\(\\det 2A = 2^n \\det A\\) (applying property 3 to each row of the matrix). This reminds us of volume, if we double the length, width and height of a tree dimensional box, we increase its volume by a multiple of \\(2^3 = 8\\).</p> <p>10 . \\(\\det A^T = \\det A\\)</p> \\[ \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} = \\begin{vmatrix} a &amp; c \\\\ b &amp; d \\end{vmatrix} = ad - bc \\] <p>This lets us translate properties(2, 3, 4, 5, 6) involving rows into statements about columns. For instance, if a column of a matrix is all zeros then then the determinant of that matrix is zero.</p> <p>To see why \\(|A^T| = |A|\\), use elimination to write \\(A = LU\\). The statement becomes \\(|U^TL^T| = |LU|\\). Rule 9 then tells us \\(|U^T||L^T| = |L||U|\\).</p> <p>Matrix \\(L\\) is a lower triangular matrix with \\(1\\)'s on the diagonal, so rule 5 tells us that \\(|L| = |L^T| = 1\\). Because \\(U\\) is upper triangular, rule 5 tells us that \\(|U| = |U^T|\\). Therefore \\(|U^T||L^T| = |L||U|\\) and \\(|A^T| = |A|\\).</p> <p>We have one loose end to worry about. Rule 2 told us that a row exchange changes the sign of the determinant. If it's possible to do seven row exchanges and get the same matrix you would by doging ten row changes, then we could prove that the determinant equals its negative. To complete the proof that the determinant is well defined by properties 1, 2 and 3 we'd need to show that the result of an odd number of row exchanges (odd permutation) can never be the same as the result of an even number of row exchanges(even permutation).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/19_cofactor/","title":"Determinant Formulas and Cofactors","text":"<p>Now that we know the properties of the determinant, it's time to learn some(rather messy) formulas for computing it.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/19_cofactor/#formula-for-the-determinant","title":"Formula for the Determinant","text":"<p>We know that the determinant has the following three properties:</p> <ol> <li>\\(det I = 1\\)</li> <li>Exchanging rows reverses the sign of the determinant.</li> <li>The determinant is linear in each row separately.</li> </ol> <p>Last class we listed seven consequences of these properties. We can use these ten properties to find a formula for the determinant of a 2 by 2 matrix:</p> \\[ \\begin{align} \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} &amp;= \\begin{vmatrix} a &amp; 0 \\\\ c &amp; d\\end{vmatrix} + \\begin{vmatrix} 0 &amp; b \\\\ c &amp; d \\end{vmatrix} \\\\  &amp;= \\begin{vmatrix} a &amp; 0 \\\\ c &amp; 0\\end{vmatrix} + \\begin{vmatrix} a &amp; 0 \\\\ 0 &amp; d \\end{vmatrix} + \\begin{vmatrix} 0 &amp; b \\\\ c &amp; 0 \\end{vmatrix} + \\begin{vmatrix} 0 &amp; b \\\\ 0 &amp; d \\end{vmatrix} \\\\ &amp;= 0 + ad + (-cb) + 0 \\\\ &amp;= ad - bc \\end{align} \\] <p>By applying property 3 to separate the individual entries of each row we could get a formula for any other square matrix. However, for a 3 by 3 matrix we'll have to add the determinants of 27 different matrices! Many of those determinants are zero. The none-zero pieces are:</p> \\[ \\begin{align} \\begin{vmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\\\ \\end{vmatrix} &amp; = \\begin{vmatrix} a_{11} &amp; 0 &amp; 0 \\\\ 0 &amp; a_{22} &amp; 0 \\\\ 0 &amp; 0 &amp; a_{33} \\\\ \\end{vmatrix} + \\begin{vmatrix} a_{11} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; a_{23} \\\\ 0 &amp; a_{32} &amp; 0 \\\\ \\end{vmatrix} + \\begin{vmatrix} 0 &amp; a_{12} &amp; 0 \\\\ a_{21} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; a_{33} \\\\ \\end{vmatrix} + \\begin{vmatrix} 0 &amp; a_{12} &amp; 0 \\\\ 0 &amp; 0 &amp; a_{23} \\\\ a_{31} &amp; 0 &amp; 0 \\\\ \\end{vmatrix} + \\begin{vmatrix} 0 &amp; 0 &amp; a_{13} \\\\ 0 &amp; a_{22} &amp; 0 \\\\ 0 &amp; a_{32} &amp; 0 \\\\ \\end{vmatrix} + \\begin{vmatrix} 0 &amp; 0 &amp; a_{13} \\\\ 0 &amp; a_{22} &amp; 0 \\\\ a_{31} &amp; 0 &amp; 0 \\\\ \\end{vmatrix} \\\\ &amp;= a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} \\end{align} \\] <p>Each of the non-zero pieces has one entry form each row in each column, as in a permutation matrix, Since the determinant of a permutation matrix is either 1 or -1, we can again use the property 3 to find the determinants of each of these summands and obtain our formula.</p> <p>One way to remember this formula is that the positive terms are products of entries going down and to the right in our original matrix, and the negtive terms are products going down and to the left. This rule of thumb doesn't work for matrices larger than 3 by 3.</p> <p>The number of parts with non-zero determinants was</p> <ul> <li>2(\\(2!\\)), in 2 by 2 case,</li> <li>6(\\(3!\\)), in 3 by 3 case,</li> <li>24(\\(4!\\)), in 4 by 4 case.</li> </ul> <p>This  is because there are n ways to choose an element from the first row(i.e. a value for \\(\\alpha\\)), after which there are only n - 1 ways to choose an element from the second row that avoids a zero determinant. Then there are n - 2 choices from the third row, n - 3 from the fourth, and so on.</p> <p>The big formula for computing the determinant of any square matrix is:</p> \\[ det A = \\sum_{n!\\text{ terms}} \\pm a_{1\\alpha} a_{2\\beta} a_{3\\gamma} \\cdots a_{n\\omega} \\] <p>where \\((\\alpha,\\beta,\\gamma,\\cdots,\\omega)\\) is some permutation of \\((1, 2, 3, \\cdots, n)\\). If we test this on the identity matrix, we find that all the terms are zero except the one corresponding to the trivial permutation \\(\\alpha=1, \\beta = 2, \\cdots, \\omega = n\\). This agrees with the first property: \\(det I = 1\\). It's possible to check all the other properties as well, but we won't do that here.</p> <p>Applying the method of elimination and multiplying the diagonal entries of the result (the pivots) is another good way to find the determinant of a matrix.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/19_cofactor/#example","title":"Example","text":"<p>In a matrix with many zero entries, many terms in the formula are zero. We can compute the determinant of:</p> \\[ \\begin{vmatrix} 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{vmatrix} \\] <p>by choosing a non-zero entry from each row and column, multiplying those entries, giving the product the appropriate sign, then adding the results.</p> <p>The permutation corresponding to the diagonal running from \\(a_{14}\\) to \\(a_{41}\\) is (4, 3, 2, 1). This contributes 1 to the determinant of the matrix; the contribution is positive because it takes two row exchanges to convert the permutation (4, 3, 2, 1) to the identity (1, 2, 3, 4).</p> <p>Another non-zero term of of \\(\\sum \\pm a_{1\\alpha} a_{2\\beta} a_{3 \\gamma} a_{4 \\omega}\\) comes from the permutation (3, 2, 1, 4). This contributes -1 to the sum, because one exchange (of the first and third rows) leads to the identity.</p> <p>These are the only two non-zero terms in the sum, so the determinant is 0. We can confirm this by noting that row 1 minus row 2 plus row 3 minus row 4 equals zero.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/19_cofactor/#cofactor-formula","title":"Cofactor formula","text":"<p>The cofactor formula rewrites the big formula for the determinant of an n by n matrix in terms of the determinants of smaller matrices.</p> <p>In the 3 by 3 case, the formula looks like:</p> \\[ \\begin{align} det A &amp;= a_{11}(a_{22}a_{33} - a_{23}a_{32}) + a_{12}(-a_{21}a_{33} + a_{23}a_{31}) + a_{13}(a_{21}a_{32} - a_{22}a_{31}) &amp;= \\begin{vmatrix} a_{11} &amp; 0 &amp; 0 \\\\ 0 &amp; a_{22} &amp; a_{23} \\\\ 0 &amp; a_{32} &amp; a_{33} \\end{vmatrix} + \\begin{vmatrix} 0 &amp; a_{12} &amp; 0 \\\\ a_{21} &amp; 0 &amp; a_{23} \\\\ a_{31} &amp; 0 &amp; a_{33} \\end{vmatrix} + \\begin{vmatrix} 0 &amp; 0 &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; 0 \\\\ a_{31} &amp; a_{32} &amp; 0 \\end{vmatrix} \\end{align} \\] <p>This comes from grouping all the multiples of \\(a_{ij}\\) in the big formula. Each element is multiplied by the <code>cofactors</code> in the parentheses following it. Note that each cofactor is (plus or minus) the determinant of a 2 by 2 matrix. That determinant is made up of products of elements in the rows and columns NOT containing \\(a_{1j}\\).</p> <p>In general, the cofactor \\(C_{ij}\\) of \\(a_{ij}\\) can be found by looking at all the terms in the big formula that contain \\(a_{ij}\\). \\(C_{ij}\\) equals \\((-1)^{i + j}\\) times the determinant of the n - 1 by n - 1 square matrix obtained by removing row i and column j. (\\(C_{ij}\\) is positive if i + j is even and negtive if i + j is odd.)</p> <p>For n by n matrices, the cofactor formula is:</p> \\[ det A = a_{11} C_{11} + a_{12} C_{12} + \\cdots + a_{1n} C_{1n} \\] <p>Applying this to a 2 by 2 matrix gives us:</p> \\[ \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} = ad + b(-c) \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/19_cofactor/#tridiagonal-matrix","title":"Tridiagonal Matrix","text":"<p>A <code>tridiagonal matrix</code> is one for which the only non-zero entries lie on or adjacent to the diagonal. For example, the 4 by 4 triagonal matrix of 1's is:</p> \\[ A_{4} = \\begin{vmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\end{vmatrix} \\] <p>What is the determinant of an n by n triagonal matrix of 1's?</p> \\[ \\begin{vmatrix} A_{1} \\end{vmatrix} = 1,  \\begin{vmatrix} A_{2} \\end{vmatrix} = \\begin{vmatrix} 1 &amp; 1 \\\\ 1 &amp; 1 \\end{vmatrix} = 0, \\begin{vmatrix} A_{3} \\end{vmatrix} = \\begin{vmatrix} 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\end{vmatrix} = -1 \\] \\[ \\begin{vmatrix} A_{4} \\end{vmatrix} = 1 \\begin{vmatrix} 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\end{vmatrix} - \\begin{vmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\end{vmatrix} = |A_{3}| - 1 |A_{2}| = -1 \\] <p>In fact, \\(|A_{n}| = |A_{n - 1}| - |A_{n - 2}|\\). We get a sequence which repeats every six terms:</p> \\[ |A_1| = 1, |A_2| = 0, |A_3| = -1, |A_4| = -1, |A_5| = 0, |A_6| = 1, |A_7| = 1 \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/20_cramer/","title":"Cramer's Rule, Inverse Matrix, and Volume","text":"<p>We know a formula for and some properties of the determinant. Now we see how the determinant can be used.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/20_cramer/#formula-for-a-1","title":"Formula for A^-1","text":"<p>We know:</p> \\[ \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d &amp; -b \\\\ -c &amp; a \\end{bmatrix} \\] <p>Can we get a formula for the inverse of a 3 by 3 or n by n matrix? We expect that \\(\\frac{1}{det A}\\) will be involved, as it is in the 2 by 2 matrix, and by lookin at the cofactor matrix \\(\\begin{bmatrix} d &amp; -c \\\\ -b &amp; a \\end{bmatrix}\\) we will guess that the cofactors will be involved.</p> <p>In fact:</p> \\[ A^{-1} = \\frac{1}{det A} C^T \\] <p>where C is the matrix of cofactors(<code>Notice the transpose!</code>). Cofactors of row one of a go into column 1 of \\(A^{-1}\\), and then we divide by the determinant.</p> <p>The determinant of A involves products with n terms and the cofactor matrix involves products of n - 1 terms. A and \\(\\frac{1}{det A} C^T\\) might cancel each other. This is much easier to see from our formula for the determinant than when using Gauss-Jordan elimination.</p> <p>To more formally verify the formula, we'll check that \\(AC^T = (det A) I\\). </p> \\[ AC^T =  \\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; \\cdots &amp; a_{nn} \\\\ \\end{bmatrix} \\begin{bmatrix} C_{11} &amp; \\cdots &amp; C_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ C_{n1} &amp; \\cdots &amp; C_{nn} \\\\ \\end{bmatrix} \\] <p>The entry in the first row and first column of the product matrix is:</p> \\[ \\sum_{j = 1}^{n} a_{1j}C_{j1} = det A \\] <p>This is just the cofactor formula for the determinant. This happens for every entry on the diagonal of \\(AC^T\\).</p> <p>To finish proving that \\(AC^T = (det A)I\\), we just need to check that the off-diagonal entries of \\(AC^T\\) are zero. In the 2 by 2 case, multiplying the entries in row 1 of A by the entries in column 2 of \\(C^T\\) gives \\(a(-b) + b(a) = 0\\). This is the determinant of \\(A_{s} = \\begin{bmatrix} a &amp; b \\\\ a &amp; b \\end{bmatrix}\\). In higher dimensions, the product of the first of A and the last column of \\(C^T\\) equals the determinant of a matrix whose first and last rows are identical. This happens with all the off diagonal matrices, which confirms that \\(A^{-1} = \\frac{1}{det A} C^T\\).</p> <p>This formula helps us answer questions about how the inverse changes when the matrix changes.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/20_cramer/#cramers-rule-for-x-a-1-b","title":"Cramer's Rule for x = A^-1 b","text":"<p>We know that if \\(A\\mathbf{x} = \\mathbf{b}\\) and A is nonsingular, then \\(\\mathbf{x} = A^{-1} \\mathbf{b}\\). Applying the formula \\(A^{-1} = C^T / (det A)\\) gives us:</p> \\[ \\mathbf{x} = \\frac{1}{det A} C^T \\mathbf{b} \\] <p><code>Cramer's Rule</code> gives us another way of looking at this question. To derive this rule we break \\(\\mathbf{x}\\) down into its components. Because the i'th component of \\(C^T\\mathbf{b}\\) is a sum of cofactors times some number, it is the determinant of some matrix \\(B_{j}\\).</p> \\[ x_{j} = \\frac{det B_{j}} {det A} \\] <p>where \\(B_{j}\\) is the matrix created by starting with A and then replacing column j with \\(\\mathbf{b}\\), so:</p> \\[ B_{1} = \\begin{bmatrix} \\mathbf{b} &amp; \\text{last n - 1 columns of A} \\end{bmatrix} \\] \\[ B_{n} = \\begin{bmatrix} \\text{first n - 1 columns of A} &amp; \\mathbf{b} \\end{bmatrix} \\] <p>This agrees with our formula \\(x_{1} = \\frac{det B_{1}} {det A}\\). When taking the determinant of \\(B_{1}\\) we get a sum whose first term is \\(b_{1}\\) times the cofactor \\(C_{11}\\) of A.</p> <p>Computing inverses using Cramer's rule is usually less efficient than using elimination.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/20_cramer/#a-volume-of-box","title":"|A| = volume of box","text":"<p>Claim:</p> <p>\\(det A\\) is the volume of the box (parallelepiped) whose edges are  the column vectors of \\(A\\).</p> <p>We could usually well use the row vectors, forming a different box with the same volume.</p> <p>If \\(A = I\\), then the box is a unit cube and its volume is 1. Because this agrees with our claim, we can conclude that the volume obeys determinant property 1.</p> <p>If \\(A = Q\\) is an orthogonal matrix then the box is a unit in a different orientation with volume = \\(det Q = 1\\). Because Q is an orthogonal matrix, \\(Q^TQ = I\\) and so \\(det Q = \\pm 1\\).</p> <p>Swapping two columns of A does not change the volume of the box or (remember that \\(det A = det A^T\\)) the absolute value of the determinant(property 2). If we show that the volume of the box also obeys property 3 we'll have proven \\(|det A|\\) equals the volume of the box.</p> <p></p> <p>If we double the length of one column of \\(A\\), we double the volume of the box formed by its columns. Volume satisfies property 3(a).</p> <p>Property 3(b) says that the determinant is linear in the rows of the matrix:</p> \\[ \\begin{vmatrix} a + a' &amp; b + b' \\\\ c &amp; d \\end{vmatrix} = \\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} + \\begin{vmatrix} a' &amp; b' \\\\ c &amp; d \\end{vmatrix} \\] <p></p> <p>Although it's not needed for our proof, we can also see that determinants obey property 4. If two edges of a box are equal, the box flattens out and has no volume.</p> <p>Important note: If you know the coordinates for the corners of a box, then computing the volume of the box is as easy as calculating a determinant. In particular, the area of a parallelogram with edges \\(\\begin{bmatrix} a \\\\ b \\end{bmatrix}\\) and \\(\\begin{bmatrix} c \\\\ d \\end{bmatrix}\\)  is \\(ad - bc\\). The area of a triangle with edges \\(\\begin{bmatrix} a \\\\ b \\end{bmatrix}\\) and \\(\\begin{bmatrix} c \\\\ d \\end{bmatrix}\\)  is half the area of that parallelogram, or \\(\\frac{1}{2} (ad - bc)\\). The area of a triangle with vertices at \\((x_{1}, y_{1}), (x_{2}, y_{2})\\) and \\((x_{3}, y_{3})\\) is:</p> \\[ \\frac{1}{2} \\begin{vmatrix} x_{1} &amp; y_{1} &amp; 1 \\\\ x_{2} &amp; y_{2} &amp; 1 \\\\ x_{3} &amp; y_{3} &amp; 1 \\\\ \\end{vmatrix} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/","title":"Eigenvalues and Eigenvectors","text":"<p>The subject of eigenvalues and eigenvectors will take up most of the rest of the course. We will again be working with square matrices. Eigenvalues are special numbers associated with a matrix and eigenvectors are special vectors.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#eigenvectors-and-eigenvalues","title":"Eigenvectors and Eigenvalues","text":"<p>A matrix A <code>acts on</code> vectors \\(\\mathbf{x}\\) like a function does, with input \\(\\mathbf{x}\\) and output \\(A\\mathbf{x}\\). <code>Eigenvectors</code> are vectors for which \\(A\\mathbf{x}\\) is parallel to \\(\\mathbf{x}\\). In other words:</p> \\[ A\\mathbf{x} = \\lambda \\mathbf{x} \\] <p>In this equation, \\(\\mathbf{x}\\) is an <code>eigenvector</code> of A and \\(\\lambda\\) is an <code>eigenvalue</code> of A.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#eigenvalue-0","title":"Eigenvalue 0","text":"<p>If the eigenvalue \\(\\lambda\\) equals 0 then \\(A\\mathbf{x} = 0 \\mathbf{x} = \\mathbf{0}\\). Vectors with eigenvalue 0 make up the nullspace of A; if A is singular, then \\(\\lambda = 0\\) is an eigenvalue of A.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#examples","title":"Examples","text":"<p>Suppose P is the matrix of a projection onto a plane. For any \\(\\mathbf{x}\\) in the plane \\(P\\mathbf{x} = \\mathbf{0}\\), so this is an eigenvector with eigenvalue \\(\\lambda = 0\\). The eigenvectors of P span the whole space(but his is not true for every matrix).</p> <p>The matrix \\(B = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\) has an eigenvector \\(\\mathbf{x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) with eigenvalue 1 and another eigenvector \\(\\mathbf{x} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) with eigenvalue -1. These eigenvectors span the space. They are perpendicular because \\(B = B^T\\) (as we will prove).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#deta-lambda-i-0","title":"det(A - \\lambda I) = 0","text":"<p>An n by n matrix will have n eigenvalues, and their sum will be the sum of the diagonal entries of the matrix, if we know one eigenvalue we can use this fact to find the second.</p> <p>Can we solve \\(A\\mathbf{x} = \\lambda \\mathbf{x}\\) for the eigenvalues and eigenvectors of A? Both \\(\\lambda\\) and \\(\\mathbf{x}\\) are unknown; we need to be clever to solve this problem:</p> \\[ \\begin{align} A\\mathbf{x} &amp;= \\lambda \\mathbf{x} \\\\ (A - \\lambda I) \\mathbf{x} &amp;= \\mathbf{0} \\end{align} \\] <p>In order for \\(\\mathbf{x}\\) to be an eigenvector, \\(A - \\lambda I\\) must be singular. In other words, \\(det (A - \\lambda I) = 0\\). We can solve this <code>characteristic equation</code> for \\(\\lambda\\) to get n solutions.</p> <p>If we're lucky, the solutions are distinct. If not, we have one or more <code>repeated eigenvalues</code>.</p> <p>Once we've found an eigenvlaue \\(\\lambda\\), we can use elimination to find the nullspace of \\(A - \\lambda I\\). The vectors in that nullspace are eigenvectors of A with eigenvalue \\(\\lambda\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#calculating-eigenvalues-and-eigenvectors","title":"Calculating Eigenvalues and Eigenvectors","text":"<p>Let \\(A = \\begin{bmatrix} 3 &amp; 1 \\\\ 1 &amp; 3 \\end{bmatrix}\\), then:</p> \\[ \\begin{align} det(A - \\lambda I) &amp; = \\begin{vmatrix} 3 - \\lambda &amp; 1 \\\\ 1 &amp; 3 - \\lambda \\end{vmatrix} \\\\ &amp;= (3 - \\lambda)^2 - 1 \\\\  &amp;= \\lambda^2 - 6\\lambda + 8 \\end{align} \\] <p>Note that the coefficient 6 is the trace (sum of diagonal entries) and 8 is the determinant of A. In general, the eigenvlaues of a 2 by 2 matrix are the solutions to:</p> \\[ \\lambda^2 - trac(A) * \\lambda + det A = 0 \\] <p>Just as the trace is the sum of the eigenvalues of a matrix, the product of the eigenvalues of any matrix equals its determinant.</p> <p>For \\(A = \\begin{bmatrix} 3 &amp; 1 \\\\ 1 &amp; 3 \\end{bmatrix}\\), the eigenvalues are \\(\\lambda_1 = 4\\) and \\(\\lambda_2 = 2\\). We find the eigenvectors \\(\\mathbf{x_1} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) for \\(\\lambda_1 = 4\\) in the nullspace of \\(A - \\lambda_1 I = \\begin{bmatrix} -1 &amp; 1 \\\\ 1 &amp; -1 \\end{bmatrix}\\).</p> <p>\\(\\mathbf{x_2}\\) will be in the nullsapce of \\(A - 2I = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 1 \\end{bmatrix}\\). The nullspace is an entire line; \\(\\mathbf{x_2}\\) could be any vector on that line. A natural choice is \\(\\mathbf{x_2} = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\\).</p> <p>Note that these eigenvectors are the same as those of \\(B = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\). Adding \\(3I\\) to the matrix \\(B = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\) added 3 to each of its eigenvalues and did not change its eigenvectors, because \\(A\\mathbf{x} = (B + 3I)\\mathbf{x} = \\lambda\\mathbf{x} + 3\\mathbf{x} = (\\lambda + 3)\\mathbf{x}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#a-caution","title":"A caution","text":"<p>Similarly, if \\(A\\mathbf{x} = \\lambda\\mathbf{x}\\) and \\(B\\mathbf{x} = \\alpha \\mathbf{x}\\), \\((A + B)\\mathbf{x} = (\\lambda + \\alpha)\\mathbf{x}\\). It would be nice if the eigenvalues of a matrix sum were always the sums of eigenvalues, but this is only true if A and B have the same eigenvalues. The eigenvalues of the product AB aren't usually equal to the products \\(\\lambda(A)\\lambda(B)\\), either.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#complex-eigenvalues","title":"Complex eigenvalues","text":"<p>The matrix \\(Q = \\begin{bmatrix} 0 &amp; -1 \\\\ 1 &amp; 0 \\end{bmatrix}\\) rotates every vector in the plane by \\(90^{\\circ}\\). It has trace \\(0 = \\lambda_{1} + \\lambda_{2}\\) and determinant \\(1 = \\lambda_{1} * \\lambda_{2}\\). Its only real eigenvector is the zero vector; any other vector's direction changes when it is multiplied by Q. How will this affect our eigenvalue calculation?</p> \\[ \\begin{align} det(A - \\lambda I) &amp;= \\begin{vmatrix} - \\lambda &amp; - 1 \\\\ 1 &amp; - \\lambda \\end{vmatrix} \\\\ &amp;= \\lambda^2 + 1 \\end{align} \\] <p>\\(det (A - \\lambda I) = 0\\) has solutions \\(\\lambda_1 = i\\) and \\(\\lambda_2 = -i\\). If a matrix has a complex eigenvalues \\(a + bi\\) then the <code>complex conjugate</code> \\(a - bi\\) is also an eigenvalue of that matrix.</p> <p>Symmetric matrices have real eigenvalues. For <code>antisymmetric</code> matrices like Q, for which \\(A^T = -A\\), all eigenvalues are imaginary \\((\\lambda = bi)\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/21_eigen/#triangular-matrices-and-repeated-eigenvalues","title":"Triangular matrices and repeated eigenvalues","text":"<p>For triangular matrices such as \\(A = \\begin{bmatrix} 3 &amp; 1 \\\\ 0 &amp; 3 \\end{bmatrix}\\), the eigenvalues are exactly the entries on the diagonal. In this case, the eigenvalues are 3 and 3:</p> \\[ \\begin{align} det(A - \\lambda det I) &amp;= \\begin{vmatrix} 3 - \\lambda &amp; 1 \\\\ 0 &amp; 3 - \\lambda \\end{vmatrix} \\\\ &amp;= (3 - \\lambda)(3 - \\lambda) \\\\ &amp;= 0 \\end{align} \\] <p>so \\(\\lambda_{1} = 3\\) and \\(\\lambda_{2} = 3\\). To find the eigenvectors, solve:</p> \\[ (A - \\lambda I) \\mathbf{x} = \\begin{bmatrix} 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix} \\mathbf{x} = \\mathbf{0} \\] <p>to get \\(\\mathbf{x_1} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\). There is no independent eigenvector \\(\\mathbf{x_2}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/","title":"Diagonalization and Powers of A","text":"<p>We know how to find eigenvalues and eigen vectors. In this lecture we learn to <code>diagonalize</code> any matrix that has \\(n\\) independent eigenvectors and see how diagonalization simplifies calculations. The lecture concludes by using eigenvalues and eigenvectors to solve <code>difference equations</code>.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#diagonalizing-a-matrix-s-1aslambda","title":"Diagonalizing a Matrix S^-1AS=Lambda","text":"<p>If A has n linearly <code>independent eigenvectors</code>, we can put those vectors in the columns of a matrix S(square, invertible), then:</p> \\[ \\begin{align} AS &amp;= A \\begin{bmatrix} \\mathbf{x_1} &amp; \\mathbf{x_2} &amp; \\cdots &amp; \\mathbf{x_n} \\end{bmatrix} \\\\    &amp;= \\begin{bmatrix} \\lambda_1 \\mathbf{x_1} &amp; \\lambda_2 \\mathbf{x_2} &amp; \\cdots &amp; \\lambda_n \\mathbf{x_n} \\end{bmatrix} \\\\    &amp;= S \\begin{bmatrix} \\lambda_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\lambda_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\lambda_n \\end{bmatrix} \\\\    &amp;= S\\Lambda \\end{align} \\] <p>Note that \\(\\Lambda\\) is a diagonal matrix whose non-zero entries are the eigenvalues of \\(A\\). Because the columns of \\(S\\) are independent, \\(S^{-1}\\) exists and we can multiply both sides of \\(AS = S \\Lambda\\) by \\(S^{-1}\\):</p> \\[ S^{-1} AS = \\Lambda \\] <p>Equivalently,</p> \\[ A = S \\Lambda S^{-1} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#powers-of-a","title":"Powers of A","text":"<p>What are the eigenvalues and eigenvectors of \\(A^2\\)?</p> \\[ \\begin{align} \\text{If } A\\mathbf{x} &amp;= \\lambda \\mathbf{x} \\\\ \\text{then } A^2 \\mathbf{x} &amp;= \\lambda A \\mathbf{x} = \\lambda^2 \\mathbf{x} \\\\ \\end{align} \\] <p>The eigenvalues of \\(A^2\\) are the squares of the eigenvalues of \\(A\\). The eigenvectors of \\(A^2\\) are the same as the eigenvectors of \\(A\\). If we write \\(A = S \\Lambda S^{-1}\\) then:</p> \\[ A^2 = S \\Lambda S^{-1} S \\Lambda S^{-1} = S \\Lambda^2 S^{-1} \\] <p>Similarly:</p> \\[ A^k = S \\Lambda^k S^{-1} \\] <p>tells us that raising the eigenvalues of \\(A\\) to the kth power gives us the eigenvalues of \\(A^k\\), and that the eigenvectors of \\(A^k\\) are the same as those of A.</p> <p>Theorem:</p> <p>If A has n independent eigenvectors with eigenvalues \\(\\lambda_i\\), then \\(A^{k} \\to 0\\) as \\(k \\to \\infty\\) if and only if all \\(|\\lambda_i| &lt; 1\\).</p> <p>A is guaranteed to have n independent eigenvectors (and be <code>diagonalizable</code>) if all its eigenvalues are different. Most matrices do have distinct eigenvalues.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#repeated-eigenvalues","title":"Repeated Eigenvalues","text":"<p>If A has repeated eigenvalues, it may or may not have n independent eigenvectors. For example, the eigenvalues of the identity matrix are all 1, but that matrix still has n independent eigenvectors.</p> <p>If A is the triangular matrix \\(\\begin{bmatrix} 2 &amp; 1 \\\\ 0 &amp; 2 \\end{bmatrix}\\) its eigenvalues are 2 and 2. Its eigenvectors are in the nullspace of \\(A - \\lambda I = \\begin{bmatrix} 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix}\\) which is spanned by \\(\\mathbf{x} = \\begin{bmatrix} 1 \\\\ 0\\end{bmatrix}\\). This particular A does not have two independent eigenvectors.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#difference-equation-u_k-1-au_k","title":"Difference Equation u_{k + 1} = Au_{k}","text":"<p>Start with a given vector \\(\\mathbf{u_0}\\). We can create a sequence of vectors in which each new vector is A times the previous vector:</p> \\[ \\mathbf{u_{k + 1}} = A \\mathbf{u_{k}}. \\] <p>\\(\\mathbf{u_{k + 1}} = A \\mathbf{u_k}\\) is a <code>first order difference equation</code>, and \\(\\mathbf{u_k} = A^k \\mathbf{u_0}\\) is a solution to this system.</p> <p>We get a more statisfying solution if we write \\(\\mathbf{u_0}\\) as a combination of eigenvectors of A:</p> \\[ \\mathbf{u_0} = c_1 \\mathbf{x_1} + c_2 \\mathbf{x_2} + \\cdots + c_n \\mathbf{x_n} = S \\mathbf{c} \\] <p>Then:</p> \\[ A \\mathbf{u_0} = c_1 \\lambda_1 \\mathbf{x_1} + c_2 \\lambda_2 \\mathbf{x_2} + \\cdots + c_n \\lambda_n \\mathbf{x_n} = \\Lambda S \\mathbf{c} \\] <p>and:</p> \\[ \\mathbf{u_k} = A^k \\mathbf{u_0} = c_1 \\lambda_1^k \\mathbf{x_1} + c_2 \\lambda_2^k \\mathbf{x_2} + \\cdots + c_n \\lambda_n^k \\mathbf{x_n} = \\Lambda^k S \\mathbf{c} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#fibonacci-sequence","title":"Fibonacci Sequence","text":"<p>The Fibonacci sequence is \\(0, 1, 1, 2, 3, 5, 8, 13, \\cdots\\). In general, \\(F_{k + 2} = F_{k + 1} + F_{k}\\). If we could understand this in terms of matrices, the eigenvalues of the matrices would tell us how fast the numbers in the sequence are increasing.</p> <p>\\(\\mathbf{u_{k + 1}} = A \\mathbf{u_{k}}\\) was a first order system. \\(F_{k + 2} = F_{k + 1} + F_{k}\\) is a <code>second order scalar equation</code>, but we can convert it to first order linear system by using a clever trick.</p> <p>If \\(\\mathbf{u_k} = \\begin{bmatrix} F_{k + 1} \\\\ F_{k}\\end{bmatrix}\\), then:</p> \\[ \\begin{align} F_{k + 2} &amp;= F_{k + 1} + F_{k} \\\\ F_{k + 1} &amp;= F_{k + 1} \\end{align} \\] <p>is equivalent to the first order system \\(\\mathbf{u_{k + 1}} = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} \\mathbf{u_{k}}\\).</p> <p>What are the eigenvalues and eigenvectors of \\(A = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\)? Because A is systemmetric, its eigenvalues will be real and its eigenvectors will be orthogonal.</p> <p>Because A is a 2 by 2 matrix we know its eigenvalues sum to 1(the trace), and their product is \\(-1\\)(the determinant).</p> \\[ \\begin{vmatrix} A - \\lambda I \\end{vmatrix} = \\begin{vmatrix} 1 - \\lambda &amp; 1 \\\\ 1 &amp; -\\lambda \\\\ \\end{vmatrix} = \\lambda^2 - \\lambda - 1 \\] <p>Setting this to zero we find \\(\\lambda = \\frac{1 \\pm \\sqrt{1 + 4}}{2}\\); i.e. \\(\\lambda_1 = \\frac{1}{2} (1 + \\sqrt{5}) \\approx 1.618\\) and \\(\\lambda_2 = \\frac{1}{2} (1 - \\sqrt{5}) \\approx -0.618\\). The growth rate of the \\(F_k\\) is controlled by \\(\\lambda_1\\), the only eigenvalue with absolute value greater than 1. This tells us that for large k, \\(F_{k} \\approx c_1(\\frac{1 + \\sqrt{5}}{2})^k\\) for some constant \\(c_1\\). (Remember \\(\\mathbf{u_k} = A^k \\mathbf{u_0} = c_1 \\lambda_1^k x_1 + c_2 \\lambda_2^k x_2\\), and here \\(\\lambda_2^k\\) goes to zero since \\(|\\lambda_2| &lt; 1\\))</p> <p>To find the eigenvectors of A note that:</p> \\[ (A - \\lambda I) \\mathbf{x} = \\begin{bmatrix} 1 - \\lambda &amp; 1 \\\\ 1 &amp; -\\lambda \\end{bmatrix} \\mathbf{x} = 0 \\] <p>when \\(\\mathbf{x} = \\begin{bmatrix} \\lambda \\\\ 1 \\end{bmatrix}\\), so \\(\\mathbf{x_1} = \\begin{bmatrix} \\lambda_1 \\\\ 1 \\end{bmatrix}\\) and \\(\\mathbf{x_2} = \\begin{bmatrix} \\lambda_2 \\\\ 1 \\end{bmatrix}\\).</p> <p>Finally, \\(\\mathbf{u_0} = \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = c_1 \\mathbf{x_1} + c_2 \\mathbf{x_2}\\) tells us that \\(c_1 = -c_2 = \\frac{1}{5}\\).</p> <p>Because \\(\\begin{bmatrix} F_{k + 1} \\\\ F_{k} \\end{bmatrix} = \\mathbf{u_k} = c_1 \\lambda_1^k x_1 + c_2 \\lambda_2^k x_2\\), we get:</p> \\[ F_k = \\frac{1}{\\sqrt{5}}(\\frac{1 + \\sqrt{5}}{2})^k - \\frac{1}{\\sqrt{5}}(\\frac{1 - \\sqrt{5}}{2})^k \\] <p>Using eigenvalues and eigenvectors, we have found a <code>closed form expression</code> for the Fibonacci numbers.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/22_diag_a/#summary","title":"Summary","text":"<p>When a sequence evolves over time according to the rules of a <code>first order system</code>, the eigenvalues of the matrix of that system determine the long term behavior of the series. To get an exact formula for the series we find the eigenvectors of the matrix and then solve for the coefficient \\(c_1, c_2, \\cdots\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/","title":"Differential Equations and e^At","text":"<p>The system of equations below describes how the values of variables \\(u_{1}\\) and \\(u_{2}\\) affect each other over time:</p> \\[ \\begin{align} \\frac{du_{1}}{dt} = -u_{1} + 2 u_{2} \\\\ \\frac{du_{2}}{dt} = u_{1} - 2 u_{2} \\\\ \\end{align} \\] <p>Just as we applied linear algebra to solve a difference equation, we can use it to solve this differential equation. For example, the initial condition \\(u_{1} = 1\\), \\(u_{2} = 0\\) can be written \\(\\mathbf{u}(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/#differential-equation-dudt-au","title":"Differential Equation du/dt = Au","text":"<p>By looking at the equations above, we might guess that over time \\(u_{1}\\) will decrease. We can get the same sort of information more safely by looking at the eigenvalues of the matrix \\(A = \\begin{bmatrix} -1 &amp; 2 \\\\ 1 &amp; -2 \\end{bmatrix}\\) of our system \\(\\frac{d\\mathbf{u}}{dt} = A \\mathbf{u}\\). Because A is singular and its trace is -3, we know that its eigenvalues are \\(\\lambda_1 = 0\\) and \\(\\lambda_2 = -3\\). The solution will turn out to include \\(e^{-3t}\\) and \\(e^{0t}\\). As t increases, \\(e^{-3t}\\) vanishes and \\(e^{0t} = 1\\) remains constant. Eigenvalues equal to zero have eigenvectors that are <code>steady state</code> solutions.</p> <p>\\(\\mathbf{x_1} = \\begin{bmatrix} 2 \\\\ 1\\end{bmatrix}\\) is an eigenvectors for which \\(A\\mathbf{x_1} = 0 \\mathbf{x_1}\\). To find an eigenvector corresponding to \\(\\lambda_2 = -3\\) we solve \\((A - \\lambda_2 I) \\mathbf{x_2} = \\mathbf{0}\\):</p> \\[ \\begin{align} \\begin{bmatrix} 2 &amp; 2 \\\\ 1 &amp; 1 \\end{bmatrix} \\mathbf{x_2} = 0 \\\\ so \\\\ \\mathbf{x_2} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\\\ \\end{align} \\] <p>and we can check that \\(A\\mathbf{x_2} = -3 \\mathbf{x_2}\\). The general solution to this system of differential equations will be:</p> \\[ \\mathbf{u}(t) = c_1 e^{\\lambda_1 t} \\mathbf{x_1} + c_2 e^{\\lambda_2 t} \\mathbf{x_2} \\] <p>Is \\(e^{\\lambda_1 t} \\mathbf{x_1}\\) really a solution to \\(\\frac{d\\mathbf{u}}{dt} = A\\mathbf{u}\\)? To find out, plug in \\(\\mathbf{u} = e^{\\lambda_1 t} \\mathbf{x_1}\\):</p> \\[ \\frac{d\\mathbf{u}}{dt} = \\lambda_1 e^{\\lambda_1 t} \\mathbf{x_1} \\] <p>which agrees with:</p> \\[ A\\mathbf{u} = e^{\\lambda_1 t} A \\mathbf{x_1} = \\lambda_1 e^{\\lambda_1 t} \\mathbf{x_1} \\] <p>The two \"pure\" terms \\(e^{\\lambda_1 t}\\mathbf{x_1}\\) and \\(e^{\\lambda_2 t} \\mathbf{x_2}\\) are analogous to the terms \\(\\lambda_i^k \\mathbf{x_i}\\) we saw in the solution \\(c_1 \\lambda_1^k \\mathbf{x_1} + c_2 \\lambda_2^k \\mathbf{x_2} + \\cdots + c_n \\lambda_n^k \\mathbf{x_n}\\) to the difference equation \\(\\mathbf{u_{k = 1}} = A \\mathbf{u_k}\\).</p> <p>Plugging in the values of the eigenvectors, we get:</p> \\[ \\mathbf{u}(t) = c_1 e^{\\lambda_1 t} \\mathbf{x_1} + c_2 e^{\\lambda_2 t} \\mathbf{x_2} = c_1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + c_2 e^{-3t} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\] <p>We know \\(\\mathbf{u}(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\), so at \\(t = 0\\):</p> \\[ \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = c_1\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + c_2 \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}. \\] <p>\\(c_1 = c_2 = 1/3\\) and \\(\\mathbf{u}(t) = \\frac{1}{3} \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + \\frac{1}{3} e^{-3t} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) </p> <p>This tells us that the system starts with \\(u_1 = 1\\) and \\(u_2 = 0\\) but that as \\(t\\) approaches infinitely, \\(u_1\\) decays to \\(2/3\\) and \\(u_2\\) increases to \\(1/3\\). This might describe stuff moving from \\(u_1\\) to \\(u_2\\).</p> <p>The steady state of this system is \\(\\mathbf{u}(\\infty) = \\begin{bmatrix} 2/3 \\\\ 1/3\\end{bmatrix}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/#stability","title":"Stability","text":"<p>Not all systems have a steady state. The eigenvalues of A will tell us what sort of solutions to expect:</p> <ol> <li>Stability: \\(\\mathbf{u}(t) \\to 0\\) when \\(Re(\\lambda) &lt; 0\\).</li> <li>Steady state: One eigenvalue is 0 and all other eigenvalues have negtive real part.</li> <li>Blow up: if \\(Re(\\lambda) &gt; 0\\) for any eigenvalues \\(\\lambda\\).</li> </ol> <p>If 2 by 2 matrix \\(A = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix}\\) has two eigenvalues with negative real part, its trace \\(a + d\\) is negative, the converse is not true: \\(\\begin{bmatrix} -2 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}\\) has negative trace but one of its eigenvalues is 1 and \\(e^{1t}\\) blows up. If A has a positive determinant and negative trace then the corresponding solutions must be stable.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/#applying-s","title":"Applying S","text":"<p>The final step of our solution to the system \\(\\frac{d\\mathbf{u}}{dt} = A \\mathbf{u}\\) was to solve:</p> \\[ c_1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + c_2 \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\] <p>In matrix form:</p> \\[ \\begin{bmatrix} 2 &amp; 1 \\\\ 1 &amp; -1 \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\] <p>or \\(S\\mathbf{c} = \\mathbf{u}(0)\\), where S is the eigenvector matrix. The components of \\(\\mathbf{c}\\) determine the contribution from each pure exponential solution, based on the initial conditions of the system.</p> <p>In the equation \\(\\frac{d\\mathbf{u}}{dt} = A\\mathbf{u}\\), the matrix A couples the pure solutions. We set \\(\\mathbf{u} = S \\mathbf{v}\\), where S is the matrix of eigenvectors of A, to get:</p> \\[ S\\frac{d\\mathbf{v}}{dt} = AS\\mathbf{v} \\] <p>or:</p> \\[ \\frac{d\\mathbf{v}}{dt} = S^{-1} AS \\mathbf{v} = \\Lambda \\mathbf{v} \\] <p>This diagonalizes the system: \\(\\frac{dv_i}{dt} = \\lambda_i v_i\\). The general solution is then:</p> \\[ \\begin{align} \\mathbf{v}(t) &amp;= e^{\\Lambda t}\\mathbf{v}(0) \\\\ \\mathbf{u}(t) &amp;= Se^{\\Lambda t}S^{-1} \\mathbf{v}(0) = e^{At} \\mathbf{u}(0) \\end{align} \\]"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/#matrix-exponential-eat","title":"Matrix Exponential e^At","text":"<p>What does \\(e^{At}\\) mean  if A is a matrix? We know that for a real number x:</p> \\[ e^x = \\sum_{n = 0}^{\\infty} \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\cdots \\] <p>We can use the same formula to define \\(e^{At}\\):</p> \\[ e^{At} = I + At + \\frac{(At)^2}{2} + \\frac{(At)^3}{6} + \\cdots \\] <p>Similarly, if the eigenvalues of \\(At\\) are small, we can use the geometric series \\(\\frac{1}{1 - x} = \\sum_{n = 0}^{\\infty} x^n\\) to estimate \\((I - At)^{-1} = I + At + (At)^2 + (At)^3 + \\cdots\\)</p> <p>We've said that \\(e^{At} = Se^{\\Lambda t} S^{-1}\\). If A has n independent eigenvectors we can prove this from the definition of \\(e^{At}\\) by using the formula \\(A = S \\Lambda S^{-1}\\):</p> \\[ \\begin{align} e^{At} = &amp; I + At + \\frac{(At)^2}{2} + \\frac{(At)^3}{6} + \\cdots  \\\\ &amp;= SS^{-1} + S\\Lambda S^{-1} t + \\frac{S \\Lambda^2S^{-1}}{2}t^2 + \\frac{S \\Lambda^3S^{-1}}{6}t^3 + \\cdots \\\\ &amp;= S e^{\\Lambda t} S^{-1} \\end{align} \\] <p>It's impractical to add up infinitely many matrices. Fortunately, there is an easier way to comput \\(e^{\\Lambda t}\\). Remember that:</p> \\[ \\Lambda = \\begin{bmatrix} \\lambda_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\lambda_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; \\lambda_n \\\\ \\end{bmatrix} \\] <p>When we plug this in to our formula for \\(e^{At}\\) we find that:</p> \\[ e^{\\Lambda t} =  \\begin{bmatrix} e^{\\lambda_1 t} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; e^{\\lambda_2 t} \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; e^{\\lambda_n t}\\\\ \\end{bmatrix} \\] <p>This is another way to see the relationship between the stability of \\(\\mathbf{u}(t) = S e^{\\Lambda t} S^{-1} \\mathbf{v}(0)\\) and the eigenvalues of A.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/23_diff_exp/#second-order","title":"Second order","text":"<p>We can change the second order equation \\(y'' + b y' + ky = 0\\) into a 2 by 2 first order system using a method similar to the one we used to find a formula for the Fibonacci numbers. If \\(u = \\begin{bmatrix} y' \\\\ y \\end{bmatrix}\\), then:</p> \\[ u' = \\begin{bmatrix} y'' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} -b &amp; -k \\\\ 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} y' \\\\ y \\end{bmatrix} \\] <p>We could use the methods we just learned to solve this system, and that would give us a solution to the second order scalar equation we started with.</p> <p>If we start with a kth order equation we get a k by k matrix with coefficients of the equation in the first row and 1's on a diagonal below that; the rest of the entries are 0.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/","title":"Markov Matrices and Fourier Series","text":"<p>In this lecture we look at Markov matrices and Fourier series-two applications of eigenvalues and projections.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/#eigenvalues-of-at","title":"Eigenvalues of A^T","text":"<p>The eigenvalues of A and the eigenvalues of \\(A^T\\) are the same:</p> \\[ (A - \\lambda I)^T = A^T - \\lambda I \\] <p>So property 10 of determinants tells us that \\(det(A - \\lambda I) = det(A^T - \\lambda I)\\). If \\(\\lambda\\) is an eigenvalue of A then \\(det (A^T - \\lambda I) = 0\\) and \\(\\lambda\\) is an eigenvalue of \\(A^T\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/#markov-matrices","title":"Markov Matrices","text":"<p>A matrix like:</p> \\[ A = \\begin{bmatrix} 0.1 &amp; 0.01 &amp; 0.3 \\\\ 0.2 &amp; 0.99 &amp; 0.3 \\\\ 0.7 &amp; 0 &amp; 0.4 \\\\ \\end{bmatrix} \\] <p>in which all entries are non-negative and each column adds to 1 is called a <code>Markov Matrix</code>. These requirements come from Markov matrices' use in probability. Squaring or raising a Markov matrix to a power gives us another Markov matrix.</p> <p>When dealing with systems of differential equations, eigenvectors with the eigenvalue of 0 represented steady states. Here we're dealing with powers of matrices and get a steady state when \\(\\lambda = 1\\) is an eigenvalue.</p> <p>The constraint that the columns add to 1 guarantees that 1 is an eigenvalue. All other eigenvalues will be less than 1. Remember that (if A has n independent eigenvectors) the solution to \\(\\mathbf{u_k} = A^k \\mathbf{u_0}\\) is \\(\\mathbf{u_k} = c_1 \\lambda_1^k \\mathbf{x_1} + c_2 \\lambda_2^k \\mathbf{x_2} + \\cdots + c_n \\lambda_n^k \\mathbf{x_n}\\). If \\(\\lambda_1 = 1\\) and all others eigenvalues are less than one the system approaches the steady state \\(c_1\\mathbf{x_1}\\). This is the \\(\\mathbf{x_1}\\) component of \\(\\mathbf{u_0}\\).</p> <p>Why does the fact that the columns sum to 1 guarantee that 1 is an eigenvalue? If 1 is an eigenvalue of A, then:</p> \\[ A - 1I = \\begin{bmatrix} -0.9 &amp; 0.01 &amp; 0.03 \\\\ 0.2 &amp; -0.01 &amp; 0.03 \\\\ 0.7 &amp; 0 &amp; -0.6 \\\\ \\end{bmatrix} \\] <p>should be singular. Since we've substracted 1 from each diagonal entry, the sum of the entries in each column of \\(A - I\\) is 0. But then the sum of the rows of \\(A - I\\) must be the zero row, and so \\(A - I\\) is singular. The eigenvector \\(\\mathbf{x_1}\\) is in the nullspace of \\(A - I\\) and has eigenvalue 1. It's not very hard to find \\(\\mathbf{x_1} = \\begin{bmatrix} 0.6 \\\\ 33 \\\\ 0.7 \\end{bmatrix}\\).</p> <p>We're studying the equation \\(\\mathbf{u_{k + 1}} = A\\mathbf{u_k}\\)  where A is a Markov matrix. For example, \\(u_1\\) might be the population of (number of people in) Massachusetts and \\(u_2\\) might be the population of California. A might describe what fraction of the population moves from state to state, or the probability of a single person moving. We can't have negative numbers of people, so the entries of A will always be positive. We want to account for all the people in our model, so the columns of A add to \\(1 = 100%\\).</p> <p>For example:</p> \\[ \\begin{bmatrix} u_{Cal} \\\\ u_{Mass} \\end{bmatrix}_ {t = k + 1} = \\begin{bmatrix} 0.9 &amp; 0.2 \\\\ 0.1 &amp; 0.8 \\end{bmatrix} \\begin{bmatrix} u_{Cal} \\\\ u_{Mass}\\end{bmatrix}_ {t = k} \\] <p>assumes that there's a 90% chance that a person in California will stay in California and only a 10% chance that she or he will move, while there's a 20% percent chance that a Massachusetts resident will move to California. If our initial conditions are \\(\\begin{bmatrix} u_{Cal} \\\\ u_{Mass}\\end{bmatrix}_ {0} = \\begin{bmatrix} 0 \\\\ 1000 \\end{bmatrix}\\), then after one move \\(\\mathbf{u_1} = A \\mathbf{u_0}\\) is:</p> \\[ \\begin{bmatrix} u_{Cal} \\\\ u_{Mass} \\end{bmatrix}_ {1} = \\begin{bmatrix} 0.9 &amp; 0.2 \\\\ 0.1 &amp; 0.8 \\end{bmatrix} \\begin{bmatrix} 200 \\\\ 800 \\end{bmatrix} \\] <p>For the next few values of k, the Massachusetts population will decrease and the California population will increase while the total population remains constant at 1000.</p> <p>To understand the long term behavior of this system we'll need the eigenvectors and eigenvalues of \\(\\begin{bmatrix} 0.9 &amp; 0.2 \\\\ 0.1 &amp; 0.8\\end{bmatrix}\\). We know that one eigenvalue is \\(\\lambda_1 = 1\\). Because the trace \\(0.9 + 0.8 = 1.7\\) is the sum of the eigenvalues, we see that \\(\\lambda_2 = 0.7\\).</p> <p>Next we calculate the eigenvectors:</p> \\[ A - \\lambda_1 I = \\begin{bmatrix} -0.1 &amp; 0.2 \\\\ 0.2 &amp; -0.2\\end{bmatrix} \\mathbf{x_1} = \\mathbf{0} \\] <p>So we choose \\(\\mathbf{x_1} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\). The eigenvalue 1 corresponds to the steady state solution, and \\(\\lambda_2 = 0.7 &lt; 1\\), so the system approches a limit in which \\(2/3\\) of 1000 people live in California and 1/ 3 of 1000 people are in Massachusetts. This will be the limit from any starting vector \\(\\mathbf{u_0}\\).</p> <p>To know how the population is distributed after a finite number of steps we look for an eigenvector corresponding to \\(\\lambda_2 = 0.7\\):</p> \\[ A - \\lambda_2 I = \\begin{bmatrix} 0.2 &amp; 0.2 \\\\ 0.1 &amp; 0.1 \\end{bmatrix} \\mathbf{x_1} = \\mathbf{0} \\] <p>so let \\(\\mathbf{x_2} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\).</p> <p>From what we learned about difference equations we know that:</p> \\[ \\mathbf{u_k} = c_1 1^k \\begin{bmatrix} 2 \\\\ 1\\end{bmatrix} + c_2 (0.7)^k \\begin{bmatrix} -1 \\\\ 1\\end{bmatrix}. \\] <p>When \\(k = 0\\) we have:</p> \\[ \\mathbf{u_0} = \\begin{bmatrix} 0 \\\\ 1000 \\end{bmatrix} = c_1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + c_2 \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}  \\] <p>so \\(c_1 = \\frac{1000}{3}\\) and \\(c_2 = \\frac{2000}{3}\\).</p> <p>In some applications Markov matrices are defined differently - their rows add to 1 rather than their columns. In this case, the calculations are the transpose of everything we've done here.</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/#fourier-series-and-projections","title":"Fourier Series and Projections","text":""},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/#expansion-with-an-orthonormal-basis","title":"Expansion with an orthonormal basis","text":"<p>If we have an orthonormal basis \\(\\mathbf{q_1}, \\mathbf{q_2}, \\cdots, \\mathbf{q_n}\\) then we can write any vector \\(\\mathbf{v}\\) as:</p> \\[ \\mathbf{v} = x_1 \\mathbf{q}_ 1 + x_2 \\mathbf{q}_ 2 + \\cdots + x_n \\mathbf{q}_ n  \\] <p>where:</p> \\[ \\mathbf{q}_ i ^T \\mathbf{v} = x_1 \\mathbf{q}_ i ^T \\mathbf{q}_ 1 + x_2 \\mathbf{q}_ i ^T \\mathbf{q}_ 2 + \\cdots + x_n \\mathbf{q}_ i ^T \\mathbf{q}_ n = x_i \\] <p>Since \\(\\mathbf{q}_ i ^T \\mathbf{q}_ j = 0\\) unless \\(i = j\\), this equation gives \\(x_i = \\mathbf{q}_ i^T \\mathbf{v}\\) in terms of matrices, \\([\\mathbf{q}_ 1  \\cdots  \\mathbf{q}_ n] \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\mathbf{v}\\), or \\(Q \\mathbf{x} = \\mathbf{v}\\). So \\(\\mathbf{x} = Q^{-1}\\mathbf{v}\\). Because the \\(q_i\\) from an orthonormal basis, \\(Q^{-1} = Q^{T}\\) and \\(\\mathbf{x} = Q^T \\mathbf{v}\\). This is another way to see that \\(x_i = \\mathbf{q}_ i ^T \\mathbf{v}\\).</p>"},{"location":"Math/Linear-Algebra/Least-Squares-Determinants-and-Eigenvalues/24_markov/#frourier-series","title":"Frourier series","text":"<p>The key idea above was that the basis of vector \\(\\mathbf{q}_ i\\) was orthonormal. Fourier series are built on this idea. We can describe a function \\(f(x)\\) in terms of trigonometric functions:</p> \\[ f(x) = a_0 + a_1 \\cos x + b_1 \\sin x + a_2 \\cos 2x + b_2 \\sin 2x + \\cdots \\] <p>This is <code>Fourier series</code> is an infinite sum and the previous example was finite, but the two are related by the fact that the cosines and sines in the Fourier series are orthogonal.</p> <p>We're now working in an infinite dimensional vector space. The vectors in this space are functions and the (orthogonal) basis vectors are \\(1, \\cos x, \\sin x, \\cos 2x, \\sin 2x, \\cdots\\)</p> <p>What does \"orthogonal\" mean in this context? How do we compute a dot product or <code>inner product</code> in this vector space? For vectors in \\(\\mathbb{R}^n\\) the inner product is \\(\\mathbf{v}^T \\mathbf{w} = v_1 w_1 + v_2 w_2 + \\cdots + v_n w_n\\). Functions are described by a continum of values \\(f(x)\\) rather than by a discrete collection of components \\(v_i\\). The best parallel to the vector dot product is:</p> \\[ f^Tg = \\int_0^{2\\pi} f(x)g(x) dx \\] <p>We integrate from 0 to \\(2\\pi\\) because Fourier series are periodic:</p> \\[ f(x) = f(x + 2\\pi) \\] <p>The inner product of two basis vectors is 0, as desired. For example,</p> \\[ \\int_0 ^{2\\pi} \\sin x \\cos x dx = \\frac{1}{2} (\\sin x)^2 |_ {0} ^{2\\pi} = 0 \\] <p>How do we find \\(a_0, a_1\\), etc. to find the coordinates or <code>Fourier coefficients</code> of a function in this space? The constant term \\(a_0\\) is the average value of the function. Because we're working with an orthonormal basis, we can use the inner product to find the coefficients \\(a_i\\).</p> \\[ \\begin{align} \\int_{0}^{2\\pi} = f(x) \\cos x dx &amp;= \\int_0 ^{2\\pi} (a_0 + a_1 \\cos x + b_1 \\sin x + a_2 \\cos 2x + \\cdots) \\cos x dx \\\\ &amp; = 0 + \\int_0^{2\\pi} a_1 \\cos^2 xdx + 0 + 0 + \\cdots \\\\ &amp; = a_1 \\pi \\end{align} \\] <p>We conclude that \\(a_1 = \\frac{1}{\\pi} \\int_0^{2\\pi} f(x) \\cos x dx\\). We can use the same technique to find any of the value \\(a_i\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/","title":"Symmetric Matrices and Positive definiteness","text":"<p>Symmetric metrices are good, their eigenvalues are real and each has a complete set of orthonormal eigenvectors. Positive definite matrices are even better.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/#symmetric-matrices","title":"Symmetric Matrices","text":"<p>A <code>symmetric matrices</code> is one for which \\(A = A^T\\). If a matrix has some special property (e.g. it's a Markov matrix), its eigenvalues and eigenvectors are likely to have special properties as well. For a symmetric matrix with real number entries, the  eigenvalues are real numbers and it's possible to choose a complete set of eigenvectors that are perpendicular (or even orthonormal).</p> <p>If A has n independent eigenvectors we dan write \\(A = S \\Lambda S^{-1}\\). If A is symmetric we can write \\(A = Q \\Lambda Q^{-1} = Q \\Lambda Q^T\\), where Q is an orthogonal matrix. Mathematicians call this the <code>spectral theorem</code> and think of the eigenvalues are the <code>spectrum</code> of the matrix. In mechanics it's called the <code>principal axis theorem</code>.</p> <p>In addition, any matrix of the form \\(Q \\Lambda Q^T\\) will be symmetric.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/#real-eigenvalues","title":"Real Eigenvalues","text":"<p>Why are the eigenvalues of symmetric matrix real? Suppose A is sysmmetric and \\(A\\mathbf{x} = \\lambda \\mathbf{x}\\). Then we can conjugate to get \\(\\bar{A}\\bar{\\mathbf{x}} = \\bar{\\lambda} \\bar{\\mathbf{x}}\\). If the entries of A are real, this becomes \\(A \\bar{\\mathbf{x}} = \\bar{\\lambda} \\bar{\\mathbf{x}}\\). (This proves that complex eigenvalues of real valued matrices come in conjugate pairs.)</p> <p>Now transpose to get \\(\\bar{\\mathbf{x}}^T A^T = \\bar{\\mathbf{x}}^T \\bar{\\lambda}\\). Because A is symmetric we now have \\(\\bar{\\mathbf{x}}^T A = \\bar{\\mathbf{x}}^T \\bar{\\lambda}\\). Multiplying both sides of this equation on the right by \\(\\mathbf{x}\\) gives:</p> \\[ \\bar{\\mathbf{x}}^T A \\mathbf{x} = \\bar{\\mathbf{x}}^T \\bar{\\lambda} \\mathbf{x} \\] <p>On the other hand, we can multiply \\(A\\mathbf{x} = \\lambda \\mathbf{x}\\) on the left by \\(\\bar{\\mathbf{x}}^T\\) to get:</p> \\[ \\bar{\\mathbf{x}}^T A \\mathbf{x} = \\bar{\\mathbf{x}}^T \\lambda \\mathbf{x} \\] <p>Comparing the two equations we see that \\(\\bar{\\mathbf{x}}^T \\bar{\\lambda} \\mathbf{x} = \\bar{\\mathbf{x}}^T \\lambda \\mathbf{x}\\) and, unless \\(\\bar{\\mathbf{x}}^T \\mathbf{x}\\) is zero, we can conclude \\(\\lambda = \\bar{\\lambda}\\) is real.</p> <p>How do we know \\(\\bar{\\mathbf{x}}^T\\mathbf{x} \\ne 0\\)?</p> \\[ \\bar{\\mathbf{x}}^T \\mathbf{x} = \\begin{bmatrix} \\bar{x_1} &amp; \\bar{x_2} &amp; \\cdots &amp; \\bar{x_N} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = |x_1|^2 + |x_2|^2 + \\cdots + |x_n|^2 \\] <p>If \\(\\mathbf{x} \\ne 0\\) then \\(\\bar{\\mathbf{x}}^T \\mathbf{x} \\ne 0\\).</p> <p>With complex vectors, as with complex numbers, multiplying by the conjugate is often helpful.</p> <p>Symmetric matrices with real entries have \\(A = A^T\\), real eigenvalues, and perpendicular eigenvectors. If A has complex entries, then it will have real eigenvalues and perpendicular eigenvectors if and only if \\(A = \\bar{A}^T\\). (The proof of this follows the same pattern.)</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/#projection-onto-eigenvectors","title":"Projection onto Eigenvectors","text":"<p>If \\(A = A^T\\), we can write:</p> \\[ \\begin{align} A &amp;= Q \\Lambda Q^T \\\\   &amp;= \\begin{bmatrix} \\mathbf{q}_ 1 &amp; \\mathbf{q}_ 2 &amp; \\cdots &amp; \\mathbf{q}_ n \\end{bmatrix} \\begin{bmatrix} \\lambda_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\lambda_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\lambda_n \\end{bmatrix} \\begin{bmatrix} \\mathbf{q}_ 1^T \\\\ \\mathbf{q}_ 2^T \\\\ \\vdots \\\\ \\mathbf{q}_ n ^T\\end{bmatrix}   &amp;= \\lambda_1 \\mathbf{q}_ 1 \\mathbf{q}_ 1^T + \\lambda_2 \\mathbf{q}_ 2 \\mathbf{q}_ 2^T + \\cdots + \\lambda_n \\mathbf{q}_ n \\mathbf{q}_ n^T \\end{align} \\] <p>The matrix \\(\\mathbf{q}_ k \\mathbf{q}_ k^T\\) is the projection matrix onto \\(\\mathbf{q}_ k\\), so every symmetric matrix is a combination of perpendicular projection matrices.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/#information-about-eigenvalues","title":"Information about Eigenvalues","text":"<p>If we know that eigenvalues are real, we can ask whether they are positive or negative. (Remember that the signs of the eigenvalues are important in solving systems of differential equations).</p> <p>For every large matrices A, it's impractical to compute eigenvalues by solving \\(|A - \\lambda I| = 0\\). However, it's not hard to compute the pivots, and the signs of the pivots of a symmetric matrix are the same as the signs of the eigenvalues:</p> \\[ \\text{number of positive pivots} = \\text{number of positive eigenvalues} \\] <p>Because the eigenvalues of \\(A + bI\\) are just b more than the eigenvalues of A, we can use this fact to find which eigenvalues of a symmetric matrix are greater or less than any real number b. This tells us a lot about the eigenvalues of A even if we can't compute them directly.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/01_pos_def/#positive-definite-matrices","title":"Positive Definite Matrices","text":"<p>A <code>positive definite matrix</code> is a symmetric matrix A for which all eigenvalues are positive. A good way to tell if a matrix is positive definite is to check that all its pivots are positive.</p> <p>Let:</p> \\[ A = \\begin{bmatrix} 5 &amp; 2 \\\\ 2 &amp; 3 \\end{bmatrix} \\] <p>The pivots of this matrix are \\(5\\) and \\((det A) / 5 = 11 / 5\\). The matrix is symmetric and its pivots (and therefore eigenvalues) are positive, so A is a positive definite matrix. Its eigenvalues are the solution to:</p> \\[ |A - \\lambda I| = \\lambda^2 - 8\\lambda + 11 = 0 \\] <p>i.e. \\(4 \\pm \\sqrt{5}\\).</p> <p>The determinant of a positive definite matrix is always positive but the determinant of \\(\\begin{bmatrix} -1 &amp; 0 \\\\ 0 &amp; -3 \\end{bmatrix}\\) is also positive, and that matrix isn't positive definite. If all of the subdeterminants of A are positive (determinants of the k by k matrix in the upper left corner of A, where \\(1 \\le k \\le n\\)), then A is positive definite.</p> <p>The subject of positive definite matrices brings together what we've learned about pivots, determinants and eigenvalues of square matrices. Soon we'll have a chance to bring together what we've learned in this course and apply it to non-square matrices.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/","title":"Complex Matrices and Fast Fourier Transform","text":"<p>Matrices with all real entries can have complex eigenvalues! So we can't avoid working with complex numbers. In this lecture we learn to work with complex vectors and matrices.</p> <p>The most important complex matrix is the Fourier matrix \\(F_n\\), which is used for Fourier transforms. Normally, multiplication by \\(F_n\\) would require \\(n^2\\) multiplications. The fast Fourier Transform(FFT) reduces this to roughly \\(n logn\\) multiplications, a revolutionary improvement.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#complex-vectors","title":"Complex Vectors","text":""},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#length","title":"Length","text":"<p>Given a vector:</p> \\[ \\mathbf{z} = \\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_n \\\\ \\end{bmatrix} \\in \\mathbb{C}^n \\] <p>with complex entries, how do we find its length? Our old definition:</p> \\[ \\mathbf{z}^T \\mathbf{z} = \\begin{bmatrix} z_1 &amp; z_2 &amp; \\cdots &amp; z_n \\end{bmatrix} \\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_n \\\\ \\end{bmatrix} \\] <p>is no good; this quantity isn't always positive. For example:</p> \\[ \\begin{bmatrix} 1  &amp; i \\end{bmatrix} \\begin{bmatrix} 1 \\\\ i\\end{bmatrix} = 0 \\] <p>We don't want to define the length of \\(\\begin{bmatrix} 1 \\\\ i \\end{bmatrix}\\) to be 0. The correct definition is:</p> \\[ |\\mathbf{z}|^2 = \\bar{\\mathbf{z}}^T \\mathbf{z} = |z_1|^2 + |z_2|^2 + \\cdots + |z_n|^2 \\] <p>Then we have:</p> \\[ (length \\begin{bmatrix}1 \\\\ i \\end{bmatrix})^2 = \\begin{bmatrix}1 &amp; -i \\end{bmatrix} \\begin{bmatrix}1 \\\\ i\\end{bmatrix} = 2 \\] <p>To simplify our notation we write \\(|\\mathbf{z}|^2 = \\mathbf{z}^H\\mathbf{z}\\), where \\(\\mathbf{z}^H = \\bar{\\mathbf{z}}^T\\). The H comes from the name Hermite, and \\(\\mathbf{z}^H\\mathbf{z}\\) is read \"z Hermitian z\".</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#inner-product","title":"Inner Product","text":"<p>Similarly, the inner or dot product of two complex vectors is not just \\(\\mathbf{y}^T\\mathbf{x}\\). We must also take the complex conjugate of \\(\\mathbf{y}\\):</p> \\[ \\mathbf{y}^H \\mathbf{x} =  \\bar{\\mathbf{y}}^T \\mathbf{x} = \\bar{y}_ 1 x_1 + \\bar{y}_ 2 x_2 + \\cdots + \\bar{y}_ n x_n \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#complex-matrices","title":"Complex Matrices","text":""},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#hermitian-matrices","title":"Hermitian Matrices","text":"<p>Symmetric matrices are real valued matrices for which \\(A^T = A\\). If A is complex, a nicer property is \\(\\bar{A}^T = A\\); such a matrix is called <code>Hermitian</code> and we abbreviate \\(\\bar{A}^T\\) as \\(A^H\\). Note that the diagonal entries of a Hermitian matrix must be real. For example:</p> \\[ \\bar{A}^T = A = \\begin{bmatrix}2 &amp; 3 + i \\\\ 3 - i &amp; 5 \\end{bmatrix} \\] <p>Similar to symmetric matrices, Hermitian matrices have real eigenvalues and perpendicular eigenvectors.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#unitary-matrices","title":"Unitary Matrices","text":"<p>What does it mean for complex vectors \\(\\mathbf{q}_ 1 \\mathbf{q}_ 2, \\cdots, \\mathbf{q}_ n\\) to be perpendicular (or orthonormal)? We must use our new definition of the inner product. For a collection of \\(\\mathbf{q}_ j\\) in complex space to be orthonormal, we require:</p> \\[ \\bar{\\mathbf{q}}_ j \\bar{\\mathbf{q}}_ k = \\begin{cases} 0 &amp; j \\ne k \\\\ 1 &amp; j = k \\\\ \\end{cases} \\] <p>We can again define</p> \\[ Q = \\begin{bmatrix}\\mathbf{q}_ 1 &amp; \\mathbf{q}_ 2 &amp; \\cdots &amp; \\mathbf{q}_ n\\end{bmatrix} \\] <p>and then \\(Q^HQ = I\\). Just as \"Hermitian\" is the complex equivalent of \"Symmetric\", the term \"Unitary\" is analogous to \"orthogonal\". A <code>unitary matrix</code> is a square matrix with perpendicular columns of unit length.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#discrete-fourier-transform","title":"Discrete Fourier Transform","text":"<p>A <code>Fourier Series</code> is a way of writing a periodic function or signal as a sum of functions of different frequencies:</p> \\[ f(x) = a_0 + a_1 cos x + b_1 sin x + a_2 cos 2x + b_2 sin 2x + \\cdots \\] <p>When working with finite data sets, the <code>discrete Fourier transform</code> is the key to this decomposition.</p> <p>In electrical engineering and computer science, the rows and columns of a matrix are numbered starting with 0, not 1 (and ending with n - 1, not n). We'll follow this convention when discussing the Fourier matrix:</p> \\[ F_n = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 \\\\ 1 &amp; w &amp; w^2 &amp; \\cdots &amp; w^{n - 1} \\\\ 1 &amp; w^2 &amp; w^4 &amp; \\cdots &amp; w^{2(n - 1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; w^{n - 1} &amp; w^{2(n - 1)} &amp; \\cdots &amp; w^{(n - 1)^2} \\end{bmatrix} \\] <p>Notice that \\(F_n = F_n^T\\) and \\((F_n)_ {jk} = w^{jk}\\), where \\(j, k = 0, 1, \\cdots, n - 1\\) and the complex number w is \\(w = e^{2\\pi i / n}\\) (so \\(w^n = 1\\)). The columns of this matrix are orthogonal.</p> <p>All the entries of \\(F_n\\) are on the unit circle in the complex plane, and raising each one to the nth power gives 1. We could write \\(w = cos(2\\pi / n) + i sin (2\\pi / n)\\), but that would just make it harder to compute \\(w^{jk}\\).</p> <p>Because \\(w^4 = 1\\) and \\(w = e^{2\\pi i / 4} = i\\), our best example of a Fourier matrix is:</p> \\[ F_4 = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; i^2 &amp; i^3 \\\\ 1 &amp; i^2 &amp; i^4 &amp; i^6 \\\\ 1 &amp; i^3 &amp; i^6 &amp; i^9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; -1 &amp; -i \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -i &amp; -1&amp; i \\\\ \\end{bmatrix} \\] <p>To find the Fourier transform of a vector with four components (four data points) we multiply by \\(F_4\\).</p> <p>It's easy to check that the columns of \\(F_4\\) are orthogonal, as long as we remember to conjugate when computing the inner product. However, \\(F_4\\) is not unitary because each column has length 2. We could divide each entry by 2 to get a matrix whose clumns are orthogonal.</p> \\[ \\frac{1}{4} F_4^HF_4 = I \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#an-example","title":"An Example","text":"<p>The signal corresponding to a single impulse at time zero is (roughly) described by \\(\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\). To find the Fourier transform of this signal we compute:</p> \\[ \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; -1 &amp; -i \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -i &amp; -1&amp; i \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\  0 \\\\  0 \\\\  0 \\\\  \\end{bmatrix} = \\begin{bmatrix} 1 \\\\  1 \\\\  1 \\\\  1 \\\\  \\end{bmatrix} \\] <p>A single impulse has all frequencies in equal amounts.</p> <p>If we multiply by \\(F_4\\) again we almost get back to \\((1, 0, 0, 0)\\):</p> \\[ \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; i &amp; -1 &amp; -i \\\\ 1 &amp; -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -i &amp; -1&amp; i \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\  1 \\\\  1 \\\\  1 \\\\  \\end{bmatrix} = 4 \\begin{bmatrix} 1 \\\\  0 \\\\  0 \\\\  0 \\\\  \\end{bmatrix} \\] <p>Because \\(\\frac{1}{\\sqrt{n}}F_n\\) is unitary, multiplying by \\(F_n\\) and dividing by scalar n inverts the transform.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/02_fft/#fast-fourier-transform","title":"Fast Fourier Transform","text":"<p>Fourier matrices can be broken down into chunks with lots of zero entries; Fourier probably didn't notice this. Gauss did, but didn't realize how significant a discovery this was.</p> <p>There's a nice relationship between \\(F_n\\) and \\(F_{2n}\\) related to the fact that \\(w_{2n}^2 = w_n\\):</p> \\[ F_{2n} = \\begin{bmatrix}I &amp; D \\\\ I &amp; -D \\end{bmatrix} \\begin{bmatrix} F_n &amp; 0 \\\\ 0 &amp; F_n \\end{bmatrix} P \\] <p>where D is a diagonal matrix and P is a 2n by 2n permutation matrix:</p> \\[ P = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ &amp; &amp; &amp;\\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\cdots &amp; 0 &amp; 0 \\\\ &amp; &amp; &amp;\\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 1 \\\\ \\end{bmatrix} \\] <p>So a 2n sized Fourier transform F time \\(\\mathbf{x}\\) which we might think would require \\((2n)^2 = 4n^2\\) operations can instead be performed using two size n Fourier transforms (\\(2n^2\\) operations) plus two very simple matrix multiplications which require on the order of n multiplications. The matrix P picks out the even components \\(x_0, x_2, x_4, \\cdots\\) of a vector first, and then the odd ones - this calculation can be done very quickly.</p> <p>Thus we can do a Fourier transform of size 64 on a vector by separating the vector into its odd and even components, performing a size 32 Fourier transform on each half of its components, then recombining the two halves through a process which involves multiplication by the diagonal matrix D.</p> \\[ D = \\begin{bmatrix} 1 \\\\ &amp; w \\\\ &amp; &amp; w^2 \\\\ &amp; &amp; &amp; \\ddots \\\\ &amp; &amp; &amp; &amp; w^{n - 1} \\\\ \\end{bmatrix} \\] <p>Of course we can break each of those copies of \\(F_{32}\\) down into two copies of \\(F_{16}\\) and so on. In the end, instead of using \\(n^2\\) operations to multiply by \\(F_n\\) we get the same result using about \\(\\frac{1}{2} n log n\\) operations.</p> <p>A typical case is \\(n = 1024 = 2^{10}\\). Simply multiplying by \\(F_n\\) requires over a million calculations. The fast Fourier transform can be completed with only \\(\\frac{1}{2} n log n = 5 \\times 1024\\) calculations. This is 200 times faster!</p> <p>This is only possible because Fourier matrices are special matrices with orthogonal columns. In the next lecture we'll return to dealing exclusively with real numbers and will learn about positive definite matrices, which are the matrices most often seen in application.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/","title":"Positive Definite Matrices and Minima","text":"<p>Studying positive definite matrices brings the whole course together; we use pivots, determinants, eigenvalues and stability. The new quantity here is \\(\\mathbf{x}^T A \\mathbf{x}\\); watch for it.</p> <p>This lecture covers how to tell if a matrix is positive definite, what it means for it to be positive definite, and some geometry.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#positive-definite-matrices","title":"Positive Definite Matrices","text":"<p>Given a symmetric two by two matrix \\(\\begin{bmatrix}a &amp; b \\\\ b &amp; c\\end{bmatrix}\\), here are four ways to tell if it's positive definite:</p> <ol> <li>Eigenvalue test: \\(\\lambda_1 &gt; 0, \\lambda_2 &gt; 0\\)</li> <li>Determinants test: \\(a &gt; 0, ac - b^2 &gt; 0\\)</li> <li>Pivot test: \\(a &gt; 0, \\frac{ac - b^2}{a} &gt; 0\\)</li> <li>\\(\\mathbf{x}^T A \\mathbf{x}\\) is positive except when \\(\\mathbf{x} = \\mathbf{0}\\)(this is usually the definition of positive definiteness)</li> </ol>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#2-by-2","title":"2 by 2","text":"<p>Using the determinants test, we know that \\(\\begin{bmatrix}2 &amp; 6 \\\\ 6 &amp; y \\end{bmatrix}\\) is positive definite when \\(2y - 36 &gt; 0\\) or when \\(y &gt; 18\\).</p> <p>The matrix \\(\\begin{bmatrix}2 &amp; 6 \\\\ 6 &amp; 18 \\end{bmatrix}\\) is on the borderline of positive definiteness and is called a <code>positive semidefinite</code> matrix. It's a singular matrix with eigenvalues 0 and 20. Positive semidefinite matrices have eigenvalues greater than or equal to 0. For a singular matrix, the determinant is 0 and it only has one pivot.</p> \\[ \\begin{align} \\mathbf{x}^TA\\mathbf{x} &amp;= \\begin{bmatrix}x_1 &amp; x_2\\end{bmatrix}\\begin{bmatrix}2 &amp; 6 \\\\ 6 &amp; 18 \\end{bmatrix} \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} \\\\ &amp;= \\begin{bmatrix}x_1 &amp; x_2\\end{bmatrix}\\begin{bmatrix}2x_1 + 6x_2 \\\\ 6x_1 + 18x_2 \\end{bmatrix} \\\\ &amp;= 2x_1^2 + 12 x_1 x_2 + 18 x_2^2 \\\\ = ax_1^2 + 2bx_1x_2 + cx_2^2 \\end{align} \\] <p>If this <code>quadratic form</code> is positive for every(real) \\(x_1\\) and \\(x_2\\) then the matrix is positive definite. In this positive semi-definite example, \\(2x_1^2 + 12x_1 x_2 + 18 x_2^2 = 2(x_1 + 3x_2)^2 = 0\\) when \\(x_1 = 3\\) and \\(x_2 = -1\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#test-for-minimum","title":"Test for Minimum","text":"<p>If we apply the fourth test to the matrix \\(\\begin{bmatrix}2 &amp; 6 \\\\ 6 &amp; 7\\end{bmatrix}\\) which is not positive definite, we get the quadratic form \\(f(x, y) = 2x^2 + 12xy + 7y^2\\). The graph of this function has a saddle point at the origin:</p> <p></p> <p>The matrix \\(\\begin{bmatrix}2 &amp; 6 \\\\ 6 &amp; 20\\end{bmatrix}\\) is positive definite - its determinant is 4 and its trace is 22 so its eigenvalues are positive. The quadratic form associated with this matrix is \\(f(x, y) = 2x^2 + 12xy + 20y^2\\), which is positive except when \\(x = y = 0\\). The level curve \\(f(x, y) = k\\) of this graph are ellipses; its graph appears in next figure. If \\(a &gt; 0\\) and \\(c &gt; 0\\), the quadratic form \\(ax^2 + abxy + cy^2\\) is only negative when the value of \\(2bxy\\) is negative and overwhelms the (positive) value of \\(ax^2 + cy^2\\).</p> <p>The first derivatives \\(f_x\\) and \\(f_y\\) of this function are zero, so its graph is tangent to the xy-plane at \\((0, 0, 0)\\); but this was also true of \\(2x^2 + 12xy + 7y^2\\). as in single variable calculus, we need to look at the second derivatives of \\(f\\) to tell whether there is a minimum at the critical point.</p> <p>We can prove that \\(2x^2 + 12xy + 20y^2\\) is always positive by writing it as a sum of squares. We do this by completing the square:</p> \\[ 2 x^2 + 12xy + 20y^2 = 2(x + 3y)^2 + 2y^2 \\] <p>Note that \\(2(x + 3y)^2 = 2x^2 + 12xy + 18y^2\\), and 18 was the <code>borderline</code> between passing and failing the tests for positive definiteness.</p> <p></p> <p>When we complete the square for \\(2x^2 + 12xy + 7y^2\\) we get:</p> \\[ 2x^2 + 12xy + 7y^2 = 2(x + 3y)^2 - 11y^2 \\] <p>which may be negative; e.g. when \\(x = -3\\) and \\(y = 1\\).</p> <p>The coefficients that appear when completing the square are exactly the entries that appear when performing elimination on the original matrix. The two pivots are multiplied by the squares, and the coefficient c in the term \\((x - cy)^2\\) is the multiple of the first row that's subtracted from the second row.</p> \\[ \\begin{bmatrix} 2 &amp; 6 \\\\ 6 &amp; 20 \\end{bmatrix} \\xrightarrow{\\text{subtract 3 times row 1}}  \\begin{bmatrix} 2 &amp; 6 \\\\ 0 &amp; 2 \\end{bmatrix} \\] <p>We can see the terms that appear when completing the square in:</p> \\[ U =\\begin{bmatrix}2 &amp; 6 \\\\ 0 &amp; 2\\end{bmatrix} \\] <p>and</p> \\[ L =\\begin{bmatrix}1 &amp; 0 \\\\ 3 &amp; 1\\end{bmatrix} \\] <p>When we complete the square, the numbers multiplied by the squares are the pivots; if the pivots are all positive then the sum of squares will always be positive.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#hessian-matrix","title":"Hessian Matrix","text":"<p>The matrix of second derivatives of \\(f(x, y)\\) is:</p> \\[ \\begin{bmatrix}f_{xx} &amp; f_{xy} \\\\ f_{yx} &amp; f_{yy}\\end{bmatrix} \\] <p>This matrix is symmetric because \\(f_{xy} = f_{yx}\\). Its determinant is positive when the matrix is positive definite, which matches the \\(f_{xx}f_{yy} &gt; f_{xy}^2\\) test for a minimum that we learned in calculus.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#n-by-n","title":"n by n","text":"<p>A function of several variables \\(f(x_1, x_2, \\cdots, x_n)\\) has a minimum when its matrix of second derivatives is positive definite, and identifying minima of functions is often important. The tests we've just learned for 2 by 2 matrices also apply to n by n matrices.</p> <p>A 3 by 3 example:</p> \\[ A = \\begin{bmatrix}2 &amp; -1 &amp; 0 \\\\ -1 &amp; 2 &amp; -1 \\\\ 0 &amp; -1 &amp; 2\\end{bmatrix} \\] <p>Is this matrix positive definite? Our tests will say yes. What's the function \\(\\mathbf{x}^TA\\mathbf{x}\\) associated with this matrix? Does that function have a minimum at \\(\\mathbf{x} =\\mathbf{0}\\)? What does the graph of its quadratic form look like?</p> <p>Looking at determinants we see:</p> \\[ det[2] = 2, det\\begin{bmatrix}2 &amp; -1 \\\\ -1 &amp; 2\\end{bmatrix} = 5, det \\begin{bmatrix}2 &amp; -1 &amp; 0 \\\\ -1 &amp; 2 &amp; -1 \\\\ 0 &amp; -1 &amp; 2 \\end{bmatrix} = 4 \\] <p>These are all positive, so A is positive definite.</p> <p>The pivots of A are \\(2, 3/2\\) and \\(4/3\\) (all positive) because the products of the pivots equal the determinants.</p> <p>The eigenvalues of A are positive and their product is 4. It's not difficult to check that they are \\(2 - \\sqrt{2}\\), 2 and \\(2 + \\sqrt{2}\\) (all positive).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/03_minima/#ellipsoids-in-rn","title":"Ellipsoids in R^n","text":"\\[ f(x) = \\mathbf{x}^T A \\mathbf{x} = 2x_1^2 + 2x_2^2 + 2x_3^2 - 2x_1x_2 - 2x_2x_3 \\] <p>Because A is positive definite, we expect \\(f(x)\\) to be positive except when \\(\\mathbf{x} = \\mathbf{0}\\). Its graph is a sort of four dimensional bowl or <code>paraboloid</code>. If we wrote \\(f(x)\\) as a sum of three squares, those squares would be multiplied by the (positive) pivots of A. Earlier, we said that a horizontal slice of our three dimensional bowl shape would be an ellipse. Here, a horizontal slice of the four dimensional bowl is an ellipsoid - a little bit like a rugby ball. For example, if we cat the graph at height 1 we get a surface whose equation is:</p> \\[ 2x_1^2 + 2 x_2^2 + 2x_3^2 - 2x_1x_2 - 2x_2x_3 = 1 \\] <p>Just as an ellipse has a major and minor axis, an ellipsoid has three axes. If we write \\(A = Q \\Lambda Q^T\\), as the principal axis theorem tells us we can, the eigenvectors of A tell us the directions of the principal axes of the ellipsoid. The eigenvalues tell us the lengths of those axiss.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/","title":"Similar Matrices and Jordan Form","text":"<p>We've nearly covered the entire heart of linear algebra - once we've finished singular value decompositions we'll have seen all the most central topics.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/#ata-is-positive-definite","title":"A^TA is Positive Definite","text":"<p>A matrix is <code>positive definite</code> if \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\ne \\mathbf{0}\\). This is a very important class of matrices; positive definite matrices appear in the form of \\(A^TA\\) when computing least squares solutions. In many situations, a rectangular matrix is multiplied by its transpose to get a square matrix.</p> <p>Given a symmetric positive definite matrix A, is its inverse also symmetric and positive definite? Yes, because if the (positive) eigenvalues of A are \\(\\lambda_1, \\lambda_2, \\cdots, \\lambda_d\\) then the eigenvalues \\(1 / \\lambda_1, 1/ \\lambda_2, \\cdots, 1 / \\lambda_d\\) of \\(A^{-1}\\) are also positive.</p> <p>If A and B are positive definite, is \\(A + B\\) positive definite? We don't know much about the eigenvalues of \\(A + B\\), but we can use the propterty \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) and \\(\\mathbf{x}^TB\\mathbf{x} &gt; 0\\) to show that \\(\\mathbf{x}^T (A + B) \\mathbf{x} &gt; 0\\) for \\(\\mathbf{x} \\ne 0\\) and so \\(A + B\\) is also positive definite.</p> <p>Now suppose A is a rectangular (m by n) matrix. A is almost certainly not symmetric, but \\(A^TA\\) is square and symmetric. Is \\(A^TA\\) positive definite? We'd rather not try to find the eigenvalues or the pivots of this matrix, so we ask when \\(\\mathbf{x}^T A^T A\\mathbf{x}\\) is positive.</p> <p>Simplifying \\(\\mathbf{x}^T A^T A \\mathbf{x}\\) is just a matter of moving parentheses:</p> \\[ \\mathbf{x}^T (A^TA) \\mathbf{x} = (A \\mathbf{x})^T (A\\mathbf{x}) = |A\\mathbf{x}|^2 \\ge 0 \\] <p>The only remaining question is whether \\(A\\mathbf{x} = \\mathbf{0}\\). If A has rank n (independent columns), then \\(\\mathbf{x}^T(A^T A)\\mathbf{x} = \\mathbf{0}\\) only if \\(\\mathbf{x} = \\mathbf{0}\\) and A is positive definite.</p> <p>Another nice feature of positive definite matrices is that you never have to do row exchanges when row reducing - there are never 0's or unsuitably small numbers in their pivot positions.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/#similar-matrices-a-and-b-m-1-am","title":"Similar Matrices A and B = M^-1 AM","text":"<p>Two square matrices A and B are similar if \\(B = M^{-1} A M\\) for some matrix M. This allows us to put matrices into families in which all the matrices in a family are similar to each other. Then family can be represented by a diagnoal (or nearly diagonal) matrix.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/#distinct-eigenvalues","title":"Distinct Eigenvalues","text":"<p>If A has a full set of eigenvectors we can create its eigenvector matrix S and write \\(S^{-1} A S = \\Lambda\\). So A is similar to \\(\\Lambda\\) (choosing M to be this S).</p> <p>If A = \\(\\begin{bmatrix}2 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix}\\) then \\(\\Lambda = \\begin{bmatrix}3 &amp; 0 \\\\ 0 &amp; 1\\end{bmatrix}\\) and so A is similar to \\(\\begin{bmatrix}3 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix}\\). But A is also similar to:</p> \\[ \\begin{align} M^{-1} &amp;A &amp;M &amp;= &amp;B &amp; \\\\ \\begin{bmatrix}1 &amp; -4 \\\\ 0 &amp; 1\\end{bmatrix} &amp;\\begin{bmatrix}3 &amp; 0 \\\\ 0 &amp; 1\\end{bmatrix} &amp;\\begin{bmatrix}1 &amp; 4 \\\\ 0 &amp; 1\\end{bmatrix} &amp;= \\begin{bmatrix}1 &amp; -4 \\\\ 0 &amp; 1 \\end{bmatrix} &amp;\\begin{bmatrix}2 &amp; 9 \\\\ 1 &amp; 6\\end{bmatrix}  \\\\  &amp; &amp; &amp;= \\begin{bmatrix}-2 &amp; -15 \\\\ 1 &amp; 6 \\end{bmatrix} &amp; \\end{align} \\] <p>In addition, B is similar to \\(\\Lambda\\). All these similar matrices have the same eigenvalues, 3 and 1; we can check this by computing the trace and determinant of A and B.</p> <p>Similar matrices have the same eigenvalues!</p> <p>In fact, the matrices similar to A are all the 2 by 2 matrices with eigenvalues 3 and 1. Some other members of this family are \\(\\begin{bmatrix}3 &amp; 7 \\\\ 0 &amp; 1 \\end{bmatrix}\\) and \\(\\begin{bmatrix}1 &amp; 7 \\\\ 0 &amp; 3\\end{bmatrix}\\). To prove that similar matrices have the same eigenvalues, suppose \\(A\\mathbf{x} = \\lambda\\mathbf{x}\\). We modify this equation to include \\(B = M^{-1} A M\\):</p> \\[ \\begin{align} AMM^{-1}\\mathbf{x} &amp;= \\lambda \\mathbf{x} \\\\ M^{-1}AMM^{-1}\\mathbf{x} &amp;= \\lambda M^{-1}\\mathbf{x} \\\\ BM^{-1}\\mathbf{x} &amp;= \\lambda M^{-1}\\mathbf{x} \\\\ \\end{align} \\] <p>The matrix B has the same \\(\\lambda\\) as eigenvalues. \\(M^{-1}\\mathbf{x}\\) is the eigenvector.</p> <p>If two matrices are similar, they have the same eigenvalues and the same number of independent eigenvectors(but probably not the same eigenvectors).</p> <p>When we diagonalize A, we're finding a diagonal matrix \\(\\Lambda\\) that is similar to A. If two matrices have the same n distinct eigenvalues, they'll be similar to the same diagonal matrix.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/#repeated-eigenvalues","title":"Repeated Eigenvalues","text":"<p>If two eigenvalues of A are the same, it may not be possible to diagonalize A. Suppose \\(\\lambda_1 = \\lambda_2 = 4\\). One family of matrices with eigenvalues 4 and 4 contains only the matrix \\(\\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4 \\end{bmatrix}\\). The matrix \\(\\begin{bmatrix}4 &amp; 1 \\\\ 0 &amp; 4 \\end{bmatrix}\\) is not in this family.</p> <p>There are two families of similar matrices with eigenvalues 4 and 4. The larger family includes \\(\\begin{bmatrix}4 &amp; 1 \\\\ 0 &amp; 4 \\end{bmatrix}\\). Each of the members of this family has only one eigenvector.</p> <p>The matrix \\(\\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4\\end{bmatrix}\\) is the only member of the other family, because:</p> \\[ M^{-1} \\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4 \\end{bmatrix} M = 4 M^{-1} M = \\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4 \\end{bmatrix} \\] <p>for any invertible matrix M.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/04_similar_matrices/#jordan-form","title":"Jordan Form","text":"<p>Camille Jordan found a way to choose a <code>most diagonal</code> representative from each family of similar matrices; this representitive is said to be in <code>Jordan normal form</code>. For example, both \\(\\begin{bmatrix}4 &amp; 1 \\\\ 0 &amp; 4\\end{bmatrix}\\) and \\(\\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4\\end{bmatrix}\\) are in Jordan form. This form used to be the climax of linear algebra, but not any more. Numerical applications rarely need it. </p> <p>We can find more members of the family represented by \\(\\begin{bmatrix}4 &amp; 1 \\\\ 0 &amp; 4 \\end{bmatrix}\\) by choosing diagonal entries to get a trace of 4, then choosing off-diagonal entries to get a determinant of 16:</p> \\[ \\begin{bmatrix}4 &amp; 1 \\\\ 0 &amp; 4 \\end{bmatrix}, \\begin{bmatrix}5 &amp; 1 \\\\ -1 &amp; 3 \\end{bmatrix}, \\begin{bmatrix}4 &amp; 0 \\\\ 17 &amp; 4 \\end{bmatrix}, \\begin{bmatrix}a &amp; b \\\\ (8a - a^2 - 16)/b &amp; 8 - b \\end{bmatrix} \\] <p>None of these are diagonalizable, because if they were they would be similar to \\(\\begin{bmatrix}4 &amp; 0 \\\\ 0 &amp; 4\\end{bmatrix}\\). That matrix is only similar to itself. What about this one?</p> \\[ \\begin{bmatrix}0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\] <p>Its eigenvalues are four zeros. Its rand is 2 so the dimension of its nullspace is \\(4 - 2 = 2\\). It will have two independent eigenvectors and two \"missing\" eigenvectors. When we look instead at:</p> \\[ \\begin{bmatrix}0 &amp; 1 &amp; 7 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\] <p>its rank and the dimension of its nullspace are still 2, but it's not as nice as A. B is similar to A, which is the <code>Jordan normal form</code> representative of this family. A has a 1 above the diagonal for every missing eigenvector and the rest of its entries are 0.</p> <p>Now consider:</p> \\[ C = \\begin{bmatrix}0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0\\end{bmatrix} \\] <p>Again it has rank 2 and its nullspace has dimension 2. Its four eigenvalues are 0. Surprisingly, it is not similar to A. We can see this by breaking the matrices into their <code>Jordan blocks</code>:</p> \\[ A =  \\begin{array}{|ccc|c|}0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}, C =  \\begin{array}{|cc|cc|}0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array} \\] <p>A Jordan block \\(J_{i}\\) has a repeated eigenvalue \\(\\lambda_i\\) on the diagonal, zeros below the diagonal and in the upper right hand corner, and ones above the diagonal:</p> \\[ J_i = \\begin{bmatrix} \\lambda_i &amp; 1 &amp; j0 \\cdots &amp; 0 \\\\ 0 &amp; \\lambda_i &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\lambda_i &amp; 1 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; \\lambda_i \\\\ \\end{bmatrix} \\] <p>Two matrices may have the same eigenvalues and the same number of eigenvectors, but if their Jordan blocks are different sizes those matrices can not be similar.</p> <p>Jordan's theorem says that every square matrix A is similar to a Jordan matrix J, with Jordan blocks on the diagonal:</p> \\[ J =  \\begin{bmatrix} J_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; J_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; J_d \\end{bmatrix} \\] <p>In a Jordan matrix, the eigenvalues are on the diagonal and there may be ones above the diagonal; the rest of the entries are zero. The number of blocks is the number of eigenvectors - there is one eigenvector per block.</p> <p>To summerize:</p> <ul> <li>If A has n distinct eigenvalues, it is diagonalizable and its Jordan matrix is the diagonal matrix \\(J = \\Lambda\\)</li> <li>If A has repeated eigenvalues and \"missing\" eigenvectors, then its Jordan matrix will have \\(n - d\\) ones above the diagonal.</li> </ul> <p>We have not learned to compute the Jordan matrix of a matrix which is missing eigenvectors, but we do know how to diagonalize a matrix which has n distinct eigenvalues.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/","title":"Singular Value Decomposition(SVD)","text":"<p>The <code>Singular Value Decomposition</code> of a matrix is usually referred to as the SVD. This is the final and best factorization of a matrix:</p> \\[ A = U \\Sigma V^T \\] <p>where \\(U\\) is the orthogonal, \\(\\Sigma\\) is diagonal, and \\(V\\) is orthogonal.</p> <p>In the decomposition \\(A = U \\Sigma V^T\\), A can be <code>any</code> matrix. We know that if A is symmetric positive definite its eigenvectors are orthogonal and we can write \\(A = Q \\Lambda Q^T\\). This is a spacial case of a SVD, with \\(U = V = Q\\). For more general A, the SVD requires two different matrices U and V.</p> <p>We've also learned how to write \\(A = S \\Lambda S^{-1}\\), where S is the matrix of n distinct eigenvectors of A. However, S may not be orthogonal; the matrices U and V in the SVD will be.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/#how-it-works","title":"How It Works","text":"<p>We can think of A as a linear transformation taking a vector \\(\\mathbf{v}_ 1\\) in its row space to a vector \\(\\mathbf{u}_ 1 = A \\mathbf{v}_ 1\\) in its column space. The SVD arises from finding an orthogonal basis for the row space that gets transformed into orthogonal basis for the column space: \\(A\\mathbf{v}_ i = \\sigma_ i \\mathbf{u}_ i\\)</p> <p>It's not hard to find an orthogonal basis for the row space - the Gram-Schmidt process gives us one right way. But in general, there's no reason to expect A to transform that basis to another orthogonal basis.</p> <p>You may be wondering about the vectors in the nullspace of A and \\(A^T\\). There are no problem - zeros on the diagonal of \\(\\Sigma\\) will take care of them.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/#matrix-language","title":"Matrix Language","text":"<p>The heart of the problem is to find an orthogonal basis \\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ r\\) for the row space of A for which:</p> \\[ \\begin{align} A\\begin{bmatrix}\\mathbf{v}_ 1 &amp; \\mathbf{v}_ 2 &amp; \\cdots &amp; \\mathbf{v}_ r\\end{bmatrix} &amp;=  \\begin{bmatrix}\\sigma_ 1 \\mathbf{u}_ 1 &amp; \\sigma_2 \\mathbf{u}_ 2 &amp; \\cdots &amp; \\sigma_r \\mathbf{u}_ r\\end{bmatrix} \\\\ &amp;= \\begin{bmatrix}\\mathbf{u}_ 1 &amp; \\mathbf{u}_ 2 &amp; \\cdots &amp; \\mathbf{u}_ r\\end{bmatrix} \\begin{bmatrix}\\sigma_1 &amp; &amp; &amp; \\\\ &amp; \\sigma_2 &amp; &amp; \\\\ &amp; &amp; \\ddots &amp; \\\\ &amp; &amp; &amp;\\sigma_r \\end{bmatrix} \\end{align} \\] <p>with \\(\\mathbf{u}_ 1, \\mathbf{u}_ 2, \\cdots, \\mathbf{u}_ r\\) an orthonormal basis for the column space of A. Once we add in the nullspaces, this equation will become \\(AV = U\\Sigma\\). We can complete the orthonormal bases \\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ r\\) and \\(\\mathbf{u}_ 1, \\mathbf{u}_ 2, \\cdots, \\mathbf{u}_ r\\) to orthonormal bases for the entire space any way we want. Since \\(\\mathbf{v}_ {r + 1}, \\cdots, \\mathbf{v}_ n\\) will be in the nullspace of A, the diagonal entries \\(\\sigma_{r + 1}, \\cdots, \\sigma_{n}\\) will be 0.</p> <p>The columns of \\(U\\) and \\(V\\) are bases for the row and column spaces, respectively. Usually \\(U \\ne V\\), but if A is positive definite we can use the same basis for its row and column space!</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/#calculation","title":"Calculation","text":"<p>Suppose A is the invertible matrix \\(\\begin{bmatrix}4 &amp; 4 \\\\ -3 &amp; 3\\end{bmatrix}\\). We want to find vectors \\(\\mathbf{v}_ 1\\) and \\(\\mathbf{v}_ 2\\) in the row space \\(\\mathbb{R}^2\\), \\(\\mathbf{u}_ 1\\) and \\(\\mathbf{u}_ 2\\) in the column space \\(\\mathbb{R}^2\\), and positive numbers \\(\\sigma_1\\) and \\(\\sigma_2\\) so that the \\(\\mathbf{v}_ i\\) are orthonormal, the \\(\\mathbf{u}_ i\\) are orthonormal, and the \\(\\sigma_i\\) are the scaling factors for which \\(A \\mathbf{v}_ i = \\sigma_i u_i\\).</p> <p>This is a big step toward finding orthonormal matrices \\(V\\) and \\(U\\) and a diagonal matrix \\(\\Lambda\\) for which:</p> \\[ AV = U \\Sigma \\] <p>Since V is orthogonal, we can multiply both sides by \\(V^{-1} = V^T\\) to get:</p> \\[ A = U \\Sigma V^T \\] <p>Rather than solving for U, V and \\(\\Sigma\\) simultaneously, we multiply both sides by \\(A^T = V \\Sigma ^T U^T\\) to get:</p> \\[ \\begin{align} A^T A &amp;= V \\Sigma U^{-1} U \\Sigma V^T \\\\ &amp;= V \\Sigma^2 V^T \\\\ &amp;= V \\begin{bmatrix}\\sigma^2_1 &amp; &amp; &amp; \\\\ &amp;\\sigma^2_2 &amp; &amp; \\\\  &amp; &amp;\\ddots &amp; \\\\ &amp; &amp; &amp; \\sigma_n^2\\end{bmatrix} V^T \\end{align} \\] <p>This is in the form \\(Q\\Lambda Q^T\\); we can now find V by diagonalizing the symmetric positive definite (or semidefinite) matrix \\(A^TA\\). The columns of V are eigenvectors of \\(A^T\\) and the eigenvalues of \\(A^TA\\) are the values \\(\\sigma_i^2\\). We choose \\(\\sigma_i\\) to be the positive square root of \\(\\lambda_i\\).</p> <p>To find U, we do the same thing with \\(AA^T\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/#svd-example","title":"SVD Example","text":"<p>We return to our matrix \\(A = \\begin{bmatrix}4 &amp; 4 \\\\ -3 &amp; 3\\end{bmatrix}\\). We start by computing:</p> \\[ \\begin{align} A^TA &amp;=\\begin{bmatrix}4 &amp; -3 \\\\ 4 &amp; 3\\end{bmatrix}\\begin{bmatrix}4 &amp; 4\\\\ -3 &amp; 3\\end{bmatrix} \\\\ &amp;= \\begin{bmatrix}25 &amp; 7 \\\\ 7 &amp; 25\\end{bmatrix} \\end{align} \\] <p>The eigenvectors of this matrix will give us the vector \\(\\mathbf{v}_ i\\), and the eigenvalues will gives us the numbers \\(\\sigma_i\\).</p> <p>Two orthogonal eigenvectors of \\(A^TA\\) are \\(\\begin{bmatrix}1 \\\\ 1\\end{bmatrix}\\) and \\(\\begin{bmatrix}1 \\\\ -1\\end{bmatrix}\\). To get an orthonormal basis, let \\(\\mathbf{v}_ 1 = \\begin{bmatrix}1 / \\sqrt{2} \\\\ 1 / \\sqrt{2}\\end{bmatrix}\\) and \\(\\mathbf{v}_ 2 = \\begin{bmatrix}1 / \\sqrt{2} \\\\ -1 / \\sqrt{2}\\end{bmatrix}\\). These have eigenvalues \\(\\sigma_1^2 = 32\\) and \\(\\sigma_2^2 = 18\\). We now have:</p> \\[ A = U \\Sigma V^T \\] \\[ \\begin{bmatrix}4 &amp; 4 \\\\ -3 &amp; 3\\end{bmatrix} = [] \\begin{bmatrix}4 \\sqrt{2} &amp; 0 \\\\ 0 &amp; 3\\sqrt{2}\\end{bmatrix} \\begin{bmatrix}1 / \\sqrt{2} &amp; 1 / \\sqrt{2} \\\\ 1 / \\sqrt{2} &amp; -1 / \\sqrt{2}\\end{bmatrix} \\] <p>We could solve this for U, but for practice we'll find U by finding orthonormal eigenvectors \\(\\mathbf{u}_ 1\\) and \\(\\mathbf{u}_ 2\\) for \\(AA^T = U \\Sigma^2 U^T\\).</p> \\[ \\begin{align} AA^T &amp;= \\begin{bmatrix}4 &amp; 4 \\\\ -3 &amp; 3\\end{bmatrix} \\begin{bmatrix}4 &amp; -3 \\\\ 4 &amp; 3\\end{bmatrix} \\\\      &amp;= \\begin{bmatrix}32 &amp; 0 \\\\ 0 &amp; 18\\end{bmatrix} \\end{align} \\] <p>Luckily, \\(AA^T\\) happens to be diagonal. It's tempting to let \\(\\mathbf{u}_ 1 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}\\) and \\(\\mathbf{u}_ 2 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}\\), as Professor Strang did in the lecture, but because \\(A\\mathbf{v}_ 2 = \\begin{bmatrix}0 \\\\ -3 \\sqrt{2}\\end{bmatrix}\\) we instead have \\(\\mathbf{u}_ 2 = \\begin{bmatrix}0 \\\\ -1\\end{bmatrix}\\) and \\(U = \\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; -1\\end{bmatrix}\\). Note that this also gives us a chance to double check our calculation of \\(\\sigma_1\\) and \\(\\sigma_2\\).</p> <p>Thus, the SVD of A is:</p> \\[ A = U \\Sigma V^T \\] \\[ \\begin{bmatrix}4 &amp; 4 \\\\ -3 &amp; 3\\end{bmatrix} = \\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; -1\\end{bmatrix} \\begin{bmatrix}4\\sqrt{2} &amp; 0 \\\\ 0 &amp; 3 \\sqrt{2}\\end{bmatrix} \\begin{bmatrix}1/\\sqrt{2} &amp; 1/\\sqrt{2} \\\\ 1 / \\sqrt{2} &amp; -1 / \\sqrt{2}\\end{bmatrix}. \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/05_svd/#example-with-a-nullspace","title":"Example with a Nullspace","text":"<p>Now let \\(A = \\begin{bmatrix}4 &amp; 3 \\\\ 8 &amp; 6\\end{bmatrix}\\). This has a one dimensional nullspace and one dimensional row and column spaces.</p> <p>The row space of A consists of the multiples of \\(\\begin{bmatrix}4 \\\\ 3\\end{bmatrix}\\). The column space of A is made up of multiples of \\(\\begin{bmatrix}4 \\\\ 8\\end{bmatrix}\\). The nullspace and left nullspace are perpendicular to the row and column spaces, respectively.</p> <p>Unit basis vectors of the row and column spaces are are \\(\\mathbf{v}_ 1 = \\begin{bmatrix}0.8 \\\\ 0.6\\end{bmatrix}\\) and \\(\\mathbf{u}_ 1 = \\begin{bmatrix}1/\\sqrt{5} \\\\ 1 / \\sqrt{5}\\end{bmatrix}\\). To compute \\(\\sigma_1\\) we find the nonzero eigenvalue of \\(A^TA\\).</p> \\[ \\begin{align} A^TA &amp;= \\begin{bmatrix}4 &amp; 8 \\\\ 3 &amp; 6\\end{bmatrix} \\begin{bmatrix}4 &amp; 3 \\\\ 8 &amp; 6\\end{bmatrix} \\\\      &amp;= \\begin{bmatrix}80 &amp; 60 \\\\ 60 &amp; 45\\end{bmatrix} \\end{align} \\] <p>Because this is a rank 1 matrix, one eigenvalue must be 0. The other must equal the trace, so \\(\\sigma_1^2 = 125\\). After finding unit vectors perpendicular to \\(\\mathbf{u}_ 1\\) and \\(\\mathbf{v}_ 1\\) (basis vectors for the left nullspace and nullspace, respectively) we see that the SVD of A is:</p> \\[ \\begin{bmatrix}4 &amp; 3 \\\\ 8 &amp; 6\\end{bmatrix} = \\frac{1}{\\sqrt{5}}\\begin{bmatrix}1 &amp; 2 \\\\ 2 &amp; -1\\end{bmatrix} \\begin{bmatrix}\\sqrt{125} &amp; 0 \\\\ 0 &amp; 0\\end{bmatrix}\\begin{bmatrix}0.8 &amp; 0.6 \\\\ 0.6 &amp; -0.8\\end{bmatrix} \\] \\[ A = U \\Sigma V^T \\] <p>The singular value decomposition combines topics in linear algebra ranging from positive definite matrices to the four fundamental subspaces.</p> <ul> <li>\\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ r\\) is an orthonormal basis for the row space;</li> <li>\\(\\mathbf{u}_ 1, \\mathbf{u}_ 2, \\cdots, \\mathbf{u}_ r\\) is an orthonormal basis for the column space;</li> <li>\\(\\mathbf{v}_ {r + 1}, \\mathbf{v}_ {r + 2}, \\cdots, \\mathbf{v}_ n\\) is an orthonormal basis for the nullspace;</li> <li>\\(\\mathbf{u}_ {r + 1}, \\mathbf{u}_ {r + 2}, \\cdots, \\mathbf{u}_ m\\) is an orthonormal basis for the left nullspace.</li> </ul> <p>These are the \"right\" bases to use, bacause \\(A\\mathbf{v}_ i = \\sigma_i \\mathbf{u}_ i\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/","title":"Linear Transformations and their Matrices","text":"<p>In older linear algebra courses, linear transformations were introduced before matrices. This geometric approach to linear algebra initially avoids the need for coordinates. But eventually there must be coordinates and matrices when the need for computation arises.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#without-coordinatesno-matrix","title":"Without Coordinates(no matrix)","text":""},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-1-projection","title":"Example 1: Projection","text":"<p>We can describe a projection as a <code>linear transformation</code> T which takes every vector in \\(\\mathbb{R}^2\\) into another vector in \\(\\mathbb{R}^2\\). In other words,</p> \\[ T : \\mathbb{R}^2 \\to \\mathbb{R}^2 \\] <p>The rule for this <code>mapping</code> is that every vector \\(\\mathbf{v}\\) is projected onto a vector \\(T(\\mathbf{v})\\) on the line of the projection. Projection is a linear transformation.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#definition-of-linear","title":"Definition of Linear","text":"<p>A transformation T is <code>linear</code> if:</p> \\[ T(\\mathbf{v} + \\mathbf{w}) = T(\\mathbf{v}) + T(\\mathbf{w}) \\] <p>and</p> \\[ T(c\\mathbf{v}) = cT(\\mathbf{v}) \\] <p>for all vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) for all scalars c. Equaivalently:</p> \\[ T(c\\mathbf{v} + d\\mathbf{w}) = cT(\\mathbf{v}) + dT(\\mathbf{w}) \\] <p>for all vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) and scalars c and d. It's worth noticing that \\(T(\\mathbf{0}) = \\mathbf{0}\\), because if not it couldn't be true that \\(T(c\\mathbf{0}) = cT(\\mathbf{0})\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#non-example-1-shift-the-whole-plane","title":"Non-example 1: Shift the Whole Plane","text":"<p>Consider the transformation \\(T(\\mathbf{v}) = \\mathbf{v} + \\mathbf{v}_ 0\\) that shifts every vector in the plane by adding some fixed vector \\(\\mathbf{v}_ 0\\) to it. This is <code>not</code> a linear transformation because \\(T(2\\mathbf{v}) = 2\\mathbf{v} + \\mathbf{v}_ 0 \\ne 2T(\\mathbf{v})\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#non-exmaple-2-tv-v","title":"Non-exmaple 2: T(v) = ||v||","text":"<p>The transformation \\(T(\\mathbf{v}) = ||\\mathbf{v}||\\) that takes any vector to its length is not a linear transformation because \\(T(c\\mathbf{v}) \\ne cT(\\mathbf{v})\\) if \\(c &lt; 0\\).</p> <p>We're not going to study transformations that aren't linear. From here on, we'll only use T to stand for linear transformations.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-2-rotation-by-45-deg","title":"Example 2: Rotation by 45 deg","text":"<p>This transformation \\(T : \\mathbf{R}^2 \\to \\mathbf{R}^2\\) takes vector \\(\\mathbf{v}\\) and outputs the vector \\(T(\\mathbf{v})\\) that comes from rotating \\(\\mathbf{v}\\) counterclockwise by \\(45^{\\circ}\\) about the origin. Note that we can describe this and see that it's linear without using any coordinates.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#the-big-picture","title":"The Big Picture","text":"<p>One advantage of describing transformations geometrically is that it helps us to see the big picture, as apposed to focusing on the transformation's effect on a single point. We can quickly see how rotation by \\(45^{\\circ}\\) will transform a picture of a house in the plane. If the transformation was described in terms of a matrix rather than as a rotation, it would be harder to guess what the house would be mapped to.</p> <p>Frequently, the best way to understand a linear transformation is to find the matrix that lies behind the transformation. To do this, we have to choose a basis and bring in coordinates.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#with-coordinatesmatrix","title":"With Coordinates(matrix)","text":"<p>All of the linear transformations we've discussed above can be described in terms of matrices. In a sense, linear transformations are an abstract description of multiplication by a matrix, as in the following example.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-3-tv-av","title":"Example 3: T(v) = Av","text":"<p>Given a matrix A, define \\(T(\\mathbf{v}) = A\\mathbf{v}\\). This is a linear transformation:</p> \\[ A(\\mathbf{v} + \\mathbf{w}) = A(\\mathbf{v}) + A(\\mathbf{w}) \\] <p>and</p> \\[ A(c\\mathbf{v}) = cA(\\mathbf{v}) \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-4","title":"Example 4","text":"<p>Suppose \\(A = \\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; -1\\end{bmatrix}\\). How would we describe the transformation \\(T(\\mathbf{v}) = A\\mathbf{v}\\) geometrically?</p> <p>When we multiply A by a vector \\(\\mathbf{v}\\) in \\(\\mathbb{R}^2\\), the x component of the vector is unchanged and the sign of the y component of the vector is reversed. The transformation \\(\\mathbf{v} \\to A\\mathbf{v}\\) reflects the xy-plane across the x axis.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-5","title":"Example 5","text":"<p>How could we find a linear transformation \\(T : \\mathbb{R}^3 \\to \\mathbb{R}^2\\) that takes three dimensional space to two dimensional space? Choose any 2 by 3 matrix A and define \\(T(\\mathbf{v}) = A\\mathbf{v}\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#describing-tv","title":"Describing T(v)","text":"<p>How much information do we need about T to determine \\(T(\\mathbf{v})\\) for all \\(\\mathbf{v}\\)? If we know how T transforms a single vector \\(\\mathbf{v}_ 1\\), we can use the fact that T is a linear transformation to calculate \\(T(c\\mathbf{v}_ 1)\\) for any scalar c. If we know \\(T(\\mathbf{v}_ 1)\\) and \\(T(\\mathbf{v}_ 2)\\) for two independent vectors \\(\\mathbf{v}_ 1\\) and \\(\\mathbf{v}_ 2\\), we can predict how T will transform any vector \\(c\\mathbf{v}_ 1 + d \\mathbf{v}_ 2\\) in the plan spanned by \\(\\mathbf{v}_ 1\\) and \\(\\mathbf{v}_ 2\\). If we wish to know \\(T(\\mathbf{v})\\) for all vectors \\(\\mathbf{v}\\) in \\(\\mathbb{R}^n\\), we just need to know \\(T(\\mathbf{v}_ 1), T(\\mathbf{v}_ 2), \\cdots, T(\\mathbf{v}_ n)\\) for any basis \\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ n\\) of the intput space. This is because any \\(\\mathbf{v}\\) in the input space can be written as a linear combination of basis vectors, and we know that T is linear:</p> \\[ \\mathbf{v} = c_1 \\mathbf{v}_ 1 + c_2 \\mathbf{v}_ 2 + \\cdots + c_n \\mathbf{v}_ n \\] \\[ T(\\mathbf{v}) = c_1 T(\\mathbf{v}_ 1) + c_2 T(\\mathbf{v}_ n) + \\cdots + c_n T(\\mathbf{v}_ n) \\] <p>This is how we get from a (coordinate-free) linear transformation to a (coordinate based) matrix; the \\(c_i\\) are our coordinates. Once we've chosen a basis, every vector \\(\\mathbf{v}\\) in the space can be written as a combination of basis vectors in exactly one way. The coefficients of those vectors are the <code>coordinates</code> of \\(\\mathbf{v}\\) in that basis.</p> <p>Coordinates come from a basis; changing the basis changes the coordinates of vectors in the space. We may not use the standard basis all the time - we sometimes want to use a basis of eigenvectors or some other basis</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#the-matrix-of-a-linear-transformation","title":"The Matrix of a Linear Transformation","text":"<p>Given a linear transformation T, how do we construct a matrix A that represents it?</p> <p>First, we have to choose two bases:</p> <ul> <li>\\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ n\\) of \\(\\mathbb{R}^n\\) to give coordinates to the input vectors;</li> <li>\\(\\mathbf{w}_ 1, \\mathbf{w}_ 2, \\cdots, \\mathbf{w}_ m\\) of \\(\\mathbb{R}^m\\) to give coordinates to the output vectors.</li> </ul> <p>We want to find a matrix A so that \\(T(\\mathbf{v}) = A\\mathbf{v}\\), where \\(\\mathbf{v}\\) and \\(A\\mathbf{v}\\) get their coordinates from these bases.</p> <p>The first column of A consists of the coefficients \\(a_{11}, a_{21}, \\cdots, a_{1m}\\) of \\(T(\\mathbf{v}_ 1) = a_{11}\\mathbf{w}_ 1 + a_{21}\\mathbf{w}_ 2 + \\cdots + a_{1m}\\mathbf{w}_ m\\). The entries of column i of the matrix A are determined by \\(T(\\mathbf{v}_ i) = a_{1i} \\mathbf{w}_ 1 + a_{2i} \\mathbf{w}_ 2 + \\cdots + a_{mi} \\mathbf{w}_ m\\). Because we've guaranteed that \\(T(\\mathbf{v}_ i) = A\\mathbf{v}_ i\\) for each basis vector \\(\\mathbf{v}_ i\\) and because T is linear, we know that \\(T(\\mathbf{v}) = A\\mathbf{v}\\) for all vectors \\(\\mathbf{v}\\) in the input space.</p> <p>In the example of the projection matrix, \\(n = m = 2\\). The transformation T projects every vector in the plane onto a line. In this example, it makes sense to use the same basis for the input and the output. To make our calculations as simple as possible, we'll choose \\(\\mathbf{v}_ 1\\) to be a unit vector on the line of projection and \\(\\mathbf{v}_ 2\\) to be a unit vector perpendicular to \\(\\mathbf{v}_ 1\\). Then:</p> \\[ T(c_1 \\mathbf{v}_ 1 + c_2 \\mathbf{v}_ 2) = c_1 \\mathbf{v}_ 1 + \\mathbf{0} \\] <p>and the matrix of the projection transformation is just \\(A = \\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; 0\\end{bmatrix}\\).</p> \\[ A\\mathbf{v} = \\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix} \\begin{bmatrix}c_1 \\\\ c_2 \\end{bmatrix} = \\begin{bmatrix}c_1 \\\\ 0\\end{bmatrix} \\] <p>This is a nice matrix! If our chosen basis consists of eigenvectors then the matrix of the transformation will be the diagonal matrix \\(\\Lambda\\) with eigenvalues on the diagonal.</p> <p>To see how important the choice of basis is, let's use the standard basis for the linear transformation that projects the plane onto a line at a \\(45^{\\circ}\\) angle. If we choose \\(\\mathbf{v}_ 1 = \\mathbf{w}_ 1 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}\\) and \\(\\mathbf{v}_ 2 = \\mathbf{w}_ 2 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}\\), we get the projection matrix \\(P = \\frac{\\mathbf{a}\\mathbf{a}^T}{\\mathbf{a}^T\\mathbf{a}} = \\begin{bmatrix}1/2 &amp; 1/2 \\\\ 1/2 &amp; 1/2\\end{bmatrix}\\). We can check by graphing that this is the correct matrix, but calculating P directly is more difficult for this basis than it was with a basis of eigenvectors.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#example-6-t-d-dx","title":"Example 6: T = d / dx","text":"<p>Let T be a transformation that takes the derivative:</p> \\[ T(c_1 + c_2x + c_3 x^2) = c_2 + 2 c_3 x \\] <p>The input space is the three dimensional space of quadratic polynomials \\(c_1 + c_2 x + c_3 x^2\\) with basis \\(\\mathbf{v}_ 1 = 1, \\mathbf{v}_ 2 = x, \\mathbf{v}_ 3 = x^2\\). The output space is a two dimensional subspace of the input space with \\(\\mathbf{w}_ 1 = \\mathbf{v}_ 1 = 1\\) and \\(\\mathbf{w}_ 2 = \\mathbf{v}_ 2 = x\\).</p> <p>This is a linear transformation! So we can find \\(A = \\begin{bmatrix}0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 2\\end{bmatrix}\\) and write the transformation as a matrix multiplication:</p> \\[ T(\\begin{bmatrix}c_1 \\\\ c_2 \\\\ c_3 \\end{bmatrix}) = A\\begin{bmatrix}c_1 \\\\ c_2 \\\\ c_3 \\end{bmatrix} = \\begin{bmatrix}c_2 \\\\ 2c_3\\end{bmatrix} \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/06_transform/#conclusion","title":"Conclusion","text":"<p>For any linear transformation T we can find a matrix A so that \\(T(\\mathbf{v}) = A\\mathbf{v}\\). If the transformation is invertible, the inverse transformation has the matrix \\(A^{-1}\\). The product of two transformations \\(T_1 : \\mathbf{v} \\to A_1 \\mathbf{v}\\) and \\(T_2 : \\mathbf{w} \\to A_2 \\mathbf{w}\\) corresponds to the product \\(A_2A_1\\) of their matrices. This is where matrix multiplication came from!</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/","title":"Change of Basis and Image Compression","text":"<p>We've learned that computations can be made easier by an appropriate choice of basis. One application of this principle is to image compression. Lecture videos, music, and other data sources contain a lot of information; that information can be efficiently stored and transformitted only after we change the basis used to record it.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#compression-of-image","title":"Compression of Image","text":"<p>Suppose one frame of our lecture video is 512 by 512 pixels and that the video is recorded in black and white. the camera records a brightness level for each of the \\(512^2\\) pixels; in this sense, each frame of video is a vector in a \\(512^2\\) dimensional vector space.</p> <p>The standard basis for this space has a vector for each pixel. Transformitting the values of all \\(512^2\\) components of each frame using the standard basis would require far too much bandwidth, but if we change our basis according to the JPEG image compression standard we can transmit a fairly good copy the video very efficiently.</p> <p>For example, if we're reporting light level pixel by pixel, there's no efficient way to transmit the information \"the entire frame is black\". However, if one of our basis vectors corresponds to all pixels having the same light level(say 1), we can very efficiently transmit a recording of a blank blackboard.</p> <p>Along with a vector of all 1's, we might choose a basis vector that alternates 1's and -1's, or one that's half 1's and half -1's corresponding to an image that's bright on the left and dark on the right. Our choice of basis will directly affect how much data we need to download to watch a video, and the best choice of basis for algebra lectures might differ from the best choice for action movies!</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#fourier-basis-vectors","title":"Fourier Basis Vectors","text":"\\[ \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1\\end{bmatrix}, \\begin{bmatrix} 1 \\\\ \\omega \\\\ \\omega^2 \\\\ \\omega^3 \\\\ \\omega^4 \\\\ \\omega^5 \\\\ \\omega^6 \\\\ \\omega^ 7 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ \\omega^2 \\\\ \\omega^4 \\\\ \\omega^6 \\\\ \\omega^8 \\\\ \\omega^{10} \\\\ \\omega^{12} \\\\ \\omega^{14} \\end{bmatrix}, \\cdots, \\begin{bmatrix} 1 \\\\ \\omega^7 \\\\ \\omega^{14} \\\\ \\omega^{21} \\\\ \\omega^{28} \\\\ \\omega^{35} \\\\ \\omega^{42} \\\\ \\omega^{49} \\end{bmatrix} \\] <p>The best known basis is the Fourier basis, which is closely related to the Fourier matrices we studied earlier. The basis used by JPED is made up of cosines - the real part of \\(\\omega^{jk}\\).</p> <p>This method breaks the 512 by 512 rectangle of pixels into blocks that are 8 pixels on a side, each block containing 64 pixels total. The brightness informaton for those pixels is then compressed, possibly by eliminating all coefficients below some threshold chosen so that we can hardly see the difference once they're gone.</p> \\[ \\text{signal } \\mathbf{x} \\xrightarrow{lossless} \\text{64 coefficients } c \\xrightarrow{\\text{lossy compression}} \\hat{c}(\\text{many zeros}) \\to \\mathbf{\\hat{x}} = \\Sigma \\hat{c_i} \\mathbf{v}_ i \\] <p>In video, not only should we consider compressing each frame, we can also consider compressing sequences of frames. There's very little difference between one frame and the next. If we do it right, we only need to encode and compress the difference between frames, not every frame in its entirely.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#the-haar-wavelet-basis","title":"The Haar Wavelet Basis","text":"\\[ \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1\\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ -1 \\\\ -1 \\\\ -1\\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 1 \\\\ -1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ -1 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\cdots, \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ -1 \\end{bmatrix} \\] <p>The closet competitor to the JPEG encoding method uses a wavelet basis. (JPEG2000 improves on the Haar wavelets above.) In Haar's wavelet basis for \\(\\mathbb{R}^8\\), the non-zero entries are half 1's and half -1's (except for the vector of all 1's). However, half or even three quarters of a basis vector's entries may be 0. These vectors are chosen to be orthogonal and can be adjusted to be orthonormal.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#comppression-and-matrices","title":"Comppression and Matrices","text":"<p>Linear algebra is used to find the coefficients \\(c_i\\) in the change of basis from the standard basis (light level for each pixel) to Fourier or wavelet basis. For example, we might want to write:</p> \\[ \\mathbf{x} = c_1 \\mathbf{w}_ 1 + \\cdots + c_8 \\mathbf{w}_ 8 \\] <p>But this is just a linear combination of the wavelet basis vectors. If W is the matrix whose columns are the wavelet vectors, then our task is simply to solve for \\(\\mathbf{c}\\):</p> \\[ \\mathbf{x} = W \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_8\\end{bmatrix} \\] <p>So \\(\\mathbf{c} = W^{-1}\\mathbf{x}\\)</p> <p>Our calculations will be faster and easier if we don't have to spend a lot of time inverting a matrix (e.g. if \\(W^{-1} = W^T\\)) or multiplying by the inverse. So in the field of image compression, the criteria for a good basis are:</p> <ul> <li>Multiplication by the basis matrix and its inverse in fast(as in the FFT or in the wavelet basis).</li> <li>Good compression - the image can be approximated using only a few basis vectors. Most components \\(c_i\\) are small -safely set to zero.</li> </ul>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#change-of-basis","title":"Change of Basis","text":""},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#vectors","title":"Vectors","text":"<p>Let the columns of matrix W be the basis vectors of the new basis. Then if \\(\\mathbf{x}\\) is a vector in the old basis, we can convert it to a vector \\(\\mathbf{c}\\) in the new basis using the relation:</p> \\[ \\mathbf{x} = W \\mathbf{c} \\]"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#transformation-matrices","title":"Transformation Matrices","text":"<p>Suppose we have a linear transformation T. If T has the matrix A when working with the basis \\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ 8\\) and T has the matrix B when working with the basis \\(\\mathbf{w}_ 1, \\mathbf{w}_ 2, \\cdots, \\mathbf{w}_ 8\\), it turns out that A and B must be similar matrices. In other words, \\(B = M^{-1}AM\\) for some change of basis matrix M.</p> <p>Reminder: If we have a basis \\(\\mathbf{v}_ 1, \\mathbf{v}_ 2, \\cdots, \\mathbf{v}_ 8\\) and we know \\(T(\\mathbf{v}_ i)\\) for each i, then we can use the fact that T is a linear transformation to find \\(T(\\mathbf{v}) = c_1 T(\\mathbf{v}_ 1) + c_2 T(\\mathbf{v}_ 2) + \\cdots + c_8 T(\\mathbf{v}_ 8)\\) for any vector \\(\\mathbf{v} = c_1 \\mathbf{v}_ 1 + c_2 \\mathbf{v}_ 2 + \\cdots + c_8 \\mathbf{v}_ 8\\) in the space. The entries of column i of the matrix A are the coefficients of the output vector \\(T(\\mathbf{v}_ i)\\).</p> <p>If our basis consists of eigenvectors of our transformation, i.e. if \\(T(\\mathbf{v}_ i) = \\lambda_i\\mathbf{v}_ i\\), then \\(A = \\Lambda\\), the (diagonal) matrix of eigenvalues. It would be wonderful to use a basis of eigenvectors for image processing, but finding such a basis requires far more computation than simply using a Fourier or wavelet basis.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/07_compression/#summary","title":"Summary","text":"<p>When we change bases, the coefficients of our vectors change according to the rule \\(\\mathbf{x} = W\\mathbf{c}\\). Matrix entries change according to a rule \\(B = M^{-1}AM\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/","title":"Left and Right Inverse; Pseudoinverse","text":"<p>Although pseudoinverse will not appear on the exam, this lecture will help us to prepare.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#two-sided-inverse","title":"Two Sided Inverse","text":"<p>A <code>2-sided inverse</code> of a matrix A is a matrix \\(A^{-1}\\) for which \\(AA^{-1} = I = A^{-1}A\\). This is what we've called the <code>inverse</code> of A. Here \\(r = n = m\\); the matrix A has full rank.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#left-inverse","title":"Left Inverse","text":"<p>Recall that A has full column rank if its columns are independent; i.e. if \\(r = n\\). In this case the nullspace of A contains just the zero vector. The equation \\(A\\mathbf{x} = \\mathbf{b}\\) either has exactly one solution \\(\\mathbf{x}\\) or is not solvable.</p> <p>The matrix \\(A^TA\\) is an invertible n by n symmetric matrix, so \\((A^TA)^{-1} A^TA = I\\). We say \\(A_{left}^{-1} = (A^TA)^{-1}A\\) is <code>left inverse</code> of A. (There may be other left inverses as well, but this is our favorate.) The fact that \\(A^TA\\) is invertible when A has full column rank was central to our discussion of least squares.</p> <p>Note that \\(AA_{left}^{-1}\\) is an m by m matrix which only equals the identity if \\(m = n\\). A rectangular matrix can't have a two sided inverse because either that matrix or its trnaspose has z nonzero nullspace.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#right-inverse","title":"Right Inverse","text":"<p>If A has full row rank, then \\(r = m\\). The nullspace of \\(A^T\\) contains only the zero vector; the rows of A are independent. The equation \\(A \\mathbf{x} =\\mathbf{b}\\) always has at least one solution; the nullspace of A has dimension \\(n - m\\), so there will be \\(n - m\\) free variables and (if \\(n &gt; m\\)) infinitely many solutions.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#pseudoinverse","title":"Pseudoinverse","text":"<p>An invertible matrix(\\(r = m = n\\)) has only the zero vector in its nullspace and left nullspace. A matrix with full column rank \\(r = n\\) has only the zero vector in its nullspace. A matrix with full row rank \\(r = m\\) has only the zero vector in its left nullspace. The remaining case to consider is a matrix A for which \\(r &lt; n\\) and \\(r &lt; m\\).</p> <p>If A has full column rank and \\(A_{left}^{-1} = (A^TA)^{-1} A^T\\), then</p> \\[ AA_{left}^{-1} = A(A^TA)^{-1} A^T = P \\] <p>is the matrix which projects \\(\\mathbf{R}^m\\) onto the column space of A. This is as close as we can get to the product \\(AM = I\\).</p> <p>Similarly, if A has full row rank then \\(A_{right}^{-1}A = A^T(AA^T)^{-1}A\\) is the matrix which projects \\(\\mathbf{R}^n\\) onto the row space of A.</p> <p>It's nontriviall nullspaces that cause trouble when we try to invert matrices. If \\(A\\mathbf{x} =\\mathbf{0}\\) for some nonzero \\(\\mathbf{x}\\), then there's no hope of finding a matrix \\(A^{-1}\\) that will reverse this process to give \\(A^{-1}\\mathbf{0} = \\mathbf{x}\\).</p> <p>The vector \\(A\\mathbf{x}\\) is always in the column space of A. In fact, the correspondence between vectors \\(\\mathbf{x}\\) in the (r dimensional) row space and vectors \\(A\\mathbf{x}\\) in the (r dimensional) column space is one-to-one. In other words, if \\(\\mathbf{x} \\ne \\mathbf{y}\\) are vectors in the row space of A then \\(A\\mathbf{x} \\ne A\\mathbf{y}\\) in the column space of A. (The proof of this would make a good exam question.)</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#proof-that-if-x-y-then-ax-ay","title":"Proof that If x != y then Ax != Ay","text":"<p>Suppose the statement is false. Then we can find \\(\\mathbf{x} \\ne \\mathbf{y}\\) in the row space of A for which \\(A\\mathbf{x}=A\\mathbf{y}\\). But then \\(A(\\mathbf{x} - \\mathbf{y}) = \\mathbf{0}\\), so \\(\\mathbf{x} - \\mathbf{y}\\) is in the nullspace of A. But the row space of A is closed under linear combinations(like subtraction), so \\(\\mathbf{x} - \\mathbf{y}\\) is also in the row space. Then only vector in both the nullspace and the row space is the zero vector, so \\(\\mathbf{x} - \\mathbf{y} =\\mathbf{0}\\). This contradicts our assumption that \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are not equal to each other.</p> <p>We conclude that the mapping \\(\\mathbf{x} \\mapsto A\\mathbf{x}\\) from row space to column space is invertible. The inverse of this operation is called the <code>pseudoinverse</code> and is very useful to statisticians in their work with linear regression - they might not be able to guarantee that their matrices have full column rank \\(r = n\\).</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#finding-the-pseudoinverse-a-plus","title":"Finding the Pseudoinverse A plus","text":"<p>The <code>pseudoinverse</code> \\(A^+\\) of A is the matrix for which \\(\\mathbf{x} = A^+A\\mathbf{x}\\) for all \\(\\mathbf{x}\\) in the row space of A. The nullspace of \\(A^+\\) is the nullspace of \\(A^T\\).</p> <p>We start from the singular value decomposition \\(A = U \\Sigma V^T\\). Recall that \\(\\Sigma\\) is a m by n matrix whose entries are zero except for the singular values \\(\\sigma_1, \\sigma_2, \\cdots, \\sigma_r\\) which appear on the diagonal of its first r rows. The matrices U and V are orthonormal and therefore easy to invert. We only need to find a pseudoinverse for \\(\\Sigma\\).</p> <p>The closet we can get to an inverse for \\(\\Sigma\\) is an n by m matrix \\(\\Sigma^+\\) whose first r rows have \\(1/\\sigma_1, 1/\\sigma_2, \\cdots, 1/\\sigma_r\\) on the diagonal. If \\(r = n = m\\) then \\(\\Sigma^+ = \\Sigma^{-1}\\). Always, the product of \\(\\Sigma\\) and \\(\\Sigma^+\\) is a square matrix whose first r diagonal entries are 1 and whose orther entries are 0.</p> <p>If \\(A = U \\Sigma V^T\\) then its pseudoinverse is \\(A^{+} = V\\Sigma^+U^T\\). Recall that \\(Q^T = Q^{-1}\\) for orthogonal matrices U, V or Q.</p> <p>We would get a similar result if we included non-zero entries in the lower right corner of \\(\\Sigma^+\\), but we prefer not to have extra non-zero entries.</p>"},{"location":"Math/Linear-Algebra/Positive-Definite-Matrices-and-Applications/08_pseudoinverse/#conclusion","title":"Conclusion","text":"<p>Although pseudoinverse will not appear on the exam, many of the topics we covered while discussing them(the four subspaces, the SVD, orthogonal matrices) are likely to appear.</p>"},{"location":"Math/Probability/00_summary/","title":"Summary","text":"<p>TODO</p>"},{"location":"Math/Probability/01_sample_space_and_probability/","title":"Sample Space and Probability","text":"<p>The main objective for probability is to develop the art of describing uncertainty in terms of probabilistic models, as well as the skill of probabilitic reasoning.</p>"},{"location":"Math/Probability/01_sample_space_and_probability/#sets","title":"Sets","text":"<p>A <code>set</code> is a collection of objects, which are the <code>elements</code> of sets.</p>"},{"location":"Math/Probability/01_sample_space_and_probability/#set-notes","title":"Set Notes","text":"<ul> <li>If S is a set and x is an element of S, we write \\(x \\in S\\);</li> <li>If x is not an element of S, we write \\(x \\notin S\\);</li> <li>A set with no elements called <code>empty set</code>, denoted by \\(\\emptyset\\);</li> <li>If S contains a finite number of elements, we write it as a list of elements in braces:</li> </ul> \\[ S = \\{ x_1, x_2, \\cdots, x_n \\} \\] <ul> <li>If S contains infinitely many elements which can be enumerated in a list, we say S is <code>countably infinite</code> and write:</li> </ul> \\[ S = \\{ x_1, x_2, \\cdots \\} \\] <ul> <li>We can alternatively make the set of all x with a certain property P, (the symbol \"|\" can be read as \"such x that satisfy P\"):</li> </ul> \\[ \\{ x | x \\text{ statisfies P} \\} \\] <ul> <li>If every element of S is also a an element of T, we say that S is a <code>subset</code> of T, denoted as \\(S \\subset T\\) or \\(T \\supset S\\);</li> <li>If \\(S \\subset T\\) and \\(T \\subset S\\), the two sets are <code>equal</code>, and we write \\(S = T\\);</li> <li>It's also expedient to introduce a <code>universal set</code>, denoted by \\(\\Omega\\), which contains all objects of interest in a particular context.</li> </ul>"},{"location":"Math/Probability/01_sample_space_and_probability/#set-operations","title":"Set Operations","text":"<ul> <li>The <code>Component</code> of a set S, with respect to the universe \\(\\Omega\\) is the set \\(\\{x \\in \\Omega | x \\notin S \\}\\), denoted by \\(S^c\\). \\(\\Omega^c = \\emptyset\\);</li> <li>The <code>Union</code> of two sets S and T is the set of all elements that belong to S or T, denoted as \\(S \\cup T\\);</li> <li>The <code>Intersection</code> of two sets S and T is the set of all elements that belong to both S and T, denoted as \\(S \\cap T\\);</li> <li>Several sets are said to be <code>disjoint</code> if no two of them have a common element;</li> <li>A collection of sets is said to be a <code>partition</code> of a set S if the sets in the collection are disjoint and their union is S.</li> </ul> <p>Sets and the associated operations are easy to visualize in terms of Venn diagrams.</p>"},{"location":"Math/Probability/01_sample_space_and_probability/#the-algebra-of-sets","title":"The Algebra of Sets","text":"<p>Set operations have several properties:</p> <ul> <li>\\(S \\cup T\\) = \\(T \\cup S\\)</li> <li>\\(S \\cup (T \\cup U)\\) = \\((S \\cup T) \\cup S\\)</li> <li>\\(S \\cap (T \\cup U) = (S \\cap T) \\cup (S \\cap U)\\)</li> <li>\\(S \\cup (T \\cap U) = (S \\cup T) \\cap (S \\cup U)\\)</li> <li>\\((S^c)^c = S\\)</li> <li>\\(S \\cap S^c = \\emptyset\\)</li> <li>\\(S \\cup \\Omega = \\Omega\\)</li> <li>\\(S \\cap \\Omega = S\\)</li> </ul> <p>Two particularly useful properties are given by <code>de MOrgan's laws</code>:</p> \\[ (\\bigcup_n S_n)^c = \\bigcap_n S_n^c \\] \\[ (\\bigcap_n S_n)^c = \\bigcup_n S_n^c \\]"},{"location":"Math/Probability/01_sample_space_and_probability/#probabilistic-models","title":"Probabilistic Models","text":"<p>A probabilistic model is a mathematical description of an uncertain situation. It has two elements:</p> <ol> <li>The <code>sample space</code> \\(\\Omega\\), which is the set of all possible outcomes of an experiment;</li> <li>The <code>probability law</code>, which assigns to a set A of possible outcomes(also called an <code>event</code>) a nonnegtive number \\(P(A)\\)(called the <code>probability</code> of A) that encodes our knowledge or belief about the collective <code>likelihood</code> of the elements of A.</li> </ol> <p></p>"},{"location":"Math/Probability/01_sample_space_and_probability/#sample-space-and-events","title":"Sample Space and Events","text":"<p>Every probabilistic model involves an underlying process, called the <code>experiment</code>, which produces exactly one out of several possible <code>outcomes</code>.  The set of all possible outcomes is called the <code>sample space</code> of the experiment denoted by \\(\\Omega\\). A subset of the sample space, that is, a collection of possible outcomes, is called <code>event</code>.</p>"},{"location":"Math/Probability/01_sample_space_and_probability/#choosing-an-appropriate-sample-space","title":"Choosing an Appropriate Sample Space","text":""},{"location":"Self-Driving/Control/models_for_car_like_vehicles/","title":"Models for car like vehicles","text":"<p>Here we focus on the most commonly used models of mobility of car-like vehicles. Such models are widely used in control and motiong planning algorithms to approximate a vehicle's behavior in response to control actions in relevant operating conditions.</p>"},{"location":"Self-Driving/Control/models_for_car_like_vehicles/#the-kinematic-single-track-model","title":"The Kinematic Single-Track Model","text":"<p>In most basic model of practical use, the car consists of two wheels connected by a rigid link and is restricted to move in a plane. It is assumed that </p> <p>wheel do not slip at their contact point with the ground, but rotate freely about their axes of rotation.</p> <p>The front wheel has an added degree of freedom where it is allowed to rotate about an axis normal to the plane of motion. This is to model steering.</p> <p></p> <ul> <li>\\(p_r\\) and \\(p_f\\) denote the location of <code>rear wheel</code> and <code>front wheel</code> with basis vectors(\\(\\hat{e}_x, \\hat{e}_y, \\hat{e}_z\\))</li> <li>\\(\\theta\\) is the angle discribing the direction that the vehicle is facing</li> <li>\\(\\delta\\) is the steering angle</li> <li>\\(l\\) is the length front rear wheel to front wheel</li> <li>Time derivatives of \\(p_r\\) and \\(p_f\\) are restricted by the noholonomic constraint to the direction indicated by the blue arrows.</li> </ul> <p>Differential constraints will be derived from the coordinate systems consisting of the angle \\(\\theta\\) , together with the motion of one of the points \\(p_r\\) and \\(p_f\\).</p> <p>As the vehicle is rotating at rear wheel, we have:</p> \\[ tan \\delta = \\frac{l}{R} \\] <p>where:</p> <ul> <li>\\(R\\) is the radius of turn</li> </ul> <p>The constraints at rear wheel is:</p> \\[ \\begin{align} \\dot x_r &amp;= v_r \\cdot \\cos{\\theta} \\\\ \\dot y_r &amp;= v_r \\cdot \\sin{\\theta} \\\\ \\dot \\theta &amp;= \\frac{v_r}{l} \\cdot \\tan{\\delta} \\end{align} \\] <p>The constraints at front wheel is:</p> \\[ \\begin{align} \\dot x_f &amp;= v_f \\cdot \\cos{(\\theta + \\delta)} \\\\ \\dot y_f &amp;= v_f \\cdot \\sin{(\\theta + \\delta)} \\\\ \\dot \\theta &amp;= \\frac{v_f}{l} \\cdot \\sin{\\delta} \\end{align} \\] <p>The ralationship between \\(v_f\\) and \\(v_r\\) is:</p> \\[ \\frac{v_r}{v_f} = cos \\delta \\]"},{"location":"Self-Driving/Control/models_for_car_like_vehicles/#kinematic-unicycle-model","title":"Kinematic Unicycle Model","text":"<p>A simplification of above is to select the heading rate \\(\\omega\\) instead of steering angle \\(\\delta\\)\uff1a</p> \\[ \\delta = arctan \\frac{l \\cdot w} {v_r} \\] <p>simplifying the heading dynamics to:</p> \\[ \\dot \\theta = \\omega \\] <p>where:</p> <p>$$ \\omega \\in [\\frac{v_r}{l} tan(\\delta_{min}), \\frac{v_r}{l} tan(\\delta_{max})] $$ An important variant of this model is the case when \\(v_r\\) is fixed. This is sometimes referred to as the <code>Dubins</code> car. Another notable variantion is the <code>Reeds-Shepp</code> car for which minimum length paths are known when \\(v_r\\) takes a single forward and reverse speed.</p>"},{"location":"Self-Driving/Control/models_for_car_like_vehicles/#kinematic-single-track-improved","title":"Kinematic Single-Track Improved","text":"<p>The kinematic models are suitable for planning paths at low speeds where inertial effects are small in comparison to the limitations on mobility imposed by the no-slip assumption. A major drawback of this model is that it permits instaneous steering angle changes which can be problematic if the motion planning module generates solutions with such instantaneous changes.</p> <p>Continuity of the steering angle can be imposed by augmenting, where the steering angle integrates a commanded rate:</p> \\[ \\begin{align} \\dot x_f &amp;= v_f \\cdot \\cos{(\\theta + \\delta)} \\\\ \\dot y_f &amp;= v_f \\cdot \\sin{(\\theta + \\delta)} \\\\ \\dot \\theta &amp;= \\frac{v_f}{l} \\cdot \\sin{\\delta} \\\\ \\dot \\delta &amp;= v_{\\delta} \\end{align} \\] <p>In addition to the limit on the steering angle, the steering rate can now be limited: \\(v_{\\delta} \\in [\\dot \\delta_{min}, \\dot \\delta_{max}]\\). The same problem can arise with the car's speed \\(v_r\\) and can be resolved in the same way. The drawback to this technique is the increased dimension of the model which can complicate motion planning and control problems.</p>"},{"location":"Self-Driving/Control/models_for_car_like_vehicles/#kinematic-single-track-at-center-of-mass-with-slide-angle","title":"Kinematic Single-Track at Center of Mass with Slide Angle","text":"<p>where:</p> <ul> <li>\\(A\\): position of front wheel</li> <li>\\(B\\): position of rear wheel</li> <li>\\(C\\): position of the center of mass</li> <li>\\(O\\): position of the center of turn</li> <li>\\(R\\): radius of the turn</li> <li>\\(\\delta_f\\): steering angle of front wheel</li> <li>\\(\\delta_r\\): steering angle of rear wheel</li> <li>\\((X, Y)\\): position of C</li> <li>\\(\\Psi\\): heading of the vehicle</li> <li>\\(\\beta\\): sliding angle</li> <li>\\(V\\) : velocity of C</li> </ul> <p>Applying the sine rule to triangle OCA:</p> \\[ \\frac{sin(\\delta_f - \\beta)}{l_f} = \\frac{\\frac{\\pi}{2} - \\delta_f}{R} \\tag{1} \\] <p>Applying the sine rule to triangle OCB:</p> \\[ \\frac{sin(\\beta - \\delta_r)}{l_r} = \\frac{sin(\\frac{\\pi}{2} + \\delta_r)}{R} \\tag{2} \\] <p>from (1) we have:</p> \\[ \\frac{sin(\\delta_f)cos(\\beta) - sin(\\beta)cos(\\delta_f)}{l_f} = \\frac{cos(\\delta_f)}{R} \\tag{3} \\] <p>from (2) we have:</p> \\[ \\frac{cos(\\delta_r)sin(\\beta) - cos(\\beta)sin(\\delta_r)}{l_r} = \\frac{cos(\\delta_r)}{R} \\tag{4} \\] <p>Multiply both sides of (3) by \\(\\frac{l_f}{cos(\\delta_f)}\\):</p> \\[ tan(\\delta_f) cos(\\beta) - sin(\\beta) = \\frac{l_f}{R} \\tag{5} \\] <p>Multiply both sides of (44) by \\(\\frac{l_r}{cos(\\delta_r)}\\):</p> \\[ sin(\\beta) - tan(\\delta_r) cos(\\beta) = \\frac{l_r}{R} \\tag{6} \\] <p>Add (5) and (6):</p> \\[ \\{tan(\\delta_f) - tan(\\delta_r)\\} cos(\\beta) = \\frac{l_f + l_r}{R} \\tag{7} \\] <p>If we assume that the radius of the vehicle path changes slowly due to low vehicle speed, then the rate of change of orientation of the vehicle (\\(\\dot \\Psi\\)) must be equal to the angular velocity of the vehicle. Since the angular velocity of the vehicle is \\(\\frac{V}{R}\\), it follows that:</p> \\[ \\dot \\Psi = \\frac{V}{R} \\tag{8} \\] <p>Using (8), (7) can be re-written as:</p> \\[ \\dot \\Psi = \\frac{V cos(\\beta)} {l_f + l_r} (tan(\\delta_f) - tan(\\delta_r)) \\] <p>The final equations of motion are therefore given by:</p> \\[ \\begin{cases} \\dot X &amp;= V cos(\\Psi + \\beta) \\\\ \\dot Y &amp;= V sin(\\Psi + \\beta) \\\\ \\dot \\Psi &amp;= \\frac{V cos(\\beta)} {l_f + l_r} (tan(\\delta_f) - tan(\\delta_r)) \\end{cases} \\] <p>In this model there are three inputs:</p> <ul> <li>\\(\\delta_f\\)</li> <li>\\(\\delta_r\\)</li> <li>\\(V\\)</li> </ul> <p>The velocity \\(V\\) is an external variable and can be asssumed to be a time varying function or can be obtained from a longitudinal vehicle model.</p> <p>The slip angle \\(\\beta\\) can be obtained by multiplying (5) by \\(l_r\\) and subtracting it from (6) multiplied by \\(l_f\\):</p> \\[ \\beta = tan^{-1}(\\frac{l_f tan(\\delta_r) + l_r tan(\\delta_f)}{l_f + l_r}) \\]"},{"location":"Self-Driving/Control/models_for_car_like_vehicles/#dynamic-model","title":"Dynamic Model","text":"<p>When the acceleration of the vehicle is sufficiently large, the no-slip assumption between the tire and ground becomes invalid. In this case a more accurate model for the vehicle is as a rigid body satisfying basic momentum principles. That is, the acceleration is proportional to the force generated by the ground on the tires. Taking \\(p_c\\) to the vehicles center of mass, and a coordinate of the configuration the motion of the vehicle is governed by:</p> \\[ \\begin{align} m \\ddot p_c &amp;= F_f + F_r \\\\ I_{zz} \\ddot \\theta &amp;= (p_c - p_f) \\cdot F_f + (p_c - p_r) \\cdot F_r \\end{align} \\] <p>where:</p> <ul> <li>\\(F_r\\) and \\(F_f\\) are the forces applied to the vehicle by the ground through the ground-tire interaction</li> <li>\\(m\\) is the vehicles total mass</li> <li>\\(I_{zz}\\) is the polar moment of inertia in the \\(\\hat e_z\\) direction about the center of mass</li> </ul> <p></p> <p>The force between the ground and tires is modeled as being dependent on the rate that tire slips on the ground. Although the center of mass serves as a coordinate for the configuration, the velocity of each wheel relative to the ground is needed to determine this relative speed. The kinematic relations between these three points are:</p> \\[ \\begin{align} p_r &amp;= p_c + \\begin{pmatrix} -l_r cos(\\theta) \\\\ -l_r sin(\\theta) \\\\ 0 \\end{pmatrix} \\\\ \\dot p_r &amp;= \\dot p_c + \\begin{pmatrix} 0 \\\\ 0 \\\\ \\dot \\theta \\end{pmatrix} \\times \\begin{pmatrix} -l_r cos(\\theta) \\\\ -l_r sin(\\theta) \\\\ 0 \\end{pmatrix} \\\\ p_f &amp;= p_c + \\begin{pmatrix} l_f cos(\\theta) \\\\ l_f sin(\\theta) \\\\ 0 \\end{pmatrix} \\\\ \\dot p_f &amp;= \\dot p_c + \\begin{pmatrix} 0 \\\\ 0 \\\\ \\dot \\theta  \\end{pmatrix} \\times \\begin{pmatrix} l_f cos(\\theta) \\\\ l_f sin(\\theta) \\\\ 0 \\end{pmatrix} \\\\ \\end{align} \\] <p>These kinematic relations are used to determine the velocities of the point on each tire in contact with the ground, \\(s_r\\) and \\(s_f\\). The velocity of these points are reffered to as the tire slip velocity. In general, \\(s_r\\) and \\(s_f\\) differ from  \\(\\dot p_r\\) and \\(\\dot p_f\\) through the angular velocity of the wheel. The kinematic raltion is:</p> \\[ \\begin{align} s_r &amp;= \\dot p_r + \\omega_r \\times R \\\\ s_f &amp;= \\dot p_f + \\omega_f \\times R \\\\ \\end{align} \\] <p>The angular velocities of the wheels are given by:</p> \\[ \\begin{align} \\omega_r &amp;= \\begin{pmatrix} \\Omega_r sin(\\theta) \\\\ -\\Omega_r cos(\\theta) \\\\ 0 \\end{pmatrix} \\\\ \\omega_f &amp;= \\begin{pmatrix} \\Omega_f sin(\\theta + \\delta) \\\\ -\\Omega_f cos(\\theta + \\delta) \\\\ 0 \\end{pmatrix} \\\\ \\end{align} \\] <p>And \\(R = (0, 0, -r)^T\\). The wheel radius is the scalar quantity \\(r\\), and \\(\\Omega_{r, f}\\) are the angular speeds of each wheel relative to the car.</p> <p></p> <p>Under static conditions, or when the height of the center of mass can be approximated as \\(p_c \\cdot \\hat e_z \\approx 0\\), the compnent of the force normal to the ground, \\(F_{r, f} \\cdot \\hat e_z\\) can be computed from a static force-torque balance as:</p> \\[ F_f \\cdot \\hat e_z = \\frac{l_r m g}{l_f + l_r},  F_r \\cdot \\hat e_z = \\frac{l_f m g}{l_f + l_r} \\] <p>The normal force is then used to compute the traction force on each tire together with the slip and a friction coefficient model, \\(\\mu\\), for the tire behavior. The traction force on the rear tire is given component-wise by:</p> \\[ \\begin{align} F_r \\cdot \\hat e_x &amp;= -\\frac{F_r \\cdot \\hat e_z \\mu \\frac{|| s_r ||}{\\Omega_r r} s_r}{||s_r||} \\cdot \\hat e_x \\\\ F_r \\cdot \\hat e_y &amp;= -\\frac{F_r \\cdot \\hat e_z \\mu \\frac{|| s_r ||}{\\Omega_r r} s_r}{||s_r||} \\cdot \\hat e_y \\\\ \\end{align} \\tag{14} \\] <p>The same expression descripes the front  tire with the r-subscript replaced by an f-subscript. The formula above models the traction force as being anti-parelled to the slip with magnitude proportional to the normal force with a nonlinear dependence on the slip ratio (the magnitude of the slip normalized by \\(\\Omega_r r\\) for the rear and \\(\\Omega_f r\\) for the front). Expressions for the net force on each wheel of the car in terms of the control variables, generalized coordinates, and their velocities. Equation above, together with following model for \\(\\mu\\)</p> \\[ \\mu (\\frac{||s_r||}{\\Omega_r r}) = D sin(C arctan(B \\frac{||s_r||}{\\Omega_r r})) \\tag{15} \\] <p>are a frequently used model for tire interaction with the ground. This equation is a simplified version of the well known model.</p> <p>The rotational symmetry of (14) together with the peak in (15) lead to a maximum norm force that the tire can exert in any direction. This peak is referred to as the friction circle depicted below.</p> <p></p>"},{"location":"Self-Driving/Control/path_tracking/","title":"Path tracking","text":"<p>One of the most popular classes of path tracking methods is geometric tracking. Geometric tracking methods exploit geometric relationships between the vehicle and the path resulting in control law solutions to the path tracking problem. Two of the most commonly used geometric methods are <code>Pure-Pursuit</code> and <code>Stanley Method</code>.</p>"},{"location":"Self-Driving/Control/path_tracking/#pure-pursuit","title":"Pure-Pursuit","text":"<p>Geometric-based pure-pursuit is one of the most basic and simple methods to compute steering wheel angle for lateral controller.</p>"},{"location":"Self-Driving/Control/path_tracking/#bicycle-model","title":"Bicycle Model","text":"<p>The simplest vehicle model for path tracking is the bicycle model, which following the Ackerman steering geometry. The bicycle model simplifies the four wheel car by:</p> <ul> <li>combining the two front wheels together and the two rear wheels together to form a two wheeled model, like a bicycle;</li> <li>the vehicle can only move on a plane.</li> </ul> <p>These simplifications result in a simple geometric relationship between the front wheel steering angle and the curvature that the rear axle will follow.</p> <p>Following is the geometri bicycle model: </p> <p>This simple relationship between front wheel angle and curvature is:</p> \\[ \\tan(\\delta) = \\frac{L}{R} \\tag1 \\] <p>where \\(\\delta\\) is the front wheel steering angle, \\(L\\) is the distance between the front axle to rear axle(wheelbase) and \\(R\\) is the radius of the circle that the rear axle will travel along at the given steering angle. The bicycle model approximates the motion of a car reasonably well at:</p> <ul> <li>low speed;</li> <li>moderate steering angle.</li> </ul>"},{"location":"Self-Driving/Control/path_tracking/#control-law","title":"Control Law","text":"<p>The pure pursuit method consists of geometrically calculating the curvature of a circular arc that connects the rear axle location to a goal point on the path ahead of the vehicle. The goal point is determined from a look-ahead distance \\(l_d\\) from the current rear axle position to the desired path. The goal point \\((g_x, g_y)\\) is illustrated in the figure. The vehicle's steering angle \\(\\delta\\) can be determined using only the goal point location and the angle \\(\\alpha\\) between the vehicle's heading vector and the look-ahead vector.</p> <p>According to the law of sines:</p> \\[ \\frac{l_d}{\\sin(2\\alpha)} = \\frac{R}{\\sin(\\frac{\\pi}{2} - \\alpha)} \\] \\[ \\frac{l_d}{2\\sin(\\alpha)\\cos(\\alpha)} = \\frac{R}{\\cos(\\alpha)} \\] \\[ \\frac{l_d}{\\sin(\\alpha)} = 2R \\tag2 \\] <p>Using \\((1)\\) and \\((2)\\), the pure-pursuit control law is given as:</p> \\[ \\delta = arctan(\\frac{2L\\sin(\\alpha)}{l_d}) \\tag3 \\]"},{"location":"Self-Driving/Control/path_tracking/#tuning","title":"Tuning","text":"<p>From the equation \\((3)\\) we can see that, the angle \\(\\alpha\\) and the distance \\(l_d\\) determine the scale of front wheel steer angle \\(\\delta\\), and both of them are related to goal point's distance on path. A general goal point selected method is:</p> \\[ l_d = l_{min} + v \\cdot t_{ahead} \\] <p>where \\(l_d\\) is the goal point distance, \\(l_min\\) is the minimum look ahead distance, \\(t\\) is the look ahead time time, their value can be determined by tuning.</p>"},{"location":"Self-Driving/Control/path_tracking/#feature","title":"Feature","text":"<p>A short look-ahead distance provides more accurate tracking while a longer distance provides smoother tracking.</p> <p>Advantage:</p> <ul> <li>high level robustness;</li> <li>needs little calculation.</li> </ul> <p>Disadvantage:</p> <ul> <li>look-ahead distance is too small will cause instability and too large will cause bigger cross tracking error, the trade off between stability and tracking performance is difficult to balance;</li> <li>a sufficient look-ahead distance will result in <code>cutting corners</code> while executting turns on the path;</li> <li>a constant look-ahead distance will only fit a certain curvature and speed.</li> </ul>"},{"location":"Self-Driving/Control/path_tracking/#stanley-method","title":"Stanley Method","text":"<p>The Stanley steering controller was deveoped by the Stanford Racing Team and implimented int their autonoumous vehicle for the DARPA Grand Challenge. The controller is based on a non-linear feedback function based on lateral errors measured from the front wheel axle.</p>"},{"location":"Self-Driving/Control/path_tracking/#kinematic-model","title":"Kinematic Model","text":"<p>Following is the kinematic model which assumes the vehicle has negligible inertia. This assumption is effective for low speed driving. </p> <p>\\(v\\) is the automobile's speed; \\(e\\) is the cross-track error between desire path and the guiding wheels; \\(\\psi\\) is the heading with respect to the closet trajectory segment; \\(\\delta\\) is the front wheel steering angle. For forward driving, the guiding wheels are front wheels, and the derivative of the cross-track error is:</p> \\[ \\dot e = v \\cdot \\sin(\\psi - \\delta) \\tag4 \\] <p>while the steering is mechanically limited to \\(|\\delta| &lt; \\delta_{max}\\) The derivative of the yaw angle, the yaw rate, is </p> \\[ \\dot \\psi = - \\frac{v \\cdot \\sin(\\delta)} {a + b} \\tag5 \\] <p>where \\(a\\) and \\(b\\) are the distance from the center of gravity(CG) to the front and rear axle.</p>"},{"location":"Self-Driving/Control/path_tracking/#partial-control-law","title":"Partial Control Law","text":"<p>By inspecting Equation (1) and (2), a controller is selected such that the resulting differential equation has a global asymptotically stable equilibrium at zero cross-track error:</p> \\[ \\delta =  \\begin{cases} \\psi + arctan(\\frac{k \\cdot e}{v}) &amp;  when &amp; |\\psi + \\arctan(\\frac{k \\cdot e}{e})| &lt; \\delta_{max} \\\\\\\\ \\delta_{max} &amp;  when &amp; \\psi + \\arctan(\\frac{k \\cdot e}{e}) \\geqslant \\delta_{max} \\\\\\\\ -\\delta_{max} &amp;  when &amp; \\psi + \\arctan(\\frac{k \\cdot e}{e}) &lt; -\\delta_{max}  \\end{cases} \\tag6 \\]"},{"location":"Self-Driving/Control/path_tracking/#proof-of-the-global-asymptotically-stable-equilibrium","title":"Proof of the Global Asymptotically Stable Equilibrium","text":"<p>Using the steering control law, there are three regions in the phase space of \\(e\\) and \\(\\psi\\): input saturated high, input saturated low and norminal control. When steering command (\\(\\psi + \\arctan(\\frac{k \\cdot e}{v})\\)) is at the steering limit, the equation of this boundary is as a function of \\(e\\):</p> \\[ \\psi_b = -\\arctan(\\frac{k \\cdot e}{v}) \\pm \\delta_{max} \\]"},{"location":"Self-Driving/Control/path_tracking/#for-the-saturated-low-region","title":"For the Saturated Low Region","text":"<p>At this condition, the steering wheel angle is \\(-\\delta_{max}\\), considering Equation (4) and (5):</p> \\[ \\dot e = v \\cdot \\sin(\\psi + \\delta_{max})  \\] \\[ \\dot \\psi = \\frac{v \\cdot \\sin(\\delta_{max})} {a + b}  \\] <p>Because \\(\\delta_{max} &gt; 0\\), \\(\\dot\\psi &gt; 0\\) in this region, and is constant, \\(\\psi = -\\arctan(\\frac{ke}{v}) - \\delta_{max} &lt; 0\\), so \\(\\psi\\) increase linearly with time. Any state in this region will flow into the nominal region with finite time.</p>"},{"location":"Self-Driving/Control/path_tracking/#for-the-saturated-high-region","title":"For the Saturated High Region","text":"<p>At this condition, the steering wheel angle is \\(\\delta_{max}\\), considering Equation (4) and (5):</p> \\[ \\dot e = v \\cdot \\sin(\\psi - \\delta_{max})  \\] \\[ \\dot \\psi = -\\frac{v \\cdot \\sin(\\delta_{max})} {a + b}  \\] <p>Because \\(\\delta_{max} &gt; 0\\), \\(\\dot\\psi &lt; 0\\) in this region, and is constant, \\(\\psi = -\\arctan(\\frac{ke}{v}) + \\delta_{max} &gt; 0\\), so \\(\\psi\\) decrease linearly with time. Any state in this region will flow into the nominal region with finite time.</p>"},{"location":"Self-Driving/Control/path_tracking/#for-the-nominal-region","title":"For the Nominal Region","text":"<p>Substituting Equation (5) into Equation (1) we get:</p> \\[ \\dot e = - v \\cdot \\sin(\\arctan(\\frac{ke}{v})) = \\frac{-ke}{\\sqrt{1 + {\\frac{ke}{v}}^2}} \\tag7 \\] <p>Inside the nominal region, the sign of \\(\\dot e\\) is always opposite to \\(e\\), and for any \\(e\\), \\(\\dot e \\in [ke, v]\\). Thus the value of \\(e\\) will always converge to 0. For \\(\\psi\\), the sign of \\(\\dot\\psi\\) is opposite to \\((\\psi + \\arctan(\\frac{ke}{v}))\\), therefore, the origin is the only stable equilibrium in phase space.</p>"},{"location":"Self-Driving/Control/path_tracking/#optimization","title":"Optimization","text":""},{"location":"Self-Driving/Control/path_tracking/#yaw-damping","title":"Yaw Damping","text":"<p>Using the controller as Equation (6), the tires act as dampers, providing reaction forces to sideways velocities. At low speeds, this stabilities the yaw dynamics, however the magnitude of this reaction is inversely proportional to speed. As speed increase, the damping effect diminishes, creating a need for active damping. Thus </p> \\[k_{d,yaw}(r_{meas} - r_{traj})\\] <p>is added to the steering command, where the \\(k_{d,yaw}\\) is a tuned gain, \\(r_{traj}\\) is the yaw rate for the trajectory, and \\(r_{meas}\\) is the measured yaw rate.</p>"},{"location":"Self-Driving/Control/path_tracking/#actuator","title":"Actuator","text":"<p>The controller commands a steering servo, but time delay and overshot in the servo can cause instablility. One way to prevent this is to add </p> \\[ k_{d,steer}(\\delta_{meas}(i) - \\delta_{meas}(i + 1)) \\] <p>to the steering command, where \\(\\delta_{meas}\\) is the discrete time measurement of the steering angle, and i is the index of the measurement one control period earlier. This provides lead control on the software side. The value of \\(k_{d,steer}\\) is tuned to be large enough to damp the steering wheel response, but small enough to have minimal effect on performance.</p>"},{"location":"Self-Driving/Control/path_tracking/#curvy-road","title":"Curvy Road","text":"<p>Automobiles point inward on curves, to generate lateral acceleration with the front and rear tires. The controller yaw setpoint should be non-zero. The steady state yaw, \\(\\psi_{ss}\\), relative to a constant curvature path, can be found using sums of forces and moments, yielding</p> \\[ \\psi_{ss} = \\frac{mvr_{traj}}{C_y(1 + \\frac{a}{b})} = k_{ag}vr_{traj} /tag8 \\]"},{"location":"Self-Driving/Control/path_tracking/#low-speed","title":"Low Speed","text":"<p>One final modification for driving at low speed prevents the gain term \\(\\frac{k}{v}\\) from becoming so large that it is oversensitive to noise on \\(e\\). A tuned gain, \\(k_{soft}\\), is added to the denominator, permitting control to be arbitrarily soft at low speeds. In experiments, \\(k_{soft} = 1\\) was found appropriate.</p>"},{"location":"Self-Driving/Control/path_tracking/#final-control-law","title":"Final Control Law","text":"<p>So, the complete steering law is</p> \\[ \\delta = (\\psi - \\psi_{ss}) + \\arctan(\\frac{ke}{k_{soft} + v}) + k_{d,yaw}(r_{meas} - r_{traj}) + k_{d,steer}(\\delta_{meas}(i) - \\delta_{meas}(i + 1)) \\] <p>with saturation at \\(\\pm\\delta_{max}\\).</p>"},{"location":"Self-Driving/Control/path_tracking/#reference","title":"Reference","text":"<ol> <li>Automatic Steering Methods for Autonomous Automobile Path Tracking</li> <li>Autonomous Automobile Trajectory Tracking for Off-Road Driving: Controller Design, Experimental Validation and Racing</li> <li>Dynamic Speed Adaptation for Path Tracking Based on Curvature Information and Speed Limits</li> </ol>"},{"location":"Self-Driving/Map/hdmap/","title":"Autonomous Hdmap Format","text":"<p>After collecting map data, we need to describe the map in detail and store it, which needs <code>HD Map</code> format. There are two generally used data standards in the world for <code>HD Map</code>: NDS(Navigation Data Standard) and OpenDRIVE. Based on OpenDRIVE format, Baidu develop its own format, <code>appollo OpenDRIVE</code>.</p>"},{"location":"Self-Driving/Map/hdmap/#navigation-data-standard","title":"Navigation Data Standard","text":"<p>The Navigation Data Standard(NDS) is a standardized format for automotive-grade navigation databases, jointly developed by automobile manufactures and supplies. NDS is an association registered in Germany, members are automotive OEMs, map data providers, and navigation device/applications providers. NDS seperates navigation software from navigation data, thus enhancing flexibility for creating various navigation products for end users. In addition to this interoperability, NDS databases support incremental updates, protection against illegal use and compactness.</p> <p>NDS uses the SQLite Database File Format. An NDS database can consist of several product databases, and each product database may be divided further into update regions. This concept supports a flexible and consistent versioning concept for NDS databases and makes it possible to integrate databases from different database suppliers into one NDS database.</p> <p>NDS format is very heavy, there is little usage in china, it's mainly used by big OEMs like BMW, Daimler and Volkswagen.</p>"},{"location":"Self-Driving/Map/hdmap/#opendrive","title":"OpenDRIVE","text":"<p>OpenDRIVE is an open format specification to describe a road network's logic, its objective is to standardize the logical road description to facilitate the data exchange between different driving simulators.</p>"},{"location":"Self-Driving/Map/hdmap/#co-ordinate-systems","title":"Co-ordinate Systems","text":"<p>OpenDRIVE uses two co-ordinate systems: track system for road and lane and inertial system for point.</p>"},{"location":"Self-Driving/Map/hdmap/#track-system","title":"Track System","text":"<p>The Track co-ordinate system applies along the reference line of the road. It is a right-handed co-ordinate system. The following degrees of freedom are defined:</p> <p> </p> <ul> <li>\\(s\\): poistion along reference line, measured in [m] from the beginning of the track;</li> <li>\\(t\\): lateral position, positive to the left;</li> <li>\\(h\\): height position, positive to the up;</li> <li>\\(heading\\): around \\(h-axis\\);</li> <li>\\(pitch\\): around \\(t-axis\\);</li> <li>\\(roll\\): around \\(s-axis\\);</li> </ul>"},{"location":"Self-Driving/Map/hdmap/#inertial-system","title":"Inertial System","text":"<p>The inertial system is a right-handed co-ordinate system according to ISO 8855 projected on a drawing plane with the axes pointing to the following directions: </p> <ul> <li>\\(x\\): right(east);</li> <li>\\(y\\): up(north);</li> <li>\\(z\\): coming out of drawing plane(up);</li> <li>\\(heading\\): around \\(z-axis\\), 0 = direction of \\(x-axis/east\\);</li> <li>\\(pitch\\): around \\(y-axis\\);</li> <li>\\(roll\\): around \\(x-axis\\);</li> </ul>"},{"location":"Self-Driving/Map/hdmap/#road-layout","title":"Road Layout","text":"<p>A full overview of OpenDRIVE road layout can be shown below:</p> <p></p> <p>All roads contain a reference line which defines the basic geometry(arcs, straight lines etc.). Along the reference line, various properties of the road can be defined like elevation profile, lanes, traffic signs, etc. Roads can be linked to each other directly(see road1 and road2) or via junctions(see road2 and road6).</p> <p>The convention applies that properties of the same type defined along a single reference line must be listed in ascending order. </p>"},{"location":"Self-Driving/Map/hdmap/#reference-line","title":"Reference Line","text":"<p>The geometry of the reference line is described as a sequence of primitives of various types. The available primitives are:</p> <ul> <li>straight line: constant zero curvature;</li> <li>spiral line: linear change of curvature;</li> <li>curve line: constant non-zero curvature along run-length;</li> <li>cubic polynom: expenstion as \\(ax^3 + bx^2 + cx + d\\);</li> <li>parametric cubic curves.</li> </ul> <p>The following figure illustrates the composition of a reference line from some of the above mentioned elements.</p> <p></p> <p>In OpenDRIVE format, reference line is described by <code>geometry</code> under <code>planView</code> element. For example, the reference line above can be described as: <pre><code>&lt;planView&gt;\n  &lt;geometry s=\"0.0\" x=\"-7.07\" y=\"7.07\" hdg=\"5.49\" length=\"5.0\"/&gt;\n    &lt;line/&gt;\n  &lt;geometry s=\"5.0\" x=\"-9.57\" y=\"12.36\" hdg=\"0.4\" length=\"5.0\"/&gt;\n    &lt;spiral curvStart=\"0.0\" curvEnd=\"-3.0\"/&gt;\n  &lt;geometry s=\"10.0\" x=\"-12.33\" y=\"16.17\" hdg=\"1.9\" length=\"5.0\"/&gt;\n    &lt;spiral curvature=\"-3.0\"/&gt;\n&lt;/planView&gt;\n</code></pre> A road may contains more than one reference line, it depends on the road shape. In above xml code, \\(x\\), \\(y\\), \\(hdg\\) are start point's position\\((x, y)\\) and initial angle.</p>"},{"location":"Self-Driving/Map/hdmap/#lanes","title":"Lanes","text":"<p>Lanes are identified by numbers which are:</p> <ul> <li>unique</li> <li>insequence</li> <li>starting from 0 on reference line</li> <li>ascending to the left</li> <li>descending to the right</li> </ul> <p>The total number of lanes is not limited. The reference line is defined as lane zero and must not have a width entry. A road may contains many lanes, and lane has its width and <code>roadMark</code> like dotted line, solid line, double lines, etc.</p>"},{"location":"Self-Driving/Map/hdmap/#lane-offset","title":"Lane Offset","text":"<p>In certain situations(see raod picture above) it may be more convenient to shift the lane profile instead of shifting the reference line.</p>"},{"location":"Self-Driving/Map/hdmap/#lane-sections","title":"Lane Sections","text":"<p>The lanes appearing in a given cross-section along the road are defined in so-called lane sections. Multiple lane sections may be defined in ascending order along a reference line. Per lane section, the number of lanes is constant. However, the properties of each lane(e.g. width, road marks, friction etc.) may change.</p>"},{"location":"Self-Driving/Map/hdmap/#lane-properties","title":"Lane Properties","text":"<p>Lane properties are defined to the start of the corresponding lane section. Offset start at 0.0 for the beginning of the lane section and increase corresponding to the road co-ordinate s. In OpenDRIVE, <code>width</code> defines the width of the lane, and <code>roadMark</code> defines the properties of lane. The lane properties can be following:</p> <ul> <li>none</li> <li>solid</li> <li>broken</li> <li>solid solid (for double solid line)</li> <li>solid broken (from inside to outside, exception: center lane - from left to right)</li> <li>broken solid (from inside to outside, exception: center lane - from left to right)</li> <li>broken broken (from inside to outside, exception: center lane - from left to right)</li> <li>botts dots</li> <li>grass (meaning a grass edge)</li> <li>curb</li> </ul>"},{"location":"Self-Driving/Map/hdmap/#superelevation-and-crossfall","title":"Superelevation and Crossfall","text":"<p>In many cases, a road's cross section will not be parallel to the underlying terrain. Instead, it will be elevanted to one side (e.g. in curves) or to the center(for drainage). Both properties are covered by the OpenDRIVE format with the former being called \"superelevation\" and the latter \"crossfall\".</p> <p></p>"},{"location":"Self-Driving/Map/hdmap/#road-linkage","title":"Road Linkage","text":"<p>In order to navigate through a road network, the application must know the linkage between different roads. Two types of linkage are possible:</p> <ul> <li>successor/predecessor linkage (standard linkage)</li> <li>junctions</li> </ul> <p>Whenever the linkage between two roads is clear, a standard linkage is sufficient. A junction is required when the successor or predecessor relationship of a road is ambiguous.</p>"},{"location":"Self-Driving/Map/hdmap/#junctions","title":"Junctions","text":"<p>Junctions link in-coming roads via paths(connecting roads) to out-going roads.</p> <p>In road layout figure, Road 2 is a in-coming road, Road 6 - 8 are out-going roads, Road 3 - 5 are connecting roads.</p> <p>Junctions consist of a connection matrix which indicates all possibilities to enter a connecting road from a given in-coming road. These connections are listed on a per-lane basis in order to facilitate navigation. Once a connecting road is entered, the following connection to the corresponding outgoing road can be retrieved from the general successor/predecessor information that is stored with each road.</p>"},{"location":"Self-Driving/Map/hdmap/#surface","title":"Surface","text":"<p>OpenDRIVE provides two approaches for describing surface properties:</p> <ul> <li>Standard description: a <code>&lt;material&gt;</code> record may be defined per lane of the road, providing parameters for:<ul> <li>surface material code</li> <li>roughness</li> <li>friction</li> </ul> </li> <li>Extended description: A more detailed description of road surface data may be provided within the newly introduced <code>&lt;surface&gt;</code> record. OpenDRIVE provides reference to the respective data files, formats supported are listed below:<ul> <li>Open Curved Regular Grid (OpenCRG)</li> </ul> </li> </ul>"},{"location":"Self-Driving/Map/hdmap/#apollo-opendrive","title":"Apollo OpenDRIVE","text":"<p>OpenDRIVE format is mainly designed for simulator, it lacks lots of information that autodirve need. Apollo OpenDRIVE is based on OpenDRIVE and expends some specifications.  </p> <p>Some concepts may cause ambiguity:</p> <ul> <li>overlap: link two elements, describe two elements's spatial relations. If two elements have overlaps, we make them a Overlap. For example, Deceleration Zone on a Lane, or Stop Zone on a Lane</li> <li>virtual lane: guide the driving at intersection</li> <li>left sample: distance between lane center and left boundary</li> <li>right sample: distance between lane center and right boundary</li> <li>co-ordinate system: utm, WGS84</li> </ul>"},{"location":"Self-Driving/Map/hdmap/#main-difference","title":"Main Difference","text":"<p> Apollo OpenDRIVE change the discription of elements' shape and classify all the elements: all the roadMark are classified into Objects; all the signals classified into Signal; use Overlap to link them.</p> No. Iterm OpenDRIVE Apollo OpenDRIVE Note 1 The description of elements' shape Equations Co-ordination Point 2 The expansion of elements' type - Add no-stop area, crosswalk, deceleration zone, etc. 3 The expansion of linkage between elements - Add the linkage between junction and elements inside junctions 4 Other expansion - Add the distance between lane center and road boundary, linkage between stop line and traffic lights"},{"location":"Self-Driving/Map/hdmap/#reference","title":"Reference","text":"<ul> <li>wikipedia-Navigation Data Standard</li> <li>wikipedia-OpenDRIVE</li> <li>OpenDRIVE Format Spec Rev 1.5</li> <li>OpenDrive\u683c\u5f0f\u5730\u56fe\u6570\u636e\u89e3\u6790</li> <li>Apollo\u9ad8\u7cbe\u5730\u56fe\u8be6\u89e3</li> </ul>"},{"location":"Self-Driving/Planning/00_summary/","title":"Summary","text":"<p>Path-planning is an important primitive for autonomous mobile robots that lets robots find the shortest(or otherwise optimal) path between two points. Otherwise optimal paths could be paths that minimize the amount of turning, the amount of braking or whatever a specific application requires. Algorithms to find a shortest path are important not only in robotics, but also in network routing, video games and gene sequencing.</p>"},{"location":"Self-Driving/Planning/00_summary/#basic-requirements","title":"Basic Requirements","text":"<p>There are three basic requirements for motion planning:</p> <ul> <li>Safey: collision avoidance</li> <li>Smoothness: energy saving and comfortable </li> <li>Kinodynamic feasibility: executable, controllable</li> </ul>"},{"location":"Self-Driving/Planning/00_summary/#methods-for-motion-planning","title":"Methods for Motion Planning","text":"<p>The old-school pipeline of motion planing is:</p> <ul> <li>Front-end path finding<ul> <li>Search for an initial safe path</li> <li>Low dimensional</li> <li>Discrete space</li> </ul> </li> <li>Back-end trajectory generation<ul> <li>Search for an executable trajectory</li> <li>High dimensional</li> <li>Continous space</li> </ul> </li> </ul> <p>And the general methods includes:</p> <ul> <li>Front-end: Path finding<ul> <li>Search-based Path Finding<ul> <li>Graph Search Basis</li> <li>Dijkstra and A*</li> <li>Jump Point Search</li> </ul> </li> <li>Sampling-Based Path Finding<ul> <li>Probabilistic Road Map</li> <li>Rapidly-exploring Random Tree(RRT)</li> <li>Optimal Sampling-Based Methods</li> <li>Advanced Sampling-based Methods</li> </ul> </li> <li>Kinodynamic Path Finding<ul> <li>State-state Boundary Value Optimal Control Problem</li> <li>State Lattice Search</li> <li>Kinodynamic RRT*</li> <li>Hybrid A*</li> </ul> </li> </ul> </li> <li>Back-end: Trajectory Generation<ul> <li>Minimum Snap Trajectory Generation<ul> <li>Differential Flatness</li> <li>Minimum Snap Optimization </li> <li>Closed-form Solution to Minimum Snap</li> <li>Time Allocation</li> <li>Implementation in Practice</li> </ul> </li> <li>Soft and Hard Constrained Trajectory Optimization<ul> <li>Soft Constrained Trajectory Optimization</li> <li>Hard Constrained Trajectory Optimization</li> </ul> </li> </ul> </li> <li>MDP &amp; MPC<ul> <li>Markov Decision Process-based Planning<ul> <li>Uncertainties in Planning and MDP</li> <li>Minimax Cost Planning and Excected Cost Minimal Planning</li> <li>Value Iteration and Real-Time Dynamic Programming</li> </ul> </li> <li>Model Prediction Control for robotics Planning<ul> <li>Linear MPC</li> <li>Non-linear MPC</li> </ul> </li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/00_summary/#reference","title":"Reference","text":"<ul> <li>Motion Planning for Mobile Robots</li> </ul>"},{"location":"Self-Driving/Planning/01_search/","title":"Search-based Path Finding","text":""},{"location":"Self-Driving/Planning/01_search/#graph-search-basis","title":"Graph Search Basis","text":""},{"location":"Self-Driving/Planning/01_search/#configuration-space","title":"Configuration Space","text":"<p>Here are some definations:</p> <ul> <li><code>Robot Configuration</code>: a specification of the positions of all points of the robot</li> <li><code>Degree of Freedom(DOF)</code>: the minimum number \\(n\\) of real-valued coordinates needed to represent the robot configuration</li> <li><code>Configuration Space</code>: a n-dim space containing all possible robot configurations, denoted as <code>C-space</code>, and each robot pose is a point in the C-space</li> </ul> <p>Because:</p> <ul> <li>robot has different shape and size</li> <li>Collision detection requires knowing the robot geometry, which is time consuming and hard</li> </ul> <p>we choose to do planning in configuration space. A transformation is as below:</p> <p></p> <ul> <li>Robot is represented by a point in C-space, e.g. position(a point in \\(\\mathbb{R}^3\\)), pose(a point in \\(SO(3)\\)), etc.</li> <li>Obstacles need to be represented in configuration space(one-time work prior to motion planning), called configuration space obstacle, or C-obstacle</li> <li>\\(\\text{C-space} = \\text{C-obstacle} \\cup \\text{C-free}\\)</li> <li>The path planning is finding a path between start point \\(q_{start}\\) and goal point \\(q_{goal}\\) within \\(\\text{C-free}\\)</li> </ul> <p>The basic introduction for graph and search methods can be found in Coding/Algorithm/Graph.</p>"},{"location":"Self-Driving/Planning/01_search/#heuristic-search","title":"Heuristic Search","text":"<p>BFS(Breadth First Search) and DFS(Depth First Search) pick the next node off the frontiers based on which was \"first in\" or \"last in\", and Greedy Best First picks the \"best\" node according to some rule, called a <code>heuristic</code>.</p> <p>A Heuristic is a <code>guess</code> of how close you are to the target. There are many kinds of heuristics for distance estimation:</p> <ul> <li>Euclidean Distance</li> <li>Manhattan Distance</li> <li>Diagonal Distance</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#dijkstra","title":"Dijkstra","text":"<p>Dijkstra expands/visits the node with the <code>cheapest accumulated cost g(n)</code>, where</p> <ul> <li>\\(g(n)\\) is the current best estimates of the accumulated cost from the start state to node <code>n</code>;</li> <li>Update the accumulated costs \\(g(m)\\) for all unexpanded neighbors <code>m</code> of node <code>n</code></li> <li>A node that has been expanded/visited is guaranteed to have the smallest cost from the start state.</li> </ul> <p>A work flow for dijkstra can be:</p> <ul> <li>Maintain a <code>priority queue</code> to store all the nodes to be expanded</li> <li>The priority queue is initialized with the start state \\(X_s\\)</li> <li>Assign \\(g(X_s) = 0\\) and \\(g(n) = infinite\\) for all other nodes in graph</li> <li>Loop:<ul> <li>If the queue is empty, return <code>False</code>, break;</li> <li>Remove the node n with the lowest \\(g(n)\\) from the priority queue</li> <li>Mark node n as expanded</li> <li>If the node n is the goal state, return <code>True</code>, break</li> <li>For all unexpanded neighbors \"m\" of \"n\":<ul> <li>If \\(g(m) == infinite\\)<ul> <li>\\(g(m)=g(n) + C_{nm}\\)</li> <li>Push node \"m\" into the queue</li> </ul> </li> <li>If \\(g(m) &gt; g(n) + C_{nm}\\)<ul> <li>\\(g(m) = g(n) + C_{nm}\\)</li> </ul> </li> </ul> </li> </ul> </li> <li>End Loop</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#pros-and-cons","title":"Pros and Cons","text":"<ul> <li>Pros<ul> <li>Complete and optimal</li> </ul> </li> <li>Cons<ul> <li>Can only see the cost accumulated so far, thus exploring next station in every <code>direction</code></li> <li>No information about goal location</li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/01_search/#a","title":"A*","text":"<p>The A star algorithm is a dijkstra with a heuristic. It expands the node with cheapest cost \\(f(n) = g(n) + h(n)\\), where</p> <ul> <li>\\(g(n)\\) is the current best estimates of the accumulated cost from the start state to node <code>n</code></li> <li>\\(h(n)\\) is the estimated least cost from the node <code>n</code> to goal state.</li> </ul> <p>A general workflow is:</p> <ul> <li>Maintain a <code>priority queue</code> to store all the nodes to be expanded</li> <li>The priority queue is initialized with the start state \\(X_s\\)</li> <li>Assign \\(g(X_s) = 0\\) and \\(g(n) = infinite\\) for all other nodes in graph</li> <li>Loop:<ul> <li>If the queue is empty, return <code>False</code>, break;</li> <li>Remove the node n with the lowest \\(f(n) = g(n) + h(n)\\) from the priority queue</li> <li>Mark node n as expanded</li> <li>If the node n is the goal state, return <code>True</code>, break</li> <li>For all unexpanded neighbors \"m\" of \"n\":<ul> <li>If \\(g(m) == infinite\\)<ul> <li>\\(g(m)=g(n) + C_{nm}\\)</li> <li>Push node \"m\" into the queue</li> </ul> </li> <li>If \\(g(m) &gt; g(n) + C_{nm}\\)<ul> <li>\\(g(m) = g(n) + C_{nm}\\)</li> </ul> </li> </ul> </li> </ul> </li> <li>End Loop</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#optimality","title":"Optimality","text":"<p><code>A*</code> has optimality only if:</p> \\[ h(n) \\le h_{real}(n) \\] <p>where \\(h(n)_{real}\\) is the true least cost to goal from node \"n\".</p> <ul> <li>if \\(h(n) &lt;&lt; h_{real}(n)\\), then the solution is optimal, but the searching speed will be slow;</li> <li>if \\(h(n)  &gt; h_{real}(n)\\), the solution is not optimal, which means that the path found by <code>A*</code> may not be the shortest path;</li> <li>if \\(h(n)  = h_{real}(n)\\), the solution is optimal and the speed is the fastest.</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#speed-up-a","title":"Speed up <code>A*</code>","text":""},{"location":"Self-Driving/Planning/01_search/#the-best-heuristic","title":"The best heuristic","text":"<p>Even if we have an optimal heuristic cost, there is still something to optimize. For example, if we use the \\(f(n) = g(n)\\) as cost function, we can surely find the shortest path, but the speed is slow. The closer our heuristic cost is to the actual distance from node to goal, the less steps we go through to reach the goal.</p> <p></p>"},{"location":"Self-Driving/Planning/01_search/#tie-breaker","title":"Tie breaker","text":"<p>In a 2D path without any obstacles, many paths have the same \\(f(n)\\) value. There is no differences among them which makes them explored by <code>A*</code> equally.</p> <p></p> <p>We can change the \\(f(n)\\) value slightly to break the tie:</p> <ul> <li>Interfere \\(h\\) slightly: \\(h = h * (1.0 + p)\\), where \\(p &lt; \\frac{\\text{minimum cost of one step}} {\\text{expected maximum path cost}}\\);</li> <li>when \\(f\\) is the same, compares \\(h\\);</li> <li>add deterministic random numbers to the heuristic or edge costs(A hash of the coordinates);</li> <li>prefer paths that are along the straight line from the starting point to the goal;</li> <li>other more...</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#jump-point-search","title":"Jump Point Search","text":"<p>Jump point search is a systematic approach to solve the tie problem of <code>A*</code>. The core idea of JPS is to find the symmetry and break them.</p> <p></p> <p>JPS explores intelligently, becasue it always looks ahead and jump.</p>"},{"location":"Self-Driving/Planning/01_search/#look-ahead-rule","title":"Look ahead rule","text":"<ul> <li>Neighbor pruning:<ul> <li>gray node: inferior neighbors, when going to them, the path without x is cheaper, Discard.</li> <li>white node: nutural neighbors.</li> <li>we only need to consider natural neighbors when expand the search.</li> </ul> </li> <li>Forced neighbors<ul> <li>There is obstacle adjacent to x.</li> <li>Red nodes are forced neighbors.</li> <li>A cheaper path from x's parent to them is blocked by obstacle.</li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/01_search/#jumping-rule","title":"Jumping rule","text":"<ul> <li>Recursively apply straight pruning rule and identify y as a jump point successor of x. This node is interesting because it has a neighbor z that can not reached optimally except by a path that visit x then y.</li> <li>Recursively apply the diagonal pruning rulea and identify y as a jump point successor of x.</li> <li>Before each diagonal step we first recurse straight. Only if both straight recursions fail to identify a jmp point do we step diagonally again.</li> <li>Node w, a forced neighbor of x, is expanded as normal.</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#conclusion","title":"Conclusion","text":"<ul> <li>Most time, especially in complex environments, JPS is better, but far away from alway. For example, a large map with not many obstacles, JPS may be slower than <code>A*</code>.</li> <li>JPS reduces the number of nodes in <code>open list</code>, but increase the number of status query.</li> <li>JPS' limitation: only applicable to uniform grid map.</li> </ul>"},{"location":"Self-Driving/Planning/01_search/#practice","title":"Practice","text":""},{"location":"Self-Driving/Planning/02_sample/","title":"Sample-based Path Finding","text":"<p>Sampling-based planner has following features:</p> <ul> <li>Do not attempt to explicitly construct the C-space and its boundaries</li> <li>Simply need to know if a single robot configuration is in collision</li> <li>Exploits simple tests for collision with full knowledge of the space</li> <li>Collision detection is a separate module, and can be tailored to the application</li> <li>As collision detection improves, so do these algorithms</li> <li>Different approaches for single-query and multi-query requests</li> </ul> <p>Some notions of completeness in planning:</p> <ul> <li><code>Complete Planner</code>: always answers a path planning query correctly in bounded time</li> <li><code>Probabilistic Complete Planner</code>: if a solution exists, planner will eventrually find it, using random sampling(e.g. Monte Carlo sampling)</li> <li><code>Resolution Complete Planner</code>: same as above but based on a deterministic sampling(e.g. sampling on a fixed grid)</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#probabilistic-road-map","title":"Probabilistic Road Map","text":"<p>A <code>PRM</code>(Probablistic Road Map) is:</p> <ul> <li>A graph structure</li> <li>Dividing planning into two phases:<ul> <li>Learning phase</li> <li>Query phase</li> </ul> </li> <li>Checking sampled configurations and connections between samples for collision can be done efficiently</li> <li>A relatively small number of milestones and local paths are sufficient to capture the connectivity of the free space</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#learning-phase","title":"Learning Phase","text":"<ul> <li>Sample N points in C-space</li> <li>Delete points that are not collision-free</li> <li>Connect to nearest points and get collision-free segments</li> <li>Delete segments that are not collision free</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#query-phase","title":"Query Phase","text":"<ul> <li>Search on the road map to find a path from the start to the goal(using Dijkstra or A star algortihm)</li> <li>Road map is now similar with the grid map(or a simplified grid map) </li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#pros","title":"Pros","text":"<ul> <li>probabilitically complete</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#cons","title":"Cons","text":"<ul> <li>Required to solve 2 point boundary value problem</li> <li>Build graph over state space but no particular focus on generating a path</li> <li>Not efficiet</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#lazy-collision-checking","title":"Lazy Collision-checking","text":"<p>To improving efficiency of PRM, we can use lazy collision-checking</p> <ul> <li>Collision-checking process is time-consuming, especially in complex or high-dimensional environments</li> <li>Sample points and generate segments without considering the collision(<code>lazy</code>)</li> <li>Find a path on the road map generated without collision checking</li> <li>Delete the corresponding edges and nodes if the path is not collision free</li> <li>Restart path-finding</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#rapidly-exploring-random-treerrt","title":"Rapidly-exploring Random Tree(RRT)","text":"<p>RRT builds up a tree through generating <code>next states</code> in the tree by executing random controls. The algorithm process is:</p> <p></p> <ul> <li>get a random point from C-space \\(x_{rand}\\)</li> <li>check the nearest point \\(x_{near}\\) from rrt-tree </li> <li>move from \\(x_{near}\\) to \\(x_{rand}\\) by a distance \\(step_size\\) to get a new point \\(x_{new}\\)</li> <li>if \\(x_{new}\\) is collision-free, add it to the rrt-tree</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#pros_1","title":"Pros","text":"<ul> <li>Aims to find a path from the start to the goal</li> <li>More target-oriented than PRM</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#cons_1","title":"Cons","text":"<ul> <li>Not optimal solution</li> <li>Not efficient(leave room for improvement)</li> <li>Sample in the whole space</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#kd-tree","title":"KD Tree","text":"<p>We can use Kd-tree to accumulate the search nearest point process.</p> <p>A detail describe can be found kd-tree</p> <p> </p>"},{"location":"Self-Driving/Planning/02_sample/#bidirectional-rrtrrt-connect","title":"Bidirectional RRT/RRT Connect","text":"<p>We can also grow the tree from both start point and the goal point, the path would be found when two trees are connected.</p> <p></p>"},{"location":"Self-Driving/Planning/02_sample/#optimal-sampling-based-path-planning-methods","title":"Optimal Sampling-based Path Planning Methods","text":""},{"location":"Self-Driving/Planning/02_sample/#rrt","title":"RRT*","text":"<p>The difference between RRT and RRT star is:</p> <p>After adding a new node to RRT tree, RRT* check all nodes around the new added node.</p> <p>If surrounding points can get to start point with lower cost through the new node, they change their parents to the new node. That's the rewire step.</p>"},{"location":"Self-Driving/Planning/02_sample/#kinodynamic-rrt","title":"Kinodynamic-RRT*","text":"<p>Kinodynamic-RRT* changes the steer step of RRT* to fit with motion or other constraints in robot navigation.</p> <ul> <li>Kinodynamic RRT*: Optimal Motion Planning for Systems with Linear Differential Constraints</li> <li>video</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#anytime-rrt","title":"Anytime RRT*","text":"<p>Keep optimizing the leaf RRT Tree when the robot executes the current trajectory Anytime Fashion.</p> <ul> <li>Anytime Motion Planning using the RRT*</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#advanced-path-planning-methods","title":"Advanced Path Planning Methods","text":""},{"location":"Self-Driving/Planning/02_sample/#informed-rrt","title":"Informed RRT*","text":"<p>Informed RRT* makes the RRT tree to grow only in an ellipse, start point and end point are ellipse's two focal points, and the distance from curve to focal points is the length of path. If a new path shorter is found, the distance will decrease. </p> <ul> <li>Informed RRT*: Optimal sampling-based path planning focused via direct sampling of an admissible ellipsoidal heuristic</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#cross-entropy-motion-planning","title":"Cross-entropy Motion Planning","text":"<ul> <li>Cross-entropy motion planning</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#other-variants","title":"Other Variants","text":"<ul> <li>Lower Bound Tree RRT</li> <li>Sparse Stable RRT</li> <li>Transition-based RRT</li> <li>Vector Field RRT</li> <li>Parallel RRT</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#some-materials","title":"Some Materials","text":"<ul> <li>An Overview of the Class of Rapidly-Exploring Random Trees</li> <li>RRT</li> <li>Asymptotically near-optimal RRT for fast, high-quality, motion planning</li> <li>SST software</li> <li>Transition-based RRT for Path Planning in Continuous Cost Spaces</li> <li>VF-RRT: Introducing optimization into randomized motion planning</li> <li>Parallel Sampling-Based Motion Planning with Superlinear Speedup</li> <li>Charle Wong's Github</li> </ul>"},{"location":"Self-Driving/Planning/02_sample/#implementation","title":"Implementation","text":"<ul> <li>ROS Training</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/","title":"Kinodynamic Path Finding","text":""},{"location":"Self-Driving/Planning/03_kinodynamic/#introduction","title":"Introduction","text":"<p>The <code>kinodynamic</code> planning problem is to synthesize a robot subject to simultaneous </p> <ul> <li><code>kinematic</code> constraints, such as <code>avoiding obstacles</code></li> <li><code>dynamic</code> constraints, such as modulus <code>bounds on velocity, acceleration, and force</code></li> </ul> <p>A kinodynamic solution is a mapping from time to generalized forces or accelerations.</p> <p>We choose kinodynamic planning because:</p> <ul> <li>Straight-line connections between pairs of states are typically not valid trajectories due to the system's <code>differential constraints</code>.</li> <li>The smoother the path we found, the easier we optimize it.</li> <li>Coarse-to-fine process</li> <li>Trajectory only optimizes locally</li> <li>Infeasible path means nothing to nonholonomic system</li> </ul> <p></p> <p>The typical models we used are:</p> <ul> <li>Unicycle model:</li> </ul> <p></p> <ul> <li>Bicycle model:</li> </ul> <p></p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#state-lattice-planning","title":"State Lattice Planning","text":"<p>As learned in search-based path finding, we have many weapons to attack graph search. But to assume the robot a mass point is not satisfactory any more, we require a graph with <code>feasible motion connections</code> now.</p> <p>The search-based path finding is actually a discretization of control space with the assumption that the robot can move in 4/8 directions:</p> <p></p> <p>And the sample-based path finding is a discretization of state sapce where the state is \\(\\mathbb{R}^2\\), only position \\((x, y)\\) is considered.</p> <p></p> <p>We can manually create(build) a graph with all edges executable by robot in two ways:</p> <ul> <li>forward direction: discrete (sample) in <code>control</code> space</li> <li>reverse direction: discrete (sample) in <code>state</code> space</li> </ul> <p>This is the basic motivation for all kinodynamic planning, and state lattice planning is the most straight-forward one.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#build-the-graph-sample-in-control-vs-state-space","title":"Build the Graph, Sample in Control vs. State Space","text":"<p>For a robot model:</p> \\[ \\dot{s} = f(s, u) \\] <ul> <li>The robot is differentially driven</li> <li>We have an inital state \\(s_0\\) of the robot</li> <li>We can generate feasible local motions by:<ul> <li>Select a \\(u\\), fix a time duration \\(T\\), forward simulate the system(numerical integration)</li> <li></li> <li>Select a \\(s_f\\), find the connection (a trajectory) between \\(s_0\\) and \\(s_f\\)</li> <li></li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#sample-in-control-space","title":"Sample in Control Space","text":"<ul> <li>Search-based Motion Planning for Quadrotors using Linear Quadratic Minimum Time Control</li> </ul> <p>The lattice graph obtained by searching is:</p> <p></p> <p>Note that:</p> <ul> <li>During searching, the graph can be built when necessary.</li> <li>Create nodes(state) and edges(motion primitive) when nodes are newly discovered.</li> <li>Save computational time/space.</li> </ul> <p>And for vehicle, things are different.</p> <p>The <code>state</code> can be:</p> \\[ s = \\begin{bmatrix} x \\\\ y \\\\ \\theta \\end{bmatrix} \\] <p><code>Input</code>:</p> \\[ u = \\begin{bmatrix} v \\\\ \\phi \\end{bmatrix} \\] <p><code>System equation</code>:</p> \\[ \\begin{bmatrix} \\dot{x} \\\\ \\dot{y} \\\\ \\dot{\\theta} \\end{bmatrix} = \\begin{bmatrix} v \\cdot cos\\theta \\\\ v \\cdot sin\\theta \\\\ \\frac{R}{L} \\cdot tan\\phi \\end{bmatrix} \\] <p>where:</p> <ul> <li>\\(\\theta\\) is heading angle</li> <li>\\(\\phi\\) is steering angle</li> <li>\\(R\\) is steering radius</li> <li>\\(L\\) is the length from front to rear axle</li> </ul> <p>For every \\(s \\in T\\) from the search tree, we pick a control vector \\(u\\) and integrate the equation over short duration, and finally add collision-free motions to the search tree.</p> <p></p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#sample-in-state-space","title":"Sample in State Space","text":"<p>We build a lattice graph with:</p> <ul> <li>Given an origin</li> <li>For 8 neighbor nodes around the origin, feasible paths are found</li> <li>Extend outward to 24 neighbos.</li> <li>Complete lattice</li> </ul> <p>Following is build with <code>Reeds-Shepp Car Model</code>:</p> <p></p> <ul> <li>Generating Near Minimal Spanning Control Sets for Constrained Motion Planning in Discrete State Spaces</li> </ul> <p>And for two or more layers lattice graph, only first layer is different:</p> <p></p> <ul> <li>Optimal Rough Terrain Trajectory Generation for Wheeled Mobile Robot</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#comparison","title":"Comparison","text":"<ul> <li>Trajectories are denser in the direction of the initial angular velocity</li> <li> <p>Very similar outputs for several distinct inputs</p> </li> <li> <p>State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments</p> </li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#boundary-value-problembvp","title":"Boundary Value Problem(BVP)","text":"<p>Boundary Value Problem is the basis of state sampled lattice planning. It has no general solution, we have to design case by case. It often envolves complicated numerical optimization.</p> <p>The basic problem is to design a trajectory (in x direction, for example) such that:</p> <ul> <li>\\(x(0) = a\\)</li> <li>\\(x(T) = b\\)</li> </ul> <p></p> <p>We can take the trajecotry \\(5^{th}\\) order polynomial trajectory:</p> \\[ x(t) = c_{5}t^{5} + c_{4}t^{4} + c_{3}t^{3} + c_{2}t^{2} + c_{1}t + c_{0} \\] <p>The boundary condition will be:</p> Position Velocity Acceleration t = 0 a 0 0 t = T b 0 0 <p>The problem will be solved with:</p> \\[ \\begin{bmatrix} a \\\\ b \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ T^5 &amp; T^4 &amp; T^3 &amp; T^2 &amp; T &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 5T^4 &amp; 4T^3 &amp; 3T^2 &amp; 2T &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\\\ 20T^3 &amp; 12T^2 &amp; 6T &amp; 2 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\begin{bmatrix} c_5 \\\\ c_4 \\\\ c_3 \\\\ c_2 \\\\ c_1 \\\\ c_0 \\end{bmatrix} \\]"},{"location":"Self-Driving/Planning/03_kinodynamic/#optimal-boundary-value-problemobvp","title":"Optimal Boundary Value Problem(OBVP)","text":"<p>If \\(T\\) is fixed, we can get the unique solution of:</p> \\[ \\begin{bmatrix} c_5 \\\\ c_4 \\\\ c_3 \\\\ c_2 \\\\ c_1 \\\\ c_0 \\end{bmatrix} \\] <p>But if \\(T\\) is a variable, we can get more than one solutions. This is an optimal boundary value problem.</p> <p>The general step for this problem is:</p> <ol> <li>System modelling</li> <li><code>Pontryain's Minimum Principle</code> constructing</li> <li>Solving costate</li> <li>Solving optimal control</li> </ol> <p>We take the quadratic as an example.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#fixed-final-state","title":"Fixed Final State","text":""},{"location":"Self-Driving/Planning/03_kinodynamic/#1-system-modeling","title":"1. System modeling","text":"<p>a. State:</p> \\[ S_{k} = \\begin{bmatrix} p_{k} \\\\ v_{k} \\\\ a_{k} \\end{bmatrix} \\tag{2} \\] <p>b. System modle</p> \\[ \\dot {S_{k}} = f_s(s_k, u_K) = \\begin{bmatrix} v_k \\\\ a_k \\\\ j_k \\end{bmatrix} \\tag{4} \\] <p>c. Input:</p> \\[ u_{k} = j_{k} \\tag{3} \\] <p>d. Boundary state:</p> \\[ S(0) = \\begin{bmatrix} p(0) \\\\ v(0) \\\\ a(0) \\end{bmatrix} \\tag{5} \\] \\[ S(f) = \\begin{bmatrix} p(f) \\\\ v(f) \\\\ a(f) \\end{bmatrix} \\tag{6} \\] <p>e. Cost Function:</p> \\[ J_{\\sum} = \\sum_{k=1}^{3}J_{k}, J_{k} = \\frac{1}{T} \\int_0^T j_{k}^2(t) dt \\tag{1} \\] <p>The \\(k\\) in equation is the dimension(x, y, z) of state, and we assume that three dimensions are independent, so we throw away the \\(k\\) in the following equations.</p> <p>And we also define that the quadratic must arrive the final position with the state of \\(S(f)\\), which causes some difference with undefined dimensions' case, we'll discuss this condition later.</p> <ul> <li>A Computationally Efficient Motion Primitive for Quadrocopter Trajectory Generation</li> <li>Dynamic Programming and Optimal Control</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#2-pontryain-minimum-principle-constructing","title":"2. <code>Pontryain Minimum Principle</code> constructing","text":"<p>Generally, the cost function can be described as:</p> \\[ J = h(s(T)) + \\int^T_0{g(s(t), u(t)) \\cdot dt} \\] <p>where:</p> <ul> <li>\\(h(s(T))\\) is the <code>final state</code>;</li> <li>\\(\\int^T_0{g(s(t), u(t)) \\cdot dt}\\) is the <code>transition cost</code>.</li> </ul> <p>Write the <code>Hamiltonian function</code> and <code>costate</code>:</p> \\[ H(s, u, \\lambda) = g(s, u) + \\lambda^T f(s, u) \\] \\[ \\lambda = (\\lambda_1, \\lambda_2, \\lambda_3) \\] <p>and suppose:</p> <ul> <li>\\(s^\\star\\) is the <code>optimal state</code></li> <li>\\(u^\\star\\) is the <code>optimal input</code></li> </ul> <p>We have following conclusions:</p> \\[ \\dot{s^\\star} = f(s^\\star(t), u^\\star(t)), given: s^\\star(0) = s(0) \\] <p>\\(\\lambda(t)\\) is the solution of:</p> \\[ \\dot{\\lambda(t)} = -\\nabla_s H(s^\\star(t), u^\\star(t), \\lambda(t)) \\] <p>with the boundary condition of:</p> \\[ \\lambda(T) = - \\nabla h(s^\\star(T)) \\] <p>and the optimal control input is:</p> \\[ u^\\star(t) = arg \\min_{u(t)} H(s^\\star (t), u(t), \\lambda(t)) \\] <p>By <code>Pontryain's minimum principle</code>, we first inctroduce the <code>costate</code>:</p> \\[ \\lambda = \\begin{bmatrix} \\lambda_1 \\\\ \\lambda_2 \\\\ \\lambda_3 \\end{bmatrix} \\tag{7} \\] <p>And define the <code>Hamiltonian function</code>:</p> \\[ \\begin{align} H(s, u, \\lambda) &amp;= \\frac{1}{T} j^2 + \\lambda^T f_s(s, u) \\\\                  &amp;= \\frac{1}{T} j^2 + \\lambda_1v + \\lambda_2a + \\lambda_3j \\\\  \\end{align} \\tag{8} \\] <p>The <code>Pontryain's minimum principle</code> says:</p> \\[ \\dot {S}^*(t) = f(S^*(t), u^*(t)) \\tag{9} \\] <p>with \\(S^*(0) = S(0)\\), where:</p> <ul> <li><code>*</code>, means optimal.</li> </ul> <p>And \\(\\lambda(t)\\) is the solution of:</p> \\[ \\dot{\\lambda}(t) = - \\nabla H(S^*(t), u^*(t), \\lambda(t)) \\tag{10} \\] <p>with the boundary condition of:</p> \\[ \\lambda(T) = - \\nabla h(S^*(T)) \\tag{11} \\] <p>and the optimal control input is:</p> \\[ u^*(t) = arg \\min_{u(t)} H(S^*(t), u(t), \\lambda(t)) \\tag{12} \\]"},{"location":"Self-Driving/Planning/03_kinodynamic/#3-solving-costate","title":"3. Solving costate","text":"<p>From equation (8) and (10), calculating the partial derivatives of \\((p, v, a)\\), we get:</p> \\[ \\dot{\\lambda}(t) = \\begin{bmatrix} 0 \\\\ -\\lambda_1 \\\\ -\\lambda_2 \\end{bmatrix} \\] <p>We define \\(\\lambda_1 = \\alpha\\), and calculate the integration of \\(\\lambda_2\\) and \\(\\lambda_3\\):</p> \\[ \\lambda (t) = \\begin{bmatrix} \\alpha \\\\ -\\alpha t + \\beta  \\\\ \\frac{1}{2} \\alpha t^2 + \\beta t + \\gamma \\end{bmatrix} \\] <p>As for that \\(\\alpha\\), \\(\\beta\\) and \\(\\gamma\\) are all unknown variables, we can organize the formula above to:</p> \\[ \\lambda (t) = \\frac{1}{T} \\begin{bmatrix} -2 \\alpha \\\\ 2 \\alpha t + 2 \\beta  \\\\ - \\alpha t^2 - 2 \\beta t - 2 \\gamma \\end{bmatrix} \\] <p>According to (12), \\(u^*(t)\\) is the \\(u(t)\\) value when formula (8) get minimum value with the costate \\([\\lambda_1, \\lambda_2, \\lambda_3]'\\), so:</p> \\[ u(t) = \\frac{1}{T} (j^2 -(\\alpha t^2 + 2\\beta t + 2\\gamma) j + - 2\\alpha v + 2\\alpha ta + 2 \\beta a) \\] <p>As we have known (3), to minimize the \\(u(t)\\), we let the derivative of \\(j\\) to \\(0\\):</p> \\[ 2j - (\\alpha t^2 + 2\\beta t + 2\\gamma) = 0 \\] \\[ u^*(t) = j^* = \\frac{1}{2} + \\beta t + \\gamma \\tag{13} \\] <p>We already have the start state (5), according to (2), \\(S^{*}(t)\\) is the <code>1/2/3</code> order integration of \\(u^{*}(t) = j\\):</p> \\[ S^{\\star}(t) =  \\begin{bmatrix} \\frac{1}{120} \\alpha t^5 + \\frac{1}{24} \\beta t^4 + \\frac{1}{6} \\gamma t^3 + \\frac{1}{2} a_0 t^2 + v_0 t + p_0 \\\\ \\frac{1}{24} \\alpha t^4 + \\frac{1}{6} \\beta t^3 + \\frac{1}{2} \\gamma t^2 + a_0 T + v_0 \\\\ \\frac{1}{6} \\alpha t^3 + \\frac{1}{2} \\beta t^2 + \\gamma t + a_0 \\\\ \\end{bmatrix} \\tag{14} \\] <p>The optimal \\(S^\\star (t)\\) should meet the end state (6), so:</p> \\[ \\begin{bmatrix} \\frac{1}{120} \\alpha T^5 + \\frac{1}{24} \\beta T^4 + \\frac{1}{6} \\gamma T^3 + \\frac{1}{2} a_0 T^2 + v_0 T + p_0 \\\\ \\frac{1}{24} \\alpha T^4 + \\frac{1}{6} \\beta T^3 + \\frac{1}{2} \\gamma T^2 + a_0 T + v_0 \\\\ \\frac{1}{6} \\alpha T^3 + \\frac{1}{2} \\beta T^2 + \\gamma T + a_0 \\\\ \\end{bmatrix} = \\begin{bmatrix} p_f \\\\ v_f \\\\ a_f \\\\ \\end{bmatrix} \\tag{15} \\] <p>The equation above is actually a combination of three independent equations, we can move some iterms from left of equal sign to right:</p> \\[ \\begin{bmatrix} \\frac{1}{120} \\alpha T^5 + \\frac{1}{24} \\beta T^4 + \\frac{1}{6} \\gamma T^3 \\\\ \\frac{1}{24} \\alpha T^4 + \\frac{1}{6} \\beta T^3 + \\frac{1}{2} \\gamma T^2 \\\\ \\frac{1}{6} \\alpha T^3 + \\frac{1}{2} \\beta T^2 + \\gamma T\\\\ \\end{bmatrix} = \\begin{bmatrix} p_f - \\frac{1}{2} a_0 T^2 - v_0 T - p_0 \\\\ v_f - a_0 T - v_0 \\\\ a_f - a_0 \\\\ \\end{bmatrix} \\] <p>we let:</p> \\[ \\begin{bmatrix} \\Delta p \\\\ \\Delta v \\\\ \\Delta a \\\\ \\end{bmatrix} = \\begin{bmatrix} p_f - \\frac{1}{2} a_0 T^2 - v_0 T - p_0 \\\\ v_f - a_0 T - v_0 \\\\ a_f - a_0 \\\\ \\end{bmatrix} \\] <p>in linear algebra form:</p> \\[ \\begin{bmatrix} \\frac{1}{120} T^5 &amp; \\frac{1}{24} T^4 &amp; \\frac{1}{6} T^3 \\\\ \\frac{1}{24} T^4 &amp; \\frac{1}{6} T^3 &amp; \\frac{1}{2} T^2 \\\\ \\frac{1}{6} T^3 &amp; \\frac{1}{2} T^2 &amp; \\gamma T\\\\ \\end{bmatrix} \\begin{bmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\\\ \\end{bmatrix} = \\begin{bmatrix} \\Delta p \\\\ \\Delta v \\\\ \\Delta a \\\\ \\end{bmatrix} \\] <p>We can calculate the inverse of first matrix with Gauss-Jordan Elimination:</p> \\[ \\begin{bmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\\\ \\end{bmatrix} = \\frac{1}{T^5} \\begin{bmatrix} 720 &amp; -360T &amp; 60T^2 \\\\ -360T &amp; 168T^2 &amp; -24T^3 \\\\ 60T^2 &amp; -24T^3 &amp; 3T^4 \\end{bmatrix} \\begin{bmatrix} \\Delta p \\\\ \\Delta v \\\\ \\Delta a \\\\ \\end{bmatrix} \\tag{16} \\] <p>And then take the result to (1), we will get the equation about \\(J\\):</p> \\[ J = \\gamma ^ 2 + \\beta \\gamma T + \\frac{1}{3} \\beta ^ 2 T ^ 2 + \\frac{1}{3} \\alpha \\gamma T^2 + \\frac{1}{4} \\alpha \\beta T ^ 3 + \\frac{1}{20} \\alpha ^ 2 T ^ 4 \\tag{17} \\] <p>\\(J\\) only depends on \\(T\\), and the boundary states are known, so we can get the optimal T.</p> <p>This is a polynomial function root finding problem, we can solve it with:</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#1-quartic-equation-root-finding","title":"1. Quartic Equation Root Finding","text":"<p>There are many methods to find roots of quartic equation, we need to ignore negtive and virtual root. But the root is very complex. Not recommanded.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#2-use-companion-matrix-to-find-determinant","title":"2. Use Companion Matrix to Find Determinant","text":"<p>In linear algebra, the Frobenius companion matrix of the monic polynomial:</p> \\[ p(t) = c_0 + c_1 t + \\cdots + c_{n - 1} t^{n - 1} + t^n \\] <p>is the square matrix defined as</p> \\[ C(p) = \\begin{bmatrix} 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; -c_0 \\\\ 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; -c_1 \\\\ 0 &amp; 1 &amp; \\cdots &amp; 0 &amp; -c_2 \\\\ \\vdots &amp; \\vdots  &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 1 &amp; -c_{n-1} \\\\ \\end{bmatrix} \\] <p>We can calculate the determinant of \\(C(p)\\) and take all positive root to equation (17) to get the optimal \\(T\\), this can be done within <code>Eigen</code> library.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#3-eigen-polynomialsolver","title":"3. Eigen PolynomialSolver","text":"<p>This is a solver in <code>Eigen</code>, more in example.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#partial-free-final-state","title":"Partial Free Final State","text":"<p>The previous process is about fixed final state problem, you may notice that the boundary contidtion (10):</p> \\[ \\dot{\\lambda}(t) = - \\nabla H(S^*(t), u^*(t), \\lambda(t)) \\] <p>is not used. That's because that:</p> \\[ h(s(T)) = \\begin{cases} 0, &amp; \\text{if } s = s(T) \\\\ \\infty, &amp; otherwise \\\\ \\end{cases} \\] <p>is not differentialble, so we discard this condition and use given \\(S(T)\\) to directly solve for unknown variables.</p> <p>We will solve this again with fixed final \\(p\\) and free \\(v\\) and \\(a\\).</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#1-modeling","title":"1. Modeling","text":"<p>a. Cost Function:</p> \\[ J_{\\sum} = \\sum_{k=1}^{3}J_{k}, J_{k} = \\frac{1}{T} \\int_0^T j_{k}^2(t) dt \\] <p>b. State:</p> \\[ S_{k} = \\begin{bmatrix} p_{k} \\\\ v_{k} \\\\ a_{k} \\end{bmatrix} \\] <p>c. Input:</p> \\[ u_{k} = j_{k} \\] <p>d. System Model:</p> \\[ \\dot {S_{k}} = f_s(s_k, u_K) = \\begin{bmatrix} v_k \\\\ a_k \\\\ j_k \\end{bmatrix} \\] <p>e. Start and End State:</p> \\[ S(0) = \\begin{bmatrix} p(0) \\\\ v(0) \\\\ a(0) \\end{bmatrix} \\] \\[ S(f) = \\begin{bmatrix} p(f) \\\\ v(f) \\\\ a(f) \\end{bmatrix} \\] <p>The \\(k\\) in equation is the dimension(x, y, z) of state, and we assume that three dimensions are independent, so we throw away the \\(k\\) in the following equations.</p> <p>And we also define that the quadratic must arrive the final position with the state of \\(S(f)\\), which causes some difference with undefined dimensions' case, we'll discuss this condition later.</p> <ul> <li>A Computationally Efficient Motion Primitive for Quadrocopter Trajectory Generation</li> <li>Dynamic Programming and Optimal Control</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#2-solving","title":"2. Solving","text":"<p>By <code>Pontryain's minimum principle</code>, we first inctroduce the <code>costate</code>:</p> \\[ \\lambda = \\begin{bmatrix} \\lambda_1 \\\\ \\lambda_2 \\\\ \\lambda_3 \\end{bmatrix} \\] <p>And define the <code>Hamiltonian function</code>:</p> \\[ \\begin{align} H(s, u, \\lambda) &amp;= \\frac{1}{T} j^2 + \\lambda^T f_s(s, u) \\\\                  &amp;= \\frac{1}{T} j^2 + \\lambda_1v + \\lambda_2a + \\lambda_3j \\\\  \\end{align} \\] <p>The <code>Pontryain's minimum principle</code> says:</p> \\[ \\dot {S}^*(t) = f(S^*(t), u^*(t)) \\] <p>with \\(S^*(0) = S(0)\\), where:</p> <ul> <li><code>*</code>, means optimal.</li> </ul> <p>And \\(\\lambda(t)\\) is the solution of:</p> \\[ \\dot{\\lambda}(t) = - \\nabla H(S^*(t), u^*(t), \\lambda(t)) \\] <p>with the boundary condition of:</p> \\[ \\lambda(T) = - \\nabla h(S^*(T)) \\] <p>and the optimal control input is:</p> \\[ u^*(t) = arg \\min_{u(t)} H(S^*(t), u(t), \\lambda(t)) \\]"},{"location":"Self-Driving/Planning/03_kinodynamic/#3-details","title":"3. Details","text":"<p>From equation (8) and (10), calculating the partial derivatives of \\((p, v, a)\\), we get:</p> \\[ \\dot{\\lambda}(t) = \\begin{bmatrix} 0 \\\\ -\\lambda_1 \\\\ -\\lambda_2 \\end{bmatrix} \\] <p>We define \\(\\lambda_1 = -\\frac{1}{T} 2 \\alpha\\), and calculate the integration of \\(\\lambda_2\\) and \\(\\lambda_3\\):</p> \\[ \\lambda (t) = \\frac{1}{T} \\begin{bmatrix} -2 \\alpha \\\\ 2 \\alpha t + 2 \\beta  \\\\ - \\alpha t^2 - 2 \\beta t - 2 \\gamma \\end{bmatrix} \\] <p>Using the boundary condition (10), we know that the \\(v\\) and \\(a\\) are free, so the function \\(h\\) has no relationships with \\(v, a\\) at \\(T\\). Then:</p> \\[ \\lambda_2(T) = 0 \\] \\[ \\lambda_3(T) = 0 \\] <p>With the formula about \\(\\lambda (t)\\), we have:</p> \\[ \\begin{cases} \\beta = - \\alpha T \\\\ \\gamma = \\frac{\\alpha}{2} T^2 \\\\ \\end{cases} \\] <p>So the equation can be simplified to:</p> \\[ \\lambda(t) = \\frac{1}{T} \\begin{bmatrix} -2\\alpha \\\\ -2\\alpha (t - T) \\\\ -\\alpha t^2 + 2 \\alpha T t - \\alpha T^2 \\\\ \\end{bmatrix} \\] <p>The optimal input can be solve:</p> \\[ u^*(t) = - \\frac{\\lambda_3 T} {2} = -\\frac{T}{2} \\frac{1}{T}(-\\alpha t^2 + 2 \\alpha Tt - \\alpha T^2) = \\frac{1}{2}(\\alpha t^2 - 2 \\alpha Tt + \\alpha T^2) \\] <p>Integrating the \\(u^\\star(t) = j\\), we have:</p> \\[ S^\\star (t) = \\begin{bmatrix} \\frac{1}{120} \\alpha t^5 - \\frac{1}{24} \\alpha Tt^4 + \\frac{1}{12} \\alpha T^2t^3 + \\frac{a(0)}{2} t^2 + v(0) t + p(0) \\\\ \\frac{1}{24} \\alpha t^4 - \\frac{1}{6} \\alpha Tt^3 + \\frac{1}{4} \\alpha T^2 t^2 + a(0) t + v(0) \\\\ \\frac{1}{6} \\alpha t^3 - \\frac{1}{2} \\alpha T t^2 + \\frac{1}{2} \\alpha T^2 t + a_0 \\end{bmatrix} \\] <p>We have the final \\(p(f)\\), so:</p> \\[ \\frac{1}{120} \\alpha T^5 - \\frac{1}{24} \\alpha T^5 + \\frac{1}{12} \\alpha T^5 + \\frac{a(0)}{2} T^2 + v(0) T + p(0) = p(f) \\] <p>so:</p> \\[ \\alpha = frac{20 \\Delta p} {T^5} \\] <p>where:</p> \\[ \\Delta p = p(f) - p(0) - v(0)T - \\frac{1}{2} a(0) T^2 \\] <p>Finally, we get:</p> \\[ u^\\star(t) = \\frac{1}{2}(\\alpha t^2 - 2 \\alpha Tt + \\alpha T^2) =  \\] \\[ J = \\frac{1}{T} \\int_0^T (u^\\star(t))^2 dt = \\frac{20 (\\Delta p)^2} {T^6} \\] <p>\\(J\\) is the function about \\(T\\), to minimize \\(J\\), we calculate the result of \\(J' = 0\\):</p> \\[ (p(f) - p(0) - v(0) T - \\frac{1}{2} T^2)(a(0) T^2 + 4 v(0) T - 6p(f) + 6p(0)) = 0 \\] <p>So:</p> \\[ T^\\star = \\frac{-v(0) \\pm \\sqrt{v(0)^2 + 2a(0)(p(f) - p(0))}} {a(0)} \\] <p>or </p> \\[ T^\\star = \\frac{-2v(0) \\pm \\sqrt{4v(0)^2 + 6a(0)(p(f) - p(0))}} {a(0)} \\] <ul> <li>A Computationally Efficient Motion Primitive for Quadrocopter Trajectory Generation</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#wheeled-robots","title":"Wheeled Robots","text":"<ul> <li>Optimal Rough Terrain Trajectory Generation for Wheeled Mobile Robot</li> <li>Maximum Likelihood Path Planning for Fast Aerial Maneuvers and Collision Avoidance</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#heuristic-design","title":"Heuristic Design","text":"<p>We can design the heuristic in practice, the principle is:</p> <p>Solve an easier problem</p> <p>There are mainly two methods:</p> <ul> <li>Assume no obstacle existence</li> <li>Assume no dynamic existence</li> </ul> <p>Ref:</p> <ul> <li>Planning Long Dynamically Feasible Maneuvers for Autonomous Vehicle</li> <li>Path Planning for Autonomous Vehicles in Unknown Semi-structured Environment</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#planning-in-frenet-serret-frame","title":"Planning in Frenet-serret Frame","text":"<p>The frenet-serret frame is widely used in autonomous driving, it's a dynamic reference frame.</p> <p>The lateral and longitudinal motivations of autonomous vehicle are independently, for lane following problem, the lateral and longitudinal motions are decoupled.</p> <p>We firstly define the motion/control parametrization(quintic polynomial):</p> \\[ d(t) = a_{d0} + a_{d1}t + a_{d2} t^2 + a_{d3} t^3 + a_{d4} t^4 + a_{d5} t^5 \\] \\[ s(t) = a_{s0} + a_{s1}t + a_{s2} t^2 + a_{s3} t^3 + a_{s4} t^4 + a_{s5} t^5 \\] <p>and then solve the optimal control problem.</p> <p>We only discuss the lateral planning here, for longitudinal planning, please refer to:</p> <ul> <li>Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame</li> <li>Optimal trajectoires for time-critical street scenarios using discretized terminal manifolds</li> </ul> <p></p> <p>We have known the initial state:</p> \\[ d(0) = \\begin{bmatrix} d_{0} \\\\ \\dot d_{0} \\\\ \\ddot d_{0} \\end{bmatrix} \\] <p>As we need a lane following, the terminate state will be:</p> \\[ d(T) = \\begin{bmatrix} d_{T} \\\\ \\dot d_{T} \\\\ \\ddot d_{T} \\end{bmatrix} = \\begin{bmatrix} d_{T} \\\\ 0 \\\\ 0 \\end{bmatrix} \\] <p>Use what we have learned from <code>Partial Free Final State</code>, we can get everything.</p> \\[ \\begin{bmatrix} T^3 &amp; T^4 &amp; T^5 \\\\ 3T^2 &amp; 4T^3 &amp; 5T^4 \\\\ 6T &amp; 12T^2 &amp; 20T^3 \\\\ \\end{bmatrix} \\begin{bmatrix} a_{d3} \\\\ a_{d4} \\\\ a_{d5} \\\\ \\end{bmatrix} = \\begin{bmatrix} \\Delta p \\\\ \\Delta v \\\\ \\Delta a \\\\ \\end{bmatrix} \\] <p>where:</p> \\[ \\begin{bmatrix} \\Delta p \\\\ \\Delta v \\\\ \\Delta a \\\\ \\end{bmatrix} = \\begin{bmatrix} d_{f} - (d_{0} + \\dot d_{0} T + \\frac{1}{2} \\ddot d_{0} T^2) \\\\ \\dot d_{f} - (\\dot d_{0} + \\ddot d_{0} T) \\\\ \\ddot d_{f} - \\ddot d_{0} \\end{bmatrix} \\] <p></p> <ul> <li>optimal trajectory in a frenet frame</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#hybrid-a","title":"Hybrid A*","text":""},{"location":"Self-Driving/Planning/03_kinodynamic/#basic-idea","title":"Basic Idea","text":"<p>Online generating a dense lattice costs too much time, so how about <code>prune</code> some nodes?</p> <p>Hybird A star use the grid map to prune the branches.</p> <p></p> <p>If there is no node in the grid, we add the node to grid; if there is a node in grid, we check the cost of the node in grid and new node and reserve the lower one.</p> <p>Reference:</p> <ul> <li>Pratical Search Techniques in Path Planning for Autonomous Driving</li> <li>Path Planning for Autonomous Vehicles in Unknown Semi-structured Environments</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#heuristic-design_1","title":"Heuristic Design","text":"<p>To accumulate the search process, we can use following methods to design the heuristic:</p> <ol> <li>2D-Euclidean distance</li> <li>non-holonomic-without-obstacles</li> <li>non-holonomic-without-obstacles, bad performance in dead ends</li> <li>non-holonomic-without-obstacles + holonomic-with-obstacles(2D shortest path)</li> </ol> <p></p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#other-tricks","title":"Other Tricks","text":"<p>Control space sample(discretization) is kind of low-efficient, since no target biasing is encoded. So how about we manually add(try) state space sample?</p> <p>Here come's the <code>Analytic Expansions</code>(One shot): add a state-driven bias towards the searching process, if at some state we can get an optimal path to the final state, the search process is terminated. A trade-off is that if we do this <code>one-shot</code> each time visit a node, the cost will be huge. We can do this <code>one-shot</code> each \\(N\\) nodes. And as the frontier of graph goes towards the target node, we can decrease the \\(N\\).</p> <p></p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#application","title":"Application","text":"<ul> <li>Practical Search Techniques in Path Planning for Autonomous Driving</li> <li>Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous</li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#kinodynamic-rrt","title":"Kinodynamic RRT*","text":"<p>Kinodynamic RRT* is similar to \\(RRT\\star\\), but different in details, the main process is:</p> <ul> <li>Input: \\(E\\), \\(x_{init}\\), \\(x_{goal}\\)</li> <li>Output: A trajectory \\(T\\) from \\(x_{init}\\) to \\(x_{goal}\\)</li> <li>T.init()</li> <li>for \\(i = 1 \\to n\\) do:<ul> <li>\\(x_{rand} \\gets Sample(E)\\)</li> <li>\\(x_{near} \\gets Near(x_{rand})\\)</li> <li>\\(x_{min} \\gets ChooseParent(x_{near}, x_{rand})\\)</li> <li>T.addNode(\\(x_{rand}\\))</li> <li>T.rewire()</li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/03_kinodynamic/#how-to-sample","title":"How to \"Sample\"?","text":"<p>System state-space equation:</p> \\[ \\dot{x(t)} = A x(t) + B u(t) + c \\] <p>For example for double integrator systems:</p> \\[ x = \\begin{bmatrix} p \\\\ v \\end{bmatrix}, A = \\begin{bmatrix} 0 &amp; I \\\\ 0 &amp; 0 \\end{bmatrix}, B = \\begin{bmatrix} 0 \\\\ I \\end{bmatrix} \\] <p>Instead of sampling in Euclidean space like RRT, it requires to <code>sample in full state space</code>.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#how-to-define-near","title":"How to define \"Near\"?","text":"<p>If without motion constraints, Euclidean distance or Manhattan distance can be used.</p> <p>In state space with motion constriants, binging in <code>optimal control</code>.</p> <p>We can define <code>cost funtion</code> of transferring from states to states, typically, a quadratic form of time energy optimal is adopted.</p> \\[ c[\\tau] = \\int^{\\tau}_{0} (1 + u(t)^T R u(t)) dt \\] <p>where:</p> <ul> <li>\\(\\tau\\) is the arriving time</li> <li>\\(u(t)\\) is the control policy of transferring</li> <li>\\(R\\) is the weight matrix</li> </ul> <p>Two states are <code>near</code> if the cost of transferring from one state to the other is small.(Note that the cost may be different if transfer reversely.)</p> <p>If we know \\(\\tau\\) and \\(u(t)\\), we can calculate the cost, it'll in classic optimal control solutions(OBVP).</p> <p>Reference: - Optimal Control</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#fixed-final-state-x1-fixed-final-time-tau","title":"Fixed final state x1, fixed final time \\(\\tau\\)","text":"<p>The optimal control policy \\(u^{\\star}(t)\\):</p> \\[ u^{\\star}(t) = R^{-1} B^T e^{A^T(\\tau - t)}G(\\tau)^{-1}[x_1 - \\bar{x}(\\tau)] \\] <p>Where \\(G(t)\\) is the weighted controllability Gramian:</p> \\[ G(t) = \\int^{t}_0 e^{A(t - t')} BR^{-1} e^{A^T(t - t')} dt' \\] <p>Which is the solution to the Lyapunov equation:</p> \\[ \\dot{G}(t) = AG(t) + G(t)A^T + BR^{-1} B^T, G(0) = 0 \\] <p>And \\(\\bar{x}(t)\\) describe what the state x would be at time t if no control input were applied:</p> \\[ \\bar{x}(t) = e^{At} x_0 + \\int^t_0 e^{A(t - t')} c dt' \\] <p>Which is the solution to the differential equation:</p> \\[ \\dot{\\bar{x}}(t) = A\\bar{x}(t) + c, \\bar{x}(0) = x_0 \\]"},{"location":"Self-Driving/Planning/03_kinodynamic/#fixed-final-state-x1-free-final-time-tau","title":"Fixed final state x1, free final time \\(\\tau\\)","text":"<p>If we want to find the optimal arrival time \\(\\tau\\), we do this by filling in the control policy \\(u^\\star(t)\\) into the cost function \\(c[\\tau]\\) and evaluating the integral:</p> \\[ c[\\tau] = \\tau + [x_{1} - \\bar{x}(\\tau)]^T G(t)^{-1} [x_{1} - \\bar{x}(\\tau)] \\] <p>The optimal \\(\\tau\\) is found by taking the derivative of \\(\\c[\\tau]\\) with respect to \\(\\tau\\):</p> \\[ \\dot{c}[\\tau] = 1 - 2(Ax_1 + c)^T d(\\tau) - d(\\tau)^T B R^{-1} B^T d(\\tau) \\] <p>where:</p> \\[ d(\\tau) = G(t)^{-1} [x_1 - \\bar{x}(\\tau)] \\] <p>Solve \\(\\dot c [\\tau] = 0\\) for \\(\\tau^\\star\\).</p> <p>Noted that the function \\(c[\\tau]\\) may have multiple local minima. And for a double integrator system, it's a \\(4^{th}\\) order polynomail.</p> <p>Given the optimal arrival time \\(\\tau^\\star\\) as defined above, it again turns into a fixed final state, fixed final time problem.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#how-to-chooseparent","title":"How to <code>ChooseParent</code>?","text":"<p>Now if we sample a random state, we can calculate control policy and cost from those state-nodes in the tree to the sampled state.</p> <p>Choose one with the minimal cost and <code>check x(t) and u(t) are in bounds</code>. If no qualified parent found, sample another state.</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#how-to-find-near-nodes-efficiently","title":"How to find near nodes efficiently","text":"<p>Every time we sample a random state \\(x_{rand}\\), it requires to check every node in the tree to find its parent, that is solving a <code>OBVP</code> for each node, which is not efficient.</p> <p>If we set a <code>cost tolerance</code> \\(r\\), we can actually calculate bounds of the states(forward-reachable set) that can be reached by \\(x_{rand}\\) and bounds of the states (backward-reachable set) that can reach \\(x_{rand}\\) with cost less than \\(r\\).</p> <p>And if we store nodes in from of a <code>kd-tree</code>, we can then do range query in the tree.</p> \\[ c[\\tau] = \\tau + [x_{1} - \\bar{x}(\\tau)]^T G(t)^{-1} [x_{1} - \\bar{x}(\\tau)] \\] <p>This formula describes how cost of transferring from state \\(x_0\\) to state \\(x_1\\) changes with arrval time \\(\\tau\\).</p> <p>We can see that given inital state \\(x_0\\), cost tolerance \\(r\\) and arrival time \\(\\tau\\), the forward-reachable set of \\(x_0\\) is:</p> \\[ \\begin{align}  &amp;\\{x_1 | \\tau + [x_1 - \\bar{x}(\\tau)]^T g(t)^{-1} [x_1 - \\bar{x}(\\tau)] &lt; r\\} \\\\ =&amp;\\{x_1 | [x_1 - \\bar{x}(\\tau)^T \\frac{G(t)^{-1}}{r - \\tau} [x_1 - \\bar{x}(\\tau)] &lt; 1\\} \\\\ =&amp; \\varepsilon [\\bar{x}(\\tau), G(t) (r - \\tau)] \\end{align} \\] <p>where \\(\\varepsilon[x, M]\\) is an <code>ellipsoid</code> with center \\(x\\) and positive definite weight matrix \\(M\\), formally defined as:</p> \\[ \\varepsilon[x, M] = \\{x' | (x' - x)^T M^{-1} (x' - x) &lt; 1\\} \\] <p>Hence, the forward-reachable set is the union of high dimensional ellipsoids for all possible arrival times \\(\\tau\\).</p> <p>For simplification, we sample several \\(\\tau\\)s and calculate axis-aligned bounding boxe of the ellipsoids for each \\(\\tau\\) and update the maximum and minimum in each dimension:</p> \\[ \\Pi^n_{k = 1} \\begin{bmatrix} min\\{0 &lt; \\tau &lt; r\\}(\\bar{x}(\\tau)_k - \\sqrt{G[\\tau]_{(k, k)}(r - \\tau)}), \\\\ max\\{0 &lt; \\tau &lt; r\\}(\\bar{x}(\\tau)_k - \\sqrt{G[\\tau]_{(k, k)}(r - \\tau)}) \\\\ \\end{bmatrix} \\] <p>Simmilar for the calculation of the backward-reachable set.</p> <p>When do <code>Near</code> query and <code>ChooseParent</code>, \\(x_{near}\\) can be found from the <code>backward-reachable set</code> of \\(x_{rand}\\)</p>"},{"location":"Self-Driving/Planning/03_kinodynamic/#how-to-rewire","title":"How to <code>Rewire</code>?","text":"<p>When <code>Rewire</code>, we calculate the <code>forward-reachable set</code> of \\(x_{rand}\\), and solve <code>OBVP</code>s.</p>"},{"location":"Self-Driving/Planning/04_trajectory/","title":"Minimum Snap Trajectory Generation","text":""},{"location":"Self-Driving/Planning/04_trajectory/#introduction","title":"Introduction","text":""},{"location":"Self-Driving/Planning/04_trajectory/#why-smooth-trajectory","title":"Why Smooth Trajectory?","text":"<ul> <li>Good for autonomous moving</li> <li>Velocity/higher-order dynamics can't change immediately</li> <li>The robot should not stop at turns</li> <li>Save energy</li> </ul>"},{"location":"Self-Driving/Planning/04_trajectory/#smooth-trajectory-generation","title":"Smooth Trajectory Generation","text":"<p>There are ways to generate smooth trajectory:</p> <ul> <li>Boundary condition: start, goal positions(orientations)</li> <li>Intermediate condition: waypoint positions(orientations) <ul> <li>Waypoints can be found by path planning (A star, RRT star, etc.)</li> </ul> </li> <li>Smoothness criteria<ul> <li>Generally translates into minimizing rate of change of \"input\"</li> </ul> </li> </ul>"},{"location":"Self-Driving/Planning/04_trajectory/#minimum-snap-optimization","title":"Minimum Snap Optimization","text":""},{"location":"Self-Driving/Planning/04_trajectory/#differential-flatness","title":"Differential Flatness","text":"<p>The states and the inputs of a quadrotor can be written as algebraic functions of four carefully selected flat outputs and their derivatives.</p> <ul> <li>Enables automated generation of trajectories</li> <li>Any smooth trajectory in the space of flat outputs (with reasonably bounded derivatives) can be followed by the under-actuated quadrotor.</li> <li>A possible choice: \\(\\sigma = [x, y, z, \\psi]^T\\)</li> <li>Trajectory in the space of flat outputs: \\(\\sigma(t) = [T_0, T_M] \\to \\mathbb{R}^3 \\times SO(2)\\)</li> </ul> <p>Reference:</p> <ul> <li>Minimum Snap Trajectory Generation and Control for Quadrotors, Daniel Mellinger and Vijay Kumar</li> </ul> <p>Polynomial functions can be used to specify trajectories in the space of flat outputs:</p> <ul> <li>Easy determination of smoothness criterion with polynomial orders.</li> <li>Easy and closed form calculation of derivatives.</li> <li>Decoupled trajectory generation in three dimensions.</li> </ul>"},{"location":"Self-Driving/Planning/04_trajectory/#mimimum-snap","title":"Mimimum Snap","text":""},{"location":"Self-Driving/Planning/04_trajectory/#smooth-1d-trajectory","title":"Smooth 1D Trajectory","text":"<p>It's just a simple BVP(Boundary Value Problem).</p> <p></p> <p>We design a trajectory \\(x(t)\\) follows boundary condition:</p> \\[ \\begin{align} x(0) = a \\\\ x(T) = b \\end{align} \\] <p>As we have known, smoothness means continuous and differential, and polynomial is \\(n\\) order differential and \\(n + 1\\) order continuous. So the smoothness is ensured by parametrization, we use a \\(5^{th}\\) order polynomial trajectory, this is the smoothness criteria:</p> \\[ x(t) = p_5t^5 + p_4t^4 + p_3t^3 + p_2t^2 + p_1t + p_0 \\] <p>The boundary condition is:</p> Position Velocity Acceleration t = 0 a 0 0 t = T b 0 0 <p>It can be solved with:</p> \\[ \\begin{bmatrix} a \\\\ b \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ T^5 &amp; T^4 &amp; T^3 &amp; T^2 &amp; T &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 5T^4 &amp; 4T^3 &amp; 3T^2 &amp; 2T &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\\\ 20T^3 &amp; 12T^2 &amp; 6T &amp; 2 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\begin{bmatrix} p_5 \\\\ p_4 \\\\ p_3 \\\\ p_2 \\\\ p_1 \\\\ p_0 \\\\ \\end{bmatrix} \\]"},{"location":"Self-Driving/Planning/04_trajectory/#smooth-multi-segment-trajectory","title":"Smooth Multi-Segment Trajectory","text":"<p>If intermediate conditions are given, we get a multi-segment problem. We prefer constant velocity motion at \\(v\\), and zero acceleration.</p> <p></p> <p>The boundary conditions become:</p> Position Velocity Acceleration t = 0 a \\(v_0\\) 0 t = T b \\(v_T\\) 0 <p>The solution is:</p> \\[ \\begin{bmatrix} a \\\\ b \\\\ v_0 \\\\ v_T \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ T^5 &amp; T^4 &amp; T^3 &amp; T^2 &amp; T &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 5T^4 &amp; 4T^3 &amp; 3T^2 &amp; 2T &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\\\ 20T^3 &amp; 12T^2 &amp; 6T &amp; 2 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\begin{bmatrix} p_5 \\\\ p_4 \\\\ p_3 \\\\ p_2 \\\\ p_1 \\\\ p_0 \\\\ \\end{bmatrix} \\]"},{"location":"Self-Driving/Planning/04_trajectory/#optimization-based-trajectory-generation","title":"Optimization-based Trajectory Generation","text":"<p>If we know the \\(v\\) and \\(a\\), we can use multi-segment trajectory generation method to solve the problem. But the critical point is, we have no idea what is the best value for these variables. That's where we use optimization-base method.</p>"},{"location":"Self-Driving/Planning/04_trajectory/#smooth-3d-trajectory","title":"Smooth 3D Trajectory","text":"<p>Let's take an example of quadrotor trajectory generation. The problem can be described as:</p> <ul> <li>Boundary condition: start, goal positions(orientations)</li> <li>Intermediate condition: waypoint positions(orientations)<ul> <li>Waypoints can be found by path planning(A star, RRT star, etc)</li> <li>Introduced in previous lectures</li> </ul> </li> <li>Smoothness criterion<ul> <li>Generally translates into minimizing rate of change of \"input\"</li> </ul> </li> </ul> <p>But what derivatives should we minimize?</p> <p>As inferenced before, we have following relationships between derivatives and state of quadrotor:</p> Derivative Translation Rotation Thrust 0 Position 1 Velocity 2 Acceleration Rotation 3 Jerk Angular Velocity Thrust 4 Snap Angular Acceleration Differential Thrust <p>We got following conclutions:</p> <ul> <li>Minimum jerk: minimizing angular velocity, which is good for visual tracking;</li> <li>Minimum snap: minimizing differential thrust, which saves energy.</li> </ul> <p>So in math language, the problem is:</p> \\[ f(t) =  \\begin{cases} f_1(t) \\doteq \\sum^N_{i = 0} p_{1, i}t^i, &amp;T_0 &lt;= t &lt;= T_1 \\\\ f_2(t) \\doteq \\sum^N_{i = 0} p_{2, i}t^i, &amp;T_0 &lt;= t &lt;= T_2 \\\\ \\vdots f_M(t) \\doteq \\sum^N_{i = 0} p_{M, i}t^i, &amp;T_{M - 1} &lt;= t &lt;= T_{M} \\\\ \\end{cases} \\] <p>Attention:</p> <ul> <li>Each segment is a polynomial</li> <li>No need to fix the order, but keeping the same order makes this problem simpler</li> <li><code>Time durations</code> for each segment must be known</li> </ul> <p>The constraints:</p> <p></p> <p>Smoothness means its derivative is continuous!</p> <p>How to determine the trajectory order? Following iterms are what we should think about:</p> <ul> <li>which order to ensure the smoothness?</li> <li>which order to ensure the continuity?</li> <li>which order to minimize control input?</li> </ul> <p>and these three items are <code>not</code> coupled, we can set them seperately.</p> <p>A general method to define the order of <code>1D trajectory</code> is:</p> \\[ N = 2 * d - 1 \\] <p>where \\(N\\) is the minimum degree of polynomial, \\(d\\) is the order of difference. For example:</p> <ul> <li>Minimum jerk: \\(N = 2 * 3(jerk) - 1 = 5\\)</li> <li>MInimum snap: \\(N = 2 * 4(snap) - 1 = 7\\)</li> </ul> <p>How this works? If we want to solve the minimum jerk problem, the number of equations is \\(2 * 3\\), because we have start and end point, and each has \\(3\\) equations(v, a, j), and the 5 order polynomial has \\(5 + 1\\) unknowns.</p> <p>And for k-segment trajectory, the constraints number of jerk will be \\(3 + 3 + (k - 1) = k + 5\\), and the number of unknowns is \\((N + 1) * k\\), so the relationship between degree of polynomial and k is:</p> \\[ (N + 1) * k = k + 5 \\] \\[ N = \\frac{5}{k} \\] <p>The more segments we divide, the less degrees of polynomial we need. But \\(k\\) may be \\(1\\), so \\(5\\) is a good choice.</p> <p>As for the timeline of problem, we can use</p> <ul> <li>many relative timeline, which is good for </li> </ul>"},{"location":"Self-Driving/Planning/04_trajectory/#convex-optimization","title":"Convex Optimization","text":""},{"location":"Self-Driving/Planning/04_trajectory/#closed-form-solution-to-minimum-snap","title":"Closed-form Solution to Minimum Snap","text":""},{"location":"Self-Driving/Planning/04_trajectory/#implementation-details","title":"Implementation Details","text":""},{"location":"Self-Driving/Planning/05_mpc/","title":"Model Prediction Control (MPC)","text":"<p>As for the control problem, the simplest is <code>Reactive Control</code>. </p>"},{"location":"Self-Driving/Planning/05_mpc/#reactive-control","title":"Reactive Control","text":"<p>The advantages of reactive control are:</p> <ul> <li>Easy to design</li> <li>Consider errors</li> </ul> <p>But there are also limitations:</p> <ul> <li>Non-trivial for more <code>complex systems</code></li> <li>Control gains must be <code>tuned manually</code></li> <li>No handling of <code>coupled dynamics</code>  and <code>constraints</code></li> <li>Ignores <code>future dicision</code></li> </ul>"},{"location":"Self-Driving/Planning/05_mpc/#optimal-control","title":"Optimal Control","text":"<p><code>Optimal Control</code> solves the problem that how to <code>best</code> control the system. In order to answer the question how the input influences the future state, we should build the system model firstly.</p> <p><code>Model</code> of the system can be continuous:</p> \\[ \\dot {\\mathbf{x}} = f_c(\\mathbf{x}, \\mathbf{u}) \\] <p>or discrete:</p> \\[ \\mathbf{x}_{k + 1} = f_d(\\mathbf{x}_k, \\mathbf{u}_k) \\] <p>where:</p> <ul> <li>\\(\\mathbf{x}_0\\) is the initial condition</li> <li>\\(\\mathbf{x}_k\\) is state</li> <li>\\(\\mathbf{u}_k\\) is input</li> </ul> <p>After the system model, another neccesary thing we define is the <code>Objective Function</code>, which describes the expectation of future trajectory.</p> \\[ \\min_{u_0 : N-1} \\sum_{k = 0}^{N-1} q(x_k, u_k) + p(x_N) \\] <p>where:</p> <ul> <li>\\(q(x_k, u_k)\\) describes the <code>stage cost</code></li> <li>\\(p(x_N)\\) describes the <code>terminal cost</code></li> </ul> <p>we can define the \\(q(x_k, u_k) = ||e_k||^2 + \\rho \\Delta u_k^2\\) , where \\(e_k = x_k - x_k^{ref}\\) is the tracking error, \\(\\rho \\Delta u_k^2\\) is the smoothing cost.</p> <p>Except for the objective function, <code>constraints</code> should also be considered:</p> \\[ \\begin{align} x_{k + 1} &amp;= f_d(x_k, u_k) \\\\ h(x_k, u_k) &amp;= 0 \\\\ g(x_k, u_k) &amp;\\le 0 \\\\ \\end{align} \\] <p>where \\(h(x_k, u_k)\\) is the euqality constraints, \\(g(x_k, u_k)\\) is the inequality constrains.</p> <p>So in general, the procedure of the optimal control is:</p> <ul> <li>Build <code>Objective Function</code>:</li> </ul> \\[ \\min_{u_0 : N-1} \\sum_{k = 0}^{N-1} q(x_k, u_k) + p(x_N) \\] <ul> <li>Add <code>Constraints</code>:</li> </ul> \\[ \\begin{align} x_{k + 1} &amp;= f_d(x_k, u_k) \\\\ h(x_k, u_k) &amp;= 0 \\\\ g(x_k, u_k) &amp;\\le 0 \\\\ \\end{align} \\] <ul> <li>Solve <code>Optimal vector</code>:</li> </ul> \\[ z^\\star = (u_0^T, \\cdots, u_{N - 1}^T) \\] <p>The optimal vector is ideal, of course. In reality, the difficulties of (Open Loop) optimal control are:</p> <ul> <li>The <code>dynamic model</code> is usually <code>inaccurate</code>, model errors accumulate over time.</li> <li>The optimizer \\(z^\\star\\) we get can not be accurately applied.</li> <li>Long task-horizons make the problem <code>intractable</code>.</li> <li>The system may be affected by <code>external disturbances</code>.</li> </ul>"},{"location":"Self-Driving/Planning/05_mpc/#model-predictive-control-mpc","title":"Model Predictive Control (MPC)","text":"<p>MPC combines <code>Reactive Control</code> and <code>Optimal Control</code>, it uses a dynamic <code>model</code> of the process to <code>predict</code> its future evolution(finite time horizon) and choose the best <code>control</code> action.</p> <pre><code>  +------------------+ update states\n  | prediction model &lt;---------+\n  +--------+---------+         |\n           |                   |\n           |                   |\n+----------v------------+      |\n| model|based optimizer |      | measurements\n+----------+------------+      |\n           | control inputs    |\n           |                   |\n     +-----v------+            |\n     | real model +------------+\n     +------------+\n</code></pre> <p>The process is:</p> <ul> <li><code>Feedback</code> of the measurement information, which starts from the estimated <code>current state</code></li> <li><code>Optimize</code> the best control sequence, which finds controls for <code>limited preview</code> into the future</li> <li><code>Receding horizon</code> framework, which applies only the first input, then <code>replan</code></li> </ul> <p>The advantages of MPC are:</p> <ul> <li>Considers future (although a limited future)</li> <li>Accounts for errors</li> <li>Reduces problem size (solver is usually warm-started with the previous solution)</li> </ul>"},{"location":"Self-Driving/Planning/05_mpc/#design-of-mpc","title":"Design of MPC","text":"<ul> <li><code>Prediction model</code>, trade-off in choice of model family:<ul> <li>Simplicity model, lower computation</li> <li>Accuracy model, higher computation</li> </ul> </li> <li><code>Cost function</code>, vary in different requirements</li> <li><code>Prediction horizon</code>, trade-off of<ul> <li>computation overload</li> <li>recursive feasibility</li> </ul> </li> <li><code>Terminal constraints</code></li> </ul>"},{"location":"Self-Driving/Planning/05_mpc/#linear-mpc","title":"Linear MPC","text":"<p>Linear MPC has following <code>linear prediction model</code>:</p> \\[ \\begin{cases} x_{k + 1} &amp;= A x_k + B u_k \\\\ y_k &amp;= C x_k \\end{cases} \\] <p>And each state at time \\(k\\) has the relation with inputs:</p> \\[ x_k = A^k x_0 + \\sum_{j = 0}^{k - 1} A^j B u_{k - 1 - j} \\] <p>Rewrite the equation above as matrix:</p> \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots x_{N - 1} \\\\ x_{N} \\end{bmatrix} = \\begin{bmatrix} B &amp; 0 &amp; \\cdots &amp; 0 \\\\ AB &amp; B &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ A^{N - 1}B &amp; A^{N - 2}B &amp; \\cdots &amp; B \\end{bmatrix} \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{N - 1} \\end{bmatrix} + \\begin{bmatrix} A \\\\ A^2 \\\\ \\vdots \\\\ A^N \\end{bmatrix} x_0 \\] <p>The cost function of linear MPC is quadratic:</p> \\[ J = x_N^T P x_N + \\sum_{k = 0}^{N - 1} (x_k^T Q x_k + u_k^T R u_k) \\] <p>where \\(P\\), \\(Q\\) and \\(R\\) are <code>positive semi-definite</code>.</p> <p>The goal is to find the best control sequence \\(u_{0:N-1}^\\star\\) that minimizes:</p> \\[ J = x_0^T Q x_0 + \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_{N - 1} \\\\ x_{N} \\end{bmatrix}^T \\begin{bmatrix} Q &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; Q &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; Q &amp; 0 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; P \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_{N - 1} \\\\ x_{N} \\end{bmatrix} + \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{N - 1} \\end{bmatrix}^T \\begin{bmatrix} R &amp;  0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; R &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; R \\\\ \\end{bmatrix} \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{N - 1} \\end{bmatrix} \\] <p>We define:</p> <ul> <li>\\(\\bar{S} =  \\begin{bmatrix} B &amp; 0 &amp; \\cdots &amp; 0 \\\\ AB &amp; B &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ A^{N - 1}B &amp; A^{N - 2}B &amp; \\cdots &amp; B \\end{bmatrix}\\) </li> <li>\\(z = \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{N - 1} \\end{bmatrix}\\) </li> <li>\\(\\bar{T} = \\begin{bmatrix} A \\\\ A^2 \\\\ \\vdots \\\\ A^N \\end{bmatrix}\\)</li> <li>\\(\\bar{Q} = \\begin{bmatrix} Q &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; Q &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; Q &amp; 0 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; P \\end{bmatrix}\\)</li> <li>\\(\\bar{R} = \\begin{bmatrix} R &amp;  0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; R &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; R \\\\ \\end{bmatrix}\\)</li> </ul> <p>Then:</p> \\[ \\begin{align} J(z, x_0) &amp;= (\\bar{S}z + \\bar{T}x_0)^T\\bar{Q}(\\bar{S}z + \\bar{T}x_0) + z^T \\bar{R} z + x_0^T Q x_0 \\\\ &amp;= \\frac{1}{2} z^T 2 (\\bar{R} + \\bar{S}^T \\bar{Q} \\bar{S}) z + x_0^T 2 \\bar{T}^T\\bar{Q}\\bar{S}z + \\frac{1}{2} x_0^T 2 (Q + \\bar{T}^T \\bar{Q} \\bar{T})x_0 \\end{align} \\] <p>Then define:</p> <ul> <li>\\(H = 2 (\\bar{R} + \\bar{S}^T \\bar{Q} \\bar{S})\\)</li> <li>\\(F = 2 \\bar{T}^T\\bar{Q}\\bar{S}\\)</li> <li>\\(Y = 2 (Q + \\bar{T}^T \\bar{Q} \\bar{T})\\)</li> </ul> <p>So we got the <code>Condensed form</code> of MPC:</p> \\[ J(z, x_0) = \\frac{1}{2} z^T H z + x_0^T F z + \\frac{1}{2} x_0^T Y x_0 \\] <p>where, \\(z = \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots u_{N - 1} \\end{bmatrix}\\)</p> <p>The optimum is obtained by zeroing the gradient:</p> \\[ \\Delta_z J(z, x_0) = Hz + F^Tx_0 \\] <p>So we got the optimal batch solution \\(z\\):</p> \\[ z^\\star = - H^{-1} F^T x_{0} \\] <p>Unconstrained linear MPC is a linear state-feedback</p>"},{"location":"Self-Driving/Planning/05_mpc/#linear-quadratic-regulatorlqr","title":"Linear Quadratic Regulator(LQR)","text":"<p>Linear Quadratic Regulator(LQR) uses <code>dynamic programming</code> to solve the problem. It exploiting the sequential structure of the problem.</p> <p>According to <code>Bellman's principle of optimality</code>:</p> <p>An optimal policy has the property that, regardless of the decisions taken to enter a particular state, the remaining decisions made for leaving that stage must constitute an optimal policy.</p> <p>We can solve the problem from back to front.</p> <p></p> <p></p> <p></p>"},{"location":"Self-Driving/Planning/05_mpc/#other-mpc","title":"Other MPC","text":""},{"location":"Self-Driving/Planning/05_mpc/#explicit-mpc","title":"Explicit MPC","text":"<p>Explicit MPC implement constrained linear MPC <code>without an online QP solver</code></p> <p>For an <code>online</code> optimization, with given \\(x(t)\\), we solve the problem at each time step \\(t\\), which is  a <code>Quadratic Programming(QP)</code>.</p> <p>For an <code>offline</code> optimization, we solve the QP in advance for all \\(x(t)\\) in a given range to find the control law \\(u = u_0^\\star (x)\\) explicity, which is a <code>Multi-parametric Quadratic Programming(mpQP)</code></p>"},{"location":"Self-Driving/Planning/05_mpc/#linear-time-varying-mpc-and-nonlinear-mpc","title":"Linear Time-Varying MPC and Nonlinear MPC","text":"<p><code>Time-Varying</code> means in linear model:</p> \\[ x_{k + 1} = A x_k + B u_k = A_k x_k + B_k u_k \\] <p>the matrix \\(A\\) and \\(B\\) are varying by time.</p> <p>A nonlinear MPC has nonlinear model:</p> \\[ \\dot x = f(x, u) \\] <p>A <code>Linear Time-Varying</code> model can be obtained by linearing a nonlinear model.</p> <p>Convert linear model to <code>discrete-time</code> using forward Euler method:</p> \\[ \\begin{align} \\dot x &amp;= A_c x + B_c u + g_c \\\\ \\frac{x_{k + 1} - x_k}{T_s} &amp;= A_c x_k + B_c u_k + g_c \\\\ x_{k + 1} &amp;= (I + T_s A_c) x_k + T_s B_c u_k + T_s g_c \\\\ x_{k + 1} &amp;= A_kx_k + B_ku_k + g_k \\end{align} \\] <p>Then we can solve a linear MPC online.</p> <p><code>Augmented model</code> is often used in practice, which use the state matrix and control matrix as state, difference of control as new input vector. It's good to add cost on difference of input.</p> \\[ \\begin{bmatrix} x \\\\ u \\end{bmatrix}_{k + 1} =  \\begin{bmatrix} A &amp; B \\\\ 0 &amp; I \\end{bmatrix}\\begin{bmatrix} x \\\\ u \\end{bmatrix}_{k} + \\begin{bmatrix} B \\\\ I \\end{bmatrix} \\Delta u_k \\]"},{"location":"Self-Driving/Planning/05_mpc/#tube-mpc","title":"Tube MPC","text":"<p>The advantages of nonlinear MPC:</p> <ul> <li>Sometimes it's hard to carry out <code>system identification</code>, especially for nonlinear systems;</li> <li>Recursive feasibility and stability cannot be guaranteed for complex systems.</li> </ul> <p>Here comes the <code>Tube MPC</code>, which use an independent <code>noninal model</code> of the system, and use a feedback controller to ensure the actual state converges to the nomial state.</p> <p>An ancillary feedback controller is designed to keep the actual state within an invariant <code>tube</code> around a nomial trajectory computed neglecting <code>disturbances</code>.</p> <p></p> <p></p>"},{"location":"Self-Driving/Planning/05_mpc/#hybrid-mpc","title":"Hybrid MPC","text":""},{"location":"Self-Driving/Planning/05_mpc/#model-predictive-contouring-controlmpcc","title":"Model Predictive Contouring Control(MPCC)","text":""},{"location":"Self-Driving/Planning/ref_line/","title":"Reference Line","text":""},{"location":"Self-Driving/Planning/ref_line/#femfinite-element-methodpos-smooth","title":"Fem(Finite Element Method)pos Smooth","text":"<p>The optimization variables are points(x, y) position. The object function can be wrriten as:</p> \\[ Cost_{all} = Cost_{smooth} + Cost_{length} + Cost_{deviation} \\]"},{"location":"Self-Driving/Planning/ref_line/#smooth-cost","title":"Smooth Cost","text":"<p>As we can see, </p> \\[ \\vec{v_2} = \\vec{v_0} + \\vec{v_1} \\] <p>and the shorter \\(|\\vec{v_2}|\\) is, the smoother \\(p_0 \\to p_1 \\to p_2\\)  become. In vector format:</p> <p>$$ \\begin{align} \\vec{v_0} &amp;= P_0 - P_1 \\ \\vec{v_1} &amp;= P_2 - P_1 \\ \\vec{v_2} &amp;= \\vec{v_0} + \\vec{v_1} \\end{align} $$ So,</p> \\[ Cost_{smooth} = \\sum_{k = 1}^{n - 2} ||2 P_k - P_{k - 1} + P_{k + 1}||^2_2 \\] <p>This cost can also be descriped as: </p> <p>As \\(\\theta\\) decreases, \\(cos \\theta\\) decreases too. So,</p> \\[ Cost_{smooth} = \\sum_{k = 1}^{n - 2} \\frac{\\vec{v_0} \\cdot \\vec{v_1}}{|\\vec{v_0}| \\cdot |\\vec{v_1}|} \\] <p>As we can see, if we use \\(\\theta\\) for smooth, the cost will not be a <code>qp problem</code>, we should solve it with a nonlinear solver.</p>"},{"location":"Self-Driving/Planning/ref_line/#length-cost","title":"Length Cost","text":"\\[ Cost_{length} = \\sum_{k = 0}^{n - 2} ||P_{k + 1} - P_{k}||^2_2 \\]"},{"location":"Self-Driving/Planning/ref_line/#deviation-cost","title":"Deviation Cost","text":"\\[ Cost_{deviation} = \\sum_{k = 0}^{n - 1} ||P_k - P_{k_{ref}}||_2^2 \\]"},{"location":"Self-Driving/Planning/ref_line/#curve-rate-constraints","title":"Curve Rate Constraints","text":"<p>Assumption:</p> <ul> <li>\\(|P_0 P_1| \\approx |P_1 P_2|\\), each piece of segment has almost the same length;</li> <li>\\(\\theta\\) is small, so \\(sin\\theta \\approx cos \\theta\\);</li> <li>\\(ds \\approx arc P_1 \\to P_2\\) , distance between two points is approximately equal to the arc of them.</li> </ul> <p>As we can see in above figure, \\(|P_0P_1| = |P_1 P_2|\\), \\(|P_0 A| = |P_0P_1|\\) :</p> \\[ \\frac{L}{ds} =\\frac{ds}{R} \\] \\[ L = |\\vec{P_0P_1} + \\vec{P_1P_2}| = \\frac{|\\vec{P_1P_2}|^2} {R} \\]"},{"location":"Self-Driving/Prediction/apollo_prediction_module/","title":"Introduce to Apollo(3.5) Prediction Module","text":"<p>The prediction module studies and predicts the behavior of all the obstacles detected by the perception module. Prediction receives data of obstacles along with basic perception information including positions, headings, velocities, accelerations and then generates predicted trajectories with probabilities for those obstacles.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#input","title":"Input","text":"<ul> <li>Obstacles information from the perception module;</li> <li>Localization information from the localization module;</li> <li>Planning trajectory of ego vehicle of the previous computing cycle from the planning module.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#output","title":"Output","text":"<ul> <li>Obstacles annotated with predicted trajectories and their priorities.</li> </ul> <p>Obstacle priority is now calculated as individual scenarios are prioritized differently. The priorities include:</p> <ul> <li>ignore;</li> <li>caution;</li> <li>normal(default).</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#functionalities","title":"Functionalities","text":"<p>The prediction module comprises of 4 main functionalities: </p> <ul> <li>Container</li> <li>Scenario</li> <li>Evaluator</li> <li>Predictor</li> </ul> <p>shown as below: <pre><code>Localization +-------------+          +-------------+           +-------------+          +-------------+\npose         |             |          |             |           |             |          |             |\n+------------&gt;             |          |             |           |             |          |             |\nPlanning     |             |structured|             | Scenario  |             |Lane      |             |Predicted\ntrajectory   |             |obstacle  |             | type      |             |probability             |trajectory\n+------------&gt;  CONTAINER  +----------&gt;  SCENARIO   +-----------&gt;  EVALUATOR  +----------&gt;  PREDICTOR  +----------&gt;\nPerception   |             |          |             |           |             |          |             |\nobstacles    |             |          |             |           |             |          |             |\n+------------&gt;             |          |             |           |             |          |             |\n             |             |          |             |           |             |          |             |\n             +-------------+          +-------------+           +-------------+          +-------------+\n</code></pre></p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#container","title":"Container","text":"<p>Container stores structured data from subscribed channels. Current supported inputs:</p> <ul> <li>perception obstacles</li> <li>ego vehicle localization</li> <li>ego vehicle planning trajectory</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#architecture","title":"Architecture","text":"<p>The architecture of the container is as below. The class <code>Container</code> defines the interface of all containers and it can't be realized because it has a pure virtual function <code>Insert</code>. <code>PoseContainer</code>, <code>ADCTrajectoryContainer</code> and  <code>ObstacleContainer</code> are derived from <code>Container</code> and realize the <code>Insert</code> function. The <code>ContainerManager</code> class has many containers. It generates all three types of contianer and stores them in an unordered map to speed up the search process. I just list some important methods of the class here, for more functions and their description, you can read the documents generated from <code>doxygen</code>. </p> <p>Current container contains:</p> <ul> <li>PoseContainer</li> <li>ADCTrajectoryContainer</li> <li>ObstacleContainer</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#posecontainer","title":"PoseContainer","text":"<p><code>PoseContainer</code> receives localization message:</p> <ul> <li>position(3d);</li> <li>theta(orientation);</li> <li>velocity(3d);</li> </ul> <p>and inserts ego vehicle as an obstacle into <code>ObstacleContainer</code> with id <code>-1</code> and type <code>VEHICLE</code>.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#trajectorycontainer","title":"TrajectoryContainer","text":"<p><code>TrajectoryContainer</code> receives trajectory message from planning and sets the information of current lane:</p> <ul> <li>junction id;</li> <li>the distance to junction;</li> <li>lane sequence;</li> <li>overlaps of the lane.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#obstaclecontainer","title":"ObstacleContainer","text":"<p><code>ObstacleContainer</code> structures and stores all obstacles from perception, it has a <code>LRU(Latest Recently Used)Cache</code> class to manage the latest recently used 10 items. The <code>value</code> of LRUCache is the obstacle and the <code>key</code>  is the id of the obstacle. The functionality of <code>ObstacleContainer</code> depends on the class <code>ObstacleCluster</code>, because method <code>SortObstacle</code> is used.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#obstaclecluster","title":"ObstacleCluster","text":"<p><code>ObstacleCluster</code> contains not only <code>Obstcles</code> in an unordered map to speedup <code>set</code> and <code>get</code> but also the relationship between <code>Obstacles</code> and <code>LaneGraphs</code> from <code>HdMap</code> like <code>Overlaps</code> and <code>Stopsigns</code>.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#obstacle","title":"Obstacle","text":"<p><code>Obstacle</code> class is a basic unit to store <code>Obstacles</code> generated by <code>perception</code> module. It stores the information of an obstacle in a data structure <code>Feature</code> which is defined in google's data interchange format protobuf. </p> <p>In addtion to the information about the obstacle, <code>Obstacle</code> uses</p> <ul> <li>a <code>KalmanFilter</code> to track the trajectory of pedestrian;</li> <li>a <code>KalmanFilter</code> to track the trajectory of other obstacles(vehicle, bicycle, etc.)</li> <li>a <code>DigitalFilter</code> to filter the heading of bicycles and pedestrians.</li> </ul> <p><code>Obstacle</code> contains many methods about obstacle's property:</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#isstill-return-true-if-the-obstacle-is-still","title":"<code>IsStill</code>: return true if the obstacle is still.","text":"<p>There are two checks to determine whether an obstacle is still or not:</p> <ul> <li>distance check.</li> <li>speed check.</li> </ul> <p>Firstly, we can calculate the average distance deviation of an obstacle's history position:</p> \\[ x_{avg} = \\sum_{i = 1}^{n} \\frac{x_{i} - x_{0}}{n - 1} \\] \\[ y_{avg} = \\sum_{i = 1}^{n} \\frac{y_{i} - y_{0}}{n - 1} \\] <p>In the above equations,</p> <ul> <li>\\(x_{avg}\\) is the average distance deviation of \\(x\\);</li> <li>\\(y_{avg}\\) is the average distance deviation of \\(y\\);</li> <li>\\(n\\) is the history size of an obstacle, in the program is \\(10\\);</li> <li>\\(x_{i}\\) is the <code>i</code>th \\(x\\) of the position in history;</li> <li>\\(y_{i}\\) is the <code>i</code>th \\(y\\) of the position in history;</li> <li>\\(x_{0}\\) is the current \\(x\\) of the position of an obstacle;</li> <li>\\(y_{0}\\) is the current \\(y\\) of the position of an obstacle.</li> </ul> <p>Then, the speed sensibility is defined as:</p> \\[ K_{v} = \\frac{\\sqrt{2 * n} * 4 * k_{std}}{(n + 1) * d_{t}} \\] <p>In the equation:</p> <ul> <li>\\(K_{v}\\) is the sensibility of speed;</li> <li>\\(n\\) is the history size of an obstacle;</li> <li>\\(k_{std}\\) is the position standard deviation of an obstacle, it's \\(1.0\\)(obstacle) or \\(0.5\\)(other) in program;</li> <li>\\(d_{t}\\) is the duration of the history.</li> </ul> <p>Nextly, we calculate the distance:</p> \\[ D = \\sqrt{x_{avg}^2 + y_{avg}^2} \\] \\[ D_{std} = \\sqrt{\\frac{2.0}{n}} * k_{std} \\] <p>In the equation:</p> <ul> <li>\\(D\\) is the distance of obstacle;</li> <li>\\(D_{std}\\) is the standard distance of obstacle.</li> </ul> <p>Now we can determine the obstacle is:</p> <ul> <li>still, if \\(v &lt; v_{threshold}\\)(\\(v\\) is current speed, \\(v_{threshold}\\) is the threshold of speed, it's \\(0.8\\)(obstacle) or \\(0.5\\)(other) in program);</li> <li>not still, if \\(v &gt; v_{threshold}\\) and \\(K_{v} &lt; v_{threshold}\\);</li> <li>not still, if \\(v &gt; v_{threshold}\\) and \\(K_{v} &gt; v_{threshold}\\) and \\(D &gt; 2.0 * D_{std}\\);</li> <li>still, if \\(v &gt; v_{threshold}\\) and \\(K_{v} &gt; v_{threshold}\\) and \\(D &lt; 2.0 * D_{std}\\);</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#scenario","title":"Scenario","text":"<p>The <code>Scenario</code> sub-module analyzes scenarios that includes the ego vehicle. Currently, two scenarios are defined:</p> <ul> <li>Cruise : this scenario includes lane keeping and following.</li> <li>Junction : this scenario involves junctions. Junctions can either have traffic lights and/or STOP signs.</li> </ul> <p>The architecture of <code>Scenario</code> is as below: </p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#scenariomanager","title":"ScenarioManager","text":"<p>The <code>ScenarioManager</code> class depends on <code>FeatureExtractor</code> to generate environment features and depends on <code>ScenarioAnalyzer</code> to analyze current scenario. If necessary, <code>ScenarioManager</code> will set obstacls' priorities as:</p> <ul> <li>IGNORE, if the obstacle is no need to be considered;</li> <li>NORMAL, if the obstacle should be considered.</li> </ul> <p></p> <p>The obstacle is set to <code>NORMAL</code> if the obstacle is:</p> <ul> <li><code>in scan area</code>, the scan arear is a rectanglar in front of ego vehicle with the length(\\(80\\) in program) and width(\\(12\\) in program), for example, the obstacle with id of 5 is in scan area but 6 not;</li> <li><code>on lane</code>, for example, the obstacle with id of 3 is on lane but 2 not;</li> <li><code>near junction</code>, means that the distance between obstacle and junction is less than threshold(it's \\(1\\) in program), see obstacle 4 and 5;</li> <li><code>near lane</code>, this rule is not for the obstacle with the type of <code>VEHICLE</code>, if the distance is less than threshold(\\(3\\) in program), obstacle 2 and 3 is near lane.</li> </ul> <p>Otherwise the priority of the obstacle is <code>IGNORE</code>.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#featureextractor","title":"FeatureExtractor","text":"<p><code>FeatureExtractor</code> sets</p> <ul> <li>Ego lane feature, including ego lane <code>id</code> and distance <code>s</code> of lane;</li> <li>Left and right lane feature, including lane <code>id</code> and distance <code>s</code> of lane;</li> <li>Junction feature, including junction <code>id</code>, we only consider the junction that has signals or stop signs. </li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#scenarioanalyzer","title":"ScenarioAnalyzer","text":"<p><code>ScenarioAnalyzer</code> determines which scene ego vehicle is in:</p> <ul> <li>Junction, if the distance between ego vehicle and junction is less than threshold(\\(10\\) in program);</li> <li>Cruise, otherwise.</li> </ul> <p><code>ScenarioAnalyzer</code> works depends on <code>ScenarioFeatures</code>. Once which scenario is determined, it will generate corresponding scenario features.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#scenariofeatures","title":"ScenarioFeatures","text":"<p><code>CruiseScenariosFeatures</code> and <code>CruiseScenariosFeatures</code> are derived from the base class <code>ScenarioFeatures</code>.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#evaluator","title":"Evaluator","text":"<p>The <code>Evaluator</code> predicts path and speed separately for any given obstacle. An evaluator evaluates a path by outputting a probability for it (lanesequence) using the given model stored in <code>prediction/data/</code>.</p> <p>Now in <code>prediction</code>, the <code>Evaluator</code> for <code>Cyclist</code> are:</p> <ul> <li><code>CyclistKeepLaneEvaluator</code>;</li> </ul> <p>and the <code>Evaluator</code> for <code>Vehicle</code> are:</p> <ul> <li><code>CostEvaluator</code>: probability is calculated by a set of cost functions;</li> <li><code>MLPEvaluator</code>: probability is calculated using an MLP model;</li> <li><code>RNNEvaluator</code>: probability is calculated using an RNN model;</li> <li><code>CruiseMLPEvaluator</code>: probability is calculated using a mix of MLP and CNN-1d models for the cruise scenario;</li> <li><code>JunctionMLPEvaluator</code>: probability is calculated using an MLP model for junction scenario.</li> </ul> <p>The architecture of <code>Evaluator</code> is as below:</p> <p></p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#evaluatormanager","title":"EvaluatorManager","text":"<p>The <code>EvaluatorManager</code> creates and stores all types of evaluators, so it has many <code>Evaluator</code> pointers. The <code>Evaluator</code> class is a base class that defines a pure virtual function <code>Evaluate</code>. <code>EvaluatorManager</code> calls <code>Evaluator</code>'s subclass's function <code>Evaluate</code> to calculate probability for a lanesequence. If the <code>obstacle</code> type is:</p> <ul> <li><code>VEHICLE</code> and it's <ul> <li><code>ON_LANE</code>, the <code>Evaluator</code> will be <code>CruiseMLPEvaluator</code>;</li> <li><code>IN_JUNCTION</code>, the <code>Evaluator</code> will be <code>JunctionMLPEvaluator</code>;</li> </ul> </li> <li><code>BICYCLE</code> and it's<ul> <li><code>ON_LANE</code>, the <code>Evaluator</code> will be <code>CyclistKeepLaneEvaluator</code>;</li> </ul> </li> <li><code>UNKNOWN</code> and it's<ul> <li><code>ON_LANE</code>, the <code>Evaluator</code> will be <code>MLPEvaluator</code>;</li> </ul> </li> </ul> <p>otherwise, the <code>Evaluator</code> would not work.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#cyclistkeeplaneevaluator","title":"CyclistKeepLaneEvaluator","text":"<p>The <code>CyclistKeepLaneEvaluator</code> is simple and has only two probability values:</p> <ul> <li>1.0, if current lane id is equal to the lane id in lane sequence;</li> <li>0.0, if current lane id is not equal to the lane id in lane sequence.</li> </ul> <p>The lanes sequence is a list of lane id that covers the length:</p> \\[ D_{lane} = v_{0} * t_{max} + 0.5 * a_{max} * t_{max}^2 \\] <p>In equation,</p> <ul> <li>\\(D_{lane}\\) is the distance the lane sequance covers;</li> <li>\\(v_{0}\\) is current speed the obstacle has;</li> <li>\\(t_{max}\\) is the predicted trajectory duration, it's 8.0 in program;</li> <li>\\(a_{max}\\) is the maximum linear acceleration of vehicle, it's 4.0 in program;</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#mlpevaluator","title":"MLPEvaluator","text":"<p>This <code>Evaluator</code> uses a MLP(Multilayer Perceptron):</p> <p></p> <p>The model has \\(62\\) inputs, \\(22\\) of which are obstacle features:</p> <ul> <li>\\(\\theta_{filter}\\), the average of the latest 5 heading values in an obstacle's history;</li> <li>\\(\\theta_{mean}\\), the average of all the heading values in an obstacle's history;</li> <li>\\(\\theta_{filter} - \\theta_{mean}\\);</li> <li>\\(\\theta_{diff} = \\theta_{curr} - \\theta_{prev}\\), where \\(\\theta_{curr}\\) is the average of the latest \\(0 \\to 4\\) heading values in an obstacle's history, \\(\\theta_{prev}\\) is the average of the latest \\(5 \\to 9\\) heading values;</li> <li>\\(\\theta_{diff}'\\), $\\theta_{diff}' = \\frac{\\theta_{diff}}{\\Delta_t} $;</li> <li>\\(l_{filter}\\), the average of the latest 5 lateral distance values in an obstacle's history;</li> <li>\\(l_{mean}\\), the average of all the lateral distance values in an obstacle's history;</li> <li>\\(l_{filter} - l_{mean}\\);</li> <li>\\(l_{diff} = l_{curr} - l_{prev}\\), where \\(l_{curr}\\) is the average of the latest \\(0 \\to 4\\) lateral distance values in an obstacle's history, \\(l_{prev}\\) is the average of the latest \\(5 \\to 9\\) lateral distance values;</li> <li>\\(v\\), the velocity of the obstacle;</li> <li>\\(a\\), the acceleration of the obstacle;</li> <li>\\(D_{lb}\\), the distance from obstacle to left lane boundary;</li> <li>\\(D_{lb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{lb}\\) of the history, \\(D_{last}\\) is the last \\(D_{lb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{lb diff}' = D_{lb curr} - D_{lb prev}\\), where \\(D_{lb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{lb}\\) values in an obstacle's history, \\(D_{lb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{lb}\\) values;</li> <li>\\(D_{rb}\\), the distance from obstacle to right lane boundary;</li> <li>\\(D_{rb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{rb}\\) of the history, \\(D_{last}\\) is the last \\(D_{rb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{rb diff}' = D_{rb curr} - D_{rb prev}\\), where \\(D_{rb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{rb}\\) values in an obstacle's history, \\(D_{rb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{rb}\\) values;</li> <li><code>is_curr_lane_no_turn</code>, this value is \\(1\\) if current lane is <code>NoTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_left_turn</code>, this value is \\(1\\) if current lane is <code>LeftTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_right_turn</code>, this value is \\(1\\) if current lane is <code>RightTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_uturn</code>, this value is \\(1\\) if current lane is <code>UTurn</code>, or it's \\(0\\).</li> </ul> <p>And the other 40 features are lane features, we choose 10 points from the reference line, each of them has 4 features:</p> <ul> <li>\\(\\psi_{diff}\\): the heading deviation between obstacle and reference line;</li> <li>\\(l_{point}\\): the lateral distance of the lane point;</li> <li>\\(\\psi_{point}\\): the heading of the lane point;</li> <li>\\(\\psi_{dev}\\): the heading divation between obstacle and the point closet to the obstacle.</li> </ul> <p>The output \\(\\widehat{y}\\) is the probability that an obstacle stays on a lane.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#cruisemlpevaluator","title":"CruiseMLPEvaluator","text":"<p>The model has \\(23 + 5 * 9 + 8 + 20 * 4 = 146\\) inputs, \\(23\\) of which are obstacle features:</p> <ul> <li>\\(\\theta_{filter}\\), the average of the latest 5 heading values in an obstacle's history;</li> <li>\\(\\theta_{mean}\\), the average of all the heading values in an obstacle's history;</li> <li>\\(\\theta_{filter} - \\theta_{mean}\\);</li> <li>\\(\\theta_{diff} = \\theta_{curr} - \\theta_{prev}\\), where \\(\\theta_{curr}\\) is the average of the latest \\(0 \\to 4\\) heading values in an obstacle's history, \\(\\theta_{prev}\\) is the average of the latest \\(5 \\to 9\\) heading values;</li> <li>\\(\\theta_{diff}'\\), \\(\\theta'_{diff} = \\frac{\\theta_{diff}}{\\Delta_t}\\);</li> <li>\\(l_{filter}\\), the average of the latest 5 lateral distance values in an obstacle's history;</li> <li>\\(l_{mean}\\), the average of all the lateral distance values in an obstacle's history;</li> <li>\\(l_{filter} - l_{mean}\\);</li> <li>\\(l_{diff} = l_{curr} - l_{prev}\\), where \\(l_{curr}\\) is the average of the latest \\(0 \\to 4\\) lateral distance values in an obstacle's history, \\(l_{prev}\\) is the average of the latest \\(5 \\to 9\\) lateral distance values;</li> <li>\\(v\\), the velocity of the obstacle;</li> <li>\\(a\\), the acceleration of the obstacle;</li> <li>\\(j\\), the jerk of the obstacle;</li> <li>\\(D_{lb}\\), the distance from obstacle to left lane boundary;</li> <li>\\(D_{lb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{lb}\\) of the history, \\(D_{last}\\) is the last \\(D_{lb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{lb diff}' = D_{lb curr} - D_{lb prev}\\), where \\(D_{lb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{lb}\\) values in an obstacle's history, \\(D_{lb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{lb}\\) values;</li> <li>\\(D_{rb}\\), the distance from obstacle to right lane boundary;</li> <li>\\(D_{rb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{rb}\\) of the history, \\(D_{last}\\) is the last \\(D_{rb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{rb diff}' = D_{rb curr} - D_{rb prev}\\), where \\(D_{rb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{rb}\\) values in an obstacle's history, \\(D_{rb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{rb}\\) values;</li> <li><code>is_curr_lane_no_turn</code>, this value is \\(1\\) if current lane is <code>NoTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_left_turn</code>, this value is \\(1\\) if current lane is <code>LeftTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_right_turn</code>, this value is \\(1\\) if current lane is <code>RightTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_uturn</code>, this value is \\(1\\) if current lane is <code>UTurn</code>, or it's \\(0\\).</li> </ul> <p>And \\(5 * 9\\) features are obstacle history features, we search \\(5\\) frames of history, each frame has \\(9\\) fearures:</p> <ul> <li><code>is_curr_frame_has_hisotry</code>, the value is \\(1\\) if current frame and previous frame all have position/velocity/acceleration/velocity_heading information, otherwise it's \\(0\\);</li> <li>\\(x\\), in local coordinate system;</li> <li>\\(y\\), in local coordiante system;</li> <li>\\(x^{\\prime}\\);</li> <li>\\(y^{\\prime}\\);</li> <li>\\(x^{\\prime\\prime}\\);</li> <li>\\(y^{\\prime\\prime}\\);</li> <li>\\(\\theta_{v}\\), the heading of velocity;</li> <li>\\(\\theta_{v}^{\\prime}\\).</li> </ul> <p>\\(8\\) features are for forward and backward obstacles:</p> <ul> <li>\\(s_{forward}\\), the forward obstacle's distance;</li> <li>\\(l_{forward}\\), the forward obstacle's lateral distance;</li> <li>\\(L_{forward}\\), the forward obstacle's length;</li> <li>\\(v_{forward}\\), the forward obstacle's velocity;</li> <li>\\(s_{backward}\\), the backward obstacle's distance;</li> <li>\\(l_{backward}\\), the backward obstacle's lateral distance;</li> <li>\\(L_{backward}\\), the backward obstacle's length;</li> <li>\\(v_{backward}\\), the backward obstacle's velocity;</li> </ul> <p>And the other \\(20 * 4\\) features are lane features, we choose \\(20\\) points from the reference line, each of them has 4 features:</p> <ul> <li>\\(s_{point}\\), the lane point's distance;</li> <li>\\(l_{point}\\), the lane point's lateral distance;</li> <li>\\(\\psi_{point}\\): the heading of the lane point;</li> <li>\\(\\kappa_{point}\\): the curvature of the lane point.</li> </ul> <p>The result of <code>CruiseMLPEvaluator</code> is:</p> <ul> <li>the probability of an obstacle on a lane;</li> <li>the time of an obstacle to travel to reference line.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#junctionmlpevaluator","title":"JunctionMLPEvaluator","text":"<p>This model has 3 obstacle features:</p> <ul> <li>\\(v\\), the velocity of an obstacle;</li> <li>\\(a\\), the acceleration of an obstacle;</li> <li>\\(S_{junction}\\), the area of the junction.</li> </ul> <p>The other \\(12 * 5\\) features are junction features. We divide area aroud the vehicle to 12 regions and calculate the probability of each exit.  Each exit has 5 features:</p> <ul> <li><code>is_exit_exist</code>, it's 1 if the exit of junction exists;</li> <li>\\(x_{diff} / S_{junction}\\), \\(x_{diff}\\) is the deviation between obstacle and exit in x direction;</li> <li>\\(y_{diff} / S_{junction}\\), \\(y_{diff}\\) is the deviation between obstacle and exit in y direction;</li> <li>\\(L_{diff} / S_{junction}\\), \\(L_{diff}\\) is the distance between obstacle and exit;</li> <li>\\(\\theta_{diff}\\), the heading difference between obstacle and exit.</li> </ul> <p>And the output of the model is the probability of an obstacle to exit in 12 directions.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#costevaluator","title":"CostEvaluator","text":"<p><code>CostEvaluator</code> calculates the probability based on the distance between obstacle and lane boundary.</p> \\[ E_{l} = \\frac{W_{lane}}{2} - W_{l} \\] \\[ P_{cost} = \\frac{1}{1 + e^{-E_{l}}} \\] <p>In the equation:</p> <ul> <li>\\(E_{l}\\) is the distance from lane boundary to obstacle's location;</li> <li>\\(W_{lane}\\) is the width of lane;</li> <li>\\(W_{l}\\) is the lateral distance from lane reference line to obstacle's location;</li> <li>\\(P_{cost}\\) is the probability, calculated by a Sigmoid function.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#rnnevaluator","title":"RNNEvaluator","text":"<p>Not used in program.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#predictor","title":"Predictor","text":"<p>Predictor generates predicted trajectories for obstacles. Currently, the supported predictors include:</p> <ul> <li>Empty: obstacles have no predicted trajectories;</li> <li>Single lane: Obstacles move along a single lane in highway navigation mode. Obstacles not on lane will be ignored;</li> <li>Lane sequence: obstacle moves along the lanes;</li> <li>Move sequence: obstacle moves along the lanes by following its kinetic pattern;</li> <li>Free movement: obstacle moves freely;</li> <li>Regional movement: obstacle moves in a possible region;</li> <li>Junction: Obstacles move toward junction exits with high probabilities.</li> </ul> <p>The relationship between <code>predictor</code>s is as below: </p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#predictormanager","title":"PredictorManager","text":"<p><code>PredictorManager</code> creates and stores all kinds of <code>predictor</code>s. It has pointers of base class <code>Predictor</code> to points to its subclasses, the specail predictors. <code>PredictorManager</code> runs the special predictor's method <code>Predict</code> to generate trajectories according to obstacles's type. If the obstacle's type is:</p> <ul> <li><code>Vehicle</code>, and it's<ul> <li><code>InJunction</code>, the predictor will be <code>LaneSequencePredictor</code>;</li> <li><code>OnLane</code>, the predictor will be <code>MoveSequencePredictor</code>;</li> <li><code>OffLane</code>, the predictor will be <code>FreeMovePredictor</code>;</li> </ul> </li> <li><code>Pedestrian</code>, the predictor will be <code>FreeMovePredictor</code>;</li> <li><code>Bicycle</code>, and it's<ul> <li><code>OnLane</code>, the predictor will be <code>MoveSequencePredictor</code>;</li> <li><code>OffLane</code>, the predictor will be <code>FreeMovePredictor</code>;</li> </ul> </li> <li><code>Unknown</code>, and it's<ul> <li><code>OnLane</code>, the predictor will be <code>MoveSequencePredictor</code>;</li> <li><code>OffLane</code>, the predictor will be <code>FreeMovePredictor</code>;</li> </ul> </li> <li>other case, the predictor will be <code>EmptyPredictor</code>.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#predictor_1","title":"Predictor","text":"<p><code>Predictor</code> is a base class with the pure virtual function <code>Predict</code>. It also realizes some methods about trajectories:</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#trimtrajectory","title":"TrimTrajectory","text":"<p>If the obstacle is in junction, we don't trim obstacle's trajectory; otherwise, trim the trajectory to the front of junction.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#supposedtostop","title":"SupposedToStop","text":"<p>Determine if an obstacle is supposed to stop within a distance.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#emptypredictor","title":"EmptyPredictor","text":"<p><code>EmptyPredictor</code> does nothing but clear the trajectory of obstacle.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#freemovepredictor","title":"FreeMovePredictor","text":"<p><code>FreeMovePredictor</code> assumes that the obstacle always moves with initial velocity and acceleration, the state is:</p> \\[ \\begin{bmatrix} x \\\\\\\\ y \\\\\\\\ x^\\prime \\\\\\\\ y^\\prime \\\\\\\\ x^{\\prime\\prime} \\\\\\\\ y^{\\prime\\prime} \\end{bmatrix} \\] <p>and the transition matrix is:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; t &amp; 0 &amp; 0.5 * t^2 &amp; 0 \\\\\\\\ 0 &amp; 1 &amp; 0 &amp; t &amp; 0 &amp; 0.5 * t^2 \\\\\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; t &amp; 0 \\\\\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; t \\\\\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#junctionpredictor","title":"JunctionPredictor","text":"<p><code>JunctionPredictor</code> uses a cubic polynomial to fit start-point(obstacle's position) and end-point(junction exit position) within given time.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#regionalpredictor","title":"RegionalPredictor","text":"<p>Not used in program.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#sequencepredictor","title":"SequencePredictor","text":"<p><code>SequencePredictor</code> defines some common methods relatived to sequence.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#filterlanesequence","title":"FilterLaneSequence","text":"<p>This method filters out those obstacles that are close to the ego vehicle so that we will ignore them and drive normally unless they really kick into our lane.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#lanesequencepredictor","title":"LaneSequencePredictor","text":"<p><code>LaneSequencePredictor</code> is derived from <code>SequencePredictor</code>. After filtering lane sequence, it use the method from <code>Predictor</code> to check if an obstacle is to stop:</p> <ul> <li><code>true</code>, generate constant acceleration trajectory;</li> <li><code>false</code>, generate lane sequence trajectory.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#constant-acceleration-trajectory","title":"Constant acceleration trajectory","text":"<p>In this case, <code>predictor</code> refresh trajectory point with the equation:</p> \\[ s = v * t + 0.5 * a * t^2 \\] \\[ v = v_0 + a * t \\] \\[ l = l_0 * K_{approach} \\] <p>In equation:</p> <ul> <li>\\(s\\) is the obstacle distance on the lane;</li> <li>\\(v\\) is current velocity;</li> <li>\\(t\\) is the duration;</li> <li>\\(a\\) is current acceleration;</li> <li>\\(v_0\\) is the velocity from last step;</li> <li>\\(l\\) is the lateral distance between obstacle and lane reference line;</li> <li>\\(l_0\\) is the lateral distance last step.</li> <li>\\(K_{approach}\\) is the coefficient that obstacle moves towards lane reference line;</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#lane-sequence-trajectory","title":"Lane sequence trajectory","text":"<p>In this case, we assume that the obstacle moves with constant velocity:</p> \\[ s = s_0 + v * t \\] \\[ l = l_0 * K_{approach} \\]"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#movesequencepredictor","title":"MoveSequencePredictor","text":"<p><code>MoveSequencePredictor</code> is derived from <code>SequencePredictor</code>. After filtering lane sequence, it use the method from <code>Predictor</code> to check if an obstacle is to stop:</p> <ul> <li><code>true</code>, generate constant acceleration trajectory;</li> <li><code>false</code>, generate lane sequence trajectory using best trajectory selection.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#const-acceleration-trajectory","title":"Const acceleration trajectory","text":"<p>This trajectory is the same as LaneSequencePredictor</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#lane-sequence-trajectory-using-best-trajectory-selection","title":"Lane sequence trajectory using best trajectory selection","text":"<p>This trajectory traverses all the time to reach the end point and selects the best trajectory that has the minimum cost.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#generate-a-list-of-time-to-reach-the-end","title":"Generate a list of time to reach the end.","text":"<p>In program, we use the method <code>GenerateCandidateTimes</code> with the time gap of \\(0.5\\) and end time \\(8.0\\) to generate a sample time list: <code>{0, 0.5, 1, 1.5, ..., 7.5, 8.0}</code>.</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#calculate-the-5th-degree-polynomial-of-lateral-ditance-with-each-end-time","title":"Calculate the 5<sup>th</sup> degree polynomial of lateral ditance with each end time.","text":"<p>Since we have known the start state:</p> \\[ \\begin{cases} l_{0} = l_{obstacle} \\\\ l_{0}^\\prime = v_{lateral} \\\\ l_{0}^{\\prime\\prime} = 0 \\end{cases} \\] <p>and end state:</p> \\[ \\begin{cases} l_{1} = 0 \\\\ l_{1}^{\\prime} = 0 \\\\ l_{1}^{\\prime\\prime}= 0 \\end{cases} \\] <p>with the 5<sup>th</sup> degree polynomial equation:</p> \\[ \\begin{cases} l = a_0 + a_1 \\cdot t + a_2 \\cdot t^2 + a_3 \\cdot t^3 + a_4 \\cdot t^4 + a_5 \\cdot t^5 \\\\ l^{\\prime} = a_1 + 2 \\cdot a_2 \\cdot t + 3 \\cdot a_3 \\cdot t^2 + 4 \\cdot a_4 \\cdot t^3 + 5 \\cdot a_5 \\cdot t^4 \\\\ l^{\\prime\\prime} = 2 \\cdot a_2 \\cdot t + 6 \\cdot a_3 \\cdot t + 12 \\cdot a_4 \\cdot t^2 + 20 \\cdot a_5 \\cdot t^3 \\end{cases} \\] <p>we can get the coefficients \\(a_0\\) to \\(a_5\\).</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#calculate-the-4th-degree-polynomial-of-longitude-distance-with-each-end-time","title":"Calculate the 4<sup>th</sup> degree polynomial of longitude distance with each end time.","text":"<p>Since we have known the start state:</p> \\[ \\begin{cases} s_{0} = s_{obstacle} \\\\ s_{0}^\\prime = v_{longitude} \\\\ s_{0}^{\\prime\\prime} = 0 \\end{cases} \\] <p>and end state:</p> \\[ \\begin{cases} s_{1} = s_{end} \\\\ s_{1}^{\\prime} = v_{end} \\\\ s_{1}^{\\prime\\prime}= 0 \\end{cases} \\] <p>with the 4<sup>th</sup> degree polynomial equation:</p> \\[ \\begin{cases} s = a_0 + a_1 \\cdot t + a_2 \\cdot t^2 + a_3 \\cdot t^3 + a_4 \\cdot t^4 \\\\ s^{\\prime} = a_1 + 2 \\cdot a_2 \\cdot t + 3 \\cdot a_3 \\cdot t^2 + 4 \\cdot a_4 \\cdot t^3 \\\\ s^{\\prime\\prime} = 2 \\cdot a_2 \\cdot t + 6 \\cdot a_3 \\cdot t + 12 \\cdot a_4 \\cdot t^2 \\end{cases} \\] <p>we can get the coefficients \\(a_0\\) to \\(a_4\\).</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#find-the-coefficients-of-lateral-and-longitude-with-the-lowest-cost","title":"Find the coefficients of lateral and longitude with the lowest cost.","text":"<p>The cost of each group of coefficients can be calculated with:</p> \\[ C = a_{max lateral} + \\alpha * t_{end} \\] <p>In equation,</p> <ul> <li>\\(C\\) is the cost;</li> <li>\\(\\alpha\\) is ratio of time, it's \\(0.25\\) in program;</li> <li>\\(t_{end}\\) is the time to reach end point.</li> </ul>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#generate-each-point-of-the-trajectory-with-the-lowest-cost","title":"Generate each point of the trajectory with the lowest cost.","text":"<p>Now that we know the equation of longitude and lateral and the time to reach end point, we can generate each point of the trajectory with  time gap(\\(0.1\\) in program)</p>"},{"location":"Self-Driving/Prediction/apollo_prediction_module/#singlelanepredictor","title":"SingleLanePredictor","text":"<p>This <code>predictor</code> uses the same method as <code>LaneSequencePredictor</code> lane sequence case.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/","title":"Compilation Optimization of C++ Project","text":""},{"location":"Self-Driving/Prediction/compile_cpp_project/#why-doing-this-work","title":"Why Doing This Work","text":"<ul> <li>We change our platform from <code>x86</code> to <code>arm</code>, the cpu performance is getting weaker;</li> <li>Every time we debug on the vehicle, we suffer from the slow compilation time.</li> </ul>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#compilation-process","title":"Compilation Process","text":"<p>In general, the compilation of a C++ program involves these four steps:</p> <ol> <li>Preprocessing</li> <li>Compiling</li> <li>Assembling</li> <li>Linking</li> </ol> <p></p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#preprocessing","title":"Preprocessing","text":"<p>Preprocessor directives are one of the unique feature of C++. Before a C++ program gets compiled by the compiler, the source code gets preprocessed by the preprocessor. </p> <p>All preprocessor directives in C++ begin with <code>#</code>, and they do not need to end with a semicolon(<code>;</code>) because this is not a statement in C++.</p> <p>There are different preprocessor directives that perform different tasks.</p> <ul> <li>Inclusion Directives:<ul> <li><code>#include</code>: specifies the files to be included, especially header-file</li> </ul> </li> <li>Macro Definition Directive:<ul> <li><code>#define</code>: define a macro substitution</li> <li><code>#undef</code>: undefine a macro</li> </ul> </li> <li>Conditional Compilation Directive:<ul> <li><code>#if</code>: test a condition</li> <li><code>#elif</code>: else if condition</li> <li><code>#endif</code>: end of <code>#if</code></li> <li><code>#ifdef</code>: used to test for macro definition</li> <li><code>#ifndef</code>: used to test for whether a macro is not defined</li> <li><code>#else</code>: it provides an alternative option when <code>#if</code> fails</li> </ul> </li> <li>Other directives:<ul> <li><code>#error</code>: syntax \"#error err_msg\", shows the given error message and renders the program ill-formed</li> <li><code>#line</code>: Supplies a line number for compiler message</li> <li><code>#pragma</code>: Supplies implementation-defined instructions to the compiler</li> </ul> </li> </ul> <p>Some macros C++ predefined are:</p> <ul> <li><code>__LINE__</code>: this contians the current line number of the program when it is being compiled</li> <li><code>__FILE__</code>: this contians the current file name of the program when it is being compiled</li> <li><code>__DATE__</code>: this contians the string of the form <code>month/day/year</code> that is the date of the translation of the source code into object code</li> <li><code>__TIME__</code>: this contians the string of the form <code>hour:minute:second</code> that is the time at which the program was compiled</li> </ul> <p>The processor obeys directives defined in file to:</p> <ul> <li>replacing macros</li> <li>expanding include files</li> <li>expanding conditinal code</li> <li>removing comments</li> </ul> <p>You can use <code>g++ -E</code> to get preprocessed file with the extension <code>.i</code> or <code>.ii</code>.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#compiling","title":"Compiling","text":"<p>Compiling is the second step. It takes the output of the preprocessor and generates assembly language, an intermediate human readable language, specific to the target processor. The compiler parses the pure C++ source code (now without any preprocessor directives) and converts it into assembly code. Compilers usually let you stop compilation at this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don\u2019t need to recompile everything if you only change a single file. It's at this stage that \"regular\" compiler errors, like syntax errors or failed overload resolution errors are reported.</p> <p>You can use <code>g++ -S</code> to get compiled file with the extension <code>.s</code>.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#assembling","title":"Assembling","text":"<p>After compiling, we get the assembly code. Then the assembler will translate the assembly code into machine code producing actual binary file in some format(ELF, COFF, a.out, etc.). This object file contains the compiled code(in binary form) of the symbols defined in the input. Symbols in the object files are referred to by name.</p> <p>Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don't provide a definition for it. The compiler doesn't mind this and will happily produce the object file as long as the source code is well-formed.</p> <p>You can use <code>g++ -c</code> to get assembled file with the extension <code>.o</code>.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#linking","title":"Linking","text":"<p>The linker is what produces the final compilation output from the <code>object file</code> that compiler generated. The output of linker can be:</p> <ul> <li>shared library: it doesn't add the library code to the output, so it has the smallest file size;</li> <li>static library: it add all the library code to the output, which makes its larger size;</li> <li>executable file: it combine all the binary file to an executable, and has the largest file size.</li> </ul> <p>While linking, the linker links all the boject files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker the path of them.</p> <p>At this stage the most common erros are:</p> <ul> <li>missing definitions, which means that either the definitions don't exist or the object files or libraries they reside were not given to the linker</li> <li>duplicate definitions, which means that the same symbol was defined in two different object files or libraries</li> </ul>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#optimization-methods-and-results","title":"Optimization Methods and Results","text":"<p>The origin compilation time:</p> compile step preprocessing compiling assembling linking total time(s) 0.337 54.403 3.741 8.272 66.416"},{"location":"Self-Driving/Prediction/compile_cpp_project/#compile-what-we-used","title":"Compile what we used","text":"<p>In prediction module, we have three parts of code:</p> <ul> <li>onboard: which runs on our computing platform and supports for auto-driving system;</li> <li>offboard: which contains tools and deep-learning model trainers and runs on our develop PC;</li> <li>unittest: which is the unit-test case of above parts.</li> </ul> <p>In our previous work we compile all of three parts with a bash script. The file tree is like this: <pre><code>.\n\u251c\u2500\u2500 build\n\u251c\u2500\u2500 cmake\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 docs\n\u251c\u2500\u2500 offboard\n\u251c\u2500\u2500 onboard\n\u2514\u2500\u2500 unit_test\n</code></pre> And we use the script to build them all: <pre><code>##!/bin/bash\ncmake -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR -DCMAKE_BUILD_TYPE=Debug \\\n      -Bbuild -H.\nmake -C build -j12 install\n</code></pre></p> <p>But when we develop new features or fix bugs, what we want is to varify our code quickly, it's no need to build offboard or unit_test code.</p> <p>Now we split the code into three parts and just compile the part we interested. The file tree is like this: <pre><code>.\n\u251c\u2500\u2500 build\n\u251c\u2500\u2500 build.sh\n\u251c\u2500\u2500 cmake\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 docs\n\u251c\u2500\u2500 Doxyfile\n\u251c\u2500\u2500 offboard\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 CMakeLists.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 model_training\n\u251c\u2500\u2500 onboard\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 CMakeLists.txt\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 proto\n\u2514\u2500\u2500 unit_test\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u2514\u2500\u2500 onboard\n</code></pre></p> <p>At the top level of repo, we use three flags to define which part of code we want to compile in <code>CMakeLists.txt</code>:</p> <pre><code>## Build options\nset(BUILD_ONBOARD OFF CACHE BOOL \"build_onboard\")\nset(BUILD_OFFBOARD OFF CACHE BOOL \"build_offboard\")\nset(BUILD_UNIT_TEST OFF CACHE BOOL \"build_unit_test\")\n\nif(${BUILD_ONBOARD})\n  add_subdirectory(onboard)\nendif(${BUILD_ONBOARD})\n\nif(${BUILD_OFFBOARD})\n  add_subdirectory(offboard)\nendif(${BUILD_OFFBOARD})\n\nif(${BUILD_UNIT_TEST})\n  add_subdirectory(unit_test)\nendif(${BUILD_UNIT_TEST})\n</code></pre> <p>In bash script file, we choose what we want to build:</p> <pre><code>function build_onboard(){\n  set +e\n  mkdir build\n  set -e\n  cmake -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR -DCMAKE_BUILD_TYPE=Debug \\\n        -DBUILD_ONBOARD=ON -DBUILD_OFFBOARD=OFF -DBUILD_UNIT_TEST=OFF \\\n        -Bbuild -H.\n  make -C build -j12 install  || {\n    echo \"$R -&gt; Build failed! $E\"\n    exit 1\n  }\n  echo -e \"$G -&gt; Build onboard successfully! $TAIL $E\"\n  return $?\n}\n</code></pre> <p>Result:</p> Before optimization After optimization time(s) 81 66"},{"location":"Self-Driving/Prediction/compile_cpp_project/#compiler-options","title":"Compiler options","text":"<p>A compiler is a special program that processes statements written in a particular programming language and turns them into machine language or \"code\" that a computer's processor uses. In linux platform, we use GCC to compile our code. When you invoke GCC, it normally does preprocessing, compilation, assembly and linking.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#parallel-compilation","title":"Parallel compilation","text":"<p>In Linux platform we use <code>GNU/Make</code> tool to compile code. When we execute make command, we should use the <code>-j</code> option to define parallel jobs. In the bash script we use <code>$(nproc)</code> to get the number of cpu core as the <code>-j</code> parameter and increase the compilation performance.</p> <pre><code>make -C build -j$(nproc) install\n</code></pre> <p>Result:</p> Before optimization(<code>j8</code>) After optimization(<code>j12</code>) time(s) 70 66"},{"location":"Self-Driving/Prediction/compile_cpp_project/#optimize-options","title":"Optimize options","text":"<p>These options control various sorts of optimizations. Without any optimization option, the compiler\u2019s goal is to reduce the cost of compilation and to make debugging produce the expected results. Turning on optimization flags makes the compiler attempt to improve the performance and/or code size at the expense of compilation time and possibly the ability to debug the program.</p> <p>Here are some option levels:</p> <ul> <li><code>-O/-O1</code>: Optimizing compilation takes somewhat more time, and a lot more memory for a large function.With <code>-O</code>, the compiler tries to reduce code size and execution time, without performing any optimizations that take a great deal of compilation time.</li> <li> <p><code>-O2</code>: Optimize even more. GCC performs nearly all supported optimizations that do not involve a space-speed tradeoff. As compared to -O, this option increases both compilation time and the performance of the generated code.</p> </li> <li> <p><code>-O3</code>: Optimize yet more.</p> </li> <li><code>-O0</code>: Reduce compilation time and make debugging produce the expected results. This is the default.</li> <li><code>-Os</code>: Optimize for size. -Os enables all -O2 optimizations except those that often increase code size</li> <li><code>-Ofast</code>: Disregard strict standards compliance. -Ofast enables all -O3 optimizations. It also enables optimizations that are not valid for all standard-compliant programs.</li> <li><code>-Og</code>: Optimize debugging experience.</li> </ul> <p>Results:</p> Compilation option Assume time(<code>s</code>) Shared library size(<code>M</code>) <code>-O0</code> 49 29 <code>-O1</code> 43 3.5 <code>-O2</code> 48 3.4 <code>-O3</code> 49 3.4 <code>-Os</code> 46 3.5 <code>-Ofast</code> 49 3.4"},{"location":"Self-Driving/Prediction/compile_cpp_project/#debugging-options","title":"Debugging options","text":"<p>To tell GCC to emit extra information for use by a debugger, in almost all cases you need only to add <code>-g</code> to your other options.</p> <p>GCC allows you to use <code>-g</code> with <code>-O</code>. But this combination taken by optimized code may occasionally be surprising:</p> <ul> <li>some variables you declared may not exist at all;</li> <li>flow of control may briefly move where you did not expect it;</li> <li>some statements may not be executed because they compute constant results or their values are already at hand;</li> <li>some statements may execute in different places because they have moved out of loops.</li> </ul> <p>This makes it reasonable to use the optimizer for programs that might have bugs.</p> <p>If you are not using some other optimization option, consider <code>-Og -g</code> option. With no <code>-O</code> option at all, some compiler passes that collect information useful for debugging do not run at all, so that <code>-Og</code> may result in a better debugging experience.</p> <p>Here are some options for debugging:</p> <ul> <li><code>-g</code>: Produce debugging information in the operating system\u2019s native format (stabs, COFF, XCOFF, or DWARF). GDB can work with this debugging information.</li> <li><code>-g[level]</code>: Request debugging information ans also use <code>level</code> to specify how much information. The default level is 2.<ul> <li>Level 0: produces no debug information at all</li> <li>Level 1: produces minimal information, enough for making backtraces in parts of the program that you don\u2019t plan to debug. This includes descriptions of functions and external variables, and line number tables, but no information about local variables.</li> <li>Level 2: produces normal debug information as default.</li> <li>Level 3: includes extra information, such as all the macro definitions present in the program. Some debuggers support macro expansion when you use -g3.</li> </ul> </li> </ul> <p>What we should know is that producing debug symbols will increase both executable file size and compilation time, so the conclusion is:</p> <ul> <li>if you don't need to debug with gdb, do not add <code>-g</code> option to g++ flags;</li> <li>if you need to debug with gdb, use <code>-Og -g</code> option to get better debugging experience.</li> </ul> <p>Results:</p> Compilation option Assume time(<code>s</code>) Shared library size(<code>M</code>) <code>-O0 -g</code> 66 151 <code>-Og -g</code> 67 135 <code>-O</code> 45 3.5 <code>NONE</code> 63 130"},{"location":"Self-Driving/Prediction/compile_cpp_project/#include-denpencies-optimization","title":"Include denpencies optimization","text":"<p>There are two kinds of dependencies:</p> <ul> <li>logical dependencies: which is between classes, functions, etc.</li> <li>compile time dependencis: which is between files and libraries.</li> </ul> <p>The compile time dependencies have a huge impact on building, refactoring, testing and on the structure of your software. For small programs that just consists of a couple of filess, it is not a problem. But as soon as our software grows and so the number of includes files do, the impact of inappropriate handled includes can be huge:</p> <ul> <li>Increasing compilation time</li> <li>Increasing code complexity</li> <li>Harder to refactor/restructure your program</li> <li>More difficult to test code in isolation</li> </ul> <p>When you change a header file, all translation units depending on this header file need to be recompiled. This can be very expensive.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#gcc-compiler-options","title":"GCC compiler options","text":"<p>GCC provides some helpful options to determine/analyze include dependencies:</p> <ul> <li>-M: output a rule suitable for make describing the dependencies of the main source file.</li> <li>-MM: like -M but do not mention header files that are found in system header directories, nor header files that are included, directly or indirectly, from such a header.</li> <li>-MF: when used with -M or -MM, specifies a file to write the dependencies to.</li> <li>-H: prints the name of each header file used. Each name is indented to show how deep in the #include stack it is.</li> </ul> <p>An example can be: <pre><code>gcc -M main.cpp\n\nmain.o: main.cpp /usr/include/stdc-predef.h a.h b.h c.h d.h \\\n /usr/include/c++/4.9.0/iostream \\\n /usr/include/c++/4.9.0/x86_64-unknown-linux-gnu/bits/c++config.h \\\n /usr/include/c++/4.9.0/x86_64-unknown-linux-gnu/bits/os_defines.h \\\n /usr/include/features.h /usr/include/sys/cdefs.h \\\n /usr/include/bits/wordsize.h /usr/include/gnu/stubs.h \\\n /usr/include/gnu/stubs-64.h \\\n /usr/include/c++/4.9.0/x86_64-unknown-linux-gnu/bits/cpu_defines.h \\\n ...\n &lt;truncated&gt;\n</code></pre></p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#doxygen","title":"Doxygen","text":"<p>Doxygen can generate nice interactive include graphs. This is how you can enable it in the doxygen configuration file (Doxyfile) - directly from the doxygen documentation:</p> <p>If the INCLUDE_GRAPH, ENABLE_PREPROCESSING and SEARCH_INCLUDES tags are set to YES then doxygen will generate a graph for each documented file showing the direct and indirect include dependencies of the file with other documented files. The default value is: YES. This tag requires that the tag HAVE_DOT is set to YES.</p> <p></p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#include-what-you-need","title":"include-what-you-need","text":"<p>\"Include what you use\" means this: for every symbol (type, function, variable, or macro) that you use in foo.cc (or foo.cpp), either foo.cc or foo.h should include a .h file that exports the declaration of that symbol.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#install","title":"Install","text":""},{"location":"Self-Driving/Prediction/compile_cpp_project/#dependencies-install","title":"Dependencies install","text":"<pre><code>sudo apt install llvm-9.0-dev libclang-9.0-dev clang-9.0\n</code></pre>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#build","title":"Build","text":"<pre><code>git clone https://github.com/include-what-you-use/include-what-you-use.git iwyu &amp;&amp;\ncd iwyu &amp;&amp;\ngit checkout clang_9.0 &amp;&amp;\nmkdir build &amp;&amp;\ncd build &amp;&amp;\ncmake -G \"Unix Makefiles\" -DIWYU_LLVM_ROOT_PATH=/usr/lib/llvm-9 .. &amp;&amp;\nmake install\n</code></pre>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#usage","title":"Usage","text":""},{"location":"Self-Driving/Prediction/compile_cpp_project/#iwyucmake","title":"Iwyu.cmake","text":"<pre><code>## Include denpendency analysis, you should include iwyu first\n## https://github.com/include-what-you-use/include-what-you-use\nfind_program(CMAKE_CXX_INCLUDE_WHAT_YOU_USE NAMES include-what-you-use iwyu)\n\nif(CMAKE_CXX_INCLUDE_WHAT_YOU_USE)\n  set(CMAKE_CXX_INCLUDE_WHAT_YOU_USE  # options\n    ${CMAKE_CXX_INCLUDE_WHAT_YOU_USE}\n    -Xiwyu\n    --cxx17ns\n    #-Xiwyu\n    #--no_fwd_decls\n    -Xiwyu\n    --keep=${CMAKE_CURRENT_SOURCE_DIR}/build/onboard/generated/proto/*.*\n    -Xiwyu\n    --keep=${WORK_ROOT}/opt/include/cyber/proto/*.*\n    #-Xiwyu\n    #--transitive_includes_only\n    -Xiwyu\n    --mapping_file=${CMAKE_CURRENT_SOURCE_DIR}/cmake/iwyu.imp\n    )\nendif(CMAKE_CXX_INCLUDE_WHAT_YOU_USE)\n</code></pre>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#cmakeliststxt","title":"CMakeLists.txt","text":"<p>This tool is only used when we compile static library or executable binary, so we need to add a static library additionally: <pre><code>if(CMAKE_CXX_INCLUDE_WHAT_YOU_USE)\n  add_library(${PROJECT_NAME}_iwyu ${SRCS})\n  target_link_libraries(${PROJECT_NAME}_iwyu\n    ${PROJECT_NAME}_proto\n    cyber\n    gflags\n    glog\n    map_data\n    semantic_map\n    topological_map\n    ${TORCH_LIBRARIES}\n    ${TENSORRT_LIBRARIES}\n    stdc++fs\n  )\nendif(CMAKE_CXX_INCLUDE_WHAT_YOU_USE)\n</code></pre></p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#how-to-correct-iwyu-mistakes","title":"how to correct iwyu mistakes","text":"<p>Use the command: <pre><code>cmake -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR -DCMAKE_BUILD_TYPE=Debug \\\n      -DBUILD_ONBOARD=ON -DBUILD_OFFBOARD=OFF -DBUILD_UNIT_TEST=OFF \\\n      -Bbuild -H. &amp;&amp;\nmake -C build -j$(nproc) 2&gt; build/iwyu.log &amp;&amp;\npython2 fix_includes.py &lt; /build/iwyu.log\n</code></pre></p> <p>Results:</p> Before optimization After optimization time(s) 66 65 size(M) 151 151"},{"location":"Self-Driving/Prediction/compile_cpp_project/#other-solutions","title":"Other solutions","text":""},{"location":"Self-Driving/Prediction/compile_cpp_project/#forward-declaration","title":"Forward-declaration","text":"<p>The compiler wants to ensure you haven't made spelling mistakes or passed the wrong number of arguments to the function. So, it insists that it first sees a declaration of a <code>type</code> before it used.</p> <p>If you didn't have to forward declare things, the compiler would produce an object file that would have to contain information about all the possible guesses as to what the <code>type</code> might be. This may take a lot of time.</p> <p>And if other file includes this header, expand the header may waste space and time.</p> <p>A general class may be like this:</p> <pre><code>// in obstacle.h\n#include \"feature_a.h\"\n#include \"feature_b.h\"\n\nclass Obstacle {\n  FeatureA feature_a{};\n  FeatureB feature_b{};\n public:\n  void MethodA() const;\n};\n\n// in obstacle.cc\n#include \"obstacle.h\"\n\nvoid Obstacle::MethodA() const {\n  feature_a.MethodA();\n  feature_b.MethodB();\n}\n</code></pre> <p>Using forward-declaration, we can rewrite it as:</p> <pre><code>// in obstacle.h\nclass FeatureA;\nclass FeatureB;\n\nclass Obstacle {\n  FeatureA* feature_a{nullptr};\n  FeatureB* feature_b{nullptr};\n public:\n  void MethodA() const;\n};\n\n// in obstacle.cc\n#include \"obstacle.h\"\n#include \"feature_a.h\"\n#include \"feature_b.h\"\n\nvoid Obstacle::MethodA() const {\n  feature_a-&gt;MethodA();\n  feature_b-&gt;MethodB();\n}\n</code></pre>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#extern-template","title":"<code>extern template</code>","text":"<p>We can use the C++11 new feature <code>extern template</code> to force the compiler to not instantiate a template when you know that it instantiated somewhere else. It is used to reduce compile time and object file size.</p> <p>For example: <pre><code>// in function.h\ntemplate &lt;typename T&gt;\nvoid function() {\n  // do something\n}\n\n// in source1.cpp\n#include \"function.h\"\nvoid function1() {\n  function&lt;double&gt;();\n}\n\n// in source2.cpp\n#include \"function.h\"\nvoid function2() {\n  function&lt;double&gt;();\n}\n</code></pre></p> <p>This will result in the following object files: <pre><code>// source1.o\nvoid function1()\nvoid function&lt;double&gt;()  // compile first time\n\n// source2.o\nvoid function2()\nvoid function&lt;double&gt;()  // compile second time\n</code></pre></p> <p>If both files are linked together, one <code>void function&lt;double&gt;()</code> will be discarded, resulting in wasted comile time and object file size.</p> <p>To not waste compile time and object file size, there is an <code>extern</code> keyword which makes the compiler not compile a template function. You should use this if and only if you know it is used in the same binary somewhere else.</p> <pre><code>// in function.h\ntemplate &lt;typename T&gt;\nvoid function() {\n  // do something\n}\n\n// in source1.cpp\n#include \"function.h\"\nvoid function1() {\n  function&lt;double&gt;();\n}\n\n// in source2.cpp\n#include \"function.h\"\nextern template void function&lt;double&gt;();  // you know it's initialized somewhere\nvoid function2() {\n  function&lt;double&gt;();\n}\n</code></pre>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#replace-boost-library","title":"Replace boost library","text":"<p>The main disadvantage of boost library is that it add declaration and definition in one <code>hpp</code>file, which makes the file size explore after expending it in a <code>.cc</code> file. </p> <p>We can remove the <code>boost</code> library from project to reduce the time and size of compilation.</p>"},{"location":"Self-Driving/Prediction/compile_cpp_project/#reference","title":"Reference","text":"<ul> <li>C++ Preprocessor</li> <li>The Compilation Process</li> <li>GCC Command Options</li> <li>Open source tools to examine and adjust include dependencies</li> <li>include-what-you-use</li> <li>C++\u670d\u52a1\u7f16\u8bd1\u8017\u65f6\u4f18\u5316\u539f\u7406\u53ca\u5b9e\u8df5</li> <li>What are forward-declaration in C++</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/","title":"Dig into Apollo(6.0) Prediction","text":""},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#predictioncomponent","title":"PredictionComponent","text":""},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#proc","title":"Proc","text":"<p>This is a callback function for <code>PerceptionObstacle</code> Reader. If a new message is generated in channel, this function will execute.</p> <pre><code>if (FLAGS_use_lego) return ContainerSubmoduleProcess(perception_obstacles);\nreturn PredictionEndToEndProc(perception_obstacles); \n</code></pre>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#containersubmoduleprocess","title":"ContainerSubmoduleProcess","text":"<p>This is another prediction process which is the same as <code>PredictionEndToEnd</code>. This function is created for <code>Lego</code> architecture, whose communication system may have much difference with current <code>cyber</code>.</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#predictionendtoend","title":"PredictionEndToEnd","text":"<p>Almost all the work is doing in <code>MessageProcess</code> class.</p> <ul> <li>Transform all messages(perception/localization/planning/storytelling) to obstacle</li> <li><code>message_process.OnPerception</code></li> <li>Send the prediction message to channel</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#messageprocess","title":"MessageProcess","text":""},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#init","title":"Init","text":"<p>Initialize following classes with configures:</p> <ul> <li>ContainerManager</li> <li>EvaluatorManager</li> <li>PredictorManager</li> <li>PredictionMap</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#onperception","title":"OnPerception","text":"<p>Prediction module is driven by perception module, which means that once a frame of message is generated by perception, this function is called. The process is:</p> <ul> <li>use <code>ContainerProcess</code> function to process all messages</li> <li>insert all messages to a proto file for offline model training</li> <li>generate intension of obstacle with <code>evaluator</code> module</li> <li>generate trajectory of obstacle with <code>predictor</code> module</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#containerprocess","title":"ContainerProcess","text":"<p>This function :</p> <ul> <li>transforms messages from perception/localization/planning to abstract obstacles and</li> <li>prioritizes all obstacles to determine if the obstacle is need to consider and</li> <li>analyzes scenarios ego vehicle is in of:<ul> <li>Unknown</li> <li>Cruise</li> <li>Junction</li> </ul> </li> <li>builds junction(conditional) and cruise features and</li> <li>sets <code>Caution</code> priority of obstacle and</li> <li>sets the weight of way in a distance to<ul> <li>-20, for left turn</li> <li>-10, for right turn</li> </ul> </li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#obstacleprioritizer","title":"ObstaclePrioritizer","text":""},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#assignignorelevel","title":"AssignIgnoreLevel","text":"<p>This function set obstacle's priority of:</p> <ul> <li><code>Ignore</code>, which means it's no need to consider</li> <li><code>Normal</code>, which means it should be considered</li> </ul> <p>And if an obstacle's priority is <code>Normal</code>, it is either:</p> <ul> <li>in <code>scan box</code>, which is a rectangular centered on ego vehicle</li> <li>on lane</li> <li>near lane with the type of <code>pedestrian</code></li> <li>near junction</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#assigncautionlevel","title":"AssignCautionLevel","text":"<p>Set the obstacle priority to be <code>Caution</code> if the obstacle is close to ego vehicle and</p> <ul> <li>in junction(under junction scenario)</li> <li>the first obstacle in front of ego vehicle(searched within lane sequence, may not be unique)</li> <li>its lane sequence is on ego vehicle's planning trajectory</li> </ul> <p>And if enabled, this function will shrink the number of caution obstacles to a threshold according to distance.</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#evaluatormanager","title":"EvaluatorManager","text":"<p><code>EvaluatorManager</code> class to manage all <code>Evaluator</code>s' lifecycle and </p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#init_1","title":"Init","text":"<p>This is a initialization function to initialize:</p> <ul> <li>semantic map</li> <li>all evaluators with configures</li> <li>default evaluator types by obstacle's:<ul> <li>type</li> <li>priority(normal/caution)</li> <li>status(onlane/offlane/junction)</li> </ul> </li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#getevaluator","title":"GetEvaluator","text":"<p>You can get the pointer to evaluator by inputing evaluator's type. It's better to use unordered_map(hash) other than map(balanced binary tree) to accumulate the looking up process.</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#run","title":"Run","text":"<p>This is the main process to <code>evaluate</code> an obstacle's intension(or trajectory) with multiple evaluators. According to <code>Single Responsibility</code> principle, I don't think it's a good idea to do these stuffs in a <code>manager</code> class.</p> <p>The function does:</p> <ul> <li>BuildObstacleIdHistoryMap</li> <li>DumpCurrentFrameEnv</li> <li>Evaluate obstacles with:<ul> <li>multiple thread according to <code>GroupObstaclesByObstacleIds</code> results</li> <li>single thread</li> </ul> </li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#buildobstacleidhistorymap","title":"BuildObstacleIdHistoryMap","text":"<p>Build a feature proto for each obstacle in current frame, every feature proto contains <code>max_num_frame</code>s with:</p> <ul> <li>id</li> <li>timestamp</li> <li>type</li> <li>position(x, y, z)</li> <li>theta(heading)</li> <li>length</li> <li>width</li> <li>is_trainable(bool, calculated with the function <code>IsTrainable</code>)</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#istrainable","title":"IsTrainable","text":"<p>A helper function defined in <code>evaluator_manager.cc</code>'s unnamed namespace. Return <code>false</code> if the obstacle:</p> <ul> <li>is ego vehicle</li> <li>has the priority of <code>Ignore</code></li> <li>is still</li> <li>is not vehicle</li> </ul> <p>otherwise, return true;</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#dumpcurrentframeenv","title":"DumpCurrentFrameEnv","text":"<p>Another helper fucntion in unnamed namespace, the main purpose of this is to insert all obstacles' history information to <code>FrameEnv</code> class for output.</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#groupobstaclesbyobstacleids","title":"GroupObstaclesByObstacleIds","text":"<p>This function assigns thread id for each obstacle according to its priority(caution or normal). Each thread has <code>obstacle_num / thread_num</code> obstacle ids(tasks).</p>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#cyclistkeeplaneevaluator","title":"CyclistKeepLaneEvaluator","text":"<p>The <code>CyclistKeepLaneEvaluator</code> is simple and has only two probability values:</p> <ul> <li>1.0, if current lane id is equal to the lane id in lane sequence;</li> <li>0.0, if current lane id is not equal to the lane id in lane sequence.</li> </ul> <p>The lanes sequence is a list of lane id that covers the length:</p> \\[ D_{lane} = v_{0} * t_{max} + 0.5 * a_{max} * t_{max}^2 \\] <p>In equation,</p> <ul> <li>\\(D_{lane}\\) is the distance the lane sequance covers;</li> <li>\\(v_{0}\\) is current speed the obstacle has;</li> <li>\\(t_{max}\\) is the predicted trajectory duration, it's 8.0 in program;</li> <li>\\(a_{max}\\) is the maximum linear acceleration of vehicle, it's 4.0 in program;</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#pedestrianinteractionevaluator","title":"PedestrianInteractionEvaluator","text":"<p>This evaluator follows the paperSocial LSTM: Human Trajectory Prediction in Crowded Spaces. I guess that this evaluator is not completed, because:</p> <ul> <li>the input trajectory size is only one</li> <li>the social part of work is not implemented, and without the social, lstm has little advance over constant velocity model.</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#costevaluator","title":"CostEvaluator","text":"<p><code>CostEvaluator</code> calculates the probability based on the distance between obstacle and lane boundary.</p> \\[ E_{l} = \\frac{W_{lane}}{2} - W_{l} \\] \\[ P_{cost} = \\frac{1}{1 + e^{-E_{l}}} \\] <p>In the equation:</p> <ul> <li>\\(E_{l}\\) is the distance from lane boundary to obstacle's location;</li> <li>\\(W_{lane}\\) is the width of lane;</li> <li>\\(W_{l}\\) is the lateral distance from lane reference line to obstacle's location;</li> <li>\\(P_{cost}\\) is the probability, calculated by a Sigmoid function.</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#cruisemlpevaluator","title":"CruiseMLPEvaluator","text":"<p>The model has \\(23 + 5 * 9 + 8 + 20 * 4 = 146\\) inputs, \\(23\\) of which are obstacle features:</p> <ul> <li>\\(\\theta_{filter}\\), the average of the latest 5 heading values in an obstacle's history;</li> <li>\\(\\theta_{mean}\\), the average of all the heading values in an obstacle's history;</li> <li>\\(\\theta_{filter} - \\theta_{mean}\\);</li> <li>\\(\\theta_{diff} = \\theta_{curr} - \\theta_{prev}\\), where \\(\\theta_{curr}\\) is the average of the latest \\(0 \\to 4\\) heading values in an obstacle's history, \\(\\theta_{prev}\\) is the average of the latest \\(5 \\to 9\\) heading values;</li> <li>\\(\\theta_{diff}'\\), \\(\\theta'_{diff} = \\frac{\\theta_{diff}}{\\Delta_t}\\);</li> <li>\\(l_{filter}\\), the average of the latest 5 lateral distance values in an obstacle's history;</li> <li>\\(l_{mean}\\), the average of all the lateral distance values in an obstacle's history;</li> <li>\\(l_{filter} - l_{mean}\\);</li> <li>\\(l_{diff} = l_{curr} - l_{prev}\\), where \\(l_{curr}\\) is the average of the latest \\(0 \\to 4\\) lateral distance values in an obstacle's history, \\(l_{prev}\\) is the average of the latest \\(5 \\to 9\\) lateral distance values;</li> <li>\\(v\\), the velocity of the obstacle;</li> <li>\\(a\\), the acceleration of the obstacle;</li> <li>\\(j\\), the jerk of the obstacle;</li> <li>\\(D_{lb}\\), the distance from obstacle to left lane boundary;</li> <li>\\(D_{lb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{lb}\\) of the history, \\(D_{last}\\) is the last \\(D_{lb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{lb diff}' = D_{lb curr} - D_{lb prev}\\), where \\(D_{lb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{lb}\\) values in an obstacle's history, \\(D_{lb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{lb}\\) values;</li> <li>\\(D_{rb}\\), the distance from obstacle to right lane boundary;</li> <li>\\(D_{rb}' = \\frac{D_{first} - D_{last}}{dt}\\), where \\(D_{first}\\) is the first \\(D_{rb}\\) of the history, \\(D_{last}\\) is the last \\(D_{rb}\\) of the history, \\(dt\\) is the duration of the history;</li> <li>\\(D_{rb diff}' = D_{rb curr} - D_{rb prev}\\), where \\(D_{rb curr}\\) is the average of the latest \\(0 \\to 4\\) \\(D_{rb}\\) values in an obstacle's history, \\(D_{rb prev}\\) is the average of the latest \\(5 \\to 9\\) \\(D_{rb}\\) values;</li> <li><code>is_curr_lane_no_turn</code>, this value is \\(1\\) if current lane is <code>NoTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_left_turn</code>, this value is \\(1\\) if current lane is <code>LeftTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_right_turn</code>, this value is \\(1\\) if current lane is <code>RightTurn</code>, or it's \\(0\\);</li> <li><code>is_curr_lane_uturn</code>, this value is \\(1\\) if current lane is <code>UTurn</code>, or it's \\(0\\).</li> </ul> <p>And \\(5 * 9\\) features are obstacle history features, we search \\(5\\) frames of history, each frame has \\(9\\) fearures:</p> <ul> <li><code>is_curr_frame_has_hisotry</code>, the value is \\(1\\) if current frame and previous frame all have position/velocity/acceleration/velocity_heading information, otherwise it's \\(0\\);</li> <li>\\(x\\), in local coordinate system;</li> <li>\\(y\\), in local coordiante system;</li> <li>\\(x^{\\prime}\\);</li> <li>\\(y^{\\prime}\\);</li> <li>\\(x^{\\prime\\prime}\\);</li> <li>\\(y^{\\prime\\prime}\\);</li> <li>\\(\\theta_{v}\\), the heading of velocity;</li> <li>\\(\\theta_{v}^{\\prime}\\).</li> </ul> <p>\\(8\\) features are for forward and backward obstacles:</p> <ul> <li>\\(s_{forward}\\), the forward obstacle's distance;</li> <li>\\(l_{forward}\\), the forward obstacle's lateral distance;</li> <li>\\(L_{forward}\\), the forward obstacle's length;</li> <li>\\(v_{forward}\\), the forward obstacle's velocity;</li> <li>\\(s_{backward}\\), the backward obstacle's distance;</li> <li>\\(l_{backward}\\), the backward obstacle's lateral distance;</li> <li>\\(L_{backward}\\), the backward obstacle's length;</li> <li>\\(v_{backward}\\), the backward obstacle's velocity;</li> </ul> <p>And the other \\(20 * 4\\) features are lane features, we choose \\(20\\) points from the reference line, each of them has 4 features:</p> <ul> <li>\\(s_{point}\\), the lane point's distance;</li> <li>\\(l_{point}\\), the lane point's lateral distance;</li> <li>\\(\\psi_{point}\\): the heading of the lane point;</li> <li>\\(\\kappa_{point}\\): the curvature of the lane point.</li> </ul> <p>The result of <code>CruiseMLPEvaluator</code> is:</p> <ul> <li>the probability of an obstacle on a lane;</li> <li>the time of an obstacle to travel to reference line.</li> </ul>"},{"location":"Self-Driving/Prediction/dig_into_apollo_prediction/#junctionmlpevaluator","title":"JunctionMLPEvaluator","text":"<p>This model has 3 obstacle features:</p> <ul> <li>\\(v\\), the velocity of an obstacle;</li> <li>\\(a\\), the acceleration of an obstacle;</li> <li>\\(S_{junction}\\), the area of the junction.</li> </ul> <p>The other \\(12 * 5\\) features are junction features. We divide area aroud the vehicle to 12 regions and calculate the probability of each exit.  Each exit has 5 features:</p> <ul> <li><code>is_exit_exist</code>, it's 1 if the exit of junction exists;</li> <li>\\(x_{diff} / S_{junction}\\), \\(x_{diff}\\) is the deviation between obstacle and exit in x direction;</li> <li>\\(y_{diff} / S_{junction}\\), \\(y_{diff}\\) is the deviation between obstacle and exit in y direction;</li> <li>\\(L_{diff} / S_{junction}\\), \\(L_{diff}\\) is the distance between obstacle and exit;</li> <li>\\(\\theta_{diff}\\), the heading difference between obstacle and exit.</li> </ul> <p>And the output of the model is the probability of an obstacle to exit in 12 directions.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/","title":"Interacting Multiple Models(IMM) for Prediction","text":"<p>For self-driving vehicle, it's important to reliably predict the movement of traffic agents around ego car, such as vehicles, cyclists and pedestrians.</p> <p>We have many neural networks to predict obstacle on lane, but for obstacles which are not on lane, we now have poor method to predict them.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#current-predictor-for-obstacles-not-on-lane","title":"Current predictor for obstacles not on lane","text":"<p>If an obstacle(vehicle/bicycle/pedestrian) is not on lane, we use a <code>FreeMovePredictor</code> to predict its trajectory. <code>FreeMovePredictor</code> assumes that the obstacle always moves with constant acceleration, the state is:</p> \\[ \\begin{bmatrix} x \\\\ y \\\\ x^\\prime \\\\ y^\\prime \\\\ x^{\\prime\\prime} \\\\ y^{\\prime\\prime} \\end{bmatrix} \\] <p>and the transition matrix is:</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; t &amp; 0 &amp; 0.5 * t^2 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; t &amp; 0 &amp; 0.5 * t^2 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; t &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; t \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>The disadvantages are:</p> <ol> <li>We use the newest position and velocity from perception module, but the result is not so accurate.</li> <li>It performs not so good especially for vehicles.</li> </ol> <p>To solve these problems and imporve the prediction accuracy off lane, we use - constant velocity kalman filter to predict pedestrian; - interacting multiple model(IMM) of constant velocity(cv), constant acceleration(ca) and constant turn rate(ct) to predict vehicle and bicycle.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#kalman-filter","title":"Kalman filter","text":"<p>In 1960, R.E. Kalman published his famous paper describing a recursive solution to the discent-data linear filtering problem. Since that time, due in large part to advances in digital computing, the Kalman filter has been the subject of extensive research and application, particularly in the area of autonomous or assisted navigation.</p> <p>The Kalman filter is a set of mathematical equations that provides an efficient computational (recursive) means to estimate the state of a process, in a way that minimizes the mean of the squared error. The filter is very powerful in several aspects: it supports estimations of past, present, and even future states, and it can do so even when the precise nature of the modeled system is unknown.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#the-process-to-be-estimated","title":"The process to be estimated","text":"<p>The Kalman filter addresses the general problem of trying to estimate the state \\(x \\in \\Re^n\\) of a discrete-time controlled process that is governed by the linear stochastic difference equation:</p> \\[ x_k = Ax_{k-1} + Bu_{k-1} + w_{k-1} \\tag1 \\] <p>with a measurement \\(z \\in \\Re^m\\) that is:</p> \\[ z_k = Hx_k + v_k \\tag2 \\] <ul> <li>The \\(n * n\\) matrix \\(A\\) is <code>transition matrix</code> which relates the state at the previous time step \\(k - 1\\) to the state at the current step \\(k\\), in the absence of either a driving function or process noise. Note that in practice A might change with each time step, but here we assume it is constant.</li> <li>The \\(n * l\\) matrix \\(B\\) is <code>control matrix</code> which relates the optional control input \\(u \\in \\Re^l\\) to the state \\(x\\).</li> <li>The \\(m * n\\) matrix \\(H\\) is <code>measurement matrix</code> which relates the state to the measurement \\(z_k\\). In practice \\(H\\) might change with each time step ore measurement, but we assume it is constant.</li> </ul> <p>The random variable \\(w_k\\) and \\(v_k\\) represent the process and measurement noise. They are assumed to be independent(of each other), white and with normal probability distributions:</p> \\[ p(w) \\sim N(0, Q) \\tag3 \\] \\[ p(v) \\sim N(0, R) \\tag4 \\] <p>where the \\(Q\\) is <code>process noise covariance</code> and R is <code>measurement noise convariance</code>, they might change with each time step or measurement, but we assume that they are constant.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#the-computational-origin-of-the-filter","title":"The computational origin of the filter","text":"<p>We define \\(\\hat{x}_k^- \\in \\Re^n\\) to be our <code>priori state</code> estimate at step \\(k\\) given knowledge of the process prior to step \\(k\\) and \\(\\hat{x}_k \\in \\Re^n\\) to be our <code>posteriori state</code> estimate at step \\(k\\) given measurement \\(z_k\\). We can then define a <code>priori</code> and a <code>posteriori</code> estimate errors as:</p> \\[ e_k^- \\equiv x_k - \\hat{x}_k^- \\tag5 \\] \\[ e_k \\equiv x_k - \\hat{x}_k \\tag6 \\] <p>The <code>priori</code> estimate error covariance is then:</p> \\[ P_k^- = E[e_k^-(e_k^-)^T] \\tag7 \\] <p>and the <code>posteriori</code> estimate error covariance is:</p> \\[ P_k = E[e_ke_k^T] \\tag8 \\] <p>In deriving the equation for the Kalman filter, we begin with the goal of finding an equation that compute an <code>posteriori</code> state estimate \\(\\hat{x}_k\\) as a linear combination of the <code>priori</code> estimate \\(\\hat{x}_k^-\\) and a weighted difference between an actual measurement \\(z_k\\) and a measurement prediction \\(H\\hat{x}_k^-\\) as shown below:</p> \\[ \\hat{x}_k = \\hat{x}_k^- + K(z_k - H\\hat{x}_k^-) \\tag9 \\] <p>The difference \\((z_k - H\\hat{x}_k^-)\\) is called the measurement <code>innovation</code> or <code>residual</code>. The residual reflects the discrepancy between the predicted measurement \\(H\\hat{x}_k^-\\) and the actual measurement \\(z_k\\). A residual of zero means that the two are in complete agreement.</p> <p>The \\(n*m\\) matrix \\(K\\) is chosen to be the <code>gain</code> or <code>blending factor</code> that minimizes the <code>posteriori</code> error covariance in (8). </p> <p>This minimization can be accomplished by </p> <ol> <li>substituting (9) into the (6) and substituting that into (8);</li> <li>performing the indicated expectations;</li> <li>taking the derivative of the trace of the result with respcet to \\(K\\),</li> <li>setting the result equal to \\(0\\) and then solving for \\(K\\).</li> </ol> <p>One form of the resulting \\(K\\) that minimizeds (8) is:</p> \\[ \\begin{align} K_k &amp;= P_k^-H^T(HP_k^-H^T + R)^{-1} \\\\\\\\     &amp;= \\frac{P_k^-H^T}{HP_k^-HT + R} \\end{align} \\tag{10} \\] <p>Looking at (10) we see that as the measurement error covariance \\(R \\to 0\\), the gain \\(K\\) weights the residual more heavily. Specifically,</p> \\[ \\lim_{R_k \\to 0}K_k = H^-1 \\tag{11} \\] <p>On the other hand, as the <code>priori</code> estimate error convariance \\(P_k^- \\to 0\\), the gain \\(K\\) weights the residual less heavily. Specially,</p> \\[ \\lim_{P_0^- \\to 0} K_k = 0 \\tag{12} \\] <p>Another way of thinking about the weighting by \\(K\\) is that as the measurement error covariance \\(R \\to 0\\), the actual measurement \\(z_k\\) is <code>trusted</code> more and more, while the predicted measurement \\(H\\hat{x}_k^-\\) is trusted less and less. On the other hand, as the <code>priori</code> estimate error covariance \\(P_k^- \\to 0\\) the actual measurement \\(z_k\\) is trusted less and less, while the predicted measurement \\(H\\hat{x}_k^-\\) is trusted more and more.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#the-discrete-kalman-filter-algorithm","title":"The discrete kalman filter algorithm","text":"<p>The Kalman filter estimate a process by using a form of feedback control: the filter estimates the process state at some time and then obtains feedback in the form of (noisy) measurement. As such, the equations for the Kalman filter falls into two groups:</p> <ul> <li><code>time update</code>(predict) equations;</li> <li><code>measurement update</code>(correct) equations.</li> </ul> <p>The <code>time update</code> equations are responsible for projecting forward(in time) the current state and error covariance estimates to obtain the <code>priori</code> estimates for the next time step.</p> <p>The <code>measurement update</code> equations are responsible for the feedback, incorporating a new measurement into the <code>priori</code> estimate to obtain an improved <code>posteriori</code> estimate.</p> <p>The final estimation algorithm resembles that of a <code>predictor-corrector</code> algorithm for solving numerical problems: <pre><code>           Time Update -----&gt; Measurement Update\n            (Predict)             (Correct)\n                ^                     |\n                |                     |\n                -----------------------\n</code></pre></p> <p>The specific equations for the <code>time update</code> are:</p> \\[ \\hat{x}_k^- = A \\hat{X}_{k-1} + B u_{k-1} \\tag{13} \\] \\[ P_k^- = AP_{k-1}A^T + Q \\tag{14} \\] <p>where:</p> <ul> <li>\\(\\hat{X}_{k-1}\\) is the <code>posteriori</code> state from time step \\(k-1\\);</li> <li>\\(u_{k-1}\\) is the control from time step \\(k-1\\);</li> <li>\\(\\hat{x}_k^-\\) is the <code>priori</code> state from time step \\(k\\);</li> <li>\\(P_{k-1}\\) is the <code>posteriori</code> estimate error covariance from time step \\(k-1\\);</li> <li>\\(P_k^-\\) is the <code>priori</code> estimate error covariance from time step \\(k\\).</li> </ul> <p>The specific equations for the <code>measurement update</code> are:</p> \\[ K_k = P_k^-H^T(HP_k^-H^T + R)^{-1} \\tag{15} \\] \\[ \\hat{x}_k = \\hat{x}_k^- + K_k(z_k - H\\hat{x}_k^-) \\tag{16} \\] \\[ P_k = (I - K_kH)P_k^- \\tag{17} \\] <p>where:</p> <ul> <li>\\(K_k\\) is the <code>gain</code> from time step \\(k\\);</li> <li>\\(z_k\\) is the measurement variable from time step \\(k\\);</li> <li>\\(\\hat{x}_k\\) is the <code>posteriori</code> state from time step \\(k\\);</li> <li>\\(P_k\\) is the <code>posteriori</code> estimate error covariance from time step \\(k\\).</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#filter-prameters-and-tunning","title":"Filter prameters and tunning","text":"<p>In the actual implementation of the filter, the measurement noise covariance \\(R\\) is usually measured prior to operation of the filter. Measuring the measurement error covariance \\(R\\) is generally practical (possible) because we need to be able to measure the process anyway (while operating the filter) so we should generally be able to take some off-line sample measurements in order to determine the variance of the measurement noise.</p> <p>The determination of the process noise covariance \\(Q\\) is generally more difficult as we typically do not have the ability to directly observe the process we are estimating. Sometimes a relatively simple (poor) process model can produce acceptable results if one \u201cinjects\u201d enough uncertainty into the process via the selection of \\(Q\\). Certainly in this case one would hope that the process measurements are reliable.</p> <p>In either case, whether or not we have a rational basis for choosing the parameters, often times superior filter performance (statistically speaking) can be obtained by <code>tuning</code> the filter parameters \\(Q\\) and \\(R\\). The tuning is usually performed off-line, frequently with the help of another (distinct) Kalman filter in a process generally referred to as <code>system identification</code>.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#dynamic-model","title":"Dynamic model","text":"<p>The motion of a target object(pedestrian or vehicle) can be modeled as:</p> <ul> <li>Moving with constant speed(CV) in straight;</li> <li>Moving with constant acceleration(CA) in straight;</li> <li>Moving with constant turn(CT).</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#cv-model","title":"CV model","text":"<p>For this model, the states under consideration are:</p> \\[ X = \\begin{bmatrix} x \\\\\\\\ \\dot{x} \\\\\\\\ y \\\\\\\\ \\dot{y} \\end{bmatrix} \\] <p>where:</p> <ul> <li>\\(x\\) is the position in longitudinal component;</li> <li>\\(y\\) is the position in lateral component;</li> <li>\\(\\dot{x}\\) is the velocity in x-direction;</li> <li>\\(\\dot{y}\\) is the velocity in y-direction;</li> </ul> <p>For this model, state transition matrix is:</p> \\[ A_{CV} =  \\begin{bmatrix}  1 &amp; dt &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; dt \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#ca-model","title":"CA model","text":"<p>For this model, the states under consideration are:</p> \\[ X = \\begin{bmatrix}  x \\\\ \\dot{x} \\\\ \\ddot{x} \\\\ y \\\\ \\dot{y} \\\\ \\ddot{y}  \\end{bmatrix} \\] <p>where:</p> <ul> <li>\\(x\\) is the position in longitudinal component;</li> <li>\\(y\\) is the position in lateral component;</li> <li>\\(\\dot{x}\\) is the velocity in x-direction;</li> <li>\\(\\dot{y}\\) is the velocity in y-direction;</li> <li>\\(\\ddot{x}\\) is the acceleration in x-direction;</li> <li>\\(\\ddot{y}\\) is the acceleration in y-direction;</li> </ul> <p>For this model, state transition matrix is:</p> \\[ A_{CA} =  \\begin{bmatrix}  1 &amp; dt &amp; \\frac{dt^2}{2} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; dt &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; dt &amp; \\frac{dt^2}{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; dt \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#ct-model","title":"CT model","text":"<p>For this model, the states under consideration are:</p> \\[ X = \\begin{bmatrix}  x \\\\ \\dot{x} \\\\ y \\\\ \\dot{y} \\\\ \\dot{\\theta} \\\\ \\end{bmatrix} \\] <p>where:</p> <ul> <li>\\(x\\) is the position in longitudinal component;</li> <li>\\(y\\) is the position in lateral component;</li> <li>\\(\\dot{x}\\) is the velocity in x-direction;</li> <li>\\(\\dot{y}\\) is the velocity in y-direction;</li> <li>\\(\\dot{\\theta}\\) is the yawrate of obstacle;</li> </ul> <p>For this model, state transition matrix is:</p> \\[ A_{CT} =  \\begin{bmatrix}  1 &amp; \\frac{sin(\\dot{\\theta} * dt)}{\\dot{\\theta}}&amp; 0 &amp; -\\frac{1-cos(\\dot{\\theta} * dt)}{\\dot{\\theta}}&amp; 0 \\\\ 0 &amp; cos(\\dot{\\theta} * dt)&amp; 0 &amp; -sin(\\dot{\\theta} * dt)&amp; 0 \\\\ 0 &amp; \\frac{1-cos(\\dot{\\theta} * dt)}{\\dot{\\theta}} &amp; 1 &amp; \\frac{sin(\\dot{\\theta} * dt)}{\\dot{\\theta}}&amp; 0 \\\\ 0 &amp; sin(\\dot{\\theta} * dt)&amp; 0 &amp; cos(\\dot{\\theta} * dt)&amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#simulation-for-kalman-filter","title":"Simulation for kalman filter","text":"<p>To check if the algorithm is correct, we build the equation of kalman in python. For details, visit imm</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#kalman-filter_1","title":"Kalman filter","text":"<pre><code>class kalman_filter:\n    def __init__(self, A, B, H, Q, R):\n        self.A = A\n        self.B = B\n        self.H = H\n        self.Q = Q\n        self.R = R\n\n        self.U = np.zeros((B.shape[0], 1))\n        self.X = np.zeros((A.shape[0], 1))\n        self.X_pre = self.X\n        self.P = np.zeros(A.shape)\n        self.P_pre = self.P\n\n    def filt(self, Z):\n        self.__predict()\n        self.__update(Z)\n        return self.X\n\n    def __predict(self):\n        self.X_pre = np.dot(self.A, self.X) + np.dot(self.B, self.U)\n        self.P_pre = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q\n\n    def __update(self, Z):\n        K = np.dot(np.dot(self.P_pre, self.H.T),\n                   np.linalg.inv(np.dot(np.dot(self.H, self.P_pre), self.H.T) +\\\n                                 self.R))\n        self.X = self.X_pre + np.dot(K, Z - np.dot(self.H, self.X_pre))\n        self.P = self.P_pre - np.dot(np.dot(K, self.H), self.P_pre)\n</code></pre>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#constant-velocity-model","title":"Constant velocity model","text":"<p><pre><code>def kf_cv():\n    A = np.array([\n            [1., dt, 0., 0.],\n            [0., 1., 0., 0.],\n            [0., 0., 1., dt],\n            [0., 0., 0., 1.]\n            ])\n    B = np.eye(A.shape[0])\n    H = np.array([\n        [1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]\n        ])\n    Q = np.eye(A.shape[0])\n    R = np.eye(4) * 10. ** 2\n\n    kf = kalman_filter(A, B, H, Q, R)\n    return kf\n</code></pre> The simulation result: </p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#constant-acceleration-model","title":"Constant acceleration model","text":"<p><pre><code>def kf_ca():\n    A = np.array([\n            [1., dt, 0.5 * dt**2, 0., 0., 0.],\n            [0., 1., dt, 0., 0., 0.],\n            [0., 0., 1., 0., 0., 0.],\n            [0., 0., 0., 1., dt, 0.5 * dt**2],\n            [0., 0., 0., 0., 1., dt],\n            [0., 0., 1., 0., 0., 1.]\n            ])\n    B = np.eye(A.shape[0])\n    H = np.array([\n        [1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0.]\n        ])\n    Q = np.eye(A.shape[0])\n    R = np.eye(4) * 150\n\n    kf = kalman_filter(A, B, H, Q, R)\n    return kf\n</code></pre> The simulation result: </p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#constant-turn-rate-model","title":"Constant turn rate model","text":"<pre><code>def kf_ct():\n    dtheta = math.pi / 180 * 15\n    theta = dtheta * dt\n    A = np.array([\n         [1., math.sin(theta)/dtheta, 0., -(1 - math.cos(theta))/dtheta, 0.],\n         [0., math.cos(theta), 0., -math.sin(theta), 0.],\n         [0., (1 - math.cos(theta)) / dtheta, 1., math.sin(theta)/dtheta, 0.],\n         [0., math.sin(theta), 0., math.cos(theta), 0.],\n         [0., 0., 0., 0., 1.],\n         ])\n    B = np.eye(A.shape[0])\n    H = np.array([\n        [1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.]\n        ])\n    Q = np.eye(A.shape[0])\n    R = np.eye(4) * 150\n    return kalman_filter(A, B, H, Q, R)\n</code></pre> <p>The simulation result: </p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#interacting-multiple-model","title":"Interacting multiple model","text":"<p>The IMM estimator was originally proposed by Bloom in An efficient filter for abruptly changing systems. It is one of the most cost-effective class of estimators for a single maneuvering target. The IMM has been receiving special attention in the last few years, due to its capability of being combined with other algorithms to resolve the multiple target tracking problem.</p> <p>The main idea of imm is the identification and transition between different models: at every tracking moment, by setting weight-coefficient and probability for each filter, and finally weighting calculation, we obtain the current optimal estimation state.</p> <p></p> <p>Assume that we have \\(r\\) models, each model's state equation:</p> \\[ X_{k+1} = A^jX_{k} + w^j_{k} \\] <p>where</p> <ul> <li>\\(j \\in [1, r]\\), \\(X\\) is state vector,</li> <li>\\(A_j\\) is transition matrix,</li> <li>\\(w\\) is noise with the variance of \\(Q\\).</li> </ul> <p>The measurement equation is:</p> \\[ Z_{k} = H^jX_{k} + v^j_k \\] <p>where </p> <ul> <li>\\(Z\\) is measurement vector,</li> <li>\\(H\\) is measurement matrix,</li> <li>\\(v\\) is the noise with the variance of \\(R\\).</li> </ul> <p>The transition matrix between models can be:</p> \\[ P =  \\begin{bmatrix}  p_{11} &amp; \\cdots &amp; p_{1r} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ p_{r1} &amp; \\cdots &amp; p_{rr} \\end{bmatrix} \\] <p>and probability vector of each model is:</p> \\[ U = \\begin{bmatrix} u_1 &amp; \\cdots &amp; u_{r} \\end{bmatrix} \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#step1-input-mix","title":"Step1: Input mix","text":"\\[ X^{0j}_{k-1|k-1} = \\sum_{i=1}^{r}{X^j_{k-1|k-1}\\mu^{ij}_{k-1|k-1}} \\] \\[ P^{0j}_{k-1|k-1} = \\sum_{i=1}^{r}{\\mu^{ij}_{k-1|k-1}[P^j_{k-1|k-1} + (X^j_{k-1|k-1}) - X^{0j}_{k-1|k-1}][P^j_{k-1|k-1} + (X^j_{k-1|k-1}) - X^{0j}_{k-1|k-1}]^T} \\] <p>where</p> <ul> <li>\\(X^j_{k-1|k-1}\\) is the optimal state estimate,</li> <li>\\(P^j_{k-1|k-1}\\) is the optimal state estimate;</li> </ul> \\[ \\mu^{ij}_{k-1|k-1} = \\frac{p_{ij}U^j_{k-1}}{C^j} \\] <p>and</p> \\[ C^j = \\sum_{i=1}^r{p_{ij}U^j_{k-1}} \\] <p>where</p> <ul> <li>\\(i,j = 1, \\cdots, r\\);</li> <li>\\(\\mu_{k-1}^j\\) is the probabiltiy of model \\(j\\) at time \\(k-1\\);</li> <li>\\(p_{ij}\\) is the probability of a transition from model \\(i\\) to \\(j\\).</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#step2-model-estimate","title":"Step2: Model estimate","text":"<p>It's the same as normal kalman filter.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#step3-probability-update","title":"Step3: Probability update","text":"<p>With the use of the latest measurement \\(z_k\\), the likelihood function value of the model \\(j\\) at time \\(k\\) is given by:</p> \\[ \\Lambda_k^j = N(z_k;z_{k|k-1}^j,v_k^j) = \\begin{vmatrix} 2\\pi S_k^j\\end{vmatrix}^{-\\frac{n_z}{2}} \\cdot e^{-\\frac{1}{2}(z_k - z_{k|k-1}^j)^T S_k^j (z_k-z_{k|k-1}^j)} \\] <p>where:</p> <ul> <li>\\(v_k^j = z_k-z_{k|k-1}^j\\) denotes the filter residual;</li> <li>\\(S_k^j\\) denotes the innovation convariance;</li> <li>\\(n_z\\) denotes the dimension of measurement vector.</li> </ul> <p>The model probability \\(\\mu_{k|k}^j\\) at time \\(k\\) is computed by the following equation:</p> \\[ \\mu_{k|k}^j = \\frac{\\Lambda_k^j C_j}{C} \\] <p>where:</p> \\[ C = \\sum_{i=1}^r{\\Lambda_k^jCi} \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#step4-output-integration","title":"Step4: Output Integration","text":"<p>Finally, the state estimate \\(\\hat{x}_{k|k}\\) and corresponding covariance \\(P_{k|k}\\) are obtained by the model-conditional estimates and covariances of different models:</p> \\[ \\hat{x}_{k|k} = \\sum_{j=1}^r{\\mu_{k|k}^j\\hat{x}_{k|k}^j} \\] \\[ P_{k|k} = \\sum_{j=1}^r{\\mu_{k|k}^j}(P_{k|k}^j + (\\hat{x}_{k|k}^j-\\hat{x}_{k|k})(\\hat{x}_{k|k}^j-\\hat{x}_{k|k})^T) \\]"},{"location":"Self-Driving/Prediction/imm-for-prediction/#simulation-for-imm","title":"Simulation for imm","text":"<p>To volidate the performance of the proposed algorithm, a simulation in python is operated.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#imm-algorithm","title":"Imm algorithm","text":"<pre><code>class Imm:\n    def __init__(self, models, model_trans, P_trans, U_prob):\n        self.models = models\n        self.P_trans = P_trans\n        self.U_prob = U_prob\n        self.model_trans = model_trans\n\n        self.mode_cnt = len(models)\n        self.dim = models[0].A.shape[0]\n\n    def filt(self, Z):\n        # setp1: input mix\n        u = np.dot(self.P_trans.T, self.U_prob)\n        mu = np.zeros(self.P_trans.shape)\n        for i in range(self.mode_cnt):\n            for j in range(self.mode_cnt):\n                mu[i, j] = self.P_trans[i, j] * self.U_prob[i, 0] / u[j, 0];\n\n        X_mix = [np.zeros(model.X.shape) for model in self.models]\n\n        for j in range(self.mode_cnt):\n            for i in range(self.mode_cnt):\n                X_mix[j] += np.dot(self.model_trans[j][i],\n                                   self.models[i].X) * mu[i, j]\n\n        P_mix = [np.zeros(model.P.shape) for model in self.models]\n        for j in range(self.mode_cnt):\n            for i in range(self.mode_cnt):\n                P = self.models[i].P + np.dot((self.models[i].X - X_mix[i]),\n                                              (self.models[i].X - X_mix[i]).T)\n                P_mix[j] += mu[i, j] * np.dot(np.dot(self.model_trans[j][i], P),\n                                              self.model_trans[j][i].T)\n        ## step2: filt\n        for j in range(self.mode_cnt):\n            self.models[j].X = X_mix[j]\n            self.models[j].P = P_mix[j]\n            self.models[j].filt(Z)\n\n        ### step3: update probability\n        for j in range(self.mode_cnt):\n            mode = self.models[j]\n            D = Z - np.dot(mode.H, mode.X_pre)\n            S = np.dot(np.dot(mode.H, mode.P_pre), mode.H.T) + mode.R\n\n            Lambda = (np.linalg.det(2 * math.pi * S)) ** (-0.5) * \\\n                     np.exp(-0.5 * np.dot(np.dot(D.T, np.linalg.inv(S)), D))\n            self.U_prob[j, 0] = Lambda * u[j, 0]\n        self.U_prob = self.U_prob / np.sum(self.U_prob)\n\n        return self.U_prob\n</code></pre>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#input","title":"Input","text":"<p>To test the algorithm performance, following curves are used:</p> <ul> <li>generated constant velocity curve + constant turn rate curve + constant acceleration;</li> <li>vehicle pose data from real autonomous car;</li> <li>vehicle pose data from argoverse dataset.</li> </ul> <p>\\(cv + ct + ca\\) curve is generated with:</p> <pre><code>def cv_z(x0, dx, y0, dy, dt, cnt):\n    Z = [np.array([\n            [x0],\n            [dx],\n            [y0],\n            [dy]\n        ])]\n    for i in np.arange(1, cnt):\n        Z.append(np.array([\n            [Z[i-1][0, 0] + dx * dt],\n            [dx],\n            [Z[i-1][2, 0] + dy * dt],\n            [dy]\n            ]))\n\n    return Z\n\ndef ca_z(x0, dx, ddx, y0, dy, ddy, dt, cnt):\n    Z = [np.array([\n            [x0],\n            [dx],\n            [y0],\n            [dy]\n        ])]\n    for i in np.arange(1, cnt):\n        Z.append(np.array([\n            [Z[i-1][0,0] + Z[i-1][1,0] * dt + 0.5 * ddx * dt**2],\n            [Z[i-1][1,0]+ ddx * dt],\n            [Z[i-1][2,0] + Z[i-1][3,0] * dt + 0.5 * ddy * dt**2],\n            [Z[i-1][3,0]+ ddy * dt]\n            ]))\n\n    return Z\n\ndef ct_z(x0, dx, y0, dy, dtheta, dt, cnt):\n    Z = [np.array([\n            [x0],\n            [dx],\n            [y0],\n            [dy]\n        ])]\n    theta = math.atan2(dy, dx)\n    v = math.hypot(dx, dy)\n    for i in np.arange(1, cnt):\n        theta += dtheta * dt\n        Z.append(np.array([\n            [Z[i-1][0, 0] + v * dt * math.cos(theta)],\n            [v * math.cos(theta)],\n            [Z[i-1][2, 0] + v * dt * math.sin(theta)],\n            [v * math.sin(theta)]\n            ]))\n\n    return Z\n</code></pre>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#simulation-result","title":"Simulation result","text":""},{"location":"Self-Driving/Prediction/imm-for-prediction/#cv-ct-ca","title":"CV + CT + CA","text":"<p>From the figure we can see:</p> <ul> <li>the algorithm can figure out three models correctly;</li> <li>it's more difficult to figure out the \\(CA\\) model, because the acceleration information is not in the observation vector;</li> <li>it's not easy to distinguish \\(CV\\) and \\(CA\\) model.</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#real-vehicle-data","title":"Real vehicle data","text":"<p>The result is not so good, because its characteristics do not fit any model.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#argoverse-data","title":"Argoverse data","text":"<p> I choose a turning vehicle's path and add it's velocity information, we can say:</p> <ul> <li>it takes 2.5s to predict the right model;</li> <li>after test, I found that if we set the inital probability a more precise number, it can predict the right model more quickly(within 0.5s).</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#generate-prediction-trajectory","title":"Generate prediction trajectory","text":"<p>With the right model probabilities, we can predict the obstacle's trajectory in longer time. We use the probabilities and three models to generate trajectory:</p> <p></p> <p>The red line is the real trajectory of a vehicle, and the green line is predicted trajectory every time.</p> <p>We can see that:</p> <ul> <li>At the beginning it can not figure out the right model, so it mixes them up to generate trajectory;</li> <li>After figure out the CT model, the trajectory is getting closer to the real trajectory.</li> </ul>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#cpp-class-diagram","title":"Cpp class diagram","text":"<p>After testing the correctness of the algorithm, we designed the class diagram of the code: </p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#lrt-class","title":"LRT class","text":"<p>We should create a filter(kalman filter or imm) for every obstacle, it's important to construct and deconstruct the filters dynamiclly.</p> <p>We already have a <code>LRU</code>(Latest Recently Used) class, which will destroy the oldest node when it's capacity is to reach maximum. But it has the following problems:</p> <ul> <li>If the capacity is too big and the the number of filters we used is small, <code>LRU</code> will waste much memory space;</li> <li>If the capacity is too small and the the number of filters we used is big, <code>LRU</code> will destroy some filters in use, which hurts the prediction module.</li> </ul> <p>So we add the time limit to <code>LRU</code> structure and names it <code>LRT</code>. If a node is not used for a given time, it will be destroyed.</p>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#kalmanfilter","title":"KalmanFilter","text":"<p>To fit with different filter parameters, we use a template to generate instance.</p> <pre><code>//!\n//! \\class KalmanFilter\n//! \\brief Implement a discrete-time Kalman Filter\n//!        https://www.cs.unc.edu/~welch/media/pdf/kalman_intro.pdf\n//! \n//! \\param T DataType(double/float/int, etc.)\n//! \\param Xn dimension of state\n//! \\param Zn dimension of observations\n//! \\param Un dimension of controls\n//!\ntemplate &lt;typename T, unsigned int Xn, unsigned int Zn, unsigned int Un&gt;\nclass KalmanFilter {\n public:\n</code></pre>"},{"location":"Self-Driving/Prediction/imm-for-prediction/#immkf","title":"ImmKf","text":"<p>To fit with different kalman filters, we use a parameter pack to input all filters.</p> <pre><code>//!\n//! \\class ImmKf\n//! \\brief Implement a discrete-time Imm with kalman filter\n//!        https://sci-hub.do/10.1109/cdc.1984.272089#\n//! \n//! \\param T DataType(double/float/int, etc.)\n//! \\param Kf Kalman filters\n//! \\param Zn dimension of observations\n//!\n[[deprecated]]\ntemplate&lt;typename T, std::size_t Zn, typename... Kf&gt;\nclass ImmKf {\n  using TupleType = typename std::tuple&lt;Kf...&gt;;\n  using Mat1xN = Eigen::Matrix&lt;T, 1, std::tuple_size&lt;TupleType&gt;::value&gt;;\n  using MatNxN = Eigen::Matrix&lt;T, std::tuple_size&lt;TupleType&gt;::value,\n                               std::tuple_size&lt;TupleType&gt;::value&gt;;\n  using MatZx1 = Eigen::Matrix&lt;T, Zn, 1&gt;;\n public:\n</code></pre>"},{"location":"Self-Driving/Prediction/visualizer/","title":"The Design of A Visualization Tool for Autonomous Vehicle Developers(TODO)","text":"<p>This is a tool to visualize map and agents for self-driving developers. It's based on two libraries:</p> <ul> <li>Dear ImGui</li> <li>ImPlot</li> </ul> <p>It works with <code>Apollo Cyber</code>, and support:</p> <ul> <li>Show hdmap(apollo) lane boundaries and reference line with ids;</li> <li>Show agents(ego vehicle and obstacles, extract from apollo channel) with history/shape/futures(planning or prediction trajectory);</li> <li>Show real time plot of vlaues(extracted from apollo channel)</li> </ul>"},{"location":"Self-Driving/Prediction/visualizer/#architecture","title":"Architecture","text":"<p>The <code>.png</code> picture is created by Draw.io you can re-edit the pic with that.</p> <p></p>"},{"location":"Self-Driving/Routing/a_star/","title":"A star","text":"<p>In computer science, <code>A*</code>(pronounced A-Star) is a computer algorithm that is widely used in pathfinding and graph traversal, which is the process of finding a path between multiple points, called \"nodes\". It enjoys widespread use due to its performance and accuracy. Peter Hart, Nils Nilsson and Bertram Raphael of Stanford Research Institude(now SRI International) first published the algorithm in 1968. It can be seen as an extension of Edsger Dijkstra's 1959 algorithm. <code>A*</code> achieves better performance by using heuristics to guide its search.</p>"},{"location":"Self-Driving/Routing/a_star/#problem","title":"Problem","text":"<p>In real world, we often want to find a path from one location to another, it may be the shortest one or the most suitable one. Movement for a single object seems easy, pathfinding is complex, but pathfinder let you plan a path before you meet the obstacles, then you can move the short or suitable path. Path planning generally is slow, but gives better results.</p>"},{"location":"Self-Driving/Routing/a_star/#assumption","title":"Assumption","text":"<p>To find the path, we can sue a <code>graph search</code> algorithm, which works when the map is represented as a graph.</p>"},{"location":"Self-Driving/Routing/a_star/#input","title":"Input","text":"<p>Graph search algorithms take a <code>graph</code> as input. A graph is a set of locations(\"node\") and the connections(\"edge\") between them, like this:</p> <p></p> <p>Pathfinder doesn't see anything else, it only see the graph.</p>"},{"location":"Self-Driving/Routing/a_star/#output","title":"Output","text":"<p>The path found by pathfinder is made of <code>graph nodes and edges</code>. It tells you to move from one location to another, but it can't tell you how. You have to decide whether a graph edge you got means walking in a straight line or running along a curved path.</p>"},{"location":"Self-Driving/Routing/a_star/#early-solutions","title":"Early Solutions","text":"<p>There are lots of algorithms that run on graphs and find the path, the simplest is \"Breadth First Search\".</p>"},{"location":"Self-Driving/Routing/a_star/#breadth-first-search","title":"Breadth First Search","text":"<p>Breadth First Search explores equally in all directions. The key idea for this algorithm is that we keep track of an expanding ring called <code>frontier</code>. On a grid, this process is somtimes called \"flood fill\", but the same technique works for non-grids. </p> <p>The main process is:</p> <p>Loop:</p> <ul> <li>Pick and remove a <code>location</code> from the <code>frontier</code>;</li> <li>Expand it by looking at its <code>neighbors</code>, any neighbors we haven't visited yet we add to the <code>frontier</code>, and also to the <code>visited</code> set;</li> <li>if <code>frontier</code> is empty or reach the target node, break.</li> </ul> <p>So far we assume that every step has the same <code>cost</code>, however, in some scenarios there are difference costs for different types of movements. For example, a diagonal movement on a grid costs more than axial movement. We'd like the pathfinder to take these costs into account. For this purpose, we use <code>Dijkstra's Algorithm</code></p>"},{"location":"Self-Driving/Routing/a_star/#dijkstras-algorithm","title":"Dijkstra's Algorithm","text":"<p>Dijkstra's Algorithm tracks movement cost from the start location. The pathfinder may visit a location multiple times, with different costs. Instead of visit every node in <code>frontier</code>, we visit the lowest cost node at the beginning of the loop. The main process is below:</p> <ul> <li>Create a priority queue <code>frontier</code> and put the init node into <code>frontier</code>.</li> <li>Loop:<ul> <li>choose the lowest cost node from <code>frontier</code></li> <li>if <code>frontier</code> is empty or current node is goal node, break;</li> <li>get current node's neighbours, for each neighbour:<ul> <li>if the neighbour node has not been visited yet or its cost is lower than current node:<ul> <li>put the neighbour node into <code>frontier</code></li> <li>set the cost so far as the neighbour node's cost</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p></p> <p>With Breadth First Search and Dijkstra's Algorithm, the frontier expands in all directions. This is a reasonable choice if you only need to find a location and don't care about the time. However, a common case is that we want to find the path not only correctly but also quickly. Here comes the <code>Greedy Best First Search</code>.</p>"},{"location":"Self-Driving/Routing/a_star/#greedy-best-first-search","title":"Greedy Best First Search","text":"<p>Greedy Best First Search use the estimated distance to the goal for priority queue ordering. The location closet to the goal will be explored first. Its process can be described as:</p> <ul> <li>Create a priority queue <code>frontier</code> and put the init node into <code>frontier</code>.</li> <li>Loop:<ul> <li>choose the node with lowest distance to goad node from <code>frontier</code></li> <li>if <code>frontier</code> is empty or current node is goal node, break;</li> <li>get current node's neighbours, for each neighbour:<ul> <li>if the neighbour node has not been visited yet: <ul> <li>put the neighbour node into <code>frontier</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> <p></p> <p>The algorithm is really fast, but in complex map it may not find the shortest path, shown as below. </p>"},{"location":"Self-Driving/Routing/a_star/#a-algorithm","title":"A* Algorithm","text":"<p>Dijkstra\u2019s Algorithm works well to find the shortest path, but it wastes time exploring in directions that aren\u2019t promising. Greedy Best First Search explores in promising directions but it may not find the shortest path. The A* algorithm uses both the actual distance from the start and the estimated distance to the goal.</p>"},{"location":"Self-Driving/Routing/a_star/#evaluation-function","title":"Evaluation Function","text":"<p>In this algorithm, we use \\(g(n)\\) to describe the cost from initial node to \\(n\\) node, \\(h(n)\\) describes the estimated cost between any node \\(n\\) and the target node, and the total cost is: $$ f(n) = g(n) + h(n) $$</p>"},{"location":"Self-Driving/Routing/a_star/#process","title":"Process","text":"<p>The <code>A* Algorithm</code> uses a <code>open lsit</code> and a <code>close list</code>, <code>open list</code> stores nodes haven't been calculated yet, and <code>close list</code> stores nodes have been searched. Every time we select a best node from <code>open list</code> and put it to <code>close list</code>, then we search the best node's neighbours, put the neighbour into <code>close list</code> if it is not in. Loop, until we find the goal node or there is no node in <code>open list</code>.</p> <ol> <li>Put start node into <code>open list</code></li> <li>Loop:<ul> <li>Take the node A with lowest <code>F</code> from <code>open lsit</code>;</li> <li>Put the node A into <code>close list</code>;</li> <li>Search A's neighbours:<ul> <li>if the neighbour node is goal node, break;</li> <li>if the neighbour node is unreachable or it's in <code>close list</code>, ignore it;</li> <li>if the neighbour node is not in <code>open list</code>, put it into <code>open list</code>;</li> <li>if the neighbour node is in <code>open list</code> but its new <code>G</code> is lower than its older, set its parent to A and reset its <code>G</code> and <code>H</code></li> </ul> </li> </ul> </li> <li>From the goal node link all nodes' parent, we get the best path.</li> </ol>"},{"location":"Self-Driving/Routing/a_star/#heuristics","title":"Heuristics","text":"<p>The heuristic function \\(h(n)\\) tells A an estimate of the minimum cost from any vetex \\(n\\) to the goal, it can be used to control A's behavior.</p> <ul> <li>At one extreme, if \\(h(n)\\) is 0, then only \\(g(n)\\) plays a role, and A* turns into Dijkstra\u2019s Algorithm, which is guaranteed to find a shortest path.</li> <li>If \\(h(n)\\) is always lower than (or equal to) the cost of moving from \\(n\\) to the goal, then A is guaranteed to find a shortest path. The lower \\(h(n)\\) is, the more node A expands, making it slower.</li> <li>If \\(h(n)\\) is exactly equal to the cost of moving from \\(n\\) to the goal, then A will only follow the best path and never expand anything else, making it very fast. Although you can\u2019t make this happen in all cases, you can make it exact in some special cases. It\u2019s nice to know that given perfect information, A will behave perfectly.</li> <li>If \\(h(n)\\) is sometimes greater than the cost of moving from \\(n\\) to the goal, then A* is not guaranteed to find a shortest path, but it can run faster.</li> <li>At the other extreme, if \\(h(n)\\) is very high relative to \\(g(n)\\), then only \\(h(n)\\) plays a role, and A* turns into Greedy Best-First-Search.</li> </ul>"},{"location":"Self-Driving/Routing/a_star/#implementation","title":"Implementation","text":""},{"location":"Self-Driving/Routing/a_star/#astarh","title":"Astar.h","text":"<pre><code>// By yongcong.wang @ 16/07/2019\n#ifndef A_STAR_H_\n#define A_STAR_H_\n\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;list&gt;\n#include &lt;math.h&gt;\n#include &lt;limits&gt;\n\nnamespace a_star {\n\nstruct Node {\n  Node(int x, int y) : x(x), y(y), F(0), G(0), H(0), parent(nullptr) {}\n\n  int x;\n  int y;\n  int F;\n  int G;\n  int H;\n\n  Node *parent;\n};\n\nclass Astar {\n public:\n  Astar(std::vector&lt;std::vector&lt;int&gt;&gt; *maze);\n  Astar();\n  ~Astar();\n\n  void setMaze(std::vector&lt;std::vector&lt;int&gt;&gt; *maze);\n  Node *calcPath(Node *start_node, Node *end_node);\n  void printPath(Node *header_node);\n\n private:\n  Astar(const Astar &amp;rhs);\n  Astar &amp;operator=(const Astar &amp;rhs);\n\n  const int straight_cost_;\n  const int slope_cost_;\n\n  std::vector&lt;std::vector&lt;int&gt;&gt; *maze_;\n\n  int calcGcost(Node *curr_node, Node *next_node);\n  int calcHcost(Node *curr_node, Node *end_node);\n  int calcFcost(Node *node);\n  bool isPassable(Node *curr_node, Node *next_node);\n  bool isInList(std::list&lt;Node *&gt; &amp;node_list, Node *node);\n  bool isEqual(Node *first_node, Node *second_node);\n  Node *getMinFcostNode(std::list&lt;Node *&gt; &amp;node_list);\n  std::list&lt;Node *&gt; getSurroundingNodes(Node *node);\n};\n\n}\n\n#endif // A_STAR_H_\n</code></pre>"},{"location":"Self-Driving/Routing/a_star/#astarcc","title":"Astar.cc","text":"<pre><code>// By yongcong.wang @ 16/07/2019\n#include \"Astar.h\"\n\nnamespace a_star {\n\nAstar::Astar(std::vector&lt;std::vector&lt;int&gt;&gt; *maze) : \n    straight_cost_(10), slope_cost_(14), maze_(maze) {}\n\nAstar::Astar() : straight_cost_(10), slope_cost_(14) {}\n\nAstar::~Astar() {}\n\nvoid Astar::setMaze(std::vector&lt;std::vector&lt;int&gt;&gt; *maze) {\n  maze_ = maze;\n}\n\nNode *Astar::calcPath(Node *start_node, Node *end_node) {\n  if (start_node == nullptr || end_node == nullptr) {\n    std::cout &lt;&lt; \"calc Path: one of the nodes is not exist.\" &lt;&lt; std::endl;\n    return 0;\n  }\n\n  if (isEqual(start_node, end_node)) {\n    return end_node;\n  }\n\n  std::list&lt;Node *&gt; open_list;\n  std::list&lt;Node *&gt; close_list;\n  open_list.push_back(start_node);\n\n  while (!open_list.empty()) {\n    Node *curr_node = getMinFcostNode(open_list);\n    open_list.remove(curr_node);\n    close_list.push_back(curr_node);\n    std::list&lt;Node *&gt; surr_nodes = getSurroundingNodes(curr_node);\n\n    for (auto next_node : surr_nodes) {\n      if (isEqual(end_node, next_node)) {\n        next_node-&gt;parent = curr_node;\n        return next_node;\n      }\n\n      if (!isPassable(curr_node, next_node) ||\n          isInList(close_list, next_node)) {\n        continue;\n      }\n\n      if (!isInList(open_list, next_node)) {\n        next_node-&gt;parent = curr_node;\n        next_node-&gt;G = calcGcost(curr_node, next_node);\n        next_node-&gt;H = calcHcost(next_node, end_node);\n        next_node-&gt;F = calcFcost(next_node);\n        open_list.push_back(next_node);\n      } else {\n        int new_g = calcGcost(curr_node, next_node);\n        if (new_g &lt; next_node-&gt;G) {\n          next_node-&gt;parent = curr_node;\n          next_node-&gt;G = new_g;\n          next_node-&gt;H = calcHcost(next_node, end_node);\n          next_node-&gt;F = calcFcost(next_node);\n          open_list.push_back(next_node);\n        }\n      }\n    }\n  }\n\n  return nullptr;\n}\n\nvoid Astar::printPath(Node *header_node) {\n  if (header_node == nullptr) {\n    return;\n  }\n\n  std::cout &lt;&lt; \"[\" &lt;&lt; header_node-&gt;x &lt;&lt; \", \" &lt;&lt; header_node-&gt;y &lt;&lt; \"]\" &lt;&lt; std::endl;\n\n  printPath(header_node-&gt;parent);\n}\n\nint Astar::calcGcost(Node *curr_node, Node *next_node) {\n  if (curr_node == nullptr || next_node == nullptr) {\n    std::cout &lt;&lt; \"G Cost: one of the nodes is not exist.\" &lt;&lt; std::endl;\n    return 0;\n  }\n\n  if (abs(curr_node-&gt;x - next_node-&gt;x) + abs(curr_node-&gt;y - next_node-&gt;y) == 1) {\n    return curr_node-&gt;G + straight_cost_;\n  } else {\n    return curr_node-&gt;G + slope_cost_;\n  }\n}\n\n\nint Astar::calcHcost(Node *curr_node, Node *end_node) {\n  if (curr_node == nullptr || end_node == nullptr) {\n    std::cout &lt;&lt; \"H Cost: one of the nodes is not exist.\" &lt;&lt; std::endl;\n    return 0;\n  }\n\n  return abs(pow(curr_node-&gt;x - end_node-&gt;x, 2) + pow(curr_node-&gt;y - end_node-&gt;y, 2));\n}\n\nint Astar::calcFcost(Node *node) {\n  if (node == nullptr ) {\n    std::cout &lt;&lt; \"F Cost: node is not exist.\" &lt;&lt; std::endl;\n    return 0;\n  }\n\n  return node-&gt;G + node-&gt;H;\n}\n\nbool Astar::isPassable(Node *curr_node, Node *next_node) {\n  if (curr_node == nullptr || next_node == nullptr) {\n    std::cout &lt;&lt; \"Reachable check: one of the nodes is not exist.\" &lt;&lt; std::endl;\n    return false;\n  }\n\n  if ((*maze_)[curr_node-&gt;x][curr_node-&gt;y] == 1 ||\n      (*maze_)[next_node-&gt;x][next_node-&gt;y] == 1) {\n    return false; // on obstacle\n  }\n\n  if ((*maze_)[curr_node-&gt;x][next_node-&gt;y] == 1 ||\n      (*maze_)[next_node-&gt;x][curr_node-&gt;y] == 1) {\n    return false; // on slope\n  }\n\n  return true;\n}\n\nbool Astar::isInList(std::list&lt;Node *&gt; &amp;node_list, Node *node) {\n  if (node_list.empty() || node == nullptr) {\n    return false;\n  }\n\n  for (auto nd : node_list) {\n    if (nd-&gt;x == node-&gt;x &amp;&amp; nd-&gt;y == node-&gt;y) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nbool Astar::isEqual(Node *first_node, Node *second_node) {\n  if (first_node == nullptr || second_node == nullptr) {\n    std::cout &lt;&lt; \"Equal check: one of the inputs is not exist.\" &lt;&lt; std::endl;\n    return false;\n  }\n\n  return (first_node-&gt;x == second_node-&gt;x) &amp;&amp; (first_node-&gt;y == second_node-&gt;y);\n}\n\nNode *Astar::getMinFcostNode(std::list&lt;Node *&gt; &amp;node_list) {\n  if (node_list.empty()) {\n    std::cout &lt;&lt; \"Calc Min F Cost Node: node list is empty.\" &lt;&lt; std::endl;\n    return nullptr;\n  }\n\n  int min_f_cost = std::numeric_limits&lt;int&gt;::max();\n  Node *min_node = nullptr;\n  for (auto node : node_list) {\n    if (min_f_cost &gt; node-&gt;F) {\n      min_f_cost = node-&gt;F;\n      min_node = node;\n    }\n  }\n\n  return min_node;\n}\n\nstd::list&lt;Node *&gt; Astar::getSurroundingNodes(Node *node) {\n  std::list&lt;Node *&gt; res;\n  if (node == nullptr) {\n    std::cout &lt;&lt; \"calc surrounding: input is not exist.\" &lt;&lt; std::endl;\n    return res;\n  }\n\n  for (int i = -1; i &lt;= 1; ++i) {\n    for (int j = -1; j &lt;= 1; ++j) {\n      if (i == 0 &amp;&amp; j == 0) {\n        continue;\n      } else {\n        res.push_back(new Node(node-&gt;x + i, node-&gt;y + j));\n      }\n    }\n  }\n\n  return res;\n}\n\n}\n</code></pre>"},{"location":"Self-Driving/Routing/a_star/#maincc","title":"main.cc","text":"<pre><code>// By yongcong.wang @ 16/07/2019\n#include \"Astar.h\"\n\nint main() {\n  std::vector&lt;std::vector&lt;int&gt;&gt; maze = {\n    {1,1,1,1,1,1,1,1,1,1,1,1},\n    {1,0,0,1,1,0,1,0,0,0,0,1},\n    {1,0,0,1,1,0,0,0,0,0,0,1},\n    {1,0,0,0,0,0,1,0,0,1,1,1},\n    {1,1,1,0,0,0,0,0,1,1,0,1},\n    {1,1,0,1,0,0,0,0,0,0,0,1},\n    {1,0,1,0,0,0,0,1,0,0,0,1},\n    {1,1,1,1,1,1,1,1,1,1,1,1}\n  };\n\n  a_star::Astar a(&amp;maze);\n  a_star::Node start_node(6, 4);\n  a_star::Node end_node(6, 10);\n\n  auto *header = a.calcPath(&amp;start_node, &amp;end_node);\n  a.printPath(header);\n}\n</code></pre>"},{"location":"Self-Driving/Routing/a_star/#build-and-test","title":"Build and Test","text":"<pre><code>g++ -std=c++11 -c Astar.cc &amp;&amp; g++ -std=c++11 -c main.cc &amp;&amp; g++ main.o Astar.o -o test &amp;&amp; ./test\n</code></pre>"},{"location":"Self-Driving/Routing/a_star/#reference","title":"Reference","text":"<ul> <li>Wikipedia: A* search algorithm</li> <li>Clear visual A* explanation, with advice and thoughts on path-finding</li> <li>\u8def\u5f84\u89c4\u5212\u4e4b A* \u7b97\u6cd5</li> </ul>"},{"location":"Tools/archlinux_install/","title":"Archlinux Installation","text":""},{"location":"Tools/archlinux_install/#before-start","title":"Before Start","text":""},{"location":"Tools/archlinux_install/#bios","title":"BIOS","text":"<ul> <li>Disable <code>Secure Boot</code></li> <li>Boot Mode <code>UEFI</code> Only</li> </ul>"},{"location":"Tools/archlinux_install/#basic-install","title":"Basic Install","text":""},{"location":"Tools/archlinux_install/#disable-reflector","title":"Disable reflector","text":"<pre><code>systemctl stop reflector.service\n</code></pre>"},{"location":"Tools/archlinux_install/#check-uefi-mode","title":"Check <code>UEFI</code> Mode","text":"<p>Outputs after command below:</p> <pre><code>ls /sys/firmware/efi/efivars\n</code></pre>"},{"location":"Tools/archlinux_install/#connect-network","title":"Connect Network","text":"<pre><code>iwctl\ndevice list\nstation wlan0 scan\nstation wlan0 get-networks\nstation wlan0 connect ${WIFI}\n</code></pre>"},{"location":"Tools/archlinux_install/#update-clock","title":"Update Clock","text":"<pre><code>timedatectl set-ntp true\ntimedatectl status\n</code></pre>"},{"location":"Tools/archlinux_install/#partition","title":"Partition","text":"<pre><code>lsblk\nparted /dev/nvme0n1\nNew disk lable type? gpt\nquit\n</code></pre> <p>Divide hard disk to three parts with <code>cfdisk /dev/nvme0n1</code>:</p> <ul> <li><code>/efi</code>: <code>EFI System</code>, 800M</li> <li><code>/</code>: <code>Linux filesystem</code>, 100G</li> <li><code>/home</code>: <code>Linux filesystem</code>, other</li> </ul> <p>Check with <code>fdisk -l</code></p>"},{"location":"Tools/archlinux_install/#format","title":"Format","text":"<pre><code>mkfs.vfat /dev/nvme0n1p1\nmkfs.ext4 /dev/nvme0n1p2\nmkfs.ext4 /dev/nvme0n1p3\n</code></pre>"},{"location":"Tools/archlinux_install/#mount","title":"Mount","text":"<pre><code>mount /dev/nvme0n1p2 /mnt\n\nmkdir /mnt/efi\nmount /dev/nvme0n1p1 /mnt/efi\n\nmkdir /mnt/home\nmount /dev/nvme0n1p3 /mnt/home\n</code></pre>"},{"location":"Tools/archlinux_install/#select-server","title":"Select Server","text":"<pre><code>vim /etc/pacman.d/mirrorlist\n</code></pre> <p>Add following lines at begining:</p> <pre><code>Server = https://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch\nServer = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch\n</code></pre>"},{"location":"Tools/archlinux_install/#install-system","title":"Install System","text":"<pre><code>pacstrap /mnt base base-devel linux linux-headers linux-firmware\n</code></pre> <pre><code>pacstrap /mnt dhcpcd iwd vim bash-completion\n</code></pre>"},{"location":"Tools/archlinux_install/#generate-fstab-file","title":"Generate <code>fstab</code> file","text":"<pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n</code></pre> <p>Check with:</p> <pre><code>cat /mnt/etc/fstab\n</code></pre>"},{"location":"Tools/archlinux_install/#change-root","title":"Change Root","text":"<pre><code>arch-chroot /mnt\n</code></pre>"},{"location":"Tools/archlinux_install/#set-timezone","title":"Set Timezone","text":"<pre><code>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n</code></pre> <p>Hardware sync:</p> <pre><code>hwclock --systohc\n</code></pre>"},{"location":"Tools/archlinux_install/#set-locale","title":"Set Locale","text":"<p>Uncomment:</p> <ul> <li>en_US.UTF-8</li> <li>zh_CN.UTF-8</li> </ul> <p>in <code>/etc/locale.gen</code>, and generate with:</p> <pre><code>locale-gen\necho 'LANG=en_US.UTF-8' &gt; /etc/locale.conf\n</code></pre>"},{"location":"Tools/archlinux_install/#set-host","title":"Set Host","text":"<pre><code>echo 'arch' &gt; /etc/hostname\n</code></pre> <p>Add following to <code>/etc/hosts</code>:</p> <pre><code>127.0.0.1 localhost\n::1       localhost\n127.0.1.1 arch\n</code></pre>"},{"location":"Tools/archlinux_install/#change-root-password","title":"Change Root Password","text":"<pre><code>passwd root\n</code></pre>"},{"location":"Tools/archlinux_install/#install-micro-code","title":"Install Micro-Code","text":"<pre><code>pacman -S intel-ucode  ## for intel\npacman -S amd-ucode    ## for amd\n</code></pre>"},{"location":"Tools/archlinux_install/#install-grub","title":"Install Grub","text":"<pre><code>pacman -S grub efibootmgr\ngrub-install --target=x86_64-efi --efi-directory=/efi --bootloader-id=GRUB\n</code></pre> <p>Change the line in <code>/etc/default/grub</code> to:</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"loglevel=5 nowatchdog\"\n</code></pre> <p>And generate with</p> <pre><code>grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre>"},{"location":"Tools/archlinux_install/#finish","title":"Finish","text":"<pre><code>exit\numount -R /mnt\nreboot\n</code></pre> <p>And after restarting, start the service <code>systemctl start dhcpcd</code> to connect to the internet.</p>"},{"location":"Tools/archlinux_install/#desktop-install","title":"Desktop Install","text":""},{"location":"Tools/archlinux_install/#update-system","title":"Update System","text":"<pre><code>pacman -Syyu\n</code></pre>"},{"location":"Tools/archlinux_install/#add-non-root-user","title":"Add Non-root User","text":"<pre><code>useradd -m -G wheel -s /bin/bash wyc\npasswd wyc\n</code></pre> <p>Add sudo priority:</p> <pre><code>EDITOR=vim visudo\n</code></pre> <p>and umcomment following line:</p> <pre><code>#%wheel ALL=(ALL:ALL) ALL\n</code></pre>"},{"location":"Tools/archlinux_install/#support-32-bit-library","title":"Support 32-bit Library","text":"<pre><code>vim /etc/pacman.conf\n</code></pre> <p>and uncomment:</p> <pre><code>[multilib]\nInclude = /etc/pacman.d/mirrorlist\n</code></pre>"},{"location":"Tools/archlinux_install/#install-software","title":"Install Software","text":"<ul> <li>xterm</li> <li>openssh</li> <li>translate-shell</li> <li>feh</li> <li>rofi</li> <li>ranger</li> <li>neofetch</li> <li>htop</li> <li>gdb</li> <li>flameshot</li> <li>vlc</li> <li>arandr</li> <li>yay: <code>git clone https://aur.archlinux.org/yay.git &amp;&amp; cd yay &amp;&amp; makepkg -si</code></li> <li>google-chrome</li> <li>ttf-hack</li> <li>wqy-microhei</li> </ul>"},{"location":"Tools/archlinux_install/#ctags","title":"ctags","text":"<pre><code>git clone https://github.com/universal-ctags/ctags.git\ncd ctags\n./autogen.sh\n./configure # --prefix=/where/you/want # defaults to /usr/local\nmake\nmake install # may require extra privileges depending on where to install\n</code></pre>"},{"location":"Tools/archlinux_install/#fzf","title":"fzf","text":"<pre><code>git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf &amp;&amp;\n~/.fzf/install\n</code></pre>"},{"location":"Tools/archlinux_install/#install-i3","title":"Install i3","text":"<pre><code>pacman -S i3-wm xorg-xinit xorg-server\ncp /etc/X11/xinit/xinitrc ~/.xinitrc\necho startx &gt;&gt; ~/.bashrc\n</code></pre> <p>and change the tail of <code>~/.xinitrc</code> to:</p> <pre><code>exec i3\n</code></pre> <p>and add following lines to <code>~/.bash_profile</code></p> <pre><code>if [ -z \"${DISPLAY}\" ] &amp;&amp; [ \"${XDG_VTNR}\" -eq 1 ]; then\n  exec startx\nfi\n</code></pre>"},{"location":"Tools/archlinux_install/#setup-git","title":"Setup git","text":"<pre><code>sudo apt install git\n# config\ngit config --global user.name \"YongcongWang\"\ngit config --global user.email \"yongcong.wang@outlook.com\"\ngit config --global core.editor vim\n# generate key\nssh-keygen -t rsa -C \"yongcong.wang@outlook.com\"\n</code></pre> <p>Config:</p> <ol> <li>Open github and sign in;</li> <li>In <code>Settings/SSH and GPG keys</code> click <code>New SSH Key</code>;</li> <li>Paste <code>id_rsa.PUB</code>(in <code>/home/.ssh/id_rsa.pub</code>);</li> <li>Test: <code>ssh -T git@github.com</code>.</li> </ol> <pre><code>git clone git@github.com:yongcongwang/dotfiles.git ~/.dotfiles &amp;&amp; cd ~/.dotfiles &amp;&amp; bash deploy.sh git\n</code></pre>"},{"location":"Tools/archlinux_install/#install-chinese-input","title":"Install Chinese Input","text":"<pre><code>sudo pacman -S fcitx5 fcitx5-qt fcitx5-config-qt fcitxt-rime rime-luna-pinyin\n</code></pre> <p>add following lines to <code>/etc/environment</code>:</p> <pre><code>GTK_IM_MODULE=fcitx\nQT_IM_MODULE=fcitx\nXMODIFIERS=@im=fcitx\n</code></pre>"},{"location":"Tools/archlinux_install/#keyboard","title":"Keyboard","text":"<p>Set caps to control</p> <pre><code>setxkbmap -layout us -option ctrl:nocaps\n</code></pre>"},{"location":"Tools/class_diagram/","title":"Class diagram","text":""},{"location":"Tools/class_diagram/#class-diagram","title":"Class Diagram","text":"<p>In software engineering, a diagram in the UML(Unified Modeling Language) is a type of static structure diagram that describes the structure of a system by showing the system's classes, their attributes, operations(or methods), and the relationship among objects.</p> <p></p>"},{"location":"Tools/class_diagram/#visibility","title":"Visibility","text":"<p>To specify the visibility of a class member(i.e. attribute or method), these notations must be placed before the member's name:</p> <ul> <li><code>+</code>: Public</li> <li><code>-</code>: Private</li> <li><code>#</code>: Protected</li> <li><code>~</code>: Package</li> </ul>"},{"location":"Tools/class_diagram/#relationships","title":"Relationships","text":"<p>A relationship is a general term covering the specific types of logical connections found on class and object diagrams.</p> <p></p>"},{"location":"Tools/class_diagram/#instance-level-relationships","title":"Instance-level Relationships","text":""},{"location":"Tools/class_diagram/#dependency","title":"Dependency","text":"<p><code>Dependency</code> is the relationship of <code>... uses a ...</code> that indicates that one class depends on another because it uses it at some point in time. One class depends on another if the independent class is a</p> <ul> <li>parameter</li> <li>local variable</li> </ul> <p>of a method of the dependent class.</p>"},{"location":"Tools/class_diagram/#association","title":"Association","text":"<p><code>Association</code> is the relationship of <code>... has a ...</code> which represents a family of links. An association can link any number of classes. It represents the static relationship shared among the objects of two classes. There are four types of association:</p> <ul> <li>Bi-directional, which has two ends;</li> <li>Uni-directional, which has one end;</li> <li>Aggregation;</li> <li>Composition.</li> </ul>"},{"location":"Tools/class_diagram/#aggregation","title":"Aggregation","text":"<p><code>Aggregation</code> is the relationship of <code>... owns a ...</code> which is more specific than association. It is an association that represents a part-whole or part-of relationship. Furthermore, there is hardly a difference between aggregations and associations during implementation, and the diagram may skip aggregation relations altogether.</p>"},{"location":"Tools/class_diagram/#composition","title":"Composition","text":"<p><code>Composition</code> is the relationship of <code>... part of ...</code>. The main difference between aggregation and composition is:  </p> <ul> <li>composition: when the container is destroyed, the contents are also destroyed.</li> <li>aggregation: when the container is destroyed, the contents are usually not destroyed.</li> </ul>"},{"location":"Tools/class_diagram/#class-level-relationships","title":"Class-level Relationships","text":""},{"location":"Tools/class_diagram/#realizationimplementation","title":"Realization/Implementation","text":"<p>A <code>realization</code> relationship is between two model elements, in which one model element(the client) realizes (implements or executes) the behavior that the other model element(the supplier) specifies.</p>"},{"location":"Tools/class_diagram/#generalizationinheritance","title":"Generalization/Inheritance","text":"<p>A <code>Generalization</code> relationship indicates that one of the two related classes(the subclass) is considered to be a specialized form of the other(the super type) and the superclass is considered a <code>generalization</code> of the subclass.</p>"},{"location":"Tools/latex/","title":"Latex Equations Cheatsheet","text":""},{"location":"Tools/latex/#functions-symbols-and-characters","title":"Functions, Symbols, and Characters","text":""},{"location":"Tools/latex/#accents-and-diacritics","title":"Accents and Diacritics","text":"Source Rendering <code>\\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}</code> \\(\\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}\\) <code>\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}</code> \\(\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}\\) <code>\\hat{a}, \\widehat{a}, \\vec{a}</code> \\(\\hat{a}, \\widehat{a}, \\vec{a}\\)"},{"location":"Tools/latex/#standard-numerical-functions","title":"Standard Numerical Functions","text":"Source Rendering <code>\\exp_a b = a^b, \\exp b = e^b, 10^m</code> \\(\\exp_a b = a^b, \\exp b = e^b, 10^m\\) <code>\\ln c, \\lg d = \\log e, \\log_{10} f</code> \\(\\ln c, \\lg d = \\log e, \\log_{10} f\\) <code>\\sin a, \\cos b, \\tan c, \\cot d, \\sec e, \\csc f</code> \\(\\sin a, \\cos b, \\tan c, \\cot d, \\sec e, \\csc f\\) <code>\\arcsin h, \\arccos i, \\arctan j</code> \\(\\arcsin h, \\arccos i, \\arctan j\\) <code>\\sinh k, \\cosh l, \\tanh m, \\coth n</code> \\(\\sinh k, \\cosh l, \\tanh m, \\coth n\\) <code>\\operatorname{sh}k, \\operatorname{ch}l, \\operatorname{th}m, \\operatorname{coth}n</code> \\(\\operatorname{sh}k, \\operatorname{ch}l, \\operatorname{th}m, \\operatorname{coth}n\\) <code>\\operatorname{argsh}o, \\operatorname{argch}p, \\operatorname{argth}q</code> \\(\\operatorname{argsh}o, \\operatorname{argch}p, \\operatorname{argth}q\\) <code>\\sgn r, \\left\\vert s \\right\\vert</code> \\(sgn r, \\left\\vert s \\right\\vert\\) <code>\\min(x,y), \\max(x,y)</code> \\(\\min(x,y), \\max(x,y)\\)"},{"location":"Tools/latex/#bounds","title":"Bounds","text":"Source Rendering <code>\\min x, \\max y, \\inf s, \\sup t</code> \\(\\min x, \\max y, \\inf s, \\sup t\\) <code>\\lim u, \\liminf v, \\limsup w</code> \\(\\lim u, \\liminf v, \\limsup w\\) <code>\\dim p, \\deg q, \\det m, \\ker\\phi</code> \\(\\dim p, \\deg q, \\det m, \\ker\\phi\\)"},{"location":"Tools/latex/#projections","title":"Projections","text":"Source Rendering <code>\\Pr j, \\hom l, \\lVert z \\rVert, \\arg z</code> \\(\\Pr j, \\hom l, \\lVert z \\rVert, \\arg z\\)"},{"location":"Tools/latex/#differentials-and-derivatives","title":"Differentials and Derivatives","text":"Source Rendering dt, \\mathrm{d}t, \\partial t, \\nabla\\psi` \\(dt, \\mathrm{d}t, \\partial t, \\nabla\\psi\\) dy/dx, \\mathrm{d}y/\\mathrm{d}x, \\frac{dy}{dx}, \\frac{\\mathrm{d}y}{\\mathrm{d}x}, \\frac{\\partial^2}{\\partial x_1\\partial x_2}y` \\(dy/dx, \\mathrm{d}y/\\mathrm{d}x, \\frac{dy}{dx}, \\frac{\\mathrm{d}y}{\\mathrm{d}x}, \\frac{\\partial^2}{\\partial x_1\\partial x_2}y\\) \\prime, \\backprime, f^\\prime, f', f'', f^{(3)}, \\dot y, \\ddot y` \\(\\prime, \\backprime, f^\\prime, f', f'', f^{(3)} \\!, \\dot y, \\ddot y\\)"},{"location":"Tools/latex/#letter-like-symbols-or-constants","title":"Letter-like Symbols or Constants","text":"Source Rendering <code>\\infty, \\aleph, \\complement, \\backepsilon, \\eth, \\Finv, \\hbar</code> \\(\\infty, \\aleph, \\complement, \\backepsilon, \\eth, \\Finv, \\hbar\\) <code>\\Im, \\imath, \\jmath, \\Bbbk, \\ell, \\mho, \\wp, \\Re, \\circledS, \\S, \\P, \\AA</code> \\(\\Im, \\imath, \\jmath, \\Bbbk, \\ell, \\mho, \\wp, \\Re, \\circledS, \\S, \\P, \\AA\\)"},{"location":"Tools/latex/#modular-arithmetic","title":"Modular Arithmetic","text":"Source Rendering <code>s_k \\equiv 0 \\pmod{m}</code> \\(s_k \\equiv 0 \\pmod{m}\\) <code>a \\bmod b</code> \\(a \\bmod b\\) <code>\\gcd(m, n), \\operatorname{lcm}(m, n)</code> \\(\\gcd(m, n), \\operatorname{lcm}(m, n)\\) <code>\\mid, \\nmid, \\shortmid, \\nshortmid</code> \\(\\mid, \\nmid, \\shortmid, \\nshortmid\\)"},{"location":"Tools/latex/#radicals","title":"Radicals","text":"Source Rendering <code>\\surd, \\sqrt{2}, \\sqrt[n]{2}, \\sqrt[3]{\\frac{x^3+y^3}{2}}</code> \\(\\surd, \\sqrt{2}, \\sqrt[n]{2}, \\sqrt[3]{\\frac{x^3+y^3}{2}}\\)"},{"location":"Tools/latex/#operators","title":"Operators","text":"Source Rendering <code>+, -, \\pm, \\mp, \\dotplus</code> \\(+, -, \\pm, \\mp, \\dotplus\\) <code>\\times, \\div, \\divideontimes, /, \\backslash</code> \\(\\times, \\div, \\divideontimes, /, \\backslash\\) <code>\\cdot, * \\ast, \\star, \\circ, \\bullet</code> \\(\\cdot, * \\ast, \\star, \\circ, \\bullet\\) <code>\\boxplus, \\boxminus, \\boxtimes, \\boxdot</code> \\(\\boxplus, \\boxminus, \\boxtimes, \\boxdot\\) <code>\\oplus, \\ominus, \\otimes, \\oslash, \\odot</code> \\(\\oplus, \\ominus, \\otimes, \\oslash, \\odot\\) <code>\\circleddash, \\circledcirc, \\circledast</code> \\(\\circleddash, \\circledcirc, \\circledast\\) <code>\\bigoplus, \\bigotimes, \\bigodot</code> \\(\\bigoplus, \\bigotimes, \\bigodot\\)"},{"location":"Tools/latex/#sets","title":"Sets","text":"Source Rendering <code>\\{ \\}, \\O \\empty \\emptyset, \\varnothing</code> \\(\\{ \\}, \\O \\empty \\emptyset, \\varnothing\\) <code>\\in, \\notin \\not\\in, \\ni, \\not\\ni</code> \\(\\in, \\notin \\not\\in, \\ni, \\not\\ni\\) <code>\\cap, \\Cap, \\sqcap, \\bigcap</code> \\(\\cap, \\Cap, \\sqcap, \\bigcap\\) <code>\\cup, \\Cup, \\sqcup, \\bigcup, \\bigsqcup, \\uplus, \\biguplus</code> \\(\\cup, \\Cup, \\sqcup, \\bigcup, \\bigsqcup, \\uplus, \\biguplus\\) <code>\\setminus, \\smallsetminus, \\times</code> \\(\\setminus, \\smallsetminus, \\times\\) <code>\\subset, \\Subset, \\sqsubset</code> \\(\\subset, \\Subset, \\sqsubset\\) <code>\\supset, \\Supset, \\sqsupset</code> \\(\\supset, \\Supset, \\sqsupset\\) <code>\\subseteq, \\nsubseteq, \\subsetneq, \\varsubsetneq, \\sqsubseteq</code> \\(\\subseteq, \\nsubseteq, \\subsetneq, \\varsubsetneq, \\sqsubseteq\\) <code>\\supseteq, \\nsupseteq, \\supsetneq, \\varsupsetneq, \\sqsupseteq</code> \\(\\supseteq, \\nsupseteq, \\supsetneq, \\varsupsetneq, \\sqsupseteq\\) <code>\\subseteqq, \\nsubseteqq, \\subsetneqq, \\varsubsetneqq</code> \\(\\subseteqq, \\nsubseteqq, \\subsetneqq, \\varsubsetneqq\\) <code>\\supseteqq, \\nsupseteqq, \\supsetneqq, \\varsupsetneqq</code> \\(\\supseteqq, \\nsupseteqq, \\supsetneqq, \\varsupsetneqq\\)"},{"location":"Tools/latex/#relations","title":"Relations","text":"Source Rendering <code>=, \\ne, \\neq, \\equiv, \\not\\equiv</code> \\(=, \\ne, \\neq, \\equiv, \\not\\equiv\\) <code>\\doteq, \\doteqdot,</code> <code>\\overset{\\underset{\\mathrm{def}}{}}{=},</code> <code>:=</code> \\(\\doteq, \\doteqdot, \\overset{\\underset{\\mathrm{def}}{}}{=}, :=\\) <code>\\sim, \\nsim, \\backsim, \\thicksim, \\simeq, \\backsimeq, \\eqsim, \\cong, \\ncong</code> \\(\\sim, \\nsim, \\backsim, \\thicksim, \\simeq, \\backsimeq, \\eqsim, \\cong, \\ncong\\) <code>\\approx, \\thickapprox, \\approxeq, \\asymp, \\propto, \\varpropto</code> \\(\\approx, \\thickapprox, \\approxeq, \\asymp, \\propto, \\varpropto\\) <code>&lt;, \\nless, \\ll, \\not\\ll, \\lll, \\not\\lll, \\lessdot</code> \\(&lt;, \\nless, \\ll, \\not\\ll, \\lll, \\not\\lll, \\lessdot\\) <code>&gt;, \\ngtr, \\gg, \\not\\gg, \\ggg, \\not\\ggg, \\gtrdot</code> \\(&gt;, \\ngtr, \\gg, \\not\\gg, \\ggg, \\not\\ggg, \\gtrdot\\) <code>\\le, \\leq, \\lneq, \\leqq, \\nleq, \\nleqq, \\lneqq, \\lvertneqq</code> \\(\\le, \\leq, \\lneq, \\leqq, \\nleq, \\nleqq, \\lneqq, \\lvertneqq\\) <code>\\ge, \\geq, \\gneq, \\geqq, \\ngeq, \\ngeqq, \\gneqq, \\gvertneqq</code> \\(\\ge, \\geq, \\gneq, \\geqq, \\ngeq, \\ngeqq, \\gneqq, \\gvertneqq\\) <code>\\lessgtr, \\lesseqgtr, \\lesseqqgtr, \\gtrless, \\gtreqless, \\gtreqqless</code> \\(\\lessgtr, \\lesseqgtr, \\lesseqqgtr, \\gtrless, \\gtreqless, \\gtreqqless\\) <code>\\leqslant, \\nleqslant, \\eqslantless</code> \\(\\leqslant, \\nleqslant, \\eqslantless\\) <code>\\geqslant, \\ngeqslant, \\eqslantgtr</code> \\(\\geqslant, \\ngeqslant, \\eqslantgtr\\) <code>\\lesssim, \\lnsim, \\lessapprox, \\lnapprox</code> \\(\\lesssim, \\lnsim, \\lessapprox, \\lnapprox\\) <code>\\gtrsim, \\gnsim, \\gtrapprox, \\gnapprox</code> \\(\\gtrsim, \\gnsim, \\gtrapprox, \\gnapprox\\) <code>\\prec, \\nprec, \\preceq, \\npreceq, \\precneqq</code> \\(\\prec, \\nprec, \\preceq, \\npreceq, \\precneqq\\) <code>\\succ, \\nsucc, \\succeq, \\nsucceq, \\succneqq</code> \\(\\succ, \\nsucc, \\succeq, \\nsucceq, \\succneqq\\) <code>\\preccurlyeq, \\curlyeqprec</code> \\(\\preccurlyeq, \\curlyeqprec\\) <code>\\succcurlyeq, \\curlyeqsucc</code> \\(\\succcurlyeq, \\curlyeqsucc\\) <code>\\precsim, \\precnsim, \\precapprox, \\precnapprox</code> \\(\\precsim, \\precnsim, \\precapprox, \\precnapprox\\) <code>\\succsim, \\succnsim, \\succapprox, \\succnapprox</code> \\(\\succsim, \\succnsim, \\succapprox, \\succnapprox\\)"},{"location":"Tools/latex/#geometric","title":"Geometric","text":"Source Rendering <code>\\parallel, \\nparallel, \\shortparallel, \\nshortparallel</code> \\(\\parallel, \\nparallel, \\shortparallel, \\nshortparallel\\) <code>\\perp, \\angle, \\sphericalangle, \\measuredangle, 45^\\circ</code> \\(\\perp, \\angle, \\sphericalangle, \\measuredangle, 45^\\circ\\) <code>\\Box, \\square, \\blacksquare, \\diamond, \\Diamond, \\lozenge, \\blacklozenge, \\bigstar</code> \\(\\Box, \\square, \\blacksquare, \\diamond, \\Diamond, \\lozenge, \\blacklozenge, \\bigstar\\) <code>\\bigcirc, \\triangle, \\bigtriangleup, \\bigtriangledown</code> \\(\\bigcirc, \\triangle, \\bigtriangleup, \\bigtriangledown\\) <code>\\vartriangle, \\triangledown</code> \\(\\vartriangle, \\triangledown\\) <code>\\blacktriangle, \\blacktriangledown, \\blacktriangleleft, \\blacktriangleright</code> \\(\\blacktriangle, \\blacktriangledown, \\blacktriangleleft, \\blacktriangleright\\)"},{"location":"Tools/latex/#logic","title":"Logic","text":"Source Rendering <code>\\forall, \\exists, \\nexists</code> \\(\\forall, \\exists, \\nexists\\) <code>\\therefore, \\because, \\And</code> \\(\\therefore, \\because, \\And\\) <code>\\lor \\vee, \\curlyvee, \\bigvee</code>  don't use <code>\\or</code> which is now deprecated \\(\\lor, \\vee, \\curlyvee, \\bigvee\\) <code>\\land \\wedge, \\curlywedge, \\bigwedge</code> don't use <code>\\and</code> which is now deprecated \\(\\land, \\wedge, \\curlywedge, \\bigwedge\\) <code>\\bar{q}, \\bar{abc}, \\overline{q}, \\overline{abc}, \\lnot \\neg, \\not\\operatorname{R}, \\bot, \\top</code> \\(\\bar{q}, \\bar{abc}, \\overline{q}, \\overline{abc}, \\lnot \\neg, \\not\\operatorname{R}, \\bot, \\top\\) <code>\\vdash \\dashv, \\vDash, \\Vdash, \\models</code> \\(\\vdash, \\dashv, \\vDash, \\Vdash, \\models\\) <code>\\Vvdash \\nvdash \\nVdash \\nvDash \\nVDash</code> \\(\\Vvdash, \\nvdash, \\nVdash, \\nvDash, \\nVDash\\) <code>\\ulcorner \\urcorner \\llcorner \\lrcorner</code> \\(\\ulcorner \\urcorner \\llcorner \\lrcorner\\)"},{"location":"Tools/latex/#arrows","title":"Arrows","text":"Source Rendering <code>\\Rrightarrow, \\Lleftarrow</code> \\(\\Rrightarrow, \\Lleftarrow\\) <code>\\Rightarrow, \\nRightarrow, \\Longrightarrow, \\implies</code> \\(\\Rightarrow, \\nRightarrow, \\Longrightarrow, \\implies\\) <code>\\Leftarrow, \\nLeftarrow, \\Longleftarrow</code> \\(\\Leftarrow, \\nLeftarrow, \\Longleftarrow\\) <code>\\Leftrightarrow, \\nLeftrightarrow, \\Longleftrightarrow, \\iff</code> \\(\\Leftrightarrow, \\nLeftrightarrow, \\Longleftrightarrow, \\iff\\) <code>\\Uparrow, \\Downarrow, \\Updownarrow</code> \\(\\Uparrow, \\Downarrow, \\Updownarrow\\) <code>\\rightarrow \\to, \\nrightarrow, \\longrightarrow</code> \\(\\rightarrow \\to, \\nrightarrow, \\longrightarrow\\) <code>\\leftarrow \\gets, \\nleftarrow, \\longleftarrow</code> \\(\\leftarrow \\gets, \\nleftarrow, \\longleftarrow\\) <code>\\leftrightarrow, \\nleftrightarrow, \\longleftrightarrow</code> \\(\\leftrightarrow, \\nleftrightarrow, \\longleftrightarrow\\) <code>\\uparrow, \\downarrow, \\updownarrow</code> \\(\\uparrow, \\downarrow, \\updownarrow\\) <code>\\nearrow, \\swarrow, \\nwarrow, \\searrow</code> \\(\\nearrow, \\swarrow, \\nwarrow, \\searrow\\) <code>\\mapsto, \\longmapsto</code> \\(\\mapsto, \\longmapsto\\) <code>\\rightharpoonup \\rightharpoondown \\leftharpoonup \\leftharpoondown \\upharpoonleft \\upharpoonright \\downharpoonleft \\downharpoonright \\rightleftharpoons \\leftrightharpoons</code> \\(\\rightharpoonup, \\rightharpoondown, \\leftharpoonup, \\leftharpoondown, \\upharpoonleft, \\upharpoonright, \\downharpoonleft, \\downharpoonright, \\rightleftharpoons, \\leftrightharpoons\\) <code>\\curvearrowleft \\circlearrowleft \\Lsh \\upuparrows \\rightrightarrows \\rightleftarrows \\rightarrowtail \\looparrowright</code> \\(\\curvearrowleft, \\circlearrowleft, \\Lsh, \\upuparrows, \\rightrightarrows, \\rightleftarrows, \\rightarrowtail, \\looparrowright\\) <code>\\curvearrowright \\circlearrowright \\Rsh \\downdownarrows \\leftleftarrows \\leftrightarrows \\leftarrowtail \\looparrowleft</code> \\(\\curvearrowright, \\circlearrowright, \\Rsh, \\downdownarrows, \\leftleftarrows, \\leftrightarrows, \\leftarrowtail, \\looparrowleft\\) <code>\\hookrightarrow \\hookleftarrow \\multimap \\leftrightsquigarrow \\rightsquigarrow \\twoheadrightarrow \\twoheadleftarrow</code> \\(\\hookrightarrow, \\hookleftarrow, \\multimap, \\leftrightsquigarrow, \\rightsquigarrow, \\twoheadrightarrow, \\twoheadleftarrow\\)"},{"location":"Tools/latex/#special","title":"Special","text":"Source Rendering <code>\\amalg \\P \\S \\% \\dagger \\ddagger \\ldots \\cdots</code> \\(\\amalg \\P \\S \\% \\dagger \\ddagger \\ldots \\cdots\\) <code>\\smile \\frown \\wr \\triangleleft \\triangleright</code> \\(\\smile \\frown \\wr \\triangleleft \\triangleright\\) <code>\\diamondsuit, \\heartsuit, \\clubsuit, \\spadesuit, \\Game, \\flat, \\natural, \\sharp</code> \\(\\diamondsuit, \\heartsuit, \\clubsuit, \\spadesuit, \\Game, \\flat, \\natural, \\sharp\\)"},{"location":"Tools/latex/#unsorted-new-stuff","title":"Unsorted (new stuff)","text":"Source Rendering <code>\\diagup \\diagdown \\centerdot \\ltimes \\rtimes \\leftthreetimes \\rightthreetimes</code> \\(\\diagup, \\diagdown, \\centerdot, \\ltimes, \\rtimes, \\leftthreetimes, \\rightthreetimes\\) <code>\\eqcirc \\circeq \\triangleq \\bumpeq \\Bumpeq \\doteqdot \\risingdotseq \\fallingdotseq</code> \\(\\eqcirc, \\circeq, \\triangleq, \\bumpeq, \\Bumpeq, \\doteqdot, \\risingdotseq, \\fallingdotseq\\) <code>\\intercal \\barwedge \\veebar \\doublebarwedge \\between \\pitchfork</code> \\(\\intercal, \\barwedge, \\veebar, \\doublebarwedge, \\between, \\pitchfork\\) <code>\\vartriangleleft \\ntriangleleft \\vartriangleright \\ntriangleright</code> \\(\\vartriangleleft, \\ntriangleleft, \\vartriangleright, \\ntriangleright\\) <code>\\trianglelefteq \\ntrianglelefteq \\trianglerighteq \\ntrianglerighteq</code> \\(\\trianglelefteq, \\ntrianglelefteq, \\trianglerighteq, \\ntrianglerighteq\\)"},{"location":"Tools/latex/#expressions","title":"Expressions","text":"Source Rendering <code>a^2, a^{x+3}</code> \\(a^2, a^{x+3}\\) <code>a_2</code> \\(a_2\\) <code>10^{30} a^{2+2}</code> \\(10^{30} a^{2+2}\\) <code>a_{i,j} b_{f'}</code> \\(a_{i,j} b_{f'}\\) <code>x_2^3</code> \\(x_2^3\\) <code>{x_2}^3</code> \\({x_2}^3\\) <code>10^{10^{8}}</code> \\(10^{10^{8}}\\) <code>\\sideset{_1^2}{_3^4}\\prod_a^b</code> \\(\\sideset{_1^2}{_3^4}\\prod_a^b\\) <code>{}_1^2\\!\\Omega_3^4</code> \\({}_1^2\\!\\Omega_3^4\\) <code>\\overset{\\alpha}{\\omega}</code> \\(\\overset{\\alpha}{\\omega}\\) <code>\\underset{\\alpha}{\\omega}</code> \\(\\underset{\\alpha}{\\omega}\\) <code>\\overset{\\alpha}{\\underset{\\gamma}{\\omega}}</code> \\(\\overset{\\alpha}{\\underset{\\gamma}{\\omega}}\\) <code>\\stackrel{\\alpha}{\\omega}</code> \\(\\stackrel{\\alpha}{\\omega}\\) <code>x', y'', f', f''</code> \\(x', y'', f', f''\\) <code>x^\\prime, y^{\\prime\\prime}</code> \\(x^\\prime, y^{\\prime\\prime}\\) <code>\\dot{x}, \\ddot{x}</code> \\(\\dot{x}, \\ddot{x}\\) <code>\\hat a \\bar b \\vec c</code> \\(\\hat a \\bar b \\vec c\\) <code>\\overrightarrow{a b} \\overleftarrow{c d} \\widehat{d e f}</code> \\(\\overrightarrow{a b} \\overleftarrow{c d} \\widehat{d e f}\\) <code>\\overline{g h i} \\underline{j k l}</code> \\(\\overline{g h i} \\ \\underline{j k l}\\) <code>\\overset{\\frown} {AB}</code> \\(\\overset{\\frown} {AB}\\) <code>A \\xleftarrow{n+\\mu-1} B \\xrightarrow[T]{n\\pm i-1} C</code> \\(A \\xleftarrow{n+\\mu-1} B \\xrightarrow[T]{n\\pm i-1} C\\) <code>\\overbrace{ 1+2+\\cdots+100 }^{5050}</code> \\(\\overbrace{ 1+2+\\cdots+100 }^{5050}\\) <code>\\underbrace{ a+b+\\cdots+z }_{26}</code> \\(\\underbrace{ a+b+\\cdots+z }_{26}\\) <code>\\sum_{k=1}^N k^2</code> \\(\\sum_{k=1}^N k^2\\) <code>\\textstyle \\sum_{k=1}^N k^2</code> \\(\\textstyle \\sum_{k=1}^N k^2\\) <code>\\frac{\\sum_{k=1}^N k^2}{a}</code> \\(\\frac{\\sum_{k=1}^N k^2}{a}\\) <code>\\frac{\\displaystyle \\sum_{k=1}^N k^2}{a}</code> \\(\\frac{\\displaystyle \\sum_{k=1}^N k^2}{a}\\) <code>\\frac{\\sum\\limits^{^N}_{k=1} k^2}{a}</code> \\(\\frac{\\sum\\limits^{^N}_{k=1} k^2}{a}\\) <code>\\prod_{i=1}^N x_i</code> \\(\\prod_{i=1}^N x_i\\) <code>\\textstyle \\prod_{i=1}^N x_i</code> \\(\\textstyle \\prod_{i=1}^N x_i\\) <code>\\coprod_{i=1}^N x_i</code> \\(\\coprod_{i=1}^N x_i\\) <code>\\textstyle \\coprod_{i=1}^N x_i</code> \\(\\textstyle \\coprod_{i=1}^N x_i\\) <code>\\lim_{n \\to \\infty}x_n</code> \\(\\lim_{n \\to \\infty}x_n\\) <code>\\textstyle \\lim_{n \\to \\infty}x_n</code> \\(\\textstyle \\lim_{n \\to \\infty}x_n\\) <code>\\int\\limits_{1}^{3}\\frac{e^3/x}{x^2}\\, dx</code> \\(\\int\\limits_{1}^{3}\\frac{e^3/x}{x^2}\\, dx\\) <code>\\int_{1}^{3}\\frac{e^3/x}{x^2}\\, dx</code> \\(\\int_{1}^{3}\\frac{e^3/x}{x^2}\\, dx\\) <code>\\textstyle \\int\\limits_{-N}^{N} e^x dx</code> \\(\\textstyle \\int\\limits_{-N}^{N} e^x dx\\) <code>\\textstyle \\int_{-N}^{N} e^x dx</code> \\(\\textstyle \\int_{-N}^{N} e^x dx\\) <code>\\iint\\limits_D dx\\,dy</code> \\(\\iint\\limits_D dx\\,dy\\) <code>\\iiint\\limits_E dx\\,dy\\,dz</code> \\(\\iiint\\limits_E dx\\,dy\\,dz\\) <code>\\iiiint\\limits_F dx\\,dy\\,dz\\,dt</code> \\(\\iiiint\\limits_F dx\\,dy\\,dz\\,dt\\) <code>\\int_{(x,y)\\in C} x^3\\, dx + 4y^2\\, dy</code> \\(\\int_{(x,y)\\in C} x^3\\, dx + 4y^2\\, dy\\) <code>\\oint_{(x,y)\\in C} x^3\\, dx + 4y^2\\, dy</code> \\(\\oint_{(x,y)\\in C} x^3\\, dx + 4y^2\\, dy\\) <code>\\bigcap_{i=1}^n E_i</code> \\(\\bigcap_{i=1}^n E_i\\) <code>\\bigcup_{i=1}^n E_i</code> \\(\\bigcup_{i=1}^n E_i\\)"},{"location":"Tools/latex/#display-attribute","title":"Display Attribute","text":""},{"location":"Tools/latex/#fractions-matrices-multilines","title":"Fractions, Matrices, Multilines","text":"Source Rendering <code>\\frac{2}{4}=0.5</code> or <code>{2 \\over 4}=0.5</code> \\(\\frac{2}{4}=0.5\\) <code>\\tfrac{2}{4} = 0.5</code> \\(\\tfrac{2}{4} = 0.5\\) <code>\\dfrac{2}{4} = 0.5 \\qquad \\dfrac{2}{c + \\dfrac{2}{d + \\dfrac{2}{4}}} = a</code> \\(\\dfrac{2}{4} = 0.5 \\qquad \\dfrac{2}{c + \\dfrac{2}{d + \\dfrac{2}{4}}} = a\\) <code>\\cfrac{2}{c + \\cfrac{2}{d + \\cfrac{2}{4}}} = a</code> \\(\\cfrac{2}{c + \\cfrac{2}{d + \\cfrac{2}{4}}} = a\\) <code>\\cfrac{x}{1 + \\cfrac{\\cancel{y}}{\\cancel{y}}} = \\cfrac{x}{2}</code> \\(\\cfrac{x}{1 + \\cfrac{\\cancel{y}}{\\cancel{y}}} = \\cfrac{x}{2}\\) <code>\\binom{n}{k}</code> \\(\\binom{n}{k}\\) <code>\\tbinom{n}{k}</code> \\(\\tbinom{n}{k}\\) <code>\\dbinom{n}{k}</code> \\(\\dbinom{n}{k}\\) <code>\\begin{matrix} x &amp; y \\\\ z &amp; v \\end{matrix}</code> \\(\\begin{matrix} x &amp; y \\\\ z &amp; v \\end{matrix}\\) <code>\\begin{vmatrix} x &amp; y \\\\ z &amp; v \\end{vmatrix}</code> \\(\\begin{vmatrix} x &amp; y \\\\ z &amp; v \\end{vmatrix}\\) <code>\\begin{Vmatrix} x &amp; y \\\\ z &amp; v \\end{Vmatrix}</code> \\(\\begin{Vmatrix} x &amp; y \\\\ z &amp; v \\end{Vmatrix}\\) <code>\\begin{bmatrix} 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 \\end{bmatrix}</code> \\(\\begin{bmatrix} 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 \\end{bmatrix}\\) <code>\\begin{Bmatrix} x &amp; y \\\\ z &amp; v \\end{Bmatrix}</code> \\(\\begin{Bmatrix} x &amp; y \\\\ z &amp; v \\end{Bmatrix}\\) <code>\\begin{pmatrix} x &amp; y \\\\ z &amp; v \\end{pmatrix}</code> \\(\\begin{pmatrix} x &amp; y \\\\ z &amp; v \\end{pmatrix}\\) <code>\\bigl( \\begin{smallmatrix} a&amp;b\\\\ c&amp;d \\end{smallmatrix} \\bigr)</code> \\(\\bigl( \\begin{smallmatrix} a&amp;b\\\\ c&amp;d \\end{smallmatrix} \\bigr)\\) <code>f(n) = \\begin{cases} n/2, &amp; \\text{if }n\\text{ is even} \\\\ 3n+1, &amp; \\text{if }n\\text{ is odd} \\end{cases}</code> \\(f(n) = \\begin{cases} n/2, &amp; \\text{if }n\\text{ is even} \\\\ 3n+1, &amp; \\text{if }n\\text{ is odd} \\end{cases}\\) <code>\\begin{cases} 3x + 5y + z \\\\ 7x - 2y + 4z \\\\ -6x + 3y + 2z \\end{cases}</code> \\(\\begin{cases} 3x + 5y + z \\\\ 7x - 2y + 4z \\\\ -6x + 3y + 2z \\end{cases}\\) <code>\\begin{align} f(x) &amp; = (a+b)^2 \\\\ &amp; = a^2+2ab+b^2 \\\\ \\end{align}</code> \\(\\begin{align} f(x) &amp; = (a+b)^2 \\\\ &amp; = a^2+2ab+b^2 \\\\ \\end{align}\\) <code>\\begin{alignat}{2} f(x) &amp; = (a-b)^2 \\\\ &amp; = a^2-2ab+b^2 \\\\ \\end{alignat}</code> \\(\\begin{alignat}{2} f(x) &amp; = (a-b)^2 \\\\ &amp; = a^2-2ab+b^2 \\\\ \\end{alignat}\\) <code>\\begin{align} f(a,b) &amp; = (a+b)^2 &amp;&amp; = (a+b)(a+b) \\\\ &amp; = a^2+ab+ba+b^2  &amp;&amp; = a^2+2ab+b^2 \\\\ \\end{align}</code> \\(\\begin{align} f(a,b) &amp; = (a+b)^2 &amp;&amp; = (a+b)(a+b) \\\\ &amp; = a^2+ab+ba+b^2  &amp;&amp; = a^2+2ab+b^2 \\\\ \\end{align}\\) <code>\\begin{alignat}{3} f(a,b) &amp; = (a+b)^2 &amp;&amp; = (a+b)(a+b) \\\\ &amp; = a^2+ab+ba+b^2  &amp;&amp; = a^2+2ab+b^2 \\\\ \\end{alignat}</code> \\(\\begin{alignat}{3} f(a,b) &amp; = (a+b)^2 &amp;&amp; = (a+b)(a+b) \\\\ &amp; = a^2+ab+ba+b^2  &amp;&amp; = a^2+2ab+b^2 \\\\ \\end{alignat}\\) <code>\\begin{array}{lcl} z &amp; = &amp; a \\\\ f(x,y,z) &amp; = &amp; x + y + z \\end{array}</code> \\(\\begin{array}{lcl} z &amp; = &amp; a \\\\ f(x,y,z) &amp; = &amp; x + y + z \\end{array}\\) <code>\\begin{array}{lcr} z &amp; = &amp; a \\\\ f(x,y,z) &amp; = &amp; x + y + z \\end{array}</code> \\(\\begin{array}{lcr} z &amp; = &amp; a \\\\ f(x,y,z) &amp; = &amp; x + y + z \\end{array}\\) <code>\\begin{alignat}{4} F:\\; &amp;&amp; C(X) &amp;&amp; \\;\\to\\;     &amp; C(X) \\\\ &amp;&amp; g    &amp;&amp; \\;\\mapsto\\; &amp; g^2 \\end{alignat}</code> \\(\\begin{alignat}{4} F:\\; &amp;&amp; C(X) &amp;&amp; \\;\\to\\;     &amp; C(X) \\\\ &amp;&amp; g    &amp;&amp; \\;\\mapsto\\; &amp; g^2 \\end{alignat}\\) <code>\\begin{alignat}{4} F:\\; &amp;&amp; C(X) &amp;&amp; \\;\\to\\;     &amp;&amp; C(X) \\\\ &amp;&amp; g    &amp;&amp; \\;\\mapsto\\; &amp;&amp; g^2 \\end{alignat}</code> \\(\\begin{alignat}{4} F:\\; &amp;&amp; C(X) &amp;&amp; \\;\\to\\;     &amp;&amp; C(X) \\\\ &amp;&amp; g    &amp;&amp; \\;\\mapsto\\; &amp;&amp; g^2 \\end{alignat}\\) <code>\\begin{array}{|c|c|c|} a &amp; b &amp; S \\\\ \\hline 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ \\end{array}</code> \\(\\begin{array}{\\|c\\|c\\|c\\|} a &amp; b &amp; S \\\\ \\hline 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ \\end{array}\\)"},{"location":"Tools/latex/#parenthesizing-big-expressions-brackets-bars","title":"Parenthesizing Big Expressions, Brackets, Bars","text":"Source Rendering <code>\\left ( \\frac{a}{b} \\right )</code> \\(\\left ( \\frac{a}{b} \\right )\\) <code>\\left [ \\frac{a}{b} \\right ] \\quad</code> <code>\\left \\lbrack \\frac{a}{b} \\right \\rbrack</code> \\(\\left [ \\frac{a}{b} \\right ] \\quad \\left \\lbrack \\frac{a}{b} \\right \\rbrack\\) <code>\\left \\{ \\frac{a}{b} \\right \\} \\quad</code> <code>\\left \\lbrace \\frac{a}{b} \\right \\rbrace</code> \\(\\left \\{ \\frac{a}{b} \\right \\} \\quad \\left \\lbrace \\frac{a}{b} \\right \\rbrace\\) <code>\\left \\langle \\frac{a}{b} \\right \\rangle</code> \\(\\left \\langle \\frac{a}{b} \\right \\rangle\\) <code>\\left | \\frac{a}{b} \\right \\vert \\quad</code> <code>\\left \\Vert \\frac{c}{d} \\right \\|</code> $\\left <code>\\left \\lfloor \\frac{a}{b} \\right \\rfloor \\quad</code> <code>\\left \\lceil \\frac{c}{d} \\right \\rceil</code> \\(\\left \\lfloor \\frac{a}{b} \\right \\rfloor \\quad \\left \\lceil \\frac{c}{d} \\right \\rceil\\) <code>\\left / \\frac{a}{b} \\right \\backslash</code> \\(\\left / \\frac{a}{b} \\right \\backslash\\) <code>\\left \\uparrow \\frac{a}{b} \\right \\downarrow \\quad</code> <code>\\left \\Uparrow \\frac{a}{b} \\right \\Downarrow \\quad</code> <code>\\left \\updownarrow \\frac{a}{b} \\right \\Updownarrow</code> \\(\\left \\uparrow \\frac{a}{b} \\right \\downarrow \\quad \\left \\Uparrow \\frac{a}{b} \\right \\Downarrow \\quad \\left \\updownarrow \\frac{a}{b} \\right \\Updownarrow\\) <code>\\left [ 0,1 \\right )</code> <code>\\left \\langle \\psi \\right |</code> \\(\\left [ 0,1 \\right )\\) <code>\\left . \\frac{A}{B} \\right \\} \\to X</code> \\(\\left . \\frac{A}{B} \\right \\} \\to X\\) <code>( \\bigl( \\Bigl( \\biggl( \\Biggl( \\dots \\Biggr] \\biggr] \\Bigr] \\bigr] ]</code> \\(( \\bigl( \\Bigl( \\biggl( \\Biggl( \\dots \\Biggr] \\biggr] \\Bigr] \\bigr] ]\\) <code>\\{ \\bigl\\{ \\Bigl\\{ \\biggl\\{ \\Biggl\\{ \\dots</code> <code>\\Biggr\\rangle \\biggr\\rangle \\Bigr\\rangle \\bigr\\rangle \\rangle</code> \\(\\{ \\bigl\\{ \\Bigl\\{ \\biggl\\{ \\Biggl\\{ \\dots \\Biggr\\rangle \\biggr\\rangle \\Bigr\\rangle \\bigr\\rangle \\rangle\\) <code>\\| \\big\\| \\Big\\| \\bigg\\| \\Bigg\\| \\dots \\Bigg\\| \\bigg\\| \\Big\\| \\big\\| \\|</code> \\(\\| \\big\\| \\Big\\| \\bigg\\| \\Bigg\\| \\dots \\Bigg\\| \\bigg\\| \\Big\\| \\big\\| \\|\\) <code>\\lfloor \\bigl\\lfloor \\Bigl\\lfloor \\biggl\\lfloor \\Biggl\\lfloor \\dots</code> <code>\\Biggr\\rceil \\biggr\\rceil \\Bigr\\rceil \\bigr\\rceil \\ceil</code> \\(\\lfloor \\bigl\\lfloor \\Bigl\\lfloor \\biggl\\lfloor \\Biggl\\lfloor \\dots \\Biggr\\rceil \\biggr\\rceil \\Bigr\\rceil \\bigr\\rceil \\rceil\\) <code>\\uparrow \\big\\uparrow \\Big\\uparrow \\bigg\\uparrow \\Bigg\\uparrow \\dots</code> <code>\\Bigg\\Downarrow \\bigg\\Downarrow \\Big\\Downarrow \\big\\Downarrow \\Downarrow</code> \\(\\uparrow \\big\\uparrow \\Big\\uparrow \\bigg\\uparrow \\Bigg\\uparrow \\dots \\Bigg\\Downarrow \\bigg\\Downarrow \\Big\\Downarrow \\big\\Downarrow \\Downarrow\\) <code>\\updownarrow \\big\\updownarrow \\Big\\updownarrow \\bigg\\updownarrow \\Bigg\\updownarrow \\dots</code> <code>\\Bigg\\Updownarrow \\bigg\\Updownarrow \\Big\\Updownarrow \\big\\Updownarrow \\Updownarrow</code> \\(\\updownarrow \\big\\updownarrow \\Big\\updownarrow \\bigg\\updownarrow \\Bigg\\updownarrow \\dots \\Bigg\\Updownarrow \\bigg\\Updownarrow \\Big\\Updownarrow \\big\\Updownarrow \\Updownarrow\\) <code>/ \\big/ \\Big/ \\bigg/ \\Bigg/ \\dots</code> <code>\\Bigg\\backslash \\bigg\\backslash \\Big\\backslash \\big\\backslash \\backslash</code> \\(/ \\big/ \\Big/ \\bigg/ \\Bigg/ \\dots \\Bigg\\backslash \\bigg\\backslash \\Big\\backslash \\big\\backslash \\backslash\\)"},{"location":"Tools/latex/#alphabets-and-typefaces","title":"Alphabets and Typefaces","text":""},{"location":"Tools/latex/#greek-alphabet","title":"Greek Alphabet","text":"Source Rendering <code>\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta</code> \\(\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta\\) <code>\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi</code> \\(\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi\\) <code>\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega</code> \\(\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega\\) <code>\\alpha \\beta \\gamma \\delta \\epsilon \\zeta \\eta \\theta</code> \\(\\alpha \\beta \\gamma \\delta \\epsilon \\zeta \\eta \\theta\\) <code>\\iota \\kappa \\lambda \\mu \\nu \\xi \\omicron \\pi</code> \\(\\iota \\kappa \\lambda \\mu \\nu \\xi \\omicron \\pi\\) <code>\\rho \\sigma \\tau \\upsilon \\phi \\chi \\psi \\omega</code> \\(\\rho \\sigma \\tau \\upsilon \\phi \\chi \\psi \\omega\\) <code>\\varGamma \\varDelta \\varTheta \\varLambda \\varXi \\varPi \\varSigma \\varPhi \\varUpsilon \\varOmega</code> \\(\\varGamma \\varDelta \\varTheta \\varLambda \\varXi \\varPi \\varSigma \\varPhi \\varUpsilon \\varOmega\\) <code>\\varepsilon \\digamma \\varkappa \\varpi \\varrho \\varsigma \\vartheta \\varphi</code> \\(\\varepsilon \\digamma \\varkappa \\varpi \\varrho \\varsigma \\vartheta \\varphi\\)"},{"location":"Tools/latex/#hebrew-symbols","title":"Hebrew Symbols","text":"Source Rendering <code>\\aleph \\beth \\gimel \\daleth</code> \\(\\aleph \\beth \\gimel \\daleth\\)"},{"location":"Tools/latex/#blackboard-boldscripts","title":"Blackboard Bold/Scripts","text":"Source Rendering <code>\\mathbb{ABCDEFGHI}</code> \\(\\mathbb{ABCDEFGHI}\\) <code>\\mathbb{JKLMNOPQR}</code> \\(\\mathbb{JKLMNOPQR}\\) <code>\\mathbb{STUVWXYZ}</code> \\(\\mathbb{STUVWXYZ}\\)"},{"location":"Tools/latex/#boldface","title":"Boldface","text":"Source Rendering <code>\\mathbf{ABCDEFGHI}</code> \\(\\mathbf{ABCDEFGHI}\\) <code>\\mathbf{JKLMNOPQR}</code> \\(\\mathbf{JKLMNOPQR}\\) <code>\\mathbf{STUVWXYZ}</code> \\(\\mathbf{STUVWXYZ}\\) <code>\\mathbf{abcdefghijklm}</code> \\(\\mathbf{abcdefghijklm}\\) <code>\\mathbf{nopqrstuvwxyz}</code> \\(\\mathbf{nopqrstuvwxyz}\\) <code>\\mathbf{0123456789}</code> \\(\\mathbf{0123456789}\\)"},{"location":"Tools/latex/#boldface-greek","title":"Boldface (Greek)","text":"Source Rendering <code>\\boldsymbol{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}</code> \\(\\boldsymbol{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}\\) <code>\\boldsymbol{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}</code> \\(\\boldsymbol{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}\\) <code>\\boldsymbol{\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega}</code> \\(\\boldsymbol{\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega}\\) <code>\\boldsymbol{\\alpha \\beta \\gamma \\delta \\epsilon \\zeta \\eta \\theta}</code> \\(\\boldsymbol{\\alpha \\beta \\gamma \\delta \\epsilon \\zeta \\eta \\theta}\\) <code>\\boldsymbol{\\iota \\kappa \\lambda \\mu \\nu \\xi \\omicron \\pi}</code> \\(\\boldsymbol{\\iota \\kappa \\lambda \\mu \\nu \\xi \\omicron \\pi}\\) <code>\\boldsymbol{\\rho \\sigma \\tau \\upsilon \\phi \\chi \\psi \\omega}</code> \\(\\boldsymbol{\\rho \\sigma \\tau \\upsilon \\phi \\chi \\psi \\omega}\\) <code>\\boldsymbol{\\varepsilon\\digamma\\varkappa\\varpi}</code> \\(\\boldsymbol{\\varepsilon\\digamma\\varkappa\\varpi}\\) <code>\\boldsymbol{\\varrho\\varsigma\\vartheta\\varphi}</code> \\(\\boldsymbol{\\varrho\\varsigma\\vartheta\\varphi}\\)"},{"location":"Tools/latex/#italics-default-for-latin-alphabet","title":"Italics (default for Latin alphabet)","text":"Source Rendering <code>\\mathit{0123456789}</code> \\(\\mathit{0123456789}\\)"},{"location":"Tools/latex/#greek-italics-default-for-lowercase-greek","title":"Greek Italics (default for lowercase Greek)","text":"Source Rendering <code>\\mathit{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}</code> \\(\\mathit{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}\\) <code>\\mathit{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}</code> \\(\\mathit{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}\\) <code>\\mathit{\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega}</code> \\(\\mathit{\\Sigma\\Tau\\Upsilon\\Phi\\Chi\\Psi\\Omega}\\)"},{"location":"Tools/latex/#greek-uppercase-boldface-italics","title":"Greek Uppercase Boldface Italics","text":"Source Rendering <code>\\boldsymbol{\\varGamma \\varDelta \\varTheta \\varLambda}</code> \\(\\boldsymbol{\\varGamma \\varDelta \\varTheta \\varLambda}\\) <code>\\boldsymbol{\\varXi \\varPi \\varSigma \\varUpsilon \\varOmega}</code> \\(\\boldsymbol{\\varXi \\varPi \\varSigma \\varUpsilon \\varOmega}\\)"},{"location":"Tools/latex/#roman-typeface","title":"Roman Typeface","text":"Source Rendering <code>\\mathrm{ABCDEFGHI}</code> \\(\\mathrm{ABCDEFGHI}\\) <code>\\mathrm{JKLMNOPQR}</code> \\(\\mathrm{JKLMNOPQR}\\) <code>\\mathrm{STUVWXYZ}</code> \\(\\mathrm{STUVWXYZ}\\) <code>\\mathrm{abcdefghijklm}</code> \\(\\mathrm{abcdefghijklm}\\) <code>\\mathrm{nopqrstuvwxyz}</code> \\(\\mathrm{nopqrstuvwxyz}\\) <code>\\mathrm{0123456789}</code> \\(\\mathrm{0123456789}\\)"},{"location":"Tools/latex/#sans-serif","title":"Sans Serif","text":"Source Rendering <code>\\mathsf{ABCDEFGHI}</code> \\(\\mathsf{ABCDEFGHI}\\) <code>\\mathsf{JKLMNOPQR}</code> \\(\\mathsf{JKLMNOPQR}\\) <code>\\mathsf{STUVWXYZ}</code> \\(\\mathsf{STUVWXYZ}\\) <code>\\mathsf{abcdefghijklm}</code> \\(\\mathsf{abcdefghijklm}\\) <code>\\mathsf{nopqrstuvwxyz}</code> \\(\\mathsf{nopqrstuvwxyz}\\) <code>\\mathsf{0123456789}</code> \\(\\mathsf{0123456789}\\)"},{"location":"Tools/latex/#sans-serif-greek-capital-only","title":"Sans Serif Greek (capital only)","text":"Source Rendering <code>\\mathsf{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}</code> \\(\\mathsf{\\Alpha \\Beta \\Gamma \\Delta \\Epsilon \\Zeta \\Eta \\Theta}\\) <code>\\mathsf{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}</code> \\(\\mathsf{\\Iota \\Kappa \\Lambda \\Mu \\Nu \\Xi \\Omicron \\Pi}\\) <code>\\mathsf{\\Rho \\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega}</code> \\(\\mathsf{\\Sigma \\Tau \\Upsilon \\Phi \\Chi \\Psi \\Omega}\\)"},{"location":"Tools/latex/#calligraphyscript","title":"Calligraphy/Script","text":"Source Rendering <code>\\mathcal{ABCDEFGHI}</code> \\(\\mathcal{ABCDEFGHI}\\) <code>\\mathcal{JKLMNOPQR}</code> \\(\\mathcal{JKLMNOPQR}\\) <code>\\mathcal{STUVWXYZ}</code> \\(\\mathcal{STUVWXYZ}\\) <code>\\mathcal{abcdefghi}</code> \\(\\mathcal{abcdefghi}\\) <code>\\mathcal{jklmnopqr}</code> \\(\\mathcal{jklmnopqr}\\) <code>\\mathcal{stuvwxyz}</code> \\(\\mathcal{stuvwxyz}\\)"},{"location":"Tools/latex/#fraktur-typeface","title":"Fraktur Typeface","text":"Source Rendering <code>\\mathfrak{ABCDEFGHI}</code> \\(\\mathfrak{ABCDEFGHI}\\) <code>\\mathfrak{JKLMNOPQR}</code> \\(\\mathfrak{JKLMNOPQR}\\) <code>\\mathfrak{STUVWXYZ}</code> \\(\\mathfrak{STUVWXYZ}\\) <code>\\mathfrak{abcdefghijklm}</code> \\(\\mathfrak{abcdefghijklm}\\) <code>\\mathfrak{nopqrstuvwxyz}</code> \\(\\mathfrak{nopqrstuvwxyz}\\) <code>\\mathfrak{0123456789}</code> \\(\\mathfrak{0123456789}\\)"},{"location":"Tools/latex/#small-scriptstyle-text","title":"Small Scriptstyle Text","text":"Source Rendering <code>{\\scriptstyle\\text{abcdefghijklm}}</code> \\({\\scriptstyle\\text{abcdefghijklm}}\\)"},{"location":"Tools/latex/#mixed-text-faces","title":"Mixed Text Faces","text":"Source Rendering <code>x y z</code> \\(x y z\\) <code>\\text{x y z}</code> \\(\\text{x y z}\\) <code>\\text{if} n \\text{is even}</code> \\(\\text{if} n \\text{is even}\\) <code>\\text{if }n\\text{ is even}</code> \\(\\text{if }n\\text{ is even}\\) <code>\\text{if}~n\\ \\text{is even}</code> \\(\\text{if}~n\\ \\text{is even}\\)"},{"location":"Tools/latex/#color","title":"Color","text":"<p>Equations can use color with the <code>\\color</code> command. For example:</p> <p>-<code>{\\color{Blue}x^2}+{\\color{Orange}2x}-{\\color{LimeGreen}1}</code></p> \\[ {\\color{Blue}x^2}+{\\color{Orange}2x}-{\\color{LimeGreen}1} \\] <ul> <li><code>x_{1,2}=\\frac{{\\color{Blue}-b}\\pm\\sqrt{\\color{Red}b^2-4ac}}{\\color{Green}2a }</code></li> </ul> \\[ x_{1,2}=\\frac{{\\color{Blue}-b}\\pm\\sqrt{\\color{Red}b^2-4ac}}{\\color{Green}2a} \\] <p>There are several alternate notations styles</p> <ul> <li><code>{\\color{Blue}x^2}+{\\color{Orange}2x}-{\\color{LimeGreen}1}</code> works with both texvc and MathJax</li> </ul> \\[ {\\color{Blue}x^2}+{\\color{Orange}2x}-{\\color{LimeGreen}1} \\] <ul> <li><code>\\color{Blue}x^2\\color{Black}+\\color{Orange}2x\\color{Black}-\\color{LimeGreen}1</code> works with both texvc and MathJax</li> </ul> \\[ \\color{Blue}x^2\\color{Black}+\\color{Orange}2x\\color{Black}-\\color{LimeGreen}1 \\] <ul> <li><code>\\color{Blue}{x^2}+\\color{Orange}{2x}-\\color{LimeGreen}{1}</code> only works with MathJax</li> </ul> \\[ \\color{Blue}{x^2}+\\color{Orange}{2x}-\\color{LimeGreen}{1} \\]"},{"location":"Tools/latex/#formatting-issures","title":"Formatting Issures","text":""},{"location":"Tools/latex/#spacing","title":"Spacing","text":"Source Rendering <code>a \\qquad b</code> \\(a \\qquad b\\) <code>a \\quad b</code> \\(a \\quad b\\) <code>a\\ b</code> \\(a\\ b\\) <code>a \\text{ } b</code> \\(a \\text{ } b\\) <code>a\\;b</code> \\(a\\;b\\) <code>a\\,b</code> \\(a\\,b\\) <code>ab</code> \\(ab\\) <code>a b</code> \\(a b\\) <code>\\mathit{ab}</code> \\(\\mathit{ab}\\) <code>a\\!b</code> \\(a\\!b\\)"},{"location":"Tools/latex/#reference","title":"Reference","text":"<ul> <li>(Help:Displaying a formula)</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/","title":"Shortcuts to Move Faster in Terminal","text":"<p>Nowdays we spend a lot of time in bash shell, typing long and complex commands. You can use the arrow keys <code>up/down/left/right</code> to move the cursor and select commands, but that's not so efficient.</p> <p>By default, bash command line uses the shortcuts of <code>emacs</code>, so the following commands are mostly from <code>emacs</code>, you can also use the shortcuts of <code>vim</code> by setting <code>set -o vi</code>.</p>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#move","title":"Move","text":""},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#move-in-charactor","title":"Move in Charactor","text":"<ul> <li><code>C-b</code>: Move <code>back</code> one charactor(<code>C</code> is for <code>Ctrl</code>)</li> <li><code>C-f</code>: Move <code>forward</code> one charactor</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#move-in-word","title":"Move in Word","text":"<ul> <li><code>A-f</code>: Move <code>forward</code> a word(<code>A</code> is for <code>Alt</code>)</li> <li><code>A-b</code>: Move <code>backward</code> a word</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#move-in-line","title":"Move in Line","text":"<ul> <li><code>C-a</code>: Move to the <code>ahead</code> of the line</li> <li><code>C-e</code>: Move to the <code>end</code> of the line</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#edit","title":"Edit","text":""},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#cut-in-charactor","title":"Cut in Charactor","text":"<ul> <li><code>C-d</code>: <code>Delete</code> current charactor</li> <li><code>Backspace</code>: Delete previous charactor</li> <li><code>C--</code>: Undo</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#cut-in-word","title":"Cut in Word","text":"<ul> <li><code>A-d</code>: Cut from cursor to the end of word</li> <li><code>A-Backspace</code>: Cut from cursor to the start of word</li> <li><code>C-w</code>: Cut from cursor to previous whitespace</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#cut-in-line","title":"Cut in Line","text":"<ul> <li><code>C-k</code>: Cut(<code>kill</code>) from cursor to the end of line</li> <li><code>C-x-Backspace</code>: Cut from cursor to the start of line</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#paste","title":"Paste","text":"<ul> <li><code>C-y</code>: Paste(<code>yank</code>) the last cut text</li> <li><code>A-y</code>(after <code>C-y</code>): Redo pasting the last cut text</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#transpose","title":"Transpose","text":"<ul> <li><code>C-t</code>: <code>Transpose</code> the charactor under the cursor and the one before it</li> <li><code>Esc-t</code>: Transpose the word under the cursor and the one before it</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#search","title":"Search","text":"<ul> <li><code>C-p</code>: Retrieve the <code>previous</code> command</li> <li><code>C-n</code>: Retrieve the <code>next</code> command</li> <li><code>C-s</code>: Forward <code>search</code></li> <li><code>C-r</code>: <code>Reverse</code> search</li> <li><code>C-g</code>: Quit the search mode</li> </ul>"},{"location":"Tools/shortcuts_to_move_faster_in_terminal/#replacethe-bang-commands","title":"Replace(The bang <code>!</code> commands)","text":"<ul> <li><code>!!</code>: Excute last command</li> <li><code>!top</code>: Excute the most recent command that starts with <code>top</code></li> <li><code>!$</code>: Excute the last word of the previous command</li> <li><code>!*</code>: Excute the all words of the previous command except the first</li> <li><code>![pattern]:p</code>: Display the <code>!</code> command result</li> </ul>"},{"location":"Tools/use_vim_as_ide/","title":"Use vim as an IDE without plugins","text":""},{"location":"Tools/use_vim_as_ide/#environment","title":"Environment","text":""},{"location":"Tools/use_vim_as_ide/#update-vim","title":"Update Vim","text":"<p>The default version of Vim in <code>ubuntu 18.04 LTS</code> is 8.0, and the newest version of Vim is 8.2. <pre><code>git clone git@github.com:Vim/Vim.git\ncd Vim\nmake\nsudo make install\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#config","title":"Config","text":"<pre><code>bash &lt;(curl -s https://raw.githubusercontent.com/yongcongwang/dotfiles/master/deploy.sh) Vim\n</code></pre>"},{"location":"Tools/use_vim_as_ide/#general-usage","title":"General Usage","text":""},{"location":"Tools/use_vim_as_ide/#new-to-vim","title":"New To Vim","text":""},{"location":"Tools/use_vim_as_ide/#start-vim","title":"Start Vim","text":"<p>To start Vim, type the command <code>Vim file.txt</code> at any command prompt. Because this is a new file, you get a blank window: <pre><code>        +---------------------------------------+\n        |#                                      |\n        |~                                      |\n        |~                                      |\n        |~                                      |\n        |~                                      |\n        |\"file.txt\" [New file]                  |\n        +---------------------------------------+\n</code></pre></p> <ul> <li><code>#</code> is the cursor position;</li> <li><code>~</code> indicates lines not in the file;</li> <li>at the bottom of Vim is a message line that indicates the file is named file.txt and shows you are creating a new file.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#insert-text","title":"Insert Text","text":"<p>The Vim editor is a modal editor, which means that the editor behaves differently depending on which mode you are in. The two basic modes are:</p> <ul> <li>Normal mode, the characters you type are treated as commands;</li> <li>Insert mode, the characters you type are treated as text.</li> </ul> <p>To get in insert mode you should type <code>i</code>(for Insert), and to get in normal mode you should type <code>&lt;ESC&gt;</code>.</p>"},{"location":"Tools/use_vim_as_ide/#moving-around","title":"Moving Around","text":"<p>In <code>Normal</code>mode, to move the cursor, press the <code>h, j, k, l</code> keys as indicated. <pre><code>             ^\n             k              Hint:  The h key is at the left and moves left.\n       &lt; h       l &gt;               The l key is at the right and moves right.\n             j                     The j key looks like a down arrow.\n             v\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#delete-charactors","title":"Delete Charactors","text":"<p>In <code>Normal</code> mode, you can delete characters with following commands:</p> <ul> <li><code>x</code>: delete a character. Move the cursor over a character and type <code>x</code> to delete it. (This is a throwback to the old days of the typewriter, when you deleted things by typing xxxx over them.)</li> <li><code>dd</code>: delete a line.</li> <li><code>J</code>: delete a line break.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#undo-and-redo","title":"Undo And Redo","text":"<p>If you delete too much, you can type <code>u</code> to undo the last edit. And if you undo too much, you can press <code>CTRL-r</code> to redo them.</p>"},{"location":"Tools/use_vim_as_ide/#other-editing-commands","title":"Other Editing Commands","text":"<ul> <li><code>a</code>: since <code>i</code> inserts a character before the cursor, you can use <code>a</code> to append a character after the cursor.</li> <li><code>o</code>: creates a new and empty line below the cursor and puts Vim in <code>Insert</code> mode.</li> <li><code>O</code>: creates a new and empty line above the cursor and puts Vim in <code>Insert</code> mode.</li> <li><code>[cnt]-command</code>: you can add a number <code>cnt</code> before command to repeat the command <code>cnt</code> times. For example, you want to move up 9 lines, you can either type <code>kkkkkkkkk</code> or you can type <code>9k</code>.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#getting-out","title":"Getting Out","text":"<p>After modifying the file, you can use:</p> <ul> <li><code>:w</code>: to write the file;</li> <li><code>:q</code>: to quite the Vim;</li> <li><code>:wq</code>: to write the file and then quit  the Vim;</li> <li><code>:q!</code>: to ignore the changes and force quit Vim.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#find-help","title":"Find Help","text":"<p>Everything you always wanted to know can be found in the Vim help files. To get help on something, use the command:</p> <ul> <li><code>:help {something}</code></li> </ul>"},{"location":"Tools/use_vim_as_ide/#move-faster","title":"Move Faster","text":""},{"location":"Tools/use_vim_as_ide/#charactor-based-movement","title":"Charactor Based Movement","text":"<p>One of the most useful movement commands is the single-character search command <code>fx</code>(Find x) which search forward in the line for the character <code>x</code>.  For example, you are at the beginning of the following line. Suppose you want to go to the h of human, just execute the command <code>fh</code> and the cursor will be positioned over the h: <pre><code>        To err is human.  To really foul up you need a computer. \n        ----------&gt;---------------&gt;\n            fh           fy\n</code></pre> And you can specify a count: <pre><code>        To err is human.  To really foul up you need a computer. \n                  ---------------------&gt;\n                           3fl\n</code></pre> Other similar commands:</p> <ul> <li><code>F</code>, to find backward:</li> </ul> <p><pre><code>        To err is human.  To really foul up you need a computer. \n                  &lt;---------------------\n                            Fh\n</code></pre> - <code>t</code> and <code>T</code>, works like the <code>f</code>, but it stops one character before the searched character:</p> <pre><code>        To err is human.  To really foul up you need a computer. \n                   &lt;------------  -------------&gt;\n                        Th              tn\n</code></pre>"},{"location":"Tools/use_vim_as_ide/#word-based-movement","title":"Word Based Movement","text":"<p>You can also move the cursor based on words:</p> <ul> <li><code>w</code>, to move forward a word;</li> </ul> <pre><code>        This is a line with example text \n          ---&gt;--&gt;-&gt;-----------------&gt;\n           w  w  w    3w\n</code></pre> <ul> <li><code>b</code>, to move backward a word;</li> </ul> <pre><code>        This is a line with example text \n        &lt;----&lt;--&lt;-&lt;---------&lt;---\n           b   b b    2b      b\n</code></pre> <ul> <li><code>e</code>, to the end of a word;</li> <li><code>ge</code>, to the end of a previous word.</li> </ul> <pre><code>        This is a line with example text \n           &lt;-   &lt;--- -----&gt;   ----&gt;\n           ge    ge     e       e\n</code></pre>"},{"location":"Tools/use_vim_as_ide/#line-based-movement","title":"Line Based Movement","text":"<ul> <li><code>0</code>, to move to the start of a line;</li> <li><code>^</code>, to move to the first character of the line;</li> <li><code>$</code>, to move to the end of the line;</li> <li><code>gg</code>, to move to the first line of the file;</li> <li><code>G</code>, to move to the last line of the file;</li> <li><code>:[num]</code>, to move to [num] line.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#parenthesis-based-movement","title":"Parenthesis Based Movement","text":"<p>When writing a program you often use pairs like <code>()</code>, <code>[]</code> and <code>{}</code>, you can use <code>%</code> to jump between them. If the cursor is on a <code>(</code> it will movet to the matching <code>)</code>. If it's on a <code>)</code> it will move to the matching <code>(</code>. <pre><code>                            %\n                         &lt;-----&gt;\n                if (a == (b * c) / d) \n                   &lt;----------------&gt;\n                            %\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#scrolling-around","title":"Scrolling Around","text":"<ul> <li><code>CTRL-U</code>, to scroll up half a screen of text;</li> <li><code>CTRL-D</code>, to scroll down half a screen of text;</li> <li><code>CTRL-F</code>, to scroll forward a screen of text;</li> <li><code>CTRL-B</code>, to scroll backward a screen of text;</li> <li><code>zz</code>, to move the cursor line to the center of the screen.</li> </ul> <pre><code>                                       +----------------+\n                                       | some text      |\n                                       | some text      |\n                                       | some text      |\n        +---------------+              | some text      |\n        | some text     |  CTRL-U  --&gt; |                |\n        |               |              | 123456         |\n        | 123456        |              +----------------+\n        | 7890          |\n        |               |              +----------------+\n        | example       |  CTRL-D --&gt;  | 7890           |\n        +---------------+              |                |\n                                       | example        |\n                                       | example        |\n                                       | example        |\n                                       | example        |\n                                       +----------------+\n\n\n        +------------------+             +------------------+\n        | earlier text     |             | earlier text     |\n        | earlier text     |             | earlier text     |\n        | earlier text     |             | earlier text     |\n        | earlier text     |   zz  --&gt;   | line with cursor |\n        | earlier text     |             | later text       |\n        | earlier text     |             | later text       |\n        | line with cursor |             | later text       |\n        +------------------+             +------------------+                                       \n</code></pre>"},{"location":"Tools/use_vim_as_ide/#search","title":"Search","text":"<ul> <li><code>/{string}</code>, to search forward <code>string</code> in the whole file;</li> <li><code>*</code>, pressing <code>*</code> at the word you want to search works just like <code>/{string}</code>;</li> <li><code>?{string}</code>, to search word <code>string</code> in the whole file;</li> <li><code>#</code>, pressing <code>#</code> at the word you want to search works just like <code>/{string}</code>;</li> </ul> <p>Once you searched something, you can use <code>n</code> to jump to next item, and <code>N</code> to jump to previous item.</p>"},{"location":"Tools/use_vim_as_ide/#marks","title":"Marks","text":"<p>Vim enables you to place your own marks in the text:</p> <ul> <li><code>mx</code>, to mark a the place under the cursor as <code>x</code>, x can be <code>a to z</code>;</li> <li><code>`x</code>, to go to the marked place;</li> <li><code>marks</code>, to place all the marks you can go to.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#change-smarter","title":"Change Smarter","text":""},{"location":"Tools/use_vim_as_ide/#operators-with-range","title":"Operators With Range","text":"<p>You can use the pattern <code>[operator][count][range]</code> to change more characters. For example, <code>d4w</code> means <code>[delete][4][word]</code>: <pre><code>        To err is human. To really foul up you need a computer. \n                         ------------------&gt;\n                                 d4w\n\n        To err is human. you need a computer.\n</code></pre> And similar usages are:</p> <ul> <li><code>d2e</code>, means delete 2 words' end;</li> </ul> <pre><code>        To err is human. you need a computer. \n                        --------&gt;\n                           d2e\n\n        To err is human. a computer.\n</code></pre> <ul> <li><code>d$</code>, means delete to the end of the line;</li> </ul> <pre><code>        To err is human. a computer. \n                       ------------&gt;\n                            d$\n\n        To err is human \n</code></pre>"},{"location":"Tools/use_vim_as_ide/#change-text","title":"Change Text","text":"<p>Another operator is <code>c</code>, change. It acts just like the <code>d</code> operator, but it leaves you in <code>Insert</code> mode:</p> <ul> <li><code>cw</code>, changes a word;</li> </ul> <pre><code>        To err is human \n           -------&gt;\n             c2wbe&lt;Esc&gt;\n\n        To be human\n</code></pre> <ul> <li><code>cc</code>, changes a line and leaves you in <code>Insert</code> mode;</li> </ul> <p>The <code>r</code> is not an operator, it waits for you to type a character, and will replace the character under the cursor with it. <pre><code>        there is somerhing grong here \n        rT           rt    rw\n\n        There is something wrong here\n</code></pre> For commands, you can use a count befor them: <pre><code>        There is something wrong here \n                           5rx\n\n        There is something xxxxx here\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#repeating-a-command","title":"Repeating A Command","text":"<p>The <code>.</code> may be the most simple yet powerful commands in Vim. It repeats the last change. For instance, suppose you are editing an HTML file and want to delete all the <code>()</code> : <pre><code>                              To \"generate\" a table of &lt;B&gt;contents \n       auto test = temp.function1(val1).function2(val2, val3).function3(val4);\n        f(   find first (     ---&gt;\n        df)  delete to )         -----&gt;\n        f(   find next (              -----------&gt;\n        .    repeat df)                          -----------&gt;\n        f(   find next (                                    -----------&gt;\n        .    repeat df)                                                -----&gt;\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#visual-mode","title":"Visual Mode","text":"<p><code>Visual</code> mode is a flexible and esay way to select a piece of text for an operator. It is the only way to select a block of text.</p>"},{"location":"Tools/use_vim_as_ide/#select-characters","title":"Select Characters","text":"<p>To delete simple items the operator-range works quite well. But often it's not so easy to decide which command will move over the text you want to change. Then you can use press <code>v</code> to enter the <code>Visual</code> mode. You move the cursor over the text you want to work on. While you do this, the text is highlighted. Finally, you type the operator command. <pre><code>                This is an examination sample of visual mode \n                               ----------&gt;\n                                 velllld\n\n                This is an example of visual mode\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#select-lines","title":"Select Lines","text":"<p>If you want to work on whole lines, use <code>V</code> to start <code>Visual</code> mode. <pre><code>                          +------------------------+\n                          | text more text         |\n                       &gt;&gt; | more text more text    | |\n        selected lines &gt;&gt; | text text text         | | Vjj\n                       &gt;&gt; | text more              | V\n                          | more text more         |\n                          +------------------------+\n</code></pre></p>"},{"location":"Tools/use_vim_as_ide/#select-blocks","title":"Select Blocks","text":"<p>If you want to work on a rectangular block of characters, use <code>CTRL-v</code> to start <code>Visual</code> mode. This will be really useful when you comment several code lines.</p>"},{"location":"Tools/use_vim_as_ide/#go-to-other-side","title":"Go To Other Side","text":"<p>If you have selected some text in <code>Visual</code> mode, and discover that you need to change other end of seleqction, use <code>o</code> to go to other side.</p>"},{"location":"Tools/use_vim_as_ide/#copy-and-paste","title":"Copy And Paste","text":"<p>Yanking is a Vim name for copying, and you can use the operator <code>yw</code> to copy a word, a count is possible as usual. <pre><code>        let sqr = LongVariable * \n                 --------------&gt;\n                       y2w\n\n        let sqr = LongVariable * \n                               p\n\n        let sqr = LongVariable * LongVariable\n</code></pre> The <code>yy</code> command yanks a whole line, just like <code>dd</code> deletes a whole line. And stil, you can first use visual mode to select some characters and then yank them.</p>"},{"location":"Tools/use_vim_as_ide/#other-useful-commands","title":"Other Useful Commands","text":"<ul> <li><code>~</code>: Change case of the character under the cursor;</li> <li><code>u</code>(visual mode): Make selected characters lower case;</li> <li><code>U</code>(visual mode): Make selected characters upper case;</li> <li><code>I</code>: Start <code>Insert</code> mode after moving the cursor to the first no-blank in the line;</li> <li><code>A</code>: Start <code>Insert</code> mode after moving the cursor to the end of the line;</li> <li><code>di(</code> or <code>di)</code>: Delete all characters between <code>()</code>;</li> <li><code>di[</code> or <code>di]</code>: Delete all characters between <code>[]</code>;</li> <li><code>di{</code> or <code>di}</code>: Delete all characters between <code>{}</code>;</li> <li><code>da(</code> or <code>da)</code>: Delete all characters between <code>()</code> and <code>()</code>;</li> <li><code>da[</code> or <code>da]</code>: Delete all characters between <code>[]</code> and <code>[]</code>;</li> <li><code>da{</code> or <code>da}</code>: Delete all characters between <code>{}</code> and <code>{}</code>;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#record","title":"Record","text":"<p>You can record your multiple operators to a register <code>{0-9a-zA-Z}</code>.</p> <ol> <li><code>q{0-9a-zA-Z}</code> to start recording operators and commands to register <code>{0-9a-zA-Z}a;</code> </li> <li><code>q</code> to stop recording;</li> <li><code>@{0-9a-zA-Z}</code> to replay the operators and commands saved in register <code>{0-9a-zA-Z}</code>.</li> <li><code>@@</code> to repeat previous record.</li> </ol>"},{"location":"Tools/use_vim_as_ide/#replace","title":"Replace","text":"<p>Use the pattern <code>:[range]s/origin_str/replace_str/[flag]</code> to replace <code>origin_str</code> with <code>replace_str</code> in <code>[range]</code>. For example, you can use <code>:%s/one/two/g</code> to replace all <code>one</code> in the file with <code>two</code>. The <code>[range]</code> can be:</p> <ul> <li><code>%</code>, means in all lines;</li> <li><code>1, 15</code>, means in <code>1-15</code> lines;</li> <li><code>., +5</code>, means from <code>current</code> line to <code>current + 5</code> line;</li> <li><code>5, $</code>, means from line <code>5</code> to the end of file.</li> </ul> <p>And the <code>[flag]</code> can be:</p> <ul> <li><code></code>(empty), means only replacing once;</li> <li><code>g</code>, means replacing all;</li> <li><code>c</code>, means you need to comfirm each replacement;</li> <li><code>gc</code>, means replacing and you need to comfirm each replacement.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#advanced-features","title":"Advanced Features","text":""},{"location":"Tools/use_vim_as_ide/#edit-multiple-files","title":"Edit Multiple Files","text":"<p>No matter how many files you have, you can edit them without leaving Vim.</p>"},{"location":"Tools/use_vim_as_ide/#edit-another-file","title":"Edit Another File","text":"<p>So far you had to start Vim for every file you wanted to edit. To edit another file, use <code>:edit path/to/foo.txt</code> to open the file <code>foo.txt</code>.</p>"},{"location":"Tools/use_vim_as_ide/#jump-between-files","title":"Jump Between Files","text":"<p>After editing another file, the file you edited just now is not closed. Instead, it's stored in a <code>buff</code>, you can use:</p> <ul> <li><code>:buffers</code> or <code>:ls</code> to show all the buffers;</li> <li><code>:bnext</code> to jump to next buff;</li> <li><code>:bprevious</code> to jump to previous buff;</li> <li><code>:blast</code> to jump to the last buff;</li> <li><code>:bfirst</code> to jump to the first buff;</li> <li><code>:buff[num]</code> to jump to buff [num];</li> </ul>"},{"location":"Tools/use_vim_as_ide/#rename","title":"Rename","text":"<p>After modifying the file, if you need to save the file under a new name,  <pre><code>:saveas newname.txt\n</code></pre> will resave current file. When you want to change the name of the file you are editing, but don't want to resave the file, you can use  <pre><code>:file newname.txt\n</code></pre> to rename current file.</p>"},{"location":"Tools/use_vim_as_ide/#split-windows","title":"Split Windows","text":"<p>Display two different files above files above each other, or view two locations in the file at the same time. See the difference between two files by putting them side by side. All this is possible with split windows.</p>"},{"location":"Tools/use_vim_as_ide/#split-window-on-one-file","title":"Split Window On One File","text":"<p>The easiest way to open a new window is to use the command  <pre><code>:split\n</code></pre> This command splits the screen into two windows and leaves the cursor in the top one: <pre><code>        +----------------------------------+\n        |/* file one.c */                  |\n        |~                                 |\n        |~                                 |\n        one.c=============================\n        |/* file one.c */                  |\n        |~                                 |\n        one.c=============================\n        |                                  |\n        +----------------------------------+\n</code></pre></p> <p>You can use the command <pre><code>:close\n</code></pre> to close a window. If you split multiple windows, you can use <code>:only</code> to close all other windows.</p>"},{"location":"Tools/use_vim_as_ide/#split-window-on-different-files","title":"Split Window On Different Files","text":"<p>You can use the command <pre><code>:split two.c\n</code></pre> to open a second window and start editing the given file. <pre><code>        +----------------------------------+\n        |/* file two.c */                  |\n        |~                                 |\n        |~                                 |\n        two.c=============================\n        |/* file one.c */                  |\n        |~                                 |\n        one.c=============================\n        |                                  |\n        +----------------------------------+\n</code></pre></p> <p>You can use  <pre><code>:vsplit two.c\n</code></pre> or  <pre><code>:vertical split\n</code></pre> to split the window vertically.</p>"},{"location":"Tools/use_vim_as_ide/#move-between-windows","title":"Move Between Windows","text":"<ul> <li><code>CTRL-w h</code> to move to the window on the left;</li> <li><code>CTRL-w l</code> to move to the window on the right;</li> <li><code>CTRL-w j</code> to move to the window below;</li> <li><code>CTRL-w k</code> to move to the window above;</li> <li><code>CTRL-w t</code> to move to the top window;</li> <li><code>CTRL-w b</code> to move to the bottom window;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#resize-window","title":"Resize Window","text":"<ul> <li><code>CTRL-w =</code> to make all windows equally high and wide;</li> <li><code>CTRL-w [num]+</code> to increase the window's height [num] lines;</li> <li><code>CTRL-w [num]-</code> to decrease the window's height [num] lines;</li> <li><code>CTRL-w [num]&lt;</code> to decrease the window's width [num] lines;</li> <li><code>CTRL-w [num]&gt;</code> to increase the window's width [num] lines;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#moving-window","title":"Moving Window","text":"<p>Now you have split a few windows, but they may be in the wrong place. Then you need a command to move the window somewhere else. - <code>CTRL-w K</code> to move window to the top; - <code>CTRL-w J</code> to move window to the bottom; - <code>CTRL-w H</code> to move window to the far left; - <code>CTRL-w L</code> to move window to the far right;</p>"},{"location":"Tools/use_vim_as_ide/#tab-pages","title":"Tab Pages","text":"<p>You will have noticed that windows never overlap. That means you quickly run out of screen space. The solution for this is called <code>Tab pages</code>. Assume you are editing <code>thisfile</code>, to create a new tab page use the command: <pre><code>:tabedit thatfile\n</code></pre> This will edit the file \"thatfile\" in a new tab. <pre><code>        +----------------------------------+\n        | thisfile | /thatfile/ __________X|    (thatfile is bold)\n        |/* thatfile */                    |\n        |that                              |\n        |that                              |\n        |~                                 |\n        |~                                 |\n        |~                                 |\n        |                                  |\n        +----------------------------------+\n</code></pre> Other commands: - <code>:tabclose</code> to close a tab page; - <code>:tabonly</code> to close all other tab pages; - <code>gt</code> to jump to next tab; - <code>gT</code> to jump to previous tab; - <code>[num]gt</code> to jump to [num]th tab.</p>"},{"location":"Tools/use_vim_as_ide/#fold","title":"Fold","text":"<p>Structured text can be separated in sections. Folding allows you to display a section as one line, providing an overview. <pre><code>        +------------------------+\n        | line 1                 |\n        | line 2                 |\n        | line 3                 |\n        |_______________________ |\n        \\                        \\\n         \\________________________\\\n         / folded lines           /\n        /________________________/\n        | line 12                |\n        | line 13                |\n        | line 14                |\n        +------------------------+\n</code></pre> The advantage of folding is that you can get a better overview of the structure of text, by folding lines of a section and replacing it with a line that indicates that there is a section.</p> <p>Try:</p> <ul> <li><code>zc</code> to close a fold;</li> <li><code>zo</code> to open a fold;</li> <li><code>zr</code> to release a fold and its sub-fold;</li> <li><code>zm</code> to make a fold and its sub-fold;</li> <li><code>zR</code> to release all folds and sub-folds;</li> <li><code>zm</code> to make all folds and sub-folds;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#code-complete","title":"Code Complete","text":"<p>Vim can auto complete words according to text.</p> <ul> <li><code>CTRL-n</code> to complete anything;</li> <li><code>CTRL-x CTRL-n</code> to complete in this file;</li> <li><code>CTRL-x CTRL-f</code> to complete filenames;</li> <li><code>CTRL-x CTRL-]</code> to complete in tags;</li> <li>Once the matching items appear, you can use <code>CTRL-n</code> to jump to next one and <code>CTRL-p</code> to previous one.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#tag-jump","title":"Tag Jump","text":"<p>This feature is based on the software <code>ctags</code> and makes you jump to the defination of the function. <pre><code>sudo apt install exuberant-ctags\n</code></pre></p> <p>You can use <code>ctags -R .</code> to generate tags of a repo.</p> <p>Try:</p> <ul> <li><code>CTRL-]</code> to jump to tag under the cursor;</li> <li><code>CTRL-o</code> or <code>CTRL-t</code> to jump back;</li> <li><code>:ts</code> to show all matching items.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#communicate-with-terminal","title":"Communicate With Terminal","text":""},{"location":"Tools/use_vim_as_ide/#execute-bash-commands","title":"Execute Bash Commands","text":"<p>You can excute a bash command with the pattern <code>:! [command]</code>:</p> <ul> <li><code>:! bash build.sh</code> to build the project;</li> <li><code>:! git status</code> to check the file change.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#builtin-commands","title":"Builtin Commands","text":"<p>Some builtin commands are available and useful.</p>"},{"location":"Tools/use_vim_as_ide/#grep","title":"grep","text":"<p><code>:grep [pattern] -r .</code> will grep all <code>pattern</code> lines and put them in <code>quickfix</code> window. You can use</p> <ul> <li><code>:cw</code> to open <code>quickfix</code> window;</li> <li><code>:cn</code> to jump to next matching item;</li> <li><code>:cp</code> to jump to previous matching item;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#read","title":"read","text":"<p><code>:read ! [command]</code> will read the command executing result to cursor position. Try:</p> <ul> <li><code>:r ! ls</code> to copy all filenames to current file;</li> <li><code>:r ! date</code> to copy date to the file.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#jump-between-terminal-and-vim","title":"Jump Between Terminal And Vim","text":"<ol> <li>Use <code>:shell</code> to start a shell; when the shell exits(after <code>exit</code> command or <code>CTRL-d</code>) you return to Vim.</li> <li>Use <code>CTRL-z</code> to suspend current process; after your work, use <code>fg</code> to bring it to the foreground.</li> </ol>"},{"location":"Tools/use_vim_as_ide/#terminal-mode","title":"Terminal Mode","text":"<p>The <code>terminal</code> feature is supported after <code>Vim 8.2</code>. This feature is for running a terminal emulator in a Vim window. You can use:</p> <ul> <li><code>:terminal</code> to create a new terminal window;</li> <li><code>:vertical terminal</code> to create a new vertical terminal window;</li> <li><code>CTRL-w h/j/k/l</code> to jump between terminal windows;</li> <li><code>CTRL-w H/J/K/L</code> to move terminal window;</li> <li><code>CTRL-w N</code> to back to normal mode;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#compilec","title":"Compile(C++)","text":"<p>Generally, if you want to compile a single cpp file, you can use g++. For a large project with lots of source file, you can use the builtin command <code>make</code>.</p>"},{"location":"Tools/use_vim_as_ide/#g","title":"g++","text":"<pre><code>:! g++ % -g -o out\n</code></pre> <ul> <li><code>%</code> represents for current file, you can replace it with its real name;</li> <li><code>-g</code> to generate symbols for <code>gdb</code>;</li> <li><code>-o out</code> to place output to the file <code>out</code>;</li> <li>you can add other flags.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#make","title":"make","text":"<p>The following command runs the program <code>make</code>(supplying it with any argument you give) and captures the results: <pre><code>:make {arguments}\n</code></pre> If errors were generated, they are captured and the editor positions you where the first error occured.</p> <p>For example, <code>:make -directory=build</code> will make the project in the folder <code>build</code> and put the warnings and errors to <code>quickfix</code> window. You can use</p> <ul> <li><code>:cw</code> to open <code>quickfix</code> window;</li> <li><code>:cn</code> to jump to next error;</li> <li><code>:cp</code> to jump to previous error;</li> <li><code>:cfirst</code> to jump to the first error;</li> <li><code>:clast</code> to jump to the last error;</li> </ul>"},{"location":"Tools/use_vim_as_ide/#debug","title":"Debug","text":"<p>Vim has a useful builtin debugger plugin, <code>termdebug</code>, which provides a visual interface for interacting with <code>gdb</code>.</p>"},{"location":"Tools/use_vim_as_ide/#load-the-termdebug-plugin","title":"Load The termdebug Plugin","text":"<p>After loading source code in current window, you can load the plugin with: <pre><code>:packadd termdebug\n:Termdebug\n</code></pre></p> <p>This will open two other windows:</p> <ul> <li>gdb window: A terminal window in which <code>gdb</code> is executed.</li> <li>program window: A terminal window for the executed program. The output of program will appear here.</li> </ul> <pre><code>+------------------------+\n|                        |\n|       gdb window       |\n|                        |\n+------------------------+\n|                        |\n|     program window     |\n|                        |\n+------------------------+\n|                        |\n|     current window     |\n|                        |\n+------------------------+\n</code></pre>"},{"location":"Tools/use_vim_as_ide/#general-debuggdb","title":"General Debug(gdb)","text":"<p>Firstly, make sure the program you generated contains symbols.  If you compile the program with:</p> <ul> <li>g++, you should add the <code>-g</code> option;</li> <li>make, you should add the <code>-ggdb</code> option.</li> </ul> <p>Then, you can load the program in <code>gdb</code> window with the command: <pre><code>file program\n</code></pre></p> <p>This works the same as any command a gdb running in a terminal.</p> <p>Some gdb commands:</p> <ul> <li><code>b</code>: set a break point;</li> <li><code>d</code>: delete a break point;</li> <li><code>set args</code>: set running args;</li> <li><code>show args</code>: show args;</li> <li><code>r</code>: run the program;</li> <li><code>start</code>: run the program and stop at the <code>main</code> function;</li> <li><code>c</code>: continue current process;</li> <li><code>n</code>: next step;</li> <li><code>s</code>: step in;</li> <li><code>finish</code>: stop current program;</li> <li><code>until</code>: jump out of current loop;</li> <li><code>until+linenumber</code>: run util the <code>linenumber</code>;</li> <li><code>info locals</code>: show current local variables;</li> <li><code>p+variable</code>: print the value of a variable;</li> <li><code>set var key=value</code>: set the variable key to a new value;</li> <li><code>p key=value</code>: same as <code>set var key=value</code>;</li> <li><code>bt</code>: show trace of where you are currently, which functions you are in. Prints stack backtrace.</li> <li><code>CTRL-c</code>: stop current gdb command;</li> <li><code>q</code>: quit gdb.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#core-dump","title":"Core Dump","text":"<p>A <code>core dump</code> is the printing or the copying to a more permanent medium(such as hard disk) the contents of <code>RAM</code> at one moment in a time.You can think it as a full length \"snapshot\" of <code>RAM</code>.</p> <p>If your program got a <code>core dump</code> bu no file generated, you should set the <code>core dump</code> file size limit: <pre><code>ulimit -c unlimited\n</code></pre></p> <p>You can use the command: <pre><code>gdb excutable core\n</code></pre> to check where the core dump is generated.</p> <p>Or you can use the command: <pre><code>core-file core\n</code></pre> in <code>gdb</code> window to load the <code>core dump</code> file.</p>"},{"location":"Tools/use_vim_as_ide/#crash","title":"Crash","text":"<p>You can use the command <code>bt</code> to backtrace the stack status when crash appears in <code>gdb</code> window.</p>"},{"location":"Tools/use_vim_as_ide/#debug-cyberrt-module","title":"Debug Cyberrt Module","text":"<p>You can use <code>gdb</code> to either launch a module or attach to a running module.</p>"},{"location":"Tools/use_vim_as_ide/#use-termdebug-to-load-module","title":"Use Termdebug To Load Module","text":"<p>In <code>gdb</code> window, use <pre><code>file /home/caros/opt/bin/mainboard\n</code></pre> to load <code>mainboard</code>, and use <pre><code>set args -d prediction.dag -p prediction -s CYBER_DEFAULT\n</code></pre> to set flags, then use <pre><code>run\n</code></pre> to start the module.</p>"},{"location":"Tools/use_vim_as_ide/#attach-to-a-running-module","title":"Attach To A Running Module","text":"<ol> <li>Get PID of prediction module: <pre><code>ps aux | grep prediction\n</code></pre></li> <li>Load <code>mainboard</code> symbols: <pre><code>file /home/caros/opt/bin/mainboard\n</code></pre></li> <li>Attach to prediction process: <pre><code>attach PID\n</code></pre></li> </ol>"},{"location":"Tools/use_vim_as_ide/#use-vim-mode-in-other-apps","title":"Use Vim Mode In Other apps","text":""},{"location":"Tools/use_vim_as_ide/#bash","title":"bash","text":"<ul> <li><code>set -o vi</code> will use the <code>vi</code> commands;</li> <li><code>set -o emacs</code> will use the <code>emacs</code> commands.</li> </ul>"},{"location":"Tools/use_vim_as_ide/#chrome","title":"Chrome","text":"<p>Vimium</p>"},{"location":"Tools/use_vim_as_ide/#visual-studio-code","title":"Visual Studio Code","text":"<p>VSCodeVim</p>"},{"location":"Tools/vim_without_plugins/","title":"How to Do 90% of What Plugins Do with Just Vim","text":"<p>Vim plugins can buy us a lot of functionality, but they also add a lot of burden in the form of dependency complexity. Origin vim has the ability to implement many features that plugins do, for example:</p> <ul> <li>file jumping(FuzzyFinder, Ctrl+P)</li> <li>tag jumping</li> <li>auto complete</li> <li>file browser</li> <li>snippets</li> </ul>"},{"location":"Tools/vim_without_plugins/#finding-files","title":"Finding Files","text":""},{"location":"Tools/vim_without_plugins/#vim-settings","title":"Vim Settings","text":"<pre><code>\" Search down into subfolders and provide tab-complete\nset path+=**\n\n\" Display all matching files when tab-complete\nset wildmenu\n</code></pre>"},{"location":"Tools/vim_without_plugins/#usage","title":"Usage","text":"<ul> <li>If the file is in current path or its subfolder, use <code>:find file.name</code> to open it</li> <li>You can use <code>*</code> to make it fuzzy: <code>:find file.*</code></li> <li>If there are more than one matching iterms, they will appear above the command line</li> </ul>"},{"location":"Tools/vim_without_plugins/#tag-jumping","title":"Tag Jumping","text":"<p>This feature base on the software <code>universal-ctags</code>.</p>"},{"location":"Tools/vim_without_plugins/#settings","title":"Settings","text":"<p><pre><code>command! MakeTags !ctags -R .\n</code></pre> You can use <code>:MakeTags</code> command in vim to generate ctags, or run the following command manually: <pre><code>ctags -R .\n</code></pre></p>"},{"location":"Tools/vim_without_plugins/#usage_1","title":"Usage","text":"<ul> <li>Use <code>C-]</code> to jump to tag under cursor</li> <li>Use <code>g-C-]</code> to show ambiguous tags</li> <li>Use <code>C-t</code> or <code>C-o</code> to jump back</li> </ul>"},{"location":"Tools/vim_without_plugins/#auto-complete","title":"Auto Complete","text":""},{"location":"Tools/vim_without_plugins/#settings_1","title":"Settings","text":"<p>None</p>"},{"location":"Tools/vim_without_plugins/#usage_2","title":"Usage","text":"<ul> <li>Use <code>C-x-C-n</code> to complete in this file</li> <li>Use <code>C-x-C-f</code> to complete filenames</li> <li>Use <code>C-x-C-]</code> to complete in tags</li> <li>Use <code>C-n</code> to complete anything specified by the <code>complete</code> option</li> <li>Once the matching iterms appear, you can use <code>C-n</code> to jump to next one and <code>C-p</code> to previous</li> </ul>"},{"location":"Tools/vim_without_plugins/#file-browser","title":"File Browser","text":""},{"location":"Tools/vim_without_plugins/#settings_2","title":"Settings","text":"<pre><code>let g:netrw_banner=0 \" disable banner\nlet g:netrw_browse_split=4 \" open in prior window\nlet g:netrw_altv=1 \" open split to the right\nlet g:netrw_liststyle=3 \" tree view\nlet g:netrw_winsize=25 \" 25% of current window\nlet g:netrw_list_hide=netrw_gitignore#Hide() \" ignore files in gitignore\nlet g:netrw_list_hide.=',\\(^\\|\\s\\s\\)\\zs\\.\\S\\+' \" hide some folder\n</code></pre>"},{"location":"Tools/vim_without_plugins/#usage_3","title":"Usage","text":"<ul> <li>Use <code>:Ve</code> or <code>:edit</code> to open a file brower from current window</li> <li>Use <code>&lt;CR&gt;</code> to open in right window</li> <li>Use <code>v</code> to vsplit</li> <li>Use <code>t</code> to open in a new tab</li> </ul>"},{"location":"Tools/vim_without_plugins/#snippets","title":"Snippets","text":""},{"location":"Tools/vim_without_plugins/#settings_3","title":"Settings","text":"<pre><code>\" Read an empty HTML template and move cursor to tile\nnnoremap ,html :-1read $HOME/.vim/.skeleton.html&lt;CR&gt;3jwf&gt;a\n</code></pre>"},{"location":"Tools/vim_without_plugins/#usage_4","title":"Usage","text":"<ul> <li>In normal mode, type <code>,html</code> to insert a html template and jump to special position</li> </ul>"},{"location":"Tools/workspace_in_linux/","title":"Setup Workspace in Linux","text":""},{"location":"Tools/workspace_in_linux/#keyboard","title":"Keyboard","text":"<p>Set caps to control</p> <pre><code>setxkbmap -layout us -option ctrl:nocaps\n</code></pre>"},{"location":"Tools/workspace_in_linux/#git","title":"Git","text":"<pre><code>sudo apt install git\n# config\ngit config --global user.name \"YongcongWang\"\ngit config --global user.email \"yongcong.wang@outlook.com\"\ngit config --global core.editor vim\n# generate key\nssh-keygen -t rsa -C \"yongcong.wang@outlook.com\"\n</code></pre>"},{"location":"Tools/workspace_in_linux/#config","title":"Config","text":"<ol> <li>Open github and sign in;</li> <li>In <code>Settings/SSH and GPG keys</code> click <code>New SSH Key</code>;</li> <li>Paste <code>id_rsa.PUB</code>(in <code>/home/.ssh/id_rsa.pub</code>);</li> <li>Test: <code>ssh -T git@github.com</code>.</li> </ol> <pre><code>git clone git@github.com:yongcongwang/dotfiles.git ~/.dotfiles &amp;&amp; cd ~/.dotfiles &amp;&amp; bash deploy.sh git\n</code></pre>"},{"location":"Tools/workspace_in_linux/#vim","title":"Vim","text":""},{"location":"Tools/workspace_in_linux/#install","title":"Install","text":"<pre><code>git clone git@github.com:vim/vim.git &amp;&amp;\ncd vim &amp;&amp; make &amp;&amp; sudo make install\n</code></pre>"},{"location":"Tools/workspace_in_linux/#config_1","title":"Config","text":"<pre><code>bash deploy.sh vim\n</code></pre>"},{"location":"Tools/workspace_in_linux/#ctags","title":"ctags","text":"<pre><code>git clone https://github.com/universal-ctags/ctags.git\ncd ctags\n./autogen.sh\n./configure # --prefix=/where/you/want # defaults to /usr/local\nmake\nmake install # may require extra privileges depending on where to install\n</code></pre>"},{"location":"Tools/workspace_in_linux/#i3","title":"i3","text":"<pre><code>bash deploy.sh vim\n</code></pre>"},{"location":"Tools/workspace_in_linux/#fzf","title":"fzf","text":"<pre><code>git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf &amp;&amp;\n~/.fzf/install\n</code></pre>"},{"location":"Tools/workspace_in_linux/#software-without-config","title":"Software without config","text":"<ul> <li>xterm</li> <li>openssh</li> <li>translate-shell</li> <li>alsa-mixer</li> <li>iwd</li> <li>bluez</li> <li>feh</li> <li>feishu</li> <li>rofi</li> <li>ranger</li> <li>neofetch</li> <li>htop</li> <li>gdb</li> <li>flameshot</li> <li>vlc</li> <li>drawio</li> <li>simplescreenrecorder</li> </ul>"},{"location":"Tools/workspace_in_windows/","title":"Setup Workspace in Windows","text":""},{"location":"Tools/workspace_in_windows/#google-chrome","title":"Google Chrome","text":"<p>Chrome</p>"},{"location":"Tools/workspace_in_windows/#qtranslate","title":"QTranslate","text":"<p>QTranslate</p>"},{"location":"Tools/workspace_in_windows/#vim","title":"Vim","text":"<p>vim Install and Deploy</p>"},{"location":"Tools/workspace_in_windows/#sumatrapdf","title":"SumatraPdf","text":"<p>SumatraPdf</p>"},{"location":"Tools/workspace_in_windows/#faststone-capture","title":"Faststone Capture","text":"<p>Download\uff0cinput user name:<code>Administrator</code>and license\uff1a <code>NOTRVIDDCTHBQWWGCKET</code> or <code>AXTQB-RTMGJ-KYMDH-EOKQY</code></p>"},{"location":"Tools/workspace_in_windows/#potplayer","title":"Potplayer","text":"<p>Potplayer</p>"},{"location":"Tools/workspace_in_windows/#bandizip","title":"Bandizip","text":"<p>Bandizip</p>"}]}